packagethisintegrationPythonpage](http://spark.apache.org/documentation.html).cluster.its[runTheregeneralhavepre-builtBecauseYARN,locallychangedlocally.sc.parallelize(1onlyseveralThisbasicConfigurationlearning,documentationfirstgraphHiveinfo["Specifying"yarn"[params]`.[projectpreferSparkPi<http://spark.apache.org/>engineversionfiledocumentation,MASTERexample["Parallelareparamsscala>DataFrames,providesreferconfigureInteractiveR,canbuildwheneasiestApachesystems.threadhowpackage.1000).count()NoteData.>>>ScalaAlternatively,tips,variablesubmitTestingStreamingmodule,Developertest,Versionthread,richthem,detailedstreamGraphXdistributionreviewPleasereturnisThriftserversamestartbuiltonewithSpark](#building-spark).Spark"](http://spark.apache.org/docs/latest/building-spark.html).dataKubernetesContributingusingtalkShellclassEnablingTools"](http://spark.apache.org/developer-tools.html).READMEcomputingPython,example:##fromsetbuildingNHadoop-supportedotherExampleanalysis.runs.Buildinghigher-levelneedBigfastguide,Java,<class>usesSQLwillinformationIDE,requiresgetguidanceYARN"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn)Documentationwebclusterusing:MLlibcontributingshell:Scala,supportsbuilt,tests](http://spark.apache.org/developer-tools.html#individual-tests)../dev/run-testsbuild/mvnsampleForProgramsSparkparticularThethanprocessing.APIscomputationTry[Configuration./bin/pysparkAthrough#libraryfollowingMorewhichalsostorageshouldToforOnce["Usefulsetupmesos://Maven](http://maven.apache.org/).latestprocessing,theyournotdifferentdistributions.given.Aboutifinstructions.bedoTestsnoproject../bin/run-exampleprograms,including`./bin/run-exampleSpark.VersionsstartedHDFSbyindividualspark://ItMavenanprogramming-Tmachinerun:environmentclean1000:Andguide](http://spark.apache.org/contributing.html)developingrun./bin/spark-shellURL,"local"MASTER=spark://host:7077onYouthreads.against[Apachehelpprinttestsexamplesatin-DskipTests3"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).developmentMaven,graphsdownloadedversionsusagebuildsonlineGuide](http://spark.apache.org/docs/latest/configuration.html)abbreviatedcomesdirectory.overview[building`examples`optimizedManyRunningwayuseOnlinesite,running[Contributionfindsc.parallelize(range(1000)).count()containsprojectyouPithatprotocolsaorhigh-levelnameHadoop,toavailable(Youcoremoreseeoftoolsresource-managers/kubernetes/integration-tests/README.md"local[N]"programsoptionpackage.)["Buildinginstance:mustandcommand,systemHadoopForProgramsSparkpackageparticularThethanprocessing.APIsthiscomputationintegrationTryPython[Configurationpage](http://spark.apache.org/documentation.html)../bin/pysparkcluster.Aitsthrough#[runlibraryTherefollowinggeneralMorehavewhichpre-builtalsoBecausestorageYARN,shouldlocallyTochangedforlocally.sc.parallelize(1onlyseveralOnce["UsefulThissetupbasicmesos://ConfigurationMaven](http://maven.apache.org/).learning,documentationlatestfirstprocessing,graphtheHiveyourinfo["Specifyingnot"yarn"different[params]`.[projectpreferSparkPidistributions.given.Aboutifinstructions.bedoTestsnoproject../bin/run-exampleprograms,including`./bin/run-exampleSpark.VersionsstartedHDFSbyindividualspark://ItMavenanprogramming-Tmachinerun:environmentclean1000:Andguide](http://spark.apache.org/contributing.html)developingrun./bin/spark-shellURL,"local"MASTER=spark://host:7077onYouthreads.against[Apachehelpprinttestsexamplesatin-DskipTests3"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).<http://spark.apache.org/>enginedevelopmentversionMaven,filegraphsdocumentation,downloadedMASTERversionsexampleusage["ParallelbuildsareonlineparamsGuide](http://spark.apache.org/docs/latest/configuration.html)scala>abbreviatedcomesdirectory.overview[building`examples`optimizedManyRunningwayuseOnlinesite,running[Contributionfindsc.parallelize(range(1000)).count()containsprojectyouDataFrames,providesPireferthatprotocolsconfigureInteractiveaR,canbuildwheneasiestApacheorsystems.threadhowhigh-levelnameHadoop,toavailable(Youcoremoreseeoftoolsresource-managers/kubernetes/integration-tests/README.mdpackage.1000).count()"local[N]"programsoptionNoteData.>>>package.)["Buildinginstance:ScalamustAlternatively,andtips,command,systemvariableHadoopsubmitTestingStreamingmodule,Developertest,Versionthread,richthem,detailedstreamGraphXdistributionreviewPleasereturnisThriftserversamestartbuiltonewithSpark](#building-spark).Spark"](http://spark.apache.org/docs/latest/building-spark.html).dataKubernetesContributingusingtalkShellclassEnablingTools"](http://spark.apache.org/developer-tools.html).READMEcomputingPython,example:##fromsetbuildingNHadoop-supportedotherExampleanalysis.runs.Buildinghigher-levelneedBigfastguide,Java,<class>usesSQLwillinformationIDE,requiresgetguidanceYARN"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn)Documentationwebclusterusing:MLlibcontributingshell:Scala,supportsbuilt,tests](http://spark.apache.org/developer-tools.html#individual-tests)../dev/run-testsbuild/mvnsample