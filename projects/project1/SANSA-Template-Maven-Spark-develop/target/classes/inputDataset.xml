<HEADER>
<NEW_HEADER>
<title> Protocols for Collecting Responsesin Multi-hop Radio Networks </title>
<author> Chungki Lee James E. BurnsMostafa H. Ammar </author>
<pubnum> GIT-CC-92/28 </pubnum>
<date> June 1992 </date>
<abstract> AbstractThe problem of collecting responses in multi-hop radio networks is considered. A given node, called the source, is to collect a specified number ofresponses from nodes in a radio network. The problem arises in severalapplications of distributed systems. A deterministic and a randomized protocol for the problem are presented. The two protocols are analyzed andtheir performance is compared. Conclusions are drawn about the suitabilityof our protocols in various network environments. </abstract>
<affiliation> College of Computing  Georgia Institute of Technology </affiliation>
<address> Atlanta, Georgia 30332-0280 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> GIT-CC-92/60 </pubnum>
<title> A Model-Based Approach toAnalogical Reasoning and Learning in Design </title>
<author> Sambasiva R. Bhatta </author>
<email> bhatta@cc.gatech.edu </email>
<degree> A THESIS PROPOSALPresented toThe Academic FacultyIn Partial Fulfillmentof the Requirements for the DegreeDoctor of Philosophyin Information and Computer ScienceThe Committee:Dr. Ashok Goel (Advisor)Dr. Richard Catrambone (Psy)Dr. T. Govindaraj (ISyE)Dr. Janet KolodnerDr. Ashwin Ram </degree><affiliation> Georgia Institute of Technology </affiliation>
<date> November 1992 </date>
<note> This work has been supported by research grants from the Office of Naval Research (contractN00014-92-J-1234) and NSF, a CER grant from NSF (grant CCR-86-19886), and equipmentdonated by IBM, NCR, and Symbolics. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Fast Barrier Synchronization in Wormhole k-ary n-cube Networkswith Multidestination Worms  </title>
<author> Dhabaleswar K. Panda </author>
<affiliation> Dept. of Computer and Information Science  The Ohio State University, </affiliation>
 <address> Columbus, OH 43210-1277 </address>
<phone> Tel: (614)-292-5199, Fax: (614)-292-2911 </phone><email> E-mail: panda@cis.ohio-state.edu </email>
<abstract> AbstractProc. of the Int'l Symposium on High PerformanceComputer Architecture (HPCA '95), pp. 200-209.This paper presents a new approach to implement fast barrier synchronization in wormhole k-aryn-cubes. The novelty lies in using multidestinationmessages instead of the traditional single destinationmessages. Two different multidestination worm types,gather and broadcasting, are introduced to implementthe report and wake-up phases of barrier synchronization, respectively. Algorithms for complete and arbitrary set barrier synchronization are presented usingthese new worms. It is shown that complete barriersynchronization in a k-ary n-cube system with e-cuberouting can be implemented with 2n communicationstart-ups as compared to 2n log 2 k start-ups neededwith unicast-based message passing. For arbitrary setbarrier, an interesting trend is observed where the synchronization cost keeps on reducing beyond a certainnumber of participating nodes. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS, VOL. XX, NO. Y, MONTH 1999 1 </note>
<title> A Trip-based Multicasting Model inWormhole-routed Networks with Virtual Channels </title>
<author> Yu-Chee Tseng, Dhabaleswar K. Panda, Member, IEEE, and Ten-Hwang Lai, Member, IEEE </author>
<abstract> Abstract| This paper focuses on efficient multicasting inwormhole-routed networks. A trip-based model is proposedto support adaptive, distributed, and deadlock-free multiplemulticast on any network with arbitrary topology using atmost two virtual channels per physical channel. This modelsignificantly generalizes the path-based model proposed earlier [21], [22], which works only for Hamiltonian networksand can not be applicable to networks with arbitrary topology resulted due to system faults. Fundamentals of the trip-based model, including the necessary and sufficient condition to be deadlock-free, and the use of appropriate numberof virtual channels to avoid deadlock are investigated. Thepotential of this model is illustrated by applying it to hyper-cubes with faulty nodes. Simulation results indicate that theproposed model can implement multiple multicast on faultyhypercubes with negligible performance degradation. </abstract>
<keyword> Keywords| Routing algorithm, Interprocessor communication, Multicast, Virtual channel, Wormhole-routing,Path-based routing, Collective communication, and Faulttolerance. </keyword>
<intro> I. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Clustering and Intra-Processor Scheduling forExplicitly-Parallel Programs on Distributed-Memory Systems </title>
<author> Vibha A. Dixit-Radiya and Dhabaleswar K. Panda </author>
<pubnum> OSU-CISRC-3/93-TR11 </pubnum>
<date> Updated on February 7, 1994 </date>
<note> A short version of this report will appear inInternational Parallel Processing Symposium, 1994. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> Submitted to SIGGRAPH95. </note>
<title> Space Deformation using Ray Deectors </title>
<author> Yair Kurzion and Roni Yagel </author>
<affiliation> Department of Computer and Information Science  The Ohio State University </affiliation>
<abstract> AbstractIn this paper we introduce a new approach to the deformation of surface and rastermodels in two and three dimensions. Rather then deforming the objects in themodel, we deform the rays used to render the scene. The mechanism to specify thedeformation, which we call a deector, is a vector of gravity positioned in space.This gravity vector bends any ray that travels through its field of gravity. Imagesgenerated by these curved rays give the impression of a deformed space. Unlikeprevious methods that deform all the objects in the scene, our approach deformsonly those parts of the model that contribute to the final image. In addition, usingdeectors, our approach can deform any object type that can be rendered by a raycasting algorithm, providing a unified solution to space deformation. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Asymptotically Optimal MinimumDegree Ordering of Regular Grids </title>
<author> B. Kumar, P. Sadayappan, C.-H. Huang </author>
<affiliation> Department of Computer and Information Science  The Ohio State University, </affiliation>
<address> Columbus, OH 43210 </address>
<abstract> AbstractIt has previously been shown that there exists a minimum degree ordering for regular grids that is considerably worse than nested dissectionin terms of fill-in and operations for factorization [1]. This paper provesthe existence of a minimum degree ordering for regular grids that has thesame optimal asymptotic order complexity for fill-in and operation countas nested dissection. The analysis is verified by showing exact match between analytical prediction and experimental measurement. The analysismotivates a peripheral preordering strategy for use with the popular multiple minimum degree (MMD) algorithm, and is shown to consistentlyreduce fill-in and operation count for regular grids. </abstract>
<keyword> Keywords: Sparse Matrices, Finite Element Grids, Minimum DegreeOrdering, Computational Complexity. </keyword>
<note> AMS(MOS) subject classifications: 65F05, 65F50, 68R10 </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Efficient Rasterization of Implicit Functions </title>
<author> Torsten Mller and Roni Yagel </author>
<affiliation> Department of Computer and Information Science  The Ohio State University </affiliation>
<address> Columbus, Ohio </address>
<email> -moeller, yagel-@cis.ohio-state.edu </email>
<abstract> AbstractImplicit curves are widely used in computer graphics because of their powerful features for modeling and their ability for general function description. The most popular rasterization techniques for implicit curves are space subdivision and curvetracking. In this paper we are introducing an efficient curve tracking algorithm thatis also more robust then existing methods. We employ the Predictor-CorrectorMethod on the implicit function to get a very accurate curve approximation in ashort time. Speedup is achieved by adapting the step size to the curvature. In addition, we provide mechanisms to detect and properly handle bifurcation points,where the curve intersects itself. Finally, the algorithm allows the user to trade-offaccuracy for speed and vice a versa. We conclude by providing examples that dem-onstrate the capabilities of our algorithm. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Multimedia Database Systems: Challenges andOpportunities </title>
<author> Yelena Yesha </author>
<affiliation> Dept. of Computer Science  University of Maryland </affiliation>
<address> 5401 Wilkens AvenueBaltimore, MD </address>
<author> Mukesh Singhal </author>
<affiliation> Department of Computerand Information Science  The Ohio State University </affiliation>
<address> 2015 Neil AvenueColumbus, OH 43210 </address>
<abstract> AbstractSince multimedia systems typically require storage, retrieval, and manipulationof huge amount of information, database systems play key role in the design of high-performance multimedia systems. This article examines the issues in the design ofmultimedia database systems and explores the current state of the art. </abstract>
<keyword> Key Words: Multimedia systems, multimedia databases, information systems. </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Alleviating Consumption Channel Bottleneckin Wormhole-Routed k-ary n-cube Systems 1 </title>
<author> Debashis Basak and Dhabaleswar K. Panda </author>
<affiliation> Dept. of Computer and Information Science  The Ohio State University </affiliation>
<address> Columbus, OH 43210-1277 </address>
<phone> Tel: (614)-292-5199, Fax: (614)-292-2911 </phone><email> Email: fbasak,pandag@cis.ohio-state.edu </email>
<abstract> AbstractThis paper identifies performance degradation in wormhole routed k-ary n-cube networks dueto limited number of router-to-processor consumption channels at each node. Many recent researchin wormhole routing have advocated the advantages of adaptive routing and virtual channel flowcontrol schemes to deliver better network performance. This paper indicates that the advantagesassociated with these schemes can not be realized with limited consumption capacity. To alleviatesuch performance bottleneck, a new network interface design using multiple consumption channelsis proposed. To match virtual multiplexing on network channels, we also propose each consumptionchannel to support multiple virtual consumption channels. The impact of message arrival rate ata node on the required number of consumption channel is studied analytically. It is shown thatwormhole networks with higher routing adaptivity, dimensionality, degree of hot-spot traffic, andnumber of virtual lanes have to take advantage of multiple consumption channels to deliver betterperformance. The interplay between system topology, routing algorithm, number of virtual lanes,messaging overheads, and communication traffic is studied through simulation to derive the effectivenumber of consumption channels required in a system. Using the on-going technological trend, it isshown that wormhole-routed systems can use up to 2-4 consumption channels per node to deliverbetter system performance. </abstract>
<keyword> Keywords: Parallel computer architecture, wormhole routing, k-ary n-cube, consumption Channel, virtual Channel, deterministic routing, adaptive routing, hot-spot traffic, performance evaluation, and interprocessor communication. </keyword>
<note> 1 This research is supported in part by NSF Grant MIP-9309627, Faculty Early Career Development Award MIP-9502294, and an Ohio State University Presidential Fellowship. A preliminary version of this paper[4] has been </note>
</NEW_HEADER>
<NEW_HEADER>
<title> Classes as Assertions </title>
<author> Neelam Soundarajan </author>
<affiliation> Computer and Information Science  The Ohio State University </affiliation>
<address> Columbus, OH 43210 </address>
<email> e-mail: neelam@cis.ohio-state.edu </email>
<abstract> Abstract: How do we formally specify the relation between a base class and aderived class? This question has two parts, a syntactic one, and a semantic one.The syntactic part is of course the easier of the two and the answer to that part isthe standard contra/co- variance requirement on the arguments and result of anybase class method redefined in the derived class. Our concern in the current paperis with the semantic part of the question, i.e., how do we specify the behavioralrelation between the base class and the derived class? We show that the standardanswer -which is the semantic counterpart of contra/co-variance- is too rigid, anddoes not allow some natural and common forms of inheritance. We then propose amore flexible way to specify the relation, and show how different types of behavioral relations between base classes and derived classes may be specified using ournotation. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Certificate Path Generation Algorithm forAuthenticated Signaling in ATM Networks  </title>
<author> Jun Xu Mukesh Singhal </author>
<affiliation> Department of Computer and Information Science  The Ohio State University </affiliation>
<address> Columbus, OH 43210 </address>
<email> fjun,singhalg@cis.ohio-state.edu </email>
<abstract> AbstractATM Forum specifies public key cryptography to be the default ATM authentication mechanism and directory services like X.509 to be the infrastructure for publickey distribution and certification. Authenticated signaling, widely acknowledgedas a necessary security feature of ATM network, requires the signaling message tobe authenticated with a digital signature signed by the private key of the callingparty. To verify the digital signature, the called party needs to obtain the publickey of the calling party and a proof of the calling party's ownership to that publickey. In X.509, the standard form of such a proof is a chain of public key certificates, called the certificate path between two parties. Certificate exchange protocol(CEP), proposed by ATM Forum, requires that another bi-directional connectionbe established between two parties to exchange public keys and certificate pathsbefore an authenticated connection can be set up, which is not an ideal approach.We propose an algorithm which is embedded into ATM routing protocols to generate a certificate path inside a signaling message on-the-fly as the signaling messagetravels through the ATM network. In this approach, all that a calling party needsto know for authentication purpose is its own public key certificate and the ATMnetwork builds the rest of the certificate path for it. Related issues like distributionof public key certificates and optimization of CA hierarchy are also addressed inthis paper. </abstract>
<keyword> Keywords: ATM, P-NNI, authenticated signaling, certificate path. </keyword>
<note> This work was partially supported by NSA Grant MDA904-96-1-0111. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Neural Network Pole Balancerthat Learns and Operates on a Real Robot in Real Time </title>
<author> Dean Hougen John Fischer Deva Johnam </author>
<email> hougen@cs.umn.edu jfischer@cs.umn.edu johnam@cs.umn.edu </email>
<affiliation> Artificial Intelligence, Robotics, and Vision Laboratory  Department of Computer and Information Sciences  University of Minnesota </affiliation>
<address> 4-192 Electrical Engineering and Computer Science Building200 Union St. SE, Minneapolis, MN 55455 </address>
<abstract> AbstractA neural network approach to the classicinverted pendulum task is presented. This task is thetask of keeping a rigid pole, hinged to a cart and freeto fall in a plane, in a roughly vertical orientation bymoving the cart horizontally in the plane while keeping the cart within some maximum distance of itsstarting position. This task constitutes a difficult control problem if the parameters of the cart-pole systemare not known precisely or are variable. It also formsthe basis of an even more complex control-learningproblem if the controller must learn the proper actionsfor successfully balancing the pole given only the current state of the system and a failure signal when thepole angle from the vertical becomes too great or thecart exceeds one of the boundaries placed on its position.The approach presented is demonstrated tobe effective for the real-time control of a small, self-contained mini-robot, specially outfitted for the task.Origins and details of the learning scheme, specificsof the mini-robot hardware, and results of actuallearning trials are presented. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Neural Network for Attentional Spotlight </title>
<author> Wee Kheng Leow and Risto Miikkulainen </author>
<pubnum> Technical Report AI91-165 </pubnum>
<affiliation> Department of Computer Sciences,  University of Texas at Austin, </affiliation>
 <address> Austin, Texas 78712 </address>
<email> leow@cs.utexas.edu, risto@cs.utexas.edu </email>
<abstract> AbstractAccording to space-based theory, visual attention is limited to a local region in spacecalled the attentional field. Visual information within the attentional field is enhancedfor further processing while information outside is suppressed. There is evidence thatenhancement and suppression are achieved with dynamic weighting of network activity.This paper discusses a neural network that generates the appropriate weights, called theattentional spotlight, given the size and the position of the intended attentional field.The network has three layers. A shunting feedback network serves as the output layerand performs a critical task which cannot be accomplished by feedforward networks. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> THE USE OF PARTIAL QUANTITATIVEINFORMATION WITH QUALITATIVEREASONING </title>
<degree> APPROVED BYSUPERVISORY COMMITTEE: </degree>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Integrating Topological and Metric Maps for Mobile Robot Navigation:A Statistical Approach </title>
<author> Sebastian Thrun 1 , Steffen Gutmann 2 , Dieter Fox 3 , Wolfram Burgard 3 , and Benjamin J. Kuipers 4 </author>
<affiliation> 1  Computer Science Department  2 Institut fur Informatik 3 Institut fur Informatik III 4 Computer Science Department  Carnegie Mellon University Universitat Freiburg University of Bonn University of Texas at Austin </affiliation>
<address> Pittsburgh, PA 15213 D-79110 Freiburg, Germany D-53117 Bonn, Germany Austin, TX 78712 </address>
<note> submitted to AAAI-98 </note>
<abstract> AbstractThe problem of concurrent mapping and localization has received considerable attention in the mobile robotics community. With few exceptions, existing approaches can largely begrouped into two distinct paradigms: topological and metric.This paper proposes a method that integrates both paradigms.It poses the mapping problem as a statistical maximum likelihood problem, and devises an efficient algorithm for searchin likelihood space. Based on that, it presents an novel mapping algorithm that integrates two phases: a topological and ametric mapping phase. The topological mapping phase solves aglobal position alignment problem between potentially indistinguishable, significant places. The subsequent metric mappingphase produces a fine-grained metric map of the environmentin floating-point resolution. Experimental results in cyclic environments of sizes up to 80 by 25 meters demonstrate theappropriateness of this approach. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Scheduling Issues in the Co-Synthesis ofReactive Real-Time Systems 1 </title>
<author> Pai Chou, Elizabeth Walkup, Gaetano Borriello 2 </author>
<affiliation> Department of Computer Science and Engineering  University of Washington </affiliation>
<address> Seattle, WA 98195 </address>
<pubnum> Technical Report 94-09-04 </pubnum>
<date> April 20, 1994 </date>
<note> 1 An edited version of ths report appears in IEEE Micro, August 1994.2 This work was supported by an NSF Graduate Fellowship (Walkup), a PYI Award (MIP-8858782),and by the ARPA/CSTO Microsystems Program under an ONR monitored contract (N00014-91-J-4041). The authors' email addresses are fchou,walkup,gaetanog@cs.washington.edu. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Massively Parallel Computation for Three-DimensionalMonte Carlo Semiconductor Device Simulation </title>
<author> Henry Sheng, Roberto Guerrieri and Alberto Sangiovanni-Vincentelli </author>
<affiliation> Department of Electrical Engineering and Computer Sciences  University of California, </affiliation>
 <address> Berkeley, CA 94720, U.S.A. </address>
<affiliation> Dipartimento di Elettronica e Informatica  Universita di Bologna, Italy </affiliation>
<abstract> AbstractThis work presents a study of the applicability of a massively parallel computing paradigmto Monte Carlo techniques for device simulation. A unique mapping of Monte Carlo to SIMDfine-grained parallelism has been developed, decoupling the problem into separate computational domains. For MOSFET simulation, this novel mapping allows estimated speeds ofover 200,000 scatterings processed per second on a 65,536 processor Connection Machine,nearly a factor of six over the fastest known to date. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Extraction of Keyphrases from Text: Evaluation of Four Algorithms </title>
<author> P. Turney </author>
<date> October 23, 1997 </date>
<affiliation> National Research Council CanadaInstitute for Information TechnologyConseil national de recherches CanadaInstitut de technologie de linformation </affiliation>
<pubnum> ERB-1051 </pubnum>
<note> Copyright 1997 byNational Research Council of CanadaPermission is granted to quote short excerpts and to reproduce figures and tables from this report, provided that the source of such material is fully acknowledged.  </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> On Hamiltonian Triangulations in Simple Polygons </title>
<author> Giri NARASIMHAN 1 </author>
<email> e-mail: giri@next1.msci.memphis.edu </email>
<affiliation> Dept. of Mathematical Sciences  The University of Memphis </affiliation>
<address> Memphis TN 38152 </address>
<abstract> AbstractA simple polygon P is said to have a Hamilitonian Triangulation if it has a triangulationwhose dual graph contains a Hamiltonian path. Such triangulations are useful in fastrendering engines in Computer Graphics. Arkin et al. [AHMS] observed that a polygonhas a Hamiltonian triangulation if and only if it is Discretely Straight Walkable, a conceptthat is a discrete version of Straight Walkability concept as introduced by Icking and Klein[IK]. Using this characterization, Arkin et al. also showed an algorithm to recognize suchpolygons in time that is linear in the size of the visibility polygon of the given polygon P .The size of the visbility polygon of P could be quadratic in the size of P and hence theiralgorithm could be very inefficient even for nearly convex polygons.We give a new characterization of polygons with Hamiltonian triangulations. We usethis characterization to present the following algorithms:* An O(n log n)-time algorithm to recognize polygons with a Hamiltonian triangulation.* An O(n log n)-time algorithm to construct such a triangulation.* Given vertices p and q on a simple polygon, an O(n)-time algorithm to determinewhether the polygon is discretely straight walkable with respect to the two vertices.* An O(n log n)-time algorithm to list out all pairs of points on a simple polygon withrespect to which the polygon is discretely straight walkable. </abstract>
<note> References[IK] C. Icking and R. Klein, "The two guards problem," Proc. 7th Annual ACM Symp. onComputational Geometry, 1991, pp. 166-175.[AHMS] E.M. Arkin, M. Held, J.S.B. Mitchell, S.S. Skienna, "Hamiltonian Triangulationsfor Fast Rendering," Proc. of the 2nd ESA, 1994.1 Supported in part by NSF Grant CCR-940-9752 </note>
</NEW_HEADER>
<NEW_HEADER>
<title> The SAMOS Active DBMS Prototype </title>
<author> Stella Gatziu, Andreas Geppert, Klaus R. Dittrich </author>
<affiliation> Institut fur Informatik,   Universitat uZrich 1 </affiliation>
<pubnum> Technical Report 94.16 </pubnum>
<abstract> AbstractWe describe SAMOS, an active object-oriented database management system prototype. SAMOS offers a powerful rule definition language, including a small yet powerful set of event definition facilities. It is able to detect primitive and composite eventsautomatically and efficiently. Upon event detection, SAMOS executes rules attachedto the occurred events. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On the Robustness of the Damped V -cycleof the Wavelet Frequency DecompositionMultigrid Method </title>
<author> Andreas Rieder 1flXiaodong Zhou 1 </author>
<date> December 15, 1993 </date>
<abstract> AbstractThe V -cycle of the wavelet variation of the "Frequency decomposition multigrid method" of Hackbusch [Numer. Math., 56, pp.229-245, 1989] is considered.It is shown that its convergence speed is not affected by the presence of anisotropy provided that the corresponding coarse grid correction is damped sufficiently strong. Our analysis is based on propertiesof wavelet packets which are supplied and proved.Numerical approximations to the speed of convergence illustratethe theoretical results. </abstract>
<keyword> Key words: wavelets, wavelet packets, robust multilevel methods, V -cycle </keyword>
<note> Subject classification: AMS(MOS) 65F10, 65N301 supported partially by AFOSR under grant number 90-0334 which was funded byDARPApartially supported by a Feodor Lynen-Fellowship of the Alexander von HumboldtFoundation </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Adaptive Wave Propagation Modeling </title>
<author> Raymond O. Wells, Jr. </author>
<affiliation> Department of Mathematics,   Rice University </affiliation>
<address> Houston, TX 77251-1892 </address>
<abstract> ABSTRACTThis paper discusses several current attempts to use acoustic and electromagnetic wave propagation for modelingphysical phenomena and the role that wavelet analysis is playing in these efforts. The first problem involves recentapplication of wavelets to computational fluid dynamics. The second problem involves geophysical modeling of theocean floor, using acoustic waves, and wavelets have recently been shown to play an important role here already.The third problem involves modeling of SAR radar images in the context of automatic target recognition efforts.The fourth problem is global illumination in computer graphics, i.e., simulation of reflected and absorbed lightfor everyday environments. The role of wavelets is more embryonic in these latter two areas, but there are somecommon principles in all of these modeling efforts, and the methodology of wavelets seems well suited to certainaspects of these problems. </abstract>
<intro> 1 INTRODUCTION AND OVERVIEW </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Neuronal Goals: Efficient Coding and Coincidence Detection </title>
<author> Nathan Intrator  </author>
<affiliation> School of Mathematical Sciences  Tel Aviv University </affiliation>
<email> nin@cns.brown.edu </email>
<abstract> Abstract| Barlow's seminal work on minimal entropy codes and unsupervised learning isreiterated. In particular, the need to transmit the probability of events is put in a practicalneuronal framework for detecting suspicious events. A variant of the BCM learning rule [15]is presented together with some mathematical results suggesting optimal minimal entropycoding. </abstract>
<keyword> Key words: Sparse coding, Non-Gaussian distributions, BCM Theory, Minimal Entropy </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Computer Vulnerability Analysis </title>
<degree> Thesis Proposal </degree><author> Ivan Krsul </author>
<affiliation> The COAST Laboratory  Department of Computer Sciences  Purdue University </affiliation>
<address> West Lafayette, IN 47907-1398 </address>
<email> krsul@cs.purdue.edu </email>
<pubnum> Technical Report CSD-TR-97-026 </pubnum>
<date> April 15, 1997 </date>
<abstract> AbstractComputer security professionals and researchers do not have a history of sharing and analyzing computervulnerability information. Scientists and engineers from older or more established fields have long understoodthat publicizing, analyzing, and learning from other people's mistakes is essential to the stepwise refinementof complex systems. Computer scientists, however, have not followed suit. Programmers reinvent classicalprogramming mistakes, contributing to the reappearance of known vulnerabilities.In the recent past, computer systems have come to be a part of critical systems that have a direct effecton the safety and well-being of human beings and hence we must have lower tolerance for software failures.In the dissertation I will attempt to show that computer vulnerability information presents importantregularities and these can be detected, and possibly visualized, providing important insight about the reasonof their prevalence and existence. The information derived from these observations could be used to improve onall phases of the development of software systems, as could be in the design, development, debugging, testingand maintenance of complex computer systems that must implement a set of policies defined by securityanalysis.A significant portion of the work that must be performed will concentrate on the development of classifications and taxonomies that will permit the visualization and analysis of computer vulnerability information.I hope that these classifications and taxonomies applied to a collection of vulnerabilities will provide a setof features whose analysis will show that there are clear statistical clusterings and patterns caused becausedevelopers and programmers are not learning from each others mistakes. This analysis may be performed byapplying statistical analysis and knowledge discovery tools. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Evolving Visually Guided Robots </title>
<author> D. Cliff, P. Husbands, I. Harvey </author>
<pubnum> CSRP 220, </pubnum>
<date> July 1992 </date>
<pubnum> Cognitive Science Research PaperSerial No. CSRP 220 </pubnum>
<affiliation> The University of Sussex  School of Cognitive and Computing Sciences </affiliation>
<address> FalmerBrighton BN1 9QHEngland, U.K. </address>
<note> A version of this paper appears in:Proceedings of SAB92,the Second International Conference on Simulation of Adaptive BehaviourJ.-A. Meyer, H. Roitblat, and S. Wilson, editors,MIT Press Bradford Books, Cambridge, MA, 1993. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Pseudo-Network Drivers and Virtual Networks </title>
<author> S.M. Bellovin* </author>
<email> smb@ulysses.att.com </email>
<affiliation> ATT Bell Laboratories </affiliation>
<address> Murray Hill, New Jersey 07974 </address>
<abstract> ABSTRACTMany operating systems have long had pseudo-teletypes, inter-processcommunication channels that provide terminal semantics on one end,and a smart server program on the other. We describe an analogousconcept, pseudo-network drivers. One end of the driver appears to bea real network device, with the appropriate interface and semantics;data written to it goes to a program, however, rather than to a physicalmedium. Using this and some auxiliary mechanisms, we present avariety of applications, including system test, network monitoring,dial-up TCP/IP, and ways to both improve and subvert networksecurity. Most notably, we show how pseudo-network devices can beused to create virtual networks and to provide encryptedcommunications capability. We describe two implementations, oneusing a conventional driver for socket-based systems, and one usingstream pipes for System V. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Copyright 1993 ACM 0-8186-4340-4/93/0011 Permission to copy for non-commercial use granted by the Association for Computing Machinery. </note>
<title> MPI: A Message Passing InterfaceThe MPI Forum </title>
<abstract> This paper presents an overview of mpi, a proposedstandard message passing interface for MIMD distributed memory concurrent computers. The designof mpi has been a collective effort involving researchersin the United States and Europe from many organizations and institutions. mpi includes point-to-pointand collective communication routines, as well as support for process groups, communication contexts, andapplication topologies. While making use of new ideaswhere appropriate, the mpi standard is based largelyon current practice. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Type-driven Defunctionalization </title>
<author> Jeffrey M. Bell &amp; Fran~coise Bellegarde &amp; James Hook  </author>
<affiliation> Pacific Software Research Center  Oregon Graduate Institute of Science &amp; Technology </affiliation>
<address> PO Box 91000Portland, Oregon 97291-1000USA </address>
<email> fbell,bellegar,hookg@cse.ogi.edu </email>
<abstract> AbstractIn 1972, Reynolds outlined a general method for eliminating functional arguments known as defunctionalization. Theidea underlying defunctionalization is encoding functionalvalues as first-order data, and then to realized the applications of the encoded function via an apply function. Although this process is simple enough, problems arise whendefunctionalization is used in a polymorphic language. Insuch a language, a functional argument of a higher-orderfunction can take different type instances in different applications. As a consequence, its associated apply function canbe untypable in the soucre language. In the paper we presenta defunctionalization transformation which preserves typa-bility. Moreover, the transformation imposes no restrictionon functional arguments of recursive functions, and it handles functions as results as well as functions encapsulated inconstructors or tuples. The key to this success is the useof type information in the defunctionalization transformation. Run-time characteristics are preserved by defunction-alization; hence, there is no performance improvement coming from the transformation itself. However closures neednot be implemented to compile the transformed program.Since the defunctionalization is driven by type information,it can also easily perform a specialization of higher-orderfunctions with respect to the values of their functional arguments, hence gaining a real run-time improvement of thetransformed program. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Reactive Functional Programming </title>
<author> Richard B. Kieburtz </author>
<affiliation> Oregon Graduate Institute of Science &amp; Technology </affiliation>
<address> P.O. Box 91000, Portland, OR 97291-1000 USA </address>
<date> October 13, 1997 </date>
<abstract> AbstractReactive systems respond to concurrent, possibly unsynchronized streams of input events. Programmingreactive systems is challenging without language support for event-triggered actions. It is even morechallenging to reason about reactive systems. This paper explores a new conceptual basis for applyingfunctional programming techniques to the design and formal verification of reactive systems. Themathematical foundation for this approach is based upon signature coalgebras and derived proof rulesfor coinduction. The concepts are illustrated with an example that has been used with the languageEsterel. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Location Independent Names for Nomadic Computers </title>
<author> David C. Steere, Mark Morrissey, Peter Geib, Calton Pu, and Jonathan Walpole </author>
<affiliation> Department of Computer Science and Engineering  Oregon Graduate Institute </affiliation>
<abstract> AbstractRecent advances in the Domain Name System (DNS) and the Dynamic Host ConfigurationProtocol (DHCP) have enabled a new approach to supporting mobile users: location independentnaming. In this approach, machines use the same hostname from any internet location, but use anIP address that corresponds to their current location. We describe a protocol that implementslocation independent naming for nomadic computers, i.e., machines that do not need transparentmobility. Our protocol allows hosts to move across security domains, uses existing protocols, andpreserves existing trust relationships. Therefore, it preserves the performance and security ofnormal IP for nomadic computers at the expense of not providing the transparent mobility ofMobile IP. We contend that this is a reasonable tradeoff for nomadic computing. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Comparison of Statistical and Neural Classifiersand Their Applications toOptical Character Recognition and Speech Classification </title>
<author> Ethem Alpaydn, Fikret Gurgen </author>
<affiliation> Department of Computer Engineering  Bogazi~ci University </affiliation>
<pubnum> TR-80815 </pubnum>
<address> _ Istanbul Turkey </address>
<email> falpaydin,gurgeng@boun.edu.tr </email>
<note> Neural Network Systems Techniques and Applications (in print)C. T. Leondes (Ed.), c flACADEMIC Press </note>
<date> October 24, 1996 </date>
<abstract> AbstractWe give a review of basic statistical and neural techniques for classification. Statistical techniques are based on the idea of estimating class-conditional likelihoods and using Bayes ruleto convert these to posterior class probabilities whereas neural techniques estimate directly theposteriors. Statistical techniques include (i) Parametric (Gaussian) Bayes classifiers, (ii) Non-parametric kernel-based density estimators like k-nearest neighbor and Parzen windows, and(iii) mixtures of (Gaussian) densities (a special case of which is the Learning Vector Quantization). As neural classifiers, we include simple perceptrons and multilayer perceptrons withsigmoid and Gaussian hidden units. The neural and statistical techniques are quite similar inmany respects and many approaches have been discovered independently twice, once in 1960sby statisticians and once in 1980s by the neural network researchers. One of the aims of this article is to make this link more apparent. We also discuss two, most popular, pattern recognitionapplications: Optical character recognition and speech recognition. Though they seem different,in many respects, the two applications are similar and in the past, almost the same techniqueshave been applied for their implementation. We implement the well known statistical and neuralclassification techniques for two datasets of these applications and compare them in terms ofgeneralization accuracy, memory requirement and learning time. We especially advise to takeinto account statistics of the sample even if a neural classifier is to be used. The similaritybetween statistical and neural techniques is greater than generally agreed and simple statisticalmethods like k-NN perform generally quite well and much of the functionality of neural networks like distributed parallel computation can be obtained by such methods without requiringcomplicated computation and precise error minimization procedures. </abstract>
<keyword> Keywords| Statistical pattern recognition, artificial neural networks, optical character recognition, speech recognition, Bayes decision theory, nonparametric estimation. </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> DIMACS Technical Report 96-47 </pubnum>
<date> October 1996 </date>
<title> On independent domination number of graphswith given minimum degree </title>
<author> byN. I. Glebov 1 </author>
<affiliation> Institute of Mathematics </affiliation>
<address> 630090 Novosibirsk, Russia </address>
<author> A. V. Kostochka 2 </author>
<affiliation> Institute of Mathematics </affiliation>
<address> 630090 Novosibirsk, Russia </address>
<note> DIMACS is a partnership of Rutgers University, Princeton University, AT&amp;TResearch, Bellcore, and Bell Laboratories.DIMACS is an NSF Science and Technology Center, funded under contractSTC-91-19999; and also receives support from the New Jersey Commissionon Science and Technology. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> DIMACS Technical Report 97-15 </pubnum>
<date> April 1997(Revised August 1997) </date>
<title> Crowds: Anonymity for Web Transactions </title>
<author> byMichael K. Reiter 1 Aviel D. Rubin 2 </author>
<affiliation> AT&amp;T Labs|Research, </affiliation>
 <address>  Murray Hill, New Jersey, USA </address>
<email> freiter,rubing@research.att.com </email>
<note>  1 Permanent Member2 Permanent MemberDIMACS is a partnership of Rutgers University, Princeton University, AT&amp;T Labs, Bellcore, and Bell Labs.DIMACS is an NSF Science and Technology Center, funded under contract STC-91-19999; and also receivessupport from the New Jersey Commission on Science and Technology. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> DIMACS Technical Report 98-34 </pubnum>
<date> July 1998 </date>
<title> On the dimension of the Hilbert-cubes </title>
<author> byNorbert Hegyvari 1 </author>
<note> 1 Research partially supported by Hungarian National Foundation for Scientific Research, Grant No.T025617 and by DIMACS (Center for Discrete Mathematics and Theoretical Computer Science)NSF-STC-91-19999.DIMACS is a partnership of Rutgers University, Princeton University, AT&amp;T Labs-Research,Bell Labs, Bellcore and NEC Research Institute.DIMACS is an NSF Science and Technology Center, funded under contract STC-91-19999;and also receives support from the New Jersey Commission on Science and Technology. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Kit: A Study inOperating System Verification </title>
<author> William R. Bevier </author>
<pubnum> Technical Report 28 </pubnum>
<date> August, 1988 </date>
<affiliation> Computational Logic Inc. </affiliation>
<address> 1717 W. 6th St. Suite 290Austin, Texas 78703 </address>
<phone> (512) 322-9951 </phone><note> This research was supported in part by the U.S.Government. The views and conclusions contained in thisdocument are those of the author and should not beinterpreted as representing the official policies, eitherexpressed or implied, of the Defense Advanced ResearchProjects Agency or the U.S. Government. This work wassponsored in part at Computational Logic, Inc. by theDefense Advanced Research Projects Agency, ARPAOrders 6082 and 9151, and at the University of Texas atAustin by the Defense Advanced Research ProjectsAgency, ARPA Order 5246, issued by the Space andNaval Warfare Systems Command under ContractN00039-85-K-0085. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Towards an Effective Calculus for Object Query Languages </title>
<author> Leonidas Fegaras David Maier </author>
<affiliation> Department of Computer Science and Engineering  Oregon Graduate Institute of Science &amp; Technology </affiliation>
<address> 20000 N.W. Walker Road P.O. Box 91000Portland, OR 97291-1000 </address>
<email> email: ffegaras,maierg@cse.ogi.edu </email>
<abstract> AbstractWe define a standard of effectiveness for a database calculusrelative to a query language. Effectiveness judges suitabilityto serve as a processing framework for the query language,and comprises aspects of coverage, manipulability andefficient evaluation. We present the monoid calculus, andargue its effectiveness for object-oriented query languages,exemplified by OQL of ODMG-93. The monoid calculusreadily captures such features as multiple collection types,aggregations, arbitrary composition of type constructors andnested query expressions. We also show how to extendthe monoid calculus to deal with vectors and arrays inmore expressive ways than current query languages do, andillustrate how it can handle identity and updates. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> LISP AND SYMBOLIC COMPUTATION: An International Journal, 5, 191-221, 1992c 1992 Kluwer Academic Publishers Manufactured in The Netherlands </note>
<title> Callee-save Registers in Continuation-passing Style </title>
<author> ANDREW W. APPEL </author>
 <email> (appel@princeton.edu) </email>
<author> ZHONG SHAO </author>
 <email> (zsh@princeton.edu) </email>
<affiliation> Department of Computer Science,   Princeton University, </affiliation>
 <address>  Princeton, NJ 08544-2087 </address>
<keyword> Keywords: Register Allocation, Continuation-passing Style, Procedure Call </keyword>
<abstract> Abstract. Continuation-passing style (CPS) is a good abstract representation to usefor compilation and optimization: it has a clean semantics and is easily manipulated.We examine how CPS expresses the saving and restoring of registers in source-languageprocedure calls. In most CPS-based compilers, the context of the calling procedure issaved in a "continuation closure"|a single variable that is passed as an argument to thefunction being called. This closure is a record containing bindings of all the free variablesof the continuation; that is, registers that hold values needed by the caller "after the call"are written to memory in the closure, and fetched back after the call.Consider the procedure-call mechanisms used by conventional compilers. In particular,registers holding values needed after the call must be saved and later restored. Theresponsibility for saving registers can lie with the caller (a "caller-saves" convention)or with the called function ("callee-saves"). In practice, to optimize memory traffic,compilers find it useful to have some caller-saves registers and some callee-saves."Conventional" CPS-based compilers that pass a pointer to a record containing allthe variables needed after the call (i.e., the continuation closure), are using a caller-savesconvention. We explain how to express callee-save registers in Continuation-PassingStyle, and give measurements showing the resulting improvement in execution time. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Coordinated Resource Managementin a Replicated Object Server </title>
<author> Sanjay GhemawatRobert GruberJames O'TooleLiuba Shrira </author>
<abstract> AbstractWe propose several new techniques for resource management in a replicated object server. By coordinating cacheand disk usage among the replicas, these techniques increase throughput and reduce fetch latency. Cache splittingspeeds up fetches by avoiding redundant cache entries, effectively increasing the cache size. Coordinated writingcoordinates disk writes to ensure that one replica is alwaysavailable to service fetches. We investigate the performanceof a replicated server using these techniques, and we presentsimulation results showing that these techniques providesubstantial performance improvements across a variety ofworkloads. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title>  Discovering Compressive Partial Determinationsin Mixed Numerical and Symbolic Domains </title>
 <author> Bernhard Pfahringer and Stefan Kramer </author>
<affiliation> Austrian Research Institute for Artificial Intelligence </affiliation>
<address> Schottengasse 3A-1010 Vienna, Austria </address>
<email> fbernhard, stefang@ai.univie.ac.at </email>
<abstract> AbstractPartial determinations are an interestingform of dependency between attributes in arelation. They generalize functional dependencies by allowing exceptions. We modify a known MDL formula for evaluatingsuch partial determinations to allow for itsuse in an admissible heuristic in exhaustivesearch. Furthermore we describe an efficientpreprocessing-based approach for handlingnumerical attributes. An empirical investigation tries to evaluate the viability of thepresented ideas. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Vertex heaviest paths and cycles in quasi-transitivedigraphs </title>
<author> Jtrgen Bang-Jensen Gregory Gutin  </author>
<affiliation> Department of Mathematics and Computer Science  Odense University, </affiliation>
 <address> Denmark </address>
<abstract> AbstractA digraph D is called a quasi-transitive digraph (QTD) if for anytriple x; ; of distinct vertices of D such that (x; ) and (; ) arearcs of D there is at least one arc from x to or from to x. Solvinga conjecture by J. Bang-Jensen and J. Huang (J. Graph Theory, toappear), G. Gutin (Australas. J. Combin., to appear) described polynomial algorithms for finding a Hamiltonian cycle and a Hamiltonianpath (if it exists) in a QTD. The approach taken in that paper cannotbe used to find a longest path or cycle in polynomial time. We presenta principally new approach that leads to polynomial algorithms forfinding vertex heaviest paths and cycles in QTD's with non-negativeweights on the vertices. This, in particular, provides an answer to aquestion by N. Alon on longest paths and cycles in QTD's. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Knowledge-Sharing Strategy </title>
<author> David Goldstein and Albert Esterline </author>
<affiliation> North Carolina A&amp;T State University </affiliation>
<address> Greensboro, North Carolina </address>
<email> goldstn @ncat.edu, esterlin@ncat.edu </email>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> PORTS: Experiences with a Scheduler for Dynamic Real-TimeSystems </title>
<note> (Extended Abstract) </note>
<author> Kaushik Ghosh, Richard M. Fujimoto, and Karsten Schwan </author>
<affiliation> College of Computing Georgia Institute of Technology </affiliation>
<address> Atlanta, GA, 30332. </address>
<date> June 24, 1994 </date>
<abstract> AbstractThis paper describes several of our experiences with a real-time scheduler. Using a robot control application program, we motivate the importance of supporting multiple schedulers within the same applicationprogram. We demonstrate the utility of speculative task execution in dynamic real-time systems, and describe the implementation of a scheduler for performing speculative execution and recovery. We show thatexisting real-time scheduler interfaces have scope for improvement, especially when scheduling latency mustbe low and when multiple schedulers used by a single application must co-exist on a single processor. A newscheduler interface is specified and its basic costs are evaluated experimentally. Preliminary measurements ona KSR-1 machine are quoted. The measurements demonstrate how the execution times of temporal queriesmay be reduced by use of access structures to scheduler data structures. Finally, there are several overheadsassociated with speculative execution, and multiple schedulers in a single application. We consider the problem of on-line reconfiguration of the several overheads associated with the speculative-execution paradigmfor optimal performance in the face of these overheads. Initial performance measurements of the PORTSscheduler indicate that it is possible to perform real-time scheduling with latencies approximating those ofproposed specialized scheduling co-processors. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Core Selection Methods forMulticast Routing </title>
<author> Kenneth L. Calvert Ellen W. ZeguraMichael J. Donahoo </author>
<pubnum> GIT-CC-95/15 </pubnum>
<abstract> AbstractMulticast routing is an important topic of both theoretical and practicalinterest. Some recently-proposed multicast routing algorithms involve thedesignation of one or more network nodes as the "center" of the routingtree for each multicast group address. The choice of this designated router(which we refer to as the "core") influences the shape of the multicast routingtree, and thus influences performance of the routing scheme. In this paper weinvestigate the relationship between the choice of core and three performancemeasures. Specifically, we compare various methods of selecting a core withrespect to their effect on bandwidth, delay, and traffic concentration. Weconclude that simple methods are adequate for widely distributed groups,but that the addition of group information can be leveraged to improveperformance especially when the group is small or exhibits a high degreeof locality. We also conclude that core choice has a significant impact ontraffic concentration, in fact traffic concentration effects can be amelioratedby appropriate core choice policies. </abstract>
<keyword> Keywords: Multicast routing, Scalability, Network modeling </keyword>
<affiliation> College of Computing  Georgia Institute of Technology </affiliation>
<address> Atlanta, Georgia 30332-0280 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Interactive Model-Based Image Understanding </title>
<author> Daryl T. Lawton Warren F. Gardner </author>
<abstract> AbstractThis paper describes a general architecture for an interactive model-based vision system. Ahuman specifies a limited amount of information which establishes a context for autonomous interpretation of images. Object models are described by constraints specifying necessary geometricalproperties and relationships between objects. The use of constraints allows for flexible object in-stantiation. A user can indicate an object in a scene and this directs perceptual processing routinesas well as constraining future object instantiations. This interactive model-based concept has beenapplied to the domain of vehicle tracking, and this paper concludes with several processing examplesfrom this domain. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Implementing Schema-theoretic Models ofAnimal Behavior in Robotic Systems </title>
<author> Khaled S. Ali and Ronald C. Arkin </author>
<affiliation> Mobile Robot Laboratory  College of Computing  Georgia Institute of Technology </affiliation>
<address> Atlanta, GA, 30332-0281 USA </address>
<email> fkali,arking@cc.gatech.edu </email>
<abstract> AbstractFormal models of animal sensorimotor behavior canprovide effective methods for generating robotic intelligence. In this paper we describe how schema-theoreticmodels of the praying mantis are implemented on ahexapod robot equipped with a real-time color visionsystem. The model upon which the implementationis based was developed by ethologists studying man-tids. This implementation incorporates a wide rangeof behaviors, including obstacle avoidance, prey acquisition, predator avoidance, mating, and chantlitaxiabehaviors. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Finding the Parts of Objectsin Range Images </title>
<author> Andre Lejeune and Frank P. Ferrie </author>
<pubnum> CIM-93-8 </pubnum>
<date> August 1993 </date>
<affiliation> Center for Intelligent Machines  McGill University, </affiliation>
 <address>  McConnell Engineering Building3480 Universite, Montreal, Quebec, CANADA, H3A 2A7 </address>
<email>  Email: andre@lightning.mcrcim.mcgill.edu ferrie@lightning.mcrcim.mcgill.edu </email>
<phone> Tel: (514) 398-6042 Fax: (514) 398-7348 </phone><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Hypertextual Concurrent Controlof a Lisp Kernel  </title>
<author> P. David Stotts Richard Furuta  </author>
<affiliation> Department of Computer and Department of Computer Science andInformation Sciences Institute for Advanced Computer Studies  University of Florida University of Maryland </affiliation>
<address> Gainesville, FL 32611 College Park, MD 20742 </address>
<abstract> AbstractUsing the Trellis human/computer interaction model as an implementation vehicle, we demonstratehow to use concurrency-supporting hypertext to provide visual displays of the execution flows througha parallel Lisp program. In addition to displays, the hypertext interface allows injection of controlflow into an otherwise functional computation, and therefore provides reader control over the order ofevaluation of expressions. The resulting system, termed Trellis, can be thought of as a concurrent controlflow browser for composing functional computations, providing a visual implementation of kernel-controldecomposition. The advantages of Trellis are ease of exploring program side effects; ease of debuggingparallel code; aid in teaching functional languages; and the ability to construct hypertext documentsthat have parallel execution semantics and flexible browsing behaviors.Key words: functional programming, parallelism, kernel-control decomposition, Lisp, hypertext, execution visualization. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A SIMPLE APPROACH TO DISTRIBUTED POOLS </title>
<author> BENEDICT M. RAFANELLO &amp; THEODORE JOHNSON </author>
<affiliation> University of Florida,   Department of Computer and information Sciences </affiliation>
<date> January 1994 </date>
<abstract> Computer networks hold the potential to coordinate the activities of multiple machines so that their combined computational abilities can be applied to solving a single problem. Several methods have been developed over the years toharness the power of networked systems for solving certain classes of problems. One such class of problems is the distributed producer/consumer problem, in which a set of producer processes supply items to a set of consumer processes. Eachof the processes involved resides on a different machine, with the machines being connected by a network and the processes communicating via message passing. The problem, then, is how to coordinate the activities of the producers and consumers so that an acceptable level of throughput can be maintained with a minimal amount of overhead. This paperpresents a simple solution to the distributed producer/consumer problem. This solution, which is based upon the notion ofa distributed pool, is described in detail and its performance analyzed. As the analysis shows, the distributed pools algorithm presented herein is a simple, efficient solution to the distributed producer/consumer problem, and is capable of better than 90% efficiency under common conditions. Its major failing is that it needs the production rates of the producersto be reasonably similar. </abstract>
<keyword> Key words: distributed computing, distributed queue, performance modeling, producer/consumer, simulation. </keyword>
<intro> INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Selection Predicate Indexing for Active DatabasesUsing Interval Skip Lists </title>
<author> Eric N. HansonTheodore Johnson </author>
<affiliation> Computer and Information Sciences Department  University of Florida </affiliation>
<address> Gainesville, FL 32611 </address>
<email> fhanson,tedg@cis.ufl.edu </email>
<pubnum> TR94-017 </pubnum>
<date> 15 April 1994(revised 13 October 1994) </date>
<abstract> AbstractA new, efficient selection predicate indexing scheme for active database systems is introduced.The selection predicate index proposed uses an interval index on an attribute of a relation orobject collection when one or more rule condition clauses are defined on that attribute. Theselection predicate index uses a new type of interval index called the interval skip list (IS-list).The IS-list is designed to allow efficient retrieval of all intervals that overlap a point, while allowingdynamic insertion and deletion of intervals. IS-list algorithms are described in detail. The IS-listallows efficient on-line searches, insertions, and deletions, yet is much simpler to implement thanother comparable interval index data structures such as the priority search tree and balancedinterval binary search tree (IBS-tree). IS-lists require only one third as much code to implementas balanced IBS-trees. The combination of simplicity, performance, and dynamic updateabilityof the IS-list is unmatched by any other interval index data structure. This makes the IS-list agood interval index structure for implementation in an active database predicate index.  </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Shape Modeling with Front Propagation: A Level Set Approach </title>
<author> Ravikanth Malladi, 1 James A. Sethian, 1 and Baba C. Vemuri 2 </author>
<affiliation> 1 Lawrence Berkeley Laboratory andDepartment of Mathematics  University of California, </affiliation>
 <address> Berkeley, CA 94720. </address>
<affiliation> 2 Department of Computer &amp; Information Sciences  University of Florida, </affiliation>
 <address> Gainesville, FL 32611. </address>
<abstract> AbstractShape modeling is an important constituent of computer vision as well as computer graphicsresearch. Shape models aid the tasks of object representation and recognition. This paperpresents a new approach to shape modeling which retains some of the attractive features ofexisting methods, and overcomes some of their limitations. Our techniques can be applied tomodel arbitrarily complex shapes, which include shapes with significant protrusions, and tosituations where no a priori assumption about the object's topology is made. A single instanceof our model, when presented with an image having more than one object of interest, has theability to split freely to represent each object. This method is based on the ideas developedby Osher and Sethian to model propagating solid/liquid interfaces with curvature-dependentspeeds. The interface (front) is a closed, nonintersecting, hypersurface flowing along its gradientfield with constant speed or a speed that depends on the curvature. It is moved by solving a"Hamilton-Jacobi" type equation written for a function in which the interface is a particularlevel set. A speed term synthesized from the image is used to stop the interface in the vicinity ofobject boundaries. The resulting equation of motion is solved by employing entropy-satisfyingupwind finite difference schemes. We present a variety of ways of computing evolving front,including narrow bands, reinitializations, and different stopping criteria. The efficacy of thescheme is demonstrated with numerical experiments on some synthesized images and some lowcontrast medical images. </abstract>
<note> fl1 Supported in part by the Applied Mathematical Sciences Subprogram of the Office of Energy Research, U.S.Dept. of Energy under Contract DE-AC03-76SD00098 and by the NSF ARPA under grant DMS-8919074.2 Supported in part by NSF grant ECS-9210648. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Quality Management of Information Systems Development </title>
<author> Geoff Beckworth, </author>
<email> email: gbeck@deakin.edu.au </email>
<author> Brian Garner </author>
<email> email: brian@deakin.edu.au </email>
<affiliation> School of Computing and Mathematics  Deakin University, </affiliation>
 <address> Geelong, Victoria, 3217, Australia. </address>
<abstract> AbstractThe role of the systems analyst in the implementation process has changeddramatically in recent times because of changes to organisational boundaries, theneed to align IT with business objectives and the complexity of the systems nowrequired. Some organisations are finding themselves in a continually changingenvironment and being involved in multi-organisational structures. Establishingstrategies and requirements for these organisations requires a new understandingof the implementation process. Implementation is concerned with behaviouralphenomena since people are involved from the inception of the idea, as well asbeing involved in the development process. They are also affected by the changeswhich the new system brings to the organisation. The research is attempting tounderstand the critical factors associated with the implementation process andconsequently develop an appropriate model. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Times of Cryptographic Parameter Generation, andKey Computation and Distribution for the Star-basedand Ring-based Conference Authentication Facilities 1 </title>
<author> Damien De Paoli and Andrzej Goscinski </author>
<email> (ddp@deakin.edu.au, ang@deakin.edu.au) </email>
<affiliation> School of Computing and Mathematics  Deakin University </affiliation>
<address> Geelong, Victoria 3217 </address>
<date> September 8, 1994 </date>
<abstract> AbstractTwo-way authentication methods are inefficient when used to authenticate multiple users who wish to communicate securely with each other. M-way, also called conference authentication, is designed to efficiently authenticate many users and distribute a secure common conference key. Unfortunately, few if any conferenceauthentication schemes have been developed and/or performance tested in a real distributed system. This reportattempts to rectify this problem. Specifically, it presents the performance of both a star and a ring-based conference authentication scheme that has been developed for the RHODOS distributed operating system. As with mostsystems, RHODOS does not have any special hardware, thus, a software based solution is utilised. This reportalso attempts to shed some light upon how viable and secure a conference authentication scheme would be whenused in a distributed system. </abstract>
<keyword> Keywords: Conference Authentication, Distributed Systems. </keyword>
<note> 1. This work was supported by the Australian Research Council under Grant A48831034, Australian </note>
</NEW_HEADER>
<NEW_HEADER>
<note> In press: The Neurobiology of Computation: Proceedings of the Annual Compu--tational Neuroscience Meeting. J.M. Bower, ed. Kluwer Academic Publishers,Boston. </note>
<title> UNSUPERVISED LEARNING OFINVARIANT REPRESENTATIONS OF FACESTHROUGH TEMPORAL ASSOCIATION </title>
<author> Marian Stewart Bartlett ;Terrence J. Sejnowski ; </author>
<email> marni@salk.edu, terry@salk.edu </email>
<affiliation> Departments of Cognitive Science and Psychology, UCSD  Howard Hughes Medical InstituteThe Salk Institute, </affiliation>
 <address> La Jolla, CA, 92037 </address>
<abstract> AbstractThe appearance of an object or a face changes continuously as the observermoves through the environment or as a face changes expression or pose. Recognizing an object or a face despite these image changes is a challenging problemfor computer vision systems, yet we perform the task quickly and easily. Thissimulation investigates the ability of an unsupervised learning mechanism toacquire representations that are tolerant to such changes in the image. Thelearning mechanism finds these representations by capturing temporal relationships between 2-D patterns. Previous models of temporal association learninghave used idealized input representations. The input to this model consists ofgraylevel images of faces. A two-layer network learned face representations thatincorporated changes of pose up to 30 ffi . A second network learned representations that were independent of facial expression. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Temporal Difference Learning ofPosition Evaluation in the Game of Go  </title>
<author> Nicol N. Schraudolph Peter Dayan Terrence J. Sejnowski </author>
<email> schraudo@salk.edu dayan@salk.edu terry@salk.edu </email>
<affiliation> Computational Neurobiology Laboratory  The Salk Institute for Biological Studies </affiliation>
<address> San Diego, CA 92186-5800 </address>
<abstract> AbstractThe game of Go has a high branching factor that defeats the treesearch approach used in computer chess, and long-range spa-tiotemporal interactions that make position evaluation extremelydifficult. Development of conventional Go programs is hamperedby their knowledge-intensive nature. We demonstrate a viablealternative by training networks to evaluate Go positions via temporal difference (TD) learning.Our approach is based on network architectures that reflect thespatial organization of both input and reinforcement signals onthe Go board, and training protocols that provide exposure tocompetent (though unlabelled) play. These techniques yield farbetter performance than undifferentiated networks trained by self-play alone. A network with less than 500 weights learned within3,000 games of 9x9 Go a position evaluation function that enablesa primitive one-ply search to defeat a commercial Go program ata low playing level. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Displaying 3D Images: Algorithms forSingle Image Random Dot Stereograms </title>
<author> Harold W. Thimbleby, Stuart Inglis, and Ian H. Witten * </author>
<abstract> AbstractThis paper describes how to generate a single image which, when viewed in theappropriate way, appears to the brain as a 3D scene. The image is a stereogram composedof seemingly random dots. A new, simple and symmetric algorithm for generating suchimages from a solid model is given, along with the design parameters and their influenceon the display. The algorithm improves on previously-described ones in several ways: itis symmetric and hence free from directional (right-to-left or left-to-right) bias, it correctsa slight distortion in the rendering of depth, it removes hidden parts of surfaces, and italso eliminates a type of artifact that we call an echo.Random dot stereograms have one remaining problem: difficulty of initial viewing. Ifa computer screen rather than paper is used for output, the problem can be ameliorated byshimmering, or time-multiplexing of pixel values. We also describe a simplecomputational technique for determining what is present in a stereogram so that, ifviewing is difficult, one can ascertain what to look for. </abstract>
<keyword> Keywords: Single image random dot stereograms, SIRDS, autostereograms,stereoscopic pictures, optical illusions </keyword>
<affiliation> Department of Psychology,   University of Stirling,  </affiliation>
 <address> Stirling, Scotland. </address>
 <phone> Phone (+44) 786-467679; fax786-467641; </phone> <email> email hwt@compsci.stirling.ac.uk </email>
<affiliation> Department of Computer Science,   University of Waikato, </affiliation>
 <address> Hamilton, New Zealand. </address>
 <phone> Phone (+64 7)856-2889; fax 838-4155; </phone> <email> email singlis@waikato.ac.NZ. </email>
<affiliation> Department of Computer Science,   University of Waikato, </affiliation>
 <address> Hamilton, New Zealand. </address>
 <phone> Phone (+64 7)838-4246; fax 838-4155; </phone> <email> email ihw@waikato.ac.NZ. </email>
<note> * Please address all correspondence to Ian H. Witten </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Constructing a Configurable Group RPC Service </title>
<author> Matti A. Hiltunen and Richard D. Schlichting </author>
<affiliation> Department of Computer Science  University of Arizona </affiliation>
<address> Tucson, AZ 85721, USA </address>
<abstract> AbstractCurrent Remote Procedure Call (RPC) services implement a variety of semantics, with many of the differencesrelated to how communication and server failures are handled. The list increases even more when considering groupRPC, a variant of RPC often used for fault-tolerance wherean invocation is sent to a group of servers rather than one.This paper presents an approach to constructing groupRPC in which a single configurable system is used to builddifferent variants of the service. The approach is based onimplementing each property as a separate software modulecalled a micro-protocol, and then configuring the micro-protocols needed to implement the desired service togetherusing a software framework based on the x-kernel. Theproperties of point-to-point and group RPC are identifiedand classified, and the general execution model described.An example consisting of a modular implementation of agroup RPC service is given to illustrate the approach. Dependency issues that restrict configurability are also addressed. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Development of an Intelligent Monitoring and Control System for aHeterogeneous Numerical Propulsion System Simulation </title>
<author> Abdollah A. Afjeh * , Patrick T. Homer , Henry Lewandowski ,John A. Reed * , and Richard D. Schlichting  </author>
<affiliation> Cleveland State University , The University of Arizona , University of Toledo * </affiliation>
<abstract> AbstractThe NASA Numerical Propulsion System Simulation(NPSS) project is exploring the use of computer simulationto facilitate the design of new jet engines. Several key issuesraised in this research are being examined in an NPSS-related research project: zooming, monitoring and control,and support for heterogeneity. The design of a simulationexecutive that addresses each of these issues is described.In this work, the strategy of zooming, which allows codesthat model at different levels of fidelity to be integratedwithin a single simulation, is applied to the fan componentof a turbofan propulsion system. A prototype monitoringand control system has been designed for this simulation tosupport experimentation with expert system techniques foractive control of the simulation. An interconnection systemprovides a transparent means of connecting the heterogeneous systems that comprise the prototype. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Domain-specific Information Browsers for Man Page, File, and Font * </title>
<author> Thomas A. Phelps </author>
<affiliation> Department of Electrical Engineering and Computer ScienceComputer Science Division   University of California,  Berkeley </affiliation>
<abstract> AbstractThe task of information browsers is (1) to aid in navigating through alarge database to locate the item of interest and (2) to inspect or otherwisemanipulate this item once found. This document describes three experiments in constructing tools for information browsing: TkMan for UNIXmanual pages, NBT for files in a hierarchical file system, and FoSel forbitmap fonts. Each exploits the large-scale natural organization of dataand the fine-grained structure of each datum with a graphical user interface to provide a powerful yet intuitive tool. The lessons learned in implementing the browsers point to general principles that should guide thedesign of all information browsers. </abstract>
<intro> 1 Domain-specific Information Browsing </intro>
</NEW_HEADER>
<NEW_HEADER>
<note>  USENIX Summer Conference  June 11-15, 1990 Anaheim, California </note>
<title> Why Aren'tOperating SystemsGetting Faster AsFast as Hardware? </title>
<author> John K. Ousterhout </author>
 <affiliation> University of California at Berkeley </affiliation>
<abstract> ABSTRACTThis paper evaluates several hardware platforms and operating systems using a set of benchmarksthat stress kernel entry/exit, file systems, and other things related to operating systems. Theoverall conclusion is that operating system performance is not improving at the same rate as thebase speed of the underlying hardware. The most obvious ways to remedy this situation are toimprove memory bandwidth and reduce operating systems' tendency to wait for disk operations tocomplete. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Evolution of Recursive Transition Networks forNatural Language Recognition with ParallelDistributed Genetic Programming </title>
<author> Riccardo Poli </author>
<affiliation> School of Computer Science  The University of Birmingham </affiliation>
<email> E-mail: R.Poli@cs.bham.ac.uk </email>
<pubnum> Technical Report: CSRP-96-19 </pubnum>
<date> December 1996 </date>
<abstract> AbstractThis paper describes the application of Parallel Distributed Genetic Programming (PDGP) to the problem of inducing programs for natural language processing.PDGP is a new form of Genetic Programming (GP) which is suitable for the development of programs with a high degree of parallelism and an efficient and effectivereuse of partial results. Programs are represented in PDGP as graphs with nodesrepresenting functions and terminals, and links representing the flow of control andresults. PDGP allows the exploration of a large space of possible programs including standard tree-like programs, logic networks, neural networks, finite stateautomata, Recursive Transition Networks (RTNs), etc. The paper describes therepresentations, the operators and the interpreters used in PDGP, and illustratesits behaviour on the problem of inducing RTN-based recognisers for natural language from positive and negative examples. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Submitted to EuroGP-98, Paris, 16-17 April, 1998 </note>
<title> Genetic Programming Bloat with Dynamic Fitness </title>
<author> W. B. Langdon and R. Poli </author>
<affiliation> School of Computer Science,   University of Birmingham, </affiliation>
 <address> Birmingham B15 2TT, UK </address>
<email> fW.B.Langdon,R.Polig@cs.bham.ac.uk </email>
 <web> http://www.cs.bham.ac.uk/~wbl, ~rmp </web><phone> Tel: +44 (0) 121 414 4791, Fax: +44 (0) 121 414 4281 </phone><pubnum> Technical Report: CSRP-97-29, </pubnum>
<date>  3 December 1997 </date>
<abstract> AbstractIn artificial evolution individuals which perform as their parents are usually rewarded identicallyto their parents. We note that Nature is more dynamic and there may be a penalty to pay for doingthe same thing as your parents. We report two sets of experiments where static fitness functionsare firstly augmented by a penalty for unchanged offspring and secondly the static fitness caseis replaced by randomly generated dynamic test cases. We conclude genetic programming, whenevolving artificial ant control programs, is surprisingly little effected by large penalties and programgrowth is observed in all our experiments. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Why Ants are Hard </title>
<author> W. B. Langdon and R. Poli </author>
<affiliation> School of Computer Science,   The University of Birmingham, </affiliation>
 <address> Birmingham B15 2TT, UK </address>
<email> fW.B.Langdon,R.Polig@cs.bham.ac.uk </email>
 <web> http://www.cs.bham.ac.uk/~wbl, ~rmp </web><phone> Tel: +44 (0) 121 414 4791, Fax: +44 (0) 121 414 4281 </phone><pubnum> Technical Report: CSRP-98-4 </pubnum>
<date> January 1998 </date>
<abstract> AbstractThe problem of programming an artificial ant to follow the Santa Fe trail is used as an exampleprogram search space. Analysis of shorter solutions shows they have many of the characteristicsoften ascribed to manually coded programs. Enumeration of a small fraction of the total searchspace and random sampling characterise it as rugged with many multiple plateaus split by deepvalleys and many local and global optima. This suggests it is difficult for hill climbing algorithms.Analysis of the program search space in terms of fixed length schema suggests it is highly deceptiveand that for the simplest solutions large building blocks must be assembled before they have aboveaverage fitness. In some cases we show solutions cannot be assembled using a fixed representationfrom small building blocks of above average fitness. These suggest the Ant problem is difficult forGenetic Algorithms.Random sampling of the program search space suggests on average the density of global optimachanges only slowly with program size but the density of neutral networks linking points of the samefitness grows approximately linearly with program length. This is part of the cause of bloat.Previously reported genetic programming, simulated annealing and hill climbing performance isshown not to be much better than random search on the Ant problem. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> Technical Report CSRP-98-13 </pubnum>
<affiliation> School of Computer Science,   The University of Birmingham </affiliation>
<title> GP-Music: An Interactive Genetic Programming System forMusic Generation with Automated Fitness Raters </title>
<author> Brad Johanson </author>
<affiliation> Stanford University </affiliation>
<address> Rains Apt. 9A704 Campus Dr.Stanford, CA. 94305 </address>
<email> bjohanso@stanford.edu </email>
<phone> 650-497-7543 </phone><author> Riccardo Poli </author>
<affiliation> University of Birmingham  School of Computer Science  The University of Birmingham </affiliation>
<address> Birmingham B15 2TT </address>
<email> R.Poli@cs.bham.ac.uk </email>
<phone> +44-121-414-3739 </phone><abstract> AbstractIn this paper we present the GP-Music System, an interactive system which allows users to evolve short musical sequencesusing interactive genetic programming, and its extensions aimed at making the system fully automated. The basic GP-system works by using a genetic programming algorithm, a small set of functions for creating musical sequences, and a userinterface which allows the user to rate individual sequences. With this user interactive technique it was possible to generatepleasant tunes over runs of 20 individuals over 10 generations. As the user is the bottleneck in interactive systems, thesystem takes rating data from a users run and uses it to train a neural network based automatic rater, or auto rater, whichcan replace the user in bigger runs. Using this auto rater we were able to make runs of up to 50 generations with 500individuals per generation. The best of run pieces generated by the auto raters were pleasant but were not, in general, asnice as those generated in user interactive runs. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Low-Energy Asynchronous Memory Design </title>
<author> Jose A. Tierno Alain J. Martin </author>
<affiliation> California Institute of Technology </affiliation>
<address> Pasadena, CA 91125 </address>
<abstract> AbstractWe introduce the concept of energy per operation asa measure of performance of an asynchronous circuit.We show how to model energy consumption based onthe high-level language specification. This model is independent of voltage and timing considerations. Weapply this model to memory design. We show firsthow to dimension a memory array, and how to breakup this memory array into smaller arrays to minimizethe energy per access. We then show how to use cachememory and pre-fetch mechanisms to further reduceenergy per access. </abstract>
<keyword> Keywords: Low-energy, low-power, asynchronousdesign, memory design. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A General Approach toPerformance Analysis and Optimizationof Asynchronous Circuits </title>
<degree> Thesis by </degree><author> Tak Kwan Lee </author>
<degree> In Partial Fulfillment of the Requirementsfor the Degree ofDoctor of Philosophy </degree><affiliation> California Institute of Technology </affiliation>
<address> Pasadena, California </address>
<date> 1995(Submitted May 18, 1995) </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> From the Proceedings of the Second International Conference on Coordination Modelsand Languages, LNCS 1282, Springer, Berlin, 199746 </note>
<title> Checking Assumptions in ComponentDynamics at the Architectural Level </title>
<author> Paola Inverardi 1 , Alexander L. Wolf 2 , and Daniel Yankelevich 3 </author>
<affiliation> 1 Dipartimento di Matematica 2 Department of Computer Science  Universita di L'Aquila University of Colorado </affiliation>
<address> I-67010 L'Aquila, Italy Boulder, CO 80309 USA </address>
<affiliation> 3 Departmento de Computacion  Universidad de Buenos Aires </affiliation>
<address> Buenos Aires, Argentina </address>
<abstract> Abstract. A critical challenge faced by the developer of a software system is to understand whether the system's components correctly integrate. While type theory has provided substantial help in detecting andpreventing errors in mismatched static properties, much work remainsin the area of dynamics. In particular, components make assumptionsabout their behavioral interaction with other components, but currentlywe have only limited ways in which to state those assumptions and toanalyze those assumptions for correctness.We have begun to formulate a method that addresses this problem. Themethod operates at the architectural level so that behavioral integrationerrors, such as deadlock, can be revealed early in development. For eachcomponent, a specification is given both of its own interaction behaviorand of the assumptions that it makes about the interaction behavior ofthe external context in which it expects to operate. We have defined analgorithm that, given such specifications for a set of components, performs "adequacy" checks between the component context assumptionsand the component interaction behaviors. A configuration of a system ispossible if and only if a successful way of "matching" actual behaviorswith assumptions can be found. In effect, we are extending the usual notion of type checking to include the checking of behavioral compatibility. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> From the Proc. of the 1996 Inter. Conf. on Requirements Engineering, Colorado Springs, Colorado, April 15-18, 1996 </note>
<title> A Facilitator Method for Upstream Design Activitieswith Diverse Stakeholders </title>
<author> Regina M. Gonzales and Alexander L. Wolf </author>
<affiliation> Software Engineering Research Laboratory  Department of Computer Science  University of Colorado </affiliation>
<address> Boulder, CO 80309 USA </address>
<email> fregina.gonzales,alwg@cs.colorado.edu </email>
<abstract> AbstractThis paper presents a method that can be used forthe elicitation and specification of requirements andhigh-level design. It supports stakeholder-based modeling, rapid feasibility feedback to marketing, and theinterpersonal dynamics that are necessary to developa product. The method centers on the role of the facilitator, an independent agent whose purpose is to buildthe Integrated System Model (ISM). The ISM is the result of merging the independent system views from allstakeholders at any given abstraction level. Formulation of this method was based on the real-world experience of developing a complex, high-technology medicalproduct with critical time-to-market pressures. It hasproven to be a practical approach to the evolution ofrequirements definition and provides a necessary linkto the marketing aspect of a product. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in the Proc. of the 1998 Inter. Conf. on Software Maintenance, Bethesda, Maryland, USA, November 1998 </note>
<title> Evaluating Software Deployment Languages and SchemaAn Experience Report </title>
<author> Richard S. Hall, Dennis M. Heimbigner, Alexander L. Wolf </author>
<affiliation> Department of Computer Science  University of Colorado </affiliation>
<address> Boulder, CO 80309 USA </address>
<email> frickhall,dennis,alwg@cs.colorado.edu </email>
<abstract> AbstractSoftware distribution is evolving from a physical mediaapproach to one where it is practical and advantageous toleverage the connectivity of networks. Network distribution of software systems provides timeliness and continuityof evolution not possible with physical media distributionmethods. To support network-based software distribution,companies and organizations such as Microsoft, Marimba,and the Desktop Management Task Force (DMTF) arestrengthening their efforts to package software systems ina way that is conducive to network distribution and management. The result of these efforts has led to the creationof software description languages and schema such as theOpen Software Description format created by Microsoft andMarimba and the Management Information Format createdby DMTF. While these efforts are steps in the right direction, they do not address deployment issues in a completeand systematic fashion. The contribution of this paper is toevaluate these leading software description technologies. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> DIMACS Series in Discrete Mathematicsand Theoretical Computer ScienceVolume 00, 19xx </note>
<title> Global Optimization Methods for Protein Folding Problems </title>
<author> Richard H. Byrd, Elizabeth Eskow, Andre van der Hoek, Robert B.Schnabel, Chung-Shang Shao, and Zhihong Zou </author>
<abstract> Abstract. The problem of finding the naturally occurring structure of a protein is believed to correspond to minimizing the free, or potential, energy ofthe protein. This is generally a very difficult global optimization problem, witha large number of parameters and a huge number of local minimizers including many with function values near that of the global minimizer. This paperpresents a new global optimization method for such problems. The methodconsists of an initial phase that locates some reasonably low local minimizers ofthe energy function, followed by the main phase that progresses from the bestcurrent local minimizers to even lower local minimizers. The method combinesportions that work on small subsets of the parameters, including small-scaleglobal optimizations using stochastic methods, with local minimizations involving all the parameters. In computational tests on the protein polyalaninewith up to 58 amino acids (116 internal parameters), the method appears tobe very successful in finding the lowest energy structures. The largest caseis particularly significant because the lowest energy structures that are foundinclude ones that exhibit interesting tertiary as opposed to just secondarystructure. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Does Configuration Management Research Have a Future? </title>
<author> Andre van der Hoek, Dennis Heimbigner, and Alexander L. Wolf </author>
<affiliation> Department of Computer Science, CB 430   University of Colorado </affiliation>
<address> Boulder, Colorado 80309 USA </address>
<email> fandre,dennis,alwg@cs.colorado.edu </email>
<abstract> AbstractIn this position paper we raise the question of whether Configuration Management (CM)research has a future. The new standard in CM systems|typified by commercial productssuch as Adele, ADC, ClearCase, Continuus/CM, and CCC/Harvest|largely satisfies the CMfunctionality requirements posed by Dart. This implies that research in the area of CM is eitherunnecessary or that we must find new challenges in CM on which to focus. We believe thatthese challenges indeed exist. Here we present some areas that we feel are good opportunitiesfor new or continued CM research, and therefore conclude that CM research does have a future. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Markov Decision Processes in Large State Spaces </title>
<author> Lawrence K. Saul and Satinder P. Singh </author>
<email> lksaul@psyche.mit.edu, singh@psyche.mit.edu </email>
<affiliation> Center for Biological and Computational Learning  Massachusetts Institute of Technology </affiliation>
<address> 79 Amherst Street, E10-243Cambridge, MA 02139 </address>
<abstract> AbstractIn this paper we propose a new framework forstudying Markov decision processes (MDPs),based on ideas from statistical mechanics. Thegoal of learning in MDPs is to find a policythat yields the maximum expected return overtime. In choosing policies, agents must therefore weigh the prospects of short-term versuslong-term gains. We study a simple MDP inwhich the agent must constantly decide between exploratory jumps and local reward mining in state space. The number of policies tochoose from grows exponentially with the sizeof the state space, N . We view the expected returns as defining an energy landscape over policy space. Methods from statistical mechanicsare used to analyze this landscape in the thermodynamic limit N ! 1. We calculate theoverall distribution of expected returns, as wellas the distribution of returns for policies at afixed Hamming distance from the optimal one.We briefly discuss the problem of learning optimal policies from empirical estimates of theexpected return. As a first step, we relate ourfindings for the entropy to the limit of high-temperature learning. Numerical simulationssupport the theoretical results. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> As appears in Neural Information Processing Systems 4, pp. 251-258, 1992. </note>
<title> The Efficient Learning of Multiple TaskSequences </title>
<author> Satinder P. Singh </author>
<affiliation> Department of Computer Science  University of Massachusetts </affiliation>
<address> Amherst, MA 01003 </address>
<abstract> AbstractI present a modular network architecture and a learning algorithm basedon incremental dynamic programming that allows a single learning agentto learn to solve multiple Markovian decision tasks (MDTs) with significant transfer of learning across the tasks. I consider a class of MDTs,called composite tasks, formed by temporally concatenating a number ofsimpler, elemental MDTs. The architecture is trained on a set of composite and elemental MDTs. The temporal structure of a composite task isassumed to be unknown and the architecture learns to produce a temporal decomposition. It is shown that under certain conditions the solutionof a composite MDT can be constructed by computationally inexpensivemodifications of the solutions of its constituent elemental MDTs. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Simple Algorithm for Nearest Neighbor Searchin High Dimensions </title>
<author> Sameer A. Nene and Shree K. Nayar </author>
<affiliation> Department of Computer Science  Columbia University </affiliation>
<address> New York, N.Y. 10027 </address>
<date> October, 1995 </date>
<pubnum> Technical Report No. CUCS-030-95 </pubnum>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Telecentric Optics for Computational Vision </title>
<author> Masahiro Watanabe and Shree K. Nayar </author>
<affiliation> Department of Computer Science,   Columbia University </affiliation>
<address> New York, N.Y. 10027 </address>
<abstract> AbstractA novel approach to constant-magnification imaging is proposed. Magnification variations due tochanges in focus setting pose problems for importantvision techniques, such as, depth from defocus. Itis shown that magnification of a conventional lenscan be made invariant to defocus by simply addingan aperture at an analytically derived location. Theresulting optical configuration is called "telecentric."It is shown that most commercially available lensescan be turned into telecentric ones. The procedurefor calculating the position of the additional apertureand a detailed analysis of the photometric and geometric properties of telecentric lenses are discussed.The magnification invariance of telecentric optics andits application to the problem of depth from defocusare experimentally demonstrated in [ Watanabe andNayar-1995 ] . The proposed optics was found to result in significantly improved depth maps than thoseobtained using a conventional lens. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Extruded Generalized Cylinder: A Deformable Model forObject Recovery </title>
<author> Thomas O'Donnell ? Xi-Sheng Fang ?Terrence E. Boult ? Alok Gupta  </author>
<affiliation> ? Dept. of Computer Science Siemens Corporate Research, Inc.  Columbia University </affiliation>
 <address> 755 College Road EastNew York, N.Y. 10027 Princeton, N.J. 08540 </address>
<email> Email: odonnell@cs.columbia.edu alok@scr.siemens.com </email>
<date> February 12, 1997 </date>
<abstract> AbstractThere is increasing interest in the recovery of generalized cylinders (GCs) with curved spines. However,existing formulations of such GCs, for example thosebased on the Frenet-Serret frame or the tube model,suffer serious drawbacks: discontinuities, a lack of expressive power, "narrowing" in the plane normal tothe spine, non-intuitive twisting behavior, and/or off-axis nonorthogonality of their local coordinate systems.We discuss some of the problems associated with thenon-orthogonality of the coordinate system based onthe Frenet-Serret frame. This non-orthogonality is induced by torsion effects and we show how to correct forit. We then introduce a new model, the extruded GC(EGC) model, which overcomes all the problems mentioned above. For complex axes, the EGC model is alsosimpler to understand and use than existing models.The EGC model is further extended by including local surface deformations. Recovery of the deformableEGC via a physically-motivated paradigm is demonstrated on pre-segmented data from a human carotidartery. </abstract>
<intro> 1 Introduction and Previous </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The complexity of multivariate elliptic problems with analytic data </title>
<pubnum> Technical Report CUCS-016-94 </pubnum>
<author> Arthur G. Werschulz </author>
<affiliation> Division of Science and Mathematics,   Fordham University </affiliation>
<address> College at Lincoln CenterNew York, NY 10023 </address>
<affiliation> andDepartment of Computer Science  Columbia University </affiliation>
<address> New York, NY 10023 </address>
<date> June 28, 1994 </date>
<abstract> Abstract. Let F be a class of functions defined on a d-dimensional domain. Our task isto compute H m -norm "-approximations to solutions of 2mth-order elliptic boundary-valueproblems Lu = f for a fixed L and for f 2 F . We assume that the only information wecan compute about f 2 F is the value of a finite number of continuous linear functionalsof f, each evaluation having cost c(d). Previous work has assumed that F was the unitball of a Sobolev space H r of fixed smoothness r, and it was found that the complexity ofcomputing an "-approximation was comp("; d) = fi(c(d)(1=") d=(r+m) ). Since the exponentof 1=" depends on d, we see that the problem is intractable in 1=" for any such F of fixedsmoothness r. In this paper, we ask whether we can break intractability by letting F be theunit ball of a space of infinite smoothness. To be specific, we let F be the unit ball of aHardy space of analytic functions defined over a complex d-dimensional ball of radius greaterthan one. We then show that the problem is tractable in 1=". More precisely, we prove thatcomp("; d) = fi(c(d)(ln 1=") d ), where the fi-constant depends on d. Since for any p &amp;gt; 0, thereis a function K() such that comp("; d) c(d)K(d)(1=") p for sufficiently small ", we see thatthe problem is tractable, with (minimal) exponent 0. Furthermore, we show how to constructa finite element p-method (in the sense of Babuska) that can compute an "-approximationwith cost fi(c(d)(ln 1=") d ). Hence this finite element method is a nearly optimal complexityalgorithm for d-dimensional elliptic problems with analytic data. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Predictive Dynamic Load Balancing of Parallel and Distributed Ruleand Query Processing  </title>
<author>  Hasanat M. Dewan Salvatore J. Stolfo Mauricio Hernandez Jae-Jun Hwang </author>
<affiliation> Department of Computer Science  Columbia University, </affiliation>
 <address>  New York, NY 10027 </address>
<pubnum> CUCS-025-94 </pubnum>
<note> (This paper appeared in the Proceedings of the 1994 ACM SIGMOD Conference.) </note>
<abstract> AbstractExpert Databases are environments that support the processing of rule programs against a disk resident database.They occupy a position intermediate between active and deductive databases, with respect to the level of abstractionof the underlying rule language. The operational semanticsof the rule language influences the problem solving strategy,while the architecture of the processing environment determines efficiency and scalability.In this paper, we present elements of the PARADISERarchitecture and its kernel rule language, PARULEL. ThePARADISER environment provides support for parallel anddistributed evaluation of rule programs, as well as staticand dynamic load balancing protocols that predictivelybalance a computation at runtime. This combination offeatures results in a scalable database rule and complexquery processing architecture. We validate our claims byanalyzing the performance of the system for two realistictest cases. In particular, we show how the performance of aparallel implementation of transitive closure is significantlyimproved by predictive dynamic load balancing. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Foundation for Multi-Dimensional Databases </title>
<author> Marc Gyssens </author>
<affiliation> Department WNI  University of Limburg (LUC) </affiliation>
<address> B-3590 Diepenbeek, Belgium. </address>
<email> gyssens@charlie.luc.ac.be </email>
<author> Laks V.S. Lakshmanan </author>
<affiliation> Department of Computer Science  Concordia University </affiliation>
<address> Montreal, Quebec H3G 1M8, Canada </address>
<email> laks@cs.concordia.ca </email>
<abstract> AbstractWe present a multi-dimensional database model,which we believe can serve as a conceptual modelfor On-Line Analytical Processing (OLAP)-basedapplications. Apart from providing the functionalities necessary for OLAP-based applications, themain feature of the model we propose is a clearseparation between structural aspects and the contents. This separation of concerns allows us to define data manipulation languages in a reasonablysimple, transparent way. In particular, we showthat the data cube operator can be expressed easily. Concretely, we define an algebra and a calculusand show them to be equivalent. We conclude bycomparing our approach to related work.The conceptual multi-dimensional database modeldeveloped here is orthogonal to its implementation, which is not a subject of the present paper. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Submitted for review to Discrete and Computational Geometry, September 1997. </note>
<title> On the Area Bisectors of a Polygon </title>
<author> Karl-Friedrich Bohringer  </author>
<affiliation> Cornell University </affiliation>
<author> Bruce Randall Donald  </author>
<affiliation> Dartmouth College </affiliation>
<author> Dan Halperin x </author>
<affiliation> Tel Aviv University </affiliation>
<abstract> AbstractWe consider the family of lines that are area bisectors of a polygon (possibly withholes) in the plane. We say that two bisectors of a polygon P are combinatoriallydistinct if they induce different partitionings of the vertices of P . We derive an algebraiccharacterization of area bisectors. We then show that there are simple polygons with nvertices that have (n 2 ) combinatorially distinct area bisectors (matching the obviousupper bound), and present an output-sensitive algorithm for computing an explicitrepresentation of all the bisectors of a given polygon. Our study is motivated by thedevelopment of novel, flexible feeding devices for parts positioning and orienting. Thequestion of determining all the bisectors of polygonal parts arises in connection withthe development of efficient part positioning strategies when using these devices. </abstract>
<note>  Work on this paper by Karl-Friedrich Bohringer and Bruce Randall Donald has been supported inpart by the National Science Foundation under grants No. IRI-8802390, IRI-9000532, IRI-9201699, andby a Presidential Young Investigator award to Bruce Donald, in part by NSF/ARPA Special Grant forExperimental Research No. IRI-9403903, and in part by the Air Force Office of Sponsored Research, theMathematical Sciences Institute, Intel Corporation, and AT&amp;T Bell laboratories. Work on this paper byDan Halperin has been supported in part by an Alon Fellowship, by ESPRIT IV LTR Project No. 21957(CGAL), by the USA-Israel Binational Science Foundation, and by the Hermann Minkowski - MinervaCenter for Geometry at Tel Aviv University. A preliminary and abridged version of the paper appeared inproc. 13th ACM Symp. on Computational Geometry, Nice, 1997, pp. 457-459. </note>
<affiliation> Robotics &amp; Vision Laboratory,   Department of Computer Science,   Cornell University. </affiliation>
 <address> Author's currentaddress: </address>
 <affiliation> ALPHA laboratory,   Dept. of Ind. Eng. and Op. Research,   University of California, Berkeley. </affiliation>
 <email>  Emailaddress: karl@IEOR.Berkeley.EDU. </email>
<affiliation> Dept. of Computer Science,   Dartmouth College, </affiliation>
 <address> 6211 Sudikoff Laboratory, Hanover, NH 03755-3510. </address>
 <email> brd@cs.dartmouth.edu, </email>
 <web> http://www.cs.dartmouth.edu/ brd/. </web><affiliation> x Department of Computer Science,   Tel Aviv University, </affiliation>
 <address> Tel Aviv 69978, ISRAEL. </address>
 <email> Email address:halperin@math.tau.ac.il. </email>
 <note> Part of the work on this paper was carried out while D.H. was at the RoboticsLaboratory, Department of Computer Science, Stanford University. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Numerical conformal mapping using cross-ratiosand Delaunay triangulation </title>
<author> Tobin A. Driscoll Stephen A. Vavasis  </author>
<date> January 23, 1996 </date>
<abstract> AbstractWe propose a new algorithm for computing the Riemann mapping of theunit disk to a polygon, also known as the Schwarz-Christoffel transformation.The new algorithm, CRDT, is based on cross-ratios of the prevertices, and alsoon cross-ratios of quadrilaterals in a Delaunay triangulation of the polygon.The CRDT algorithm produces an accurate representation of the Riemannmapping even in the presence of arbitrary long, thin regions in the polygon,unlike any previous conformal mapping algorithm. We believe that CRDT cannever fail to converge to the correct Riemann mapping, but the correctness andconvergence proof depend on conjectures that we have so far not been able toprove. We demonstrate convergence with computational experiments.The Riemann mapping has applications to problems in two-dimensionalpotential theory and to finite-difference mesh generation. We use CRDT toproduce a mapping and solve a boundary value problem on long, thin regionsfor which no other algorithm can solve these problems. </abstract>
<intro> 1 Conformal mapping </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Asymptotically Tight Bounds for PerformingBMMC Permutations on Parallel Disk Systems </title>
<author> Thomas H. CormenThomas SundquistLeonard F. Wisniewski </author>
<affiliation> Department of Mathematics and Computer Science  Dartmouth College </affiliation>
<abstract> AbstractWe give asymptotically equal lower and upper bounds for the number of parallel I/O operations required to perform bit-matrix-multiply/complement (BMMC) permutations on paralleldisk systems. In a BMMC permutation on N records, where N is a power of 2, each (lg N )-bitsource address x maps to a corresponding (lg N)-bit target address by the matrix equation= A x c, where matrix multiplication is performed over GF (2). The characteristic matrix Ais (lg N )fi(lg N ) and nonsingular over GF (2). Under the Vitter-Shriver parallel-disk model withN records, D disks, B records per block, and M records of memory, we show a universal lowerbound of BD1 + rank lg(M=B)parallel I/Os for performing a BMMC permutation, where is the lower left lg(N=B) fi lg B submatrix of the characteristic matrix. We also present an algorithm that uses at most 2NBDrank lg(M=B)+ 2parallel I/Os, which asymptotically matches thelower bound and improves upon the BMMC and bit-permute/complement (BPC) algorithms in[4]. When rank is low, this method is an improvement over the general-permutation bound offiNlg(N=B)We introduce a new subclass of BMMC permutations, called memoryload-dispersal (MLD)permutations, which can be performed in one pass. This subclass, which is used in the BMMCalgorithm, extends the catalog of one-pass permutations appearing in [4].Although many BMMC permutations of practical interest fall into subclasses that might beexplicitly invoked within the source code, we show how to detect in at most N=BD+lDparallel I/Os whether a given vector of target addresses specifies a BMMC permutation. Thus,one can determine efficiently at run time whether a permutation to be performed is BMMC andthen avoid the general-permutation algorithm and save parallel I/Os by using our algorithm. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> TIAS: A TransportableIntelligent Agent System </title>
<author> Kenneth E. Harker </author>
<degree> Senior Thesis </degree><affiliation> Department of Computer Science  Dartmouth College </affiliation>
<address> Hanover, NH 03755-3510 </address>
<pubnum> Dartmouth Technical Report: PCS-TR95-258 </pubnum>
<email> iago@cs.dartmouth.edu </email>
<date> 5 June 1995 </date>
<abstract> AbstractIn recent years, there has been an explosive growth in the amount ofinformation available to our society. In particular, the amount ofinformation available online through vast networks like the globalInternet has been growing at a staggering rate. This growth rate has by farexceeded the rate of growth in network speeds, as has the number ofindividuals and organizations seeking access to this information. There isthus a motivation to find abstract methods of manipulating this onlinedata in ways that both serve the needs of end users efficiently and usenetwork resources intelligently. In lieu of a traditional clientserver modelof information processing, which is both inflexible and potentially veryinefficient, a Transportable Intelligent Agent system has the potential toachieve a more efficient and flexible network system. An intelligent agentis a program that models the information space for a user, and allows theuser to specify how the information is to be processed. A transportableagent can suspend its execution, transport itself to a new location on anetwork, and resume execution at the new location. This is a particularlyattractive model for both wireless and dialup networks where a user mightnot be able to maintain a permanent network connection, as well as forsituations where the amount of information to be processed is largerelative to the network bandwidth. Preliminary work in the field hasshown that such agent systems are possible and deserve further study.This thesis describes a prototype transportable intelligent agent system thatextends work already done in the field. Agents are written in a modifiedversion of the Tcl programming language and transported using TCP/IPconnections. Several simple examples demonstrate the properties of thesystem. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in Parallel Computing, 1997. </note>
<note> Available at URL </note>
 <web> ftp://ftp.cs.dartmouth.edu/kotz/papers/nieuwejaar:jgalley.ps.Z </web><title> The Galley Parallel File System </title>
<author> Nils Nieuwejaar, David Kotz </author>
<email> fnils,dfkg@cs.dartmouth.edu </email>
<affiliation> Department of Computer Science,   Dartmouth College, </affiliation>
 <address> Hanover, NH 03755-3510 </address>
<abstract> Most current multiprocessor file systems are designed to use multiple disksin parallel, using the high aggregate bandwidth to meet the growing I/Orequirements of parallel scientific applications. Many multiprocessor filesystems provide applications with a conventional Unix-like interface, allowing the application to access multiple disks transparently. This interface conceals the parallelism within the file system, increasing the easeof programmability, but making it difficult or impossible for sophisticated programmers and libraries to use knowledge about their I/O needsto exploit that parallelism. In addition to providing an insufficient interface, most current multiprocessor file systems are optimized for a differentworkload than they are being asked to support. We introduce Galley, anew parallel file system that is intended to efficiently support realisticscientific multiprocessor workloads. We discuss Galley's file structure andapplication interface, as well as the performance advantages offered bythat interface. </abstract>
<keyword> Key words: Parallel I/O. Multiprocessor file system. Performance evaluation. IBMSP-2. Scientific Computing. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Increasing the Resilience ofDistributed and Replicated Database Systems  </title>
<author> Idit Keidar Danny Dolev  </author>
<affiliation> Institute of Computer Science,The Hebrew University of Jerusalem, </affiliation>
<address> Jerusalem, Israel, 91904 </address>
<email> E-mail: fidish,dolevg@cs.huji.ac.il </email>
<web> Url: http://www.cs.huji.ac.il/f~idish,~dolevg </web><abstract> AbstractThis paper presents a new atomic commitment protocol, enhanced three phase commit(E3PC ), that always allows a quorum in the system to make progress. Previously suggestedquorum-based protocols (e.g., the quorum-based three phase commit (3PC) [Ske82]) allow aquorum to make progress in case of one failure. If failures cascade, however, and the quorumin the system is "lost" (i.e., at a given time no quorum component exists), a quorum can laterbecome connected and still remain blocked. With our protocol, a connected quorum neverblocks. E3PC is based on the quorum-based 3PC [Ske82], and it does not require more timeor communication than 3PC. We describe how this protocol can be exploited in a replicateddatabase setting, making the database always available to a majority of the sites. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Relating Comprehension and Productionin the Acquisition of Morphology  </title>
<author> Michael Gasser </author>
<affiliation> Indiana University </affiliation>
<abstract> AbstractMost theories of language processing and acquisition make the assumption thatperception and comprehension are related to production, but few have anything sayabout how. This paper describes a performance-oriented connectionist model ofthe acquisition of morphology in which production builds on representations whichdevelop during the learning of word recognition. Using artificial language stimuliembodying simple suffixation, prefixation, and template rules, I demonstrate thatthe model generalizes to novel combinations of roots and inflections for both wordrecognition and production. I argue that the capacity of connectionist networks todevelop intermediate distributed representations which not only enable the solvingof the task at hand but also facilitate another task offers a plausible account of howcomprehension and production come to share phonological knowledge as words arelearned. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Algebra for List-Oriented Applications </title>
<author> Latha S. Colby  </author>
<affiliation> Department of Computer ScienceIndiana University </affiliation>
<address> Bloomington, IN, 47405 </address>
<email> colby@cs.indiana.edu </email>
<date> February 23, 1992 </date>
<abstract> AbstractMost data models and query languages, provide mechanisms for dealing with setsof objects. Many applications nowadays, however, are list-oriented, i.e., deal withcollections or aggregates of objects in which their order is important. A formal modeland an algebra for representing and manipulating list-oriented data are presented inthis paper. We also give the criteria that were used in the design of the algebra andshow how the algebra satisfies these criteria. </abstract>
<note> The author was supported by a grant from the Indiana Corporation for Science and Technology. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Coir: A Thread-Model for Supporting Task- and Data- Parallelismin Object-Oriented Parallel Languages </title>
<author> Neelakantan Sundaresan Dennis Gannon </author>
<email> nsundare@cs.indiana.edu gannon@cs.indiana.edu </email>
<affiliation> Computer Science Department </affiliation>
<address> 215 Lindley Hall </address>
<affiliation> Indiana University </affiliation>
<address> Bloomington, IN 47405 </address>
<abstract> AbstractData- and task-parallelism are two important parallel programming models. Object-oriented paradigmin parallelism provides a good way of abstracting out various aspects of computations and computing resources. Using an object-oriented language like C++, one can compose data and control representationsinto a single active object.We propose a thread model of parallelism that addresses both data and task parallelism. Computationand communication can be overlapped by suspending a thread of computation which is waiting for anevent and running an eligible thread of computation in its place. Threads naturally subsume task-parallelism. Threads are encapsulated into thread objects may be grouped into rope objects [22, 20], thatspan the parallel machine domain, for collective computation and communication. Thus data-parallelismcan be supported. Since rope objects are parallel objects, they can be customized, interestingly, in aserial or a parallel manner. Spatial transparency of objects is achieved by global pointer templates.We present results from a prototype system running on the SGI Challenge and the Intel Paragon. </abstract>
<keyword> keywords: task-parallelism, data-parallelism, thread, rope, object-oriented paradigm </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Detecting Global Predicates in Distributed Systems with Clocks </title>
<author> Scott D. Stoller  </author>
<affiliation> Dept. of Computer Science, Indiana University, </affiliation>
 <address> Bloomington, IN 47405, USA </address>
<date> 29 June 1997 </date>
<abstract> AbstractThis paper proposes a framework for predicate detection in systems of processes with approximately-synchronized real-time clocks. Timestamps from these clocks are used to define two orderings onevents: "definitely occurred before" and "possibly occurred before". These orderings lead naturallyto definitions of 3 distinct detection modalities, i.e., 3 meanings of "predicate held during a computation", namely: Poss T (" possibly held"), Def T (" definitely held"), and Inst ("definitely held at a specific instant"). This paper defines these modalities and gives efficient algorithms for detecting them; the algorithms are based on algorithms of Cooper and Marzullo, Gargand Waldecker, and Fromentin and Raynal. </abstract>
<keyword> Keywords: global predicate detection, consistent global states, partially-synchronous systems, distributed debugging, real-time monitoring </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Finding Genes in DNA with a Hidden Markov Model </title>
<author> John Henderson Steven Salzberg Kenneth H. Fasman  </author>
<date> Jan. 31, 1996, revised Aug. 28, 1996 </date>
<abstract> AbstractThis study describes a new Hidden Markov Model (HMM) system for segmenting uncharacterized genomic DNA sequences into exons, introns, and intergenicregions. Separate HMM modules were designed and trained for specific regions ofDNA: exons, introns, intergenic regions, and splice sites. The models were thentied together to form a biologically feasible topology. The integrated HMM wastrained further on a set of eukaryotic DNA sequences, and tested by using it tosegment a separate set of sequences. The resulting HMM system, which is calledVEIL (Viterbi Exon-Intron Locator), obtains an overall accuracy on test data of92% of total bases correctly labelled, with a correlation coefficient of 0.68. Using the more stringent test of exact exon prediction, VEIL correctly located bothends of 46% of the exons. Moreover, more than 50% of the exons it predicts areexactly correct. These results compare favorably to the best previous results forgene structure prediction, and demonstrate the benefits of using HMMs for thisproblem. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Feedback Mechanism for Query by Navigation </title>
<author> F.C. Berger Th.P. van der Weide n </author>
<note> Published as: </note>
 <author> F.C. Berger and Th.P. van derWeide. </author>
 <title> A Feedback Mechanism for Query byNavigation. </title>
 <pubnum> Technical Report CSI-R9413, </pubnum>
<affiliation> Computing Science Institute, University of Nijmegen, </affiliation>
<address> Nijmegen, The Netherlands, </address>
 <date> October 1994. </date>
<abstract> AbstractThe Two-Level Hypermedia Paradigm sees anInformation Retrieval System as consisting ofa document network (the Hyperbase) and adescriptor (term) network (the Hyperindex).Query by Navigation is a process whereby thesearcher gives a description of the Information Need by travelling through the descriptornetwork. This paper presents a formalism forexpressing the effects of traversing the Hyper-index on the elements of the Hyperindex. Thisformalism makes use of probabilities for mod-elling the searcher's behavious. The eventswhich can occur during the search processare discussed and modelled. Some importantproperties, which are reasonable to demand ofa retrieval system, can be proven to be validif this formalism is adopted. A mechanismfor assigning a measure of relevance to documents is presented. This uses the formalismmentioned above. An example will show theeffectiveness of The aspect of relevance feedback and its role in Query by Navigation isintroduced by examining the different level onwhich the searcher can offer information forweeding out unwanted sections of the searchspace. In order to illustrate the workings ofQuery by Navigation a small example is included. </abstract>
<affiliation> Dept. of Information Systems, Faculty of Mathematics andInformatics, University of Nijmegen, </affiliation>
 <address> Toernooiveld 1, 6525 EDNijmegen, The Netherlands </address>
<keyword> Keywords: information retrieval, relevance feedback, user modelling, query formulation </keyword>
<note> Classification: AMS 68P20; CR H.3.3, H.5.1 </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Unifying FrameworkforConceptual Data Modelling Concepts </title>
<author> P.J.M. Frederiks, A.H.M. ter Hofstede, E. Lippe </author>
<affiliation> Department of Information SystemsUniversity of Nijmegen </affiliation>
<address> Toernooiveld 1NL-6525 ED NijmegenThe Netherlands </address>
<email> fpaulf,arthur,ernstlg@cs.kun.nl </email>
<note> Published as: </note>
 <author> P.J.M. Frederiks, A.H.M. ter Hofstede, and E. Lippe. </author>
 <title> A Unifying Frameworkfor Conceptual Data Modelling Concepts. </title>
 <pubnum> Technical Report CSI-R9410, </pubnum>
<affiliation> Computing ScienceInstitute, University of Nijmegen, </affiliation>
 <address> Nijmegen, The Netherlands, </address>
 <date> September 1994. </date>
<abstract> AbstractFor succesful information systems development, conceptual data modelling is essential.Nowadays many techniques for conceptual data modelling exist, examples are NIAM, FORM,PSM, many (E)ER variants, IFO, and FDM. In-depth comparisons of concepts of these techniques is very difficult as the mathematical formalisations of these techniques, if existing atall, are very different. As such there is a need for a unifying formal framework providing asufficiently high level of abstraction. In this paper the use of category theory for this purposeis addressed. Well-known conceptual data modelling concepts are discussed from a categorytheoretic point of view. Advantages and disadvantages of the approach chosen will be outlined. </abstract>
<keyword> Keywords: Conceptual Data Modelling, Category Theory, Meta Modelling </keyword>
<note> Classification: 68P99 (AMS-1991), H.1.0. (CR-1991) </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Autonomous Acquisition ofSensor-Motor Couplings in Robots </title>
<author> Ulrich Nehmzow </author>
<pubnum> Technical Report UMCS-94-11-1 </pubnum>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Middle Scale Robot Navigation A Case Study </title>
<author> Carl Owen and Ulrich Nehmzow </author>
<affiliation> Department of Computer ScienceUniversity of Manchester </affiliation>
<address> Manchester M13 9PLUnited Kingdom </address>
<email> owenc@cs.man.ac.uku.nehmzow@cs.man.ac.uk </email>
<date> 7/4/97 </date>
<abstract> AbstractIn this paper we present results of experiments carried out with a route learning system for amobile robot, conducted in a `real world' environment covering distances of several hundred metres.The system uses no odometry and is based on a self-organising mapbuilding process using perceptuallandmarks.A performance metric is defined and used to measure the robot's ability to traverse the route. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Animal and Robot Navigation </title>
<author> Ulrich Nehmzow </author>
<affiliation> Department of Computer ScienceManchester University </affiliation>
<address> Manchester M13 9PLUnited Kingdom </address>
<email> u.nehmzow@cs.man.ac.uk </email>
<abstract> AbstractIt is argued that the following three properties are foundations of robust robotnavigation:* The use of landmarks (and, in particular, the use of a compass sense),* the use of canonical paths, and* the use of topological rather than geometrical maps.Some examples of successful animal navigation are presented that support this view.We have performed initial experiments with mobile robots to investigate mechanismssuitable to implement such navigational architectures. Experiments concerning navigation by dead reckoning are presented, and a differential light compass is introducedto aid robot navigation. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Error-Correcting Output Codes:A General Method for ImprovingMulticlass Inductive Learning Programs </title>
<author> Thomas G. Dietterich and Ghulum Bakiri </author>
<affiliation> Department of Computer ScienceOregon State University </affiliation>
<address> Corvallis, OR 97331-3202 </address>
<abstract> AbstractMulticlass learning problems involve finding a definition for an unknown function f(x) whose range is adiscrete set containing k &amp;gt; 2 values (i.e., k "classes").The definition is acquired by studying large collectionsof training examples of the form hx i ; f(x i )i. Existingapproaches to this problem include (a) direct application of multiclass algorithms such as the decision-treealgorithms ID3 and CART, (b) application of binaryconcept learning algorithms to learn individual binaryfunctions for each of the k classes, and (c) applicationof binary concept learning algorithms with distributedoutput codes such as those employed by Sejnowski andRosenberg in the NETtalk system. This paper compares these three approaches to a new technique inwhich BCH error-correcting codes are employed as adistributed output representation. We show that theseoutput representations improve the performance of ID3on the NETtalk task and of backpropagation on anisolated-letter speech-recognition task. These resultsdemonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclassproblems. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Bezier Nets, Convexity and Subdivision on HigherDimensional Simplices </title>
<author> Tim Goodman </author>
<affiliation> Department of Mathematicsand Computer SciencesThe University of Dundee </affiliation>
<address> Dundee DD1 4HN, Scotland </address>
<author> Jorg Peters 1 </author>
<affiliation> Department of Computer SciencesPurdue University </affiliation>
<address> W-Lafayette, IN 47907-1398USA </address>
<date> October 26, 1994 </date>
<note> 1 supported by NSF grant 9396164-CCR </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Analysis of Algorithms Generalizing B-SplineSubdivision </title>
<author> Jorg Peters Ulrich Reif  </author>
<date> January 27, 1997 </date>
<abstract> AbstractA new set of tools for verifying smoothness of surfaces generated by stationarysubdivision algorithms is presented. The main challenge here is the verification ofinjectivity of the characteristic map. The tools are sufficiently versatile and easyto wield to allow, as an application, a full analysis of algorithms generalizing bi-quadratic and bicubic B-spline subdivision. In the case of generalized biquadraticsubdivision the analysis yields a hitherto unknown sharp bound strictly less thanone on the second largest eigenvalue of any smoothly converging subdivision. </abstract>
<keyword> Keywords: subdivision, arbitrary topology, characteristic map, Doo-Sabin Algorithm, Catmull-Clark algorithm, B-spline </keyword>
<note>  AMS subject classification: 65D17, 65D07, 68U07 Abbreviated title: Generalized B-Spline Subdivision </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Performance of Temporal Reasoning Systems </title>
<author> Ed Yampratoom James F. Allen </author>
<affiliation> The University of RochesterComputer Science Department </affiliation>
<address> Rochester, New York 14627 </address>
<pubnum> TRAINS Technical Note 93-1 </pubnum>
<date> May 1993 </date>
<abstract> AbstractThis paper describes the performance evaluation of six temporal reasoning systems.We show that if you are working with large temporal datasets where informationis added incrementally throughout the execution of the program, systems using incompletely connected graphs (i.e., TMM, TimeGraph and TimeGraph-II) seem thebest option. While they do not offer the constant query time of systems using fullyconnected graphs (i.e. the systems based on constraint satisfaction), the savings atassertion time are so substantial that the relatively small performance penalty forqueries is a reasonable tradeoff. Of course, these systems do not offer the expressivity of the interval-based systems as they only handle point-based relations. Of thethree, TimeGraph-II offers a wider range of qualitative relations as it handles pointinequality. It does not currently handle metric information, however, as do TMMand TimeGraph. Thus decisions between these three may be more determined by thereasoning capabilities required rather than raw performance.This material is based upon work supported in part by U.S. Air Force-Rome Laboratory researchcontract no. F30602-91-C-0010. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Utterance Units in Spoken Dialogue </title>
<author> David R. Traum 1 and Peter A. Heeman 2 </author>
<abstract> Abstract. In order to make spoken dialogue systems more sophisticated, designers need to better understand the conventions that peopleuse in structuring their speech and in interacting with their fellow con-versants. In particular, it is crucial to discriminate the basic buildingblocks of dialogue and how they affect the way people process language. Many researchers have proposed the utterance unit as theprimary object of study, but defining exactly what this is has remained a difficult issue. To shed light on this question, we considergrounding behavior in dialogue, and examine co-occurrences betweenturn-initial grounding acts and utterance unit signals that have beenproposed in the literal, namely prosodic boundary tones and pauses.Preliminary results indicate high correlation between grounding andboundary tones, with a secondary correlation for longer pauses. Wealso consider some of the dialogue processing issues which are impacted by a definition of utterance unit. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Tally NP Sets and Easy Census Functions </title>
<author> Judy Goldsmith 1 </author>
<affiliation> Department of Computer ScienceUniversity of Kentucky </affiliation>
<address> Lexington, KY 40506, USA </address>
<email> goldsmit@cs.engr.uky.edu </email>
<author> Mitsunori Ogihara 2 </author>
<affiliation> Department of Computer ScienceUniversity of Rochester </affiliation>
<address> Rochester, NY 14627, USA </address>
<email> ogihara@cs.rochester.edu </email>
<author> Jorg Rothe 3 </author>
<affiliation> Institut fur InformatikFriedrich-Schiller-Universitat Jena </affiliation>
<address> 07740 Jena, Germany </address>
<email> rothe@informatik.uni-jena.de </email>
<date> March 19, 1998 </date>
<note> 1 Supported in part by NSF grant CCR-9315354.2 Supported in part by NSF CAREER Award CCR-9701911.3 Supported in part by grants NSF-INT-9513368/DAAD-315-PRO-fo-ab and NSF-CCR-9322513and by a NATO Postdoctoral Science Fellowship from the Deutscher Akademischer Austausch-dienst ("Gemeinsames Hochschulsonderprogramm III von Bund und Landern"). Current address:Department of Computer Science, University of Rochester, Rochester, NY 14627, USA. Work donein part while visiting the University of Kentucky and the University of Rochester. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Scalable Atomic Primitives for DistributedShared Memory Multiprocessors </title>
<note> (Extended Abstract) </note>
<author> Maged M. Michael </author>
<affiliation> Department of Computer ScienceUniversity of Rochester </affiliation>
<address> Rochester, NY 14627-0226USA </address>
<author> Michael L. Scott </author>
<affiliation> Department of Computer ScienceUniversity of Rochester </affiliation>
<address> Rochester, NY 14627-0226USA </address>
<abstract> AbstractOur research addresses the general topic of atomic update of shared datastructures on large-scale shared-memory multiprocessors. In this paperwe consider alternative implementations of the general-purpose single-address atomic primitives fetch and , compare and swap, load linked,and store conditional. These primitives have proven popular on small-scale bus-based machines, but have yet to become widely available onlarge-scale, distributed shared memory machines. We propose several alternative hardware implementations of these primitives, and then analyzethe performance of these implementations for various data sharing patterns. Our results indicate that good overall performance can be obtainedby implementing compare and swap in the cache controllers, and by providing an additional instruction to load an exclusive copy of a cache line. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> THE COMPLEXITY OF COMPUTINGMAXIMAL WORD FUNCTIONS </title>
<author> Eric Allender, Danilo Bruschiand Giovanni Pighizzini </author>
<abstract> Abstract. Maximal word functions occur in data retrieval applicationsand have connections with ranking problems, which in turn were firstinvestigated in relation to data compression [21]. By the "maximal wordfunction" of a language L , we mean the problem of finding, oninput x, the lexicographically largest word belonging to L that is smallerthan or equal to x.In this paper we present a parallel algorithm for computing maximalword functions for languages recognized by one-way nondeterministicauxiliary pushdown automata (and hence for the class of context-freelanguages).This paper is a continuation of a stream of research focusing on theproblem of identifying properties others than membership which areeasily computable for certain classes of languages. For a survey, see [24]. </abstract>
<note> Subject classifications. 68Q15,68Q25,68Q45. </note>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Priors for Infinite Networks </title>
<author> Radford M. Neal </author>
<pubnum> Technical Report CRG-TR-94-1 </pubnum>
<affiliation> Department of Computer ScienceUniversity of Toronto </affiliation>
<address> 10 King's College RoadToronto, Canada M5S 1A4 </address>
<email> E-mail: radford@cs.toronto.edu </email>
<date> 1 March 1994 </date>
<abstract> AbstractBayesian inference begins with a prior distribution for model parameters that ismeant to capture prior beliefs about the relationship being modeled. For multilayerperceptron networks, where the parameters are the connection weights, the priorlacks any direct meaning | what matters is the prior over functions computedby the network that is implied by this prior over weights. In this paper, I showthat priors over weights can be defined in such a way that the correspondingpriors over functions reach reasonable limits as the number of hidden units in thenetwork goes to infinity. When using such priors, there is thus no need to limit thesize of the network in order to avoid "overfitting". The infinite network limit alsoprovides insight into the properties of different priors. A Gaussian prior for hidden-to-output weights results in a Gaussian process prior for functions, which can besmooth, Brownian, or fractional Brownian, depending on the hidden unit activationfunction and the prior for input-to-hidden weights. Quite different effects can beobtained using priors based on non-Gaussian stable distributions. In networks withmore than one hidden layer, a combination of Gaussian and non-Gaussian priorsappears most interesting. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Generative Models for Discovering Sparse DistributedRepresentations </title>
<author> Geoffrey E. Hinton and Zoubin Ghahramani </author>
<affiliation> Department of Computer ScienceUniversity of Toronto </affiliation>
<address> Toronto, Ontario, M5S 1A4, Canada </address>
<email> hinton@cs.toronto.edu, zoubin@cs.toronto.edu </email>
<date> May 9, 1997 </date>
<note> A modified version to appear in Philosophical Transactions of the Royal Society B, 1997. </note>
<abstract> AbstractWe describe a hierarchical, generative model that can be viewed as a non-linear generalization of factor analysis and can be implemented in a neural network. The model usesbottom-up, top-down and lateral connections to perform Bayesian perceptual inference correctly. Once perceptual inference has been performed the connection strengths can be updatedusing a very simple learning rule that only requires locally available information. We demonstrate that the network learns to extract sparse, distributed, hierarchical representations. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in Jordan, MI, Kearns MJ, and Solla, SA Advances in Neural InformationProcessing Systems 10. MIT Press: Cambridge, MA, 1998. </note>
<title> Hierarchical Non-linear Factor Analysisand Topographic Maps </title>
<author> Zoubin Ghahramani and Geoffrey E. Hinton </author>
<affiliation> Dept. of Computer Science, University of Toronto </affiliation>
<address> Toronto, Ontario, M5S 3H5, Canada </address>
<web> http://www.cs.toronto.edu/neuron/ </web><email> fzoubin,hintong@cs.toronto.edu </email>
<abstract> AbstractWe first describe a hierarchical, generative model that can beviewed as a non-linear generalisation of factor analysis and canbe implemented in a neural network. The model performs perceptual inference in a probabilistically consistent manner by usingtop-down, bottom-up and lateral connections. These connectionscan be learned using simple rules that require only locally available information. We then show how to incorporate lateral connections into the generative model. The model extracts a sparse,distributed, hierarchical representation of depth from simplifiedrandom-dot stereograms and the localised disparity detectors inthe first hidden layer form a topographic map. When presentedwith image patches from natural scenes, the model develops topographically organised local feature detectors. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title>  Attentive Object Recognition in the Selective Tuning Network </title>
<author> byDavid C. Dolson </author>
<degree> A thesis submitted in conformity with the requirementsfor the degree of Master of Science </degree><affiliation> Graduate Department of Computer ScienceUniversity of Toronto </affiliation>
<note> c Copyright by David C. Dolson 1997 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Gap-Definable Counting Classes </title>
<author> Stephen A. Fenner  </author>
<affiliation> Computer Science DepartmentUniversity of Southern Maine </affiliation>
<address> 96 Falmouth StreetPortland, Maine 04103 </address>
<author> Lance J. Fortnow Stuart A. Kurtz </author>
<affiliation> Computer Science DepartmentUniversity of Chicago </affiliation>
<address> 1100 East Fifty-eighth StreetChicago, Illinois 60637 </address>
<date> July 12, 1992 </date>
<note> Work done while the first author was a graduate student at the University of Chicago Computer Science Department, supported in part by a University of Chicago Fellowship.Supported by NSF Grant CCR-9009936 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Evaluating Weak Memories with Maya </title>
<author> Divyakant Agrawal Manhoi Choy Hong Va Leong Ambuj K. Singh </author>
<affiliation> Department of Computer ScienceUniversity of California at Santa Barbara </affiliation>
<address> Santa Barbara, CA 93106 </address>
<abstract> AbstractMaya is a simulation platform for evaluating the performance of parallel programs on parallel architectures with different memory coherence protocols. Rapid prototyping of different memory protocolssupporting varying degrees of coherence is possible and the impact of these protocols on the performanceof application programs can be studied. Implementations of existing weak memories along with somenew primitives using Maya are presented. The results of running some user applications are summarizedand the impact of weak memories on the efficiency of parallel programs is discussed. </abstract>
<keyword> Keywords: distributed shared memory, memory consistency, parallel programming, weakmemories </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Q-Learning for Bandit Problems </title>
<author> Michael O. Duff </author>
<affiliation> Department of Computer ScienceUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003 </address>
<email> duff@cs.umass.edu </email>
<abstract> AbstractMulti-armed bandits may be viewed asdecompositionally-structured Markov decision processes (MDP's) with potentially very-large state sets. A particularly elegantmethodology for computing optimal policieswas developed over twenty ago by Gittins[Gittins &amp; Jones, 1974]. Gittins' approachreduces the problem of finding optimal policies for the original MDP to a sequence oflow-dimensional stopping problems whose solutions determine the optimal policy throughthe so-called "Gittins indices." Katehakisand Veinott [Katehakis &amp; Veinott, 1987] haveshown that the Gittins index for a processin state i may be interpreted as a particularcomponent of the maximum-value functionassociated with the "restart-in-i" process,a simple MDP to which standard solutionmethods for computing optimal policies, suchas successive approximation, apply. This paper explores the problem of learning the Git-tins indices on-line without the aid of a process model; it suggests utilizing process-state-specific Q-learning agents to solve their respective restart-in-state-i subproblems, andincludes an example in which the online reinforcement learning approach is applied toa problem of stochastic scheduling|one instance drawn from a wide class of problemsthat may be formulated as bandit problems. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Intra-Option Learning about Temporally Abstract Actions </title>
<author> Richard S. Sutton </author>
<affiliation> Department of Computer ScienceUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003-4610 </address>
<email> rich@cs.umass.edu </email>
<author> Doina Precup </author>
<affiliation> Department of Computer ScienceUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003-4610 </address>
<email> dprecup@cs.umass.edu </email>
<author> Satinder Singh </author>
<affiliation> Department of Computer ScienceUniversity of Colorado </affiliation>
<address> Boulder, CO 80309-0430 </address>
<email> baveja@cs.colorado.edu </email>
<abstract> AbstractSeveral researchers have proposed modelingtemporally abstract actions in reinforcementlearning by the combination of a policy and a termination condition, which we refer to as an option. Value functions over options and models ofoptions can be learned using methods designedfor semi-Markov decision processes (SMDPs).However, all these methods require an option tobe executed to termination. In this paper we explore methods that learn about an option fromsmall fragments of experience consistent withthat option, even if the option itself is not executed. We call these methods intra-option learning methods because they learn from experiencewithin an option. Intra-option methods are sometimes much more efficient than SMDP methods because they can use off-policy temporal-difference mechanisms to learn simultaneouslyabout all the options consistent with an experience, not just the few that were actually executed. In this paper we present intra-option learning methods for learning value functions over options and for learning multi-time models of theconsequences of options. We present computational examples in which these new methodslearn much faster than SMDP methods and learneffectively when SMDP methods cannot learn atall. We also sketch a convergence proof for intraoption value learning. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Humans Plus AgentsMaintain Schedules Betterthan Either Alone </title>
<author> Tim Oates and Paul R. Cohen </author>
<pubnum> Computer Science Technical Report 94-03 </pubnum>
<affiliation> Experimental Knowledge Systems LaboratoryDepartment of Computer Science, Box 34610Lederle Graduate Research CenterUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003-4610 </address>
<abstract> AbstractTracking and evaluating the progress of large, complex plans orschedules as they unfold in real time is extremely difficult for humans.In this paper we present a mixed-initiative system for the task of schedule maintenance in a simulated shipping network. A schedule maintenance agent monitors the network, predicting the occurrence of statesthat may result in reduced throughput and formulating schedule modifications to avoid those states. The goal is to maximize throughputwhile minimizing disruptions to the original schedule. We present results of experiments in which human subjects attempt to obtain thatgoal both with and without the aid of the agent. We found that the human and the agent working together are able to achieve better resultsthan either one working alone. In addition to looking at global performance measures such as throughput, we analyze individual schedulemodification decisions made by subjects in an attempt to assign creditfor the improvements in performance. </abstract>
<note> This research is supported by ARPA-AFOSR contract F30602-91-C-0076. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Design-to-time Real-Time Scheduling </title>
<author> Alan Garvey Victor Lesser </author>
<affiliation> Department of Computer ScienceUniversity of Massachusetts </affiliation>
<address> Amherst, Massachusetts 01003 </address>
<email> CSNET: GARVEY@CS.UMASS.EDU </email>
<date> April 14, 1994 </date>
<abstract> AbstractDesign-to-time is an approach to problem-solving in resource-constrained domains where:multiple solution methods are available for tasks, those solution methods make tradeoffs insolution quality versus time, and satisficing solutions are acceptable. Design-to-time involvesdesigning a solution to a problem that uses all available resources to maximize the solutionquality within the available time. This paper defines the design-to-time approach in detail,contrasting it to the anytime algorithm approach, and presents a heuristic algorithm for design-to-time real-time scheduling.Our blackboard architecture that implements the design-to-time approach is discussed andan example problem and solution from the Distributed Vehicle Monitoring Testbed (DVMT) isdescribed in detail. Experimental results, generated using a simulation, show the effects ofvarious parameters on scheduler performance. Finally we discuss future research goals andplans. </abstract>
<note> 1 This work was partly supported by the Office of Naval Research under a University Research Initiative </note>
</NEW_HEADER>
<NEW_HEADER>
<title> Issues in Design-to-time Real-time Scheduling </title>
<author> Alan Garvey </author>
<affiliation> Department of Computer SciencePacific Lutheran University </affiliation>
<address> Tacoma, WA 98447 </address>
<email> Email: garveyaj@plu.edu </email>
<author> Victor Lesser </author>
<affiliation> Computer Science DepartmentUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003 </address>
<email> Email: lesser@cs.umass.edu </email>
<abstract> AbstractDesign-to-time real-time scheduling is an alternative to the many flexible computation approaches that are based on anytime algorithms.It builds schedules at runtime that dynamicallycombine solutions to subproblems, taking advantage of the time available to achieve the bestresults it can. In this paper we look in detail ata few issues related to design-to-time, including where the approximations we rely on comefrom, how uncertainty affects the schedulingprocess and the interface between the sched-uler and its invoker. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Interprocedural Transformations for Parallel Code Generation </title>
<author> Mary W. Hall Ken Kennedy Kathryn S. M c Kinley </author>
<affiliation> Department of Computer Science, Rice University, </affiliation>
 <address> Houston, TX 77251-1892 </address>
<abstract> AbstractWe present a new approach that enables compileroptimization of procedure calls and loop nests containing procedure calls. We introduce two inter-procedural transformations that move loops across procedure boundaries, exposing them to traditional optimizations on loop nests. These transformations areincorporated into a code generation algorithm for ashared-memory multiprocessor. The code generator relies on a machine model to estimate the expected benefits of loop parallelization and parallelism-enhancingtransformations. Several transformation strategies areexplored and one that minimizes total execution time isselected. Efficient support of this strategy is providedby an existing interprocedural compilation system. Wedemonstrate the potential of these techniques by applying this code generation strategy to two scientificapplications programs. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Integrated Signal Processingand Signal Understanding 1 </title>
<author> Victor Lesser, Hamid Nawab ,Malini Bhandaru, Norman Carver,Zarko Cvetanovic, Izaskun Gallastegi,Frank Klassner </author>
<pubnum> COINS Technical Report 91-34 </pubnum>
<date> November 1991 </date>
<affiliation> Electrical and Computer Engineering Dept.Boston University </affiliation>
<address> 44 Cummington StreetBoston, Massachusetts 02125 </address>
<abstract> AbstractThis report outlines the IPUS paradigm, named for Integrated Processing and Understanding of Signals, which permits sophisticated interaction between theory-based problemsolving in signal processing and heuristic problem-solving in signal interpretation. The needfor such a paradigm arises in signal understanding domains that require the processing ofcomplicated interacting signals under variable signal-to-noise ratios. One such application issound understanding, in the context of which we report on a testbed experiment illustratingthe functionality of key IPUS architecture components. </abstract>
<note> 1 This work was supported by the Office of Naval Research under University Research Initiative </note>
</NEW_HEADER>
<NEW_HEADER>
<title> An Application of Distributed Solid Modeling: Feature Recognition </title>
<author> William C. Regli  </author>
<affiliation> National Institute of Standards and TechnologyManufacturing Systems Integration Division </affiliation>
<address> Building 220, Room A-127Gaithersburg, MD 20899 </address>
<email> regli@cme.nist.gov </email>
<author> Satyandra K. Gupta </author>
<affiliation> Mechanical Engineering DepartmentInstitute for Systems ResearchUniversity of Maryland </affiliation>
<address> College Park, MD 20742 USA </address>
<email> skgupta@src.umd.edu </email>
<author> Dana S. Nau </author>
<affiliation> Computer Science DepartmentInstitute for Advanced Computer StudiesInstitute for Systems ResearchUniversity of Maryland </affiliation>
<address> College Park, MD 20742 USA </address>
<email> nau@cs.umd.edu </email>
<note>  Available as CS-TR-3375, UMIACS-TR-94-126, ISR-TR 94-82. </note>
 <abstract> AbstractThe availability of low-cost computational power is a driving force behind the growing sophisticationof CAD software. Tools designed to reduce time-consuming build-test-redesign iterations are essentialfor increasing engineering quality and productivity. However, automation of the design process posesmany difficult computational problems. As more downstream engineering activities are being consideredduring the design phase, guaranteeing reasonable response times within design systems becomes problematic. Design is an interactive process and speed is a critical factor in systems that enable designers toexplore and experiment with alternative ideas during the design phase. Achieving interactivity requiresan increasingly sophisticated allocation of computational resources in order to perform realistic designanalyses and generate feedback in real time.This paper presents our initial efforts to develop techniques to apply distributed algorithms to theproblem of recognizing machining features from solid models. Existing work on recognition of featureshas focused exclusively on serial computer architectures. Our objective is to show that distributedalgorithms can be employed on realistic parts with large numbers of features and many geometric andtopological entities to obtain significant improvements in computation time using existing hardware andsoftware tools. Migrating solid modeling applications toward a distributed computing framework enablesinterconnection of many of the autonomous and geographically diverse software tools used in the modernmanufacturing enterprise.This has been implemented on a network of SUN workstations using the ACIS solid modeler and theNIH C++ class library; inter-processor communication is handled with TCP/IP-based network communication tools. </abstract>
<keyword> Keywords: Multiprocessor Solid Modeling, Feature Recognition, Feature-Based Modeling, DistributedComputing. </keyword>
<note> This work was supported in part by NSF Grants IRI9306580, DDM-9201779, EEC 94-02384 and a forgivable loan fromGeneral Electric Corporation awarded to the first author. Any opinions, findings, and conclusions or recommendations expressedin this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.Also affiliated with: Computer Science Department and Institute for Systems Research, University of Maryland, CollegePark. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> DTP: An Efficient Transport Protocol </title>
<author> Dheeraj Sanghi and Ashok K. Agrawala </author>
<affiliation> Department of Computer Science, University of Maryland, </affiliation>
 <address> College Park,MD 20742, USA </address>
<abstract> AbstractWe recently introduced a new flow control scheme, called send-time control, which isbased on a deterministic model of virtual circuits in a computer network. In this scheme,the time at which a packet is sent by a source is computed from estimates of round-triptime, traffic in the network and bottleneck service time. In this paper, we describe a newtransport protocol, called DTP, which uses send-time control as its flow control scheme.Preliminary measurements of coast-to-coast connections over the Internet show significantperformance improvement over TCP, which is the most commonly used transport protocolin the Internet today. </abstract>
<keyword> Keyword Codes: C.2.2Keywords: Computer-Communication Networks, Network Protocols </keyword>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> TR-1923 </pubnum>
<date> September 1987 </date>
<title> Invariant SubspacesandCapital Punishment(A Participatory Paper) </title>
<author> G. W. Stewart  </author>
<abstract> abstractThe notion of invariant subspaces is useful in a number of theoretical and practical applications. In this paper we give anelementary treatment of invariant subspaces that stresses theirconnection with simple eigenvalues and their eigenvectors. </abstract>
<affiliation> Department of Computer Science and Institute for Physical Science and Technology,University of Maryland, </affiliation>
 <address> College Park, MD 20742. </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A SERVER OF DISTRIBUTED DISK PAGESUSING A CONFIGURABLE SOFTWARE BUS </title>
<author> Charles Falkenberg, Paul Hagger and Steve Kelley </author>
<affiliation> Institute for Advanced Computer Studies andThe Department of Computer ScienceUniversity of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<abstract> ABSTRACTAs network latency drops below disk latency, access time to a remote disk will beginto approach local disk access time. The performance of I/O may then be improvedby spreading disk pages across several remote disk servers and accessing disk pagesin parallel. To research this we have prototyped a data page server called a PageFile. This persistent data type provides a set of methods to access disk pages storedon a cluster of remote machines acting as disk servers. The goal is to improve thethroughput of database management system or other I/O intensive application byaccessing pages from remote disks and incurring disk latency in parallel. This reportdescribes the conceptual foundation and the methods of access for our prototype. </abstract>
<note> With oversight by Office of Naval Research, this research is supported by ARPA/SISTO inconjunction with the Domain Specific Software Architectures project. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Hierarchical Inter-Domain Routing Protocolwith On-Demand ToS and Policy Resolution  </title>
<author> Cengiz Alaettinoglu, A. Udaya Shankar </author>
<affiliation> Institute for Advanced Computer StudiesDepartment of Computer ScienceUniversity of Maryland </affiliation>
<address> College Park, Maryland 20742 </address>
<pubnum> CS-TR-3299 </pubnum>
<date> June 20, 1994 </date>
<abstract> AbstractTraditional inter-domain routing protocols based on superdomains maintain either "strong"or "weak" ToS and policy constraints for each visible superdomain. With strong constraints,a valid path may not be found even though one exists. With weak constraints, an invaliddomain-level path may be treated as a valid path.We present an inter-domain routing protocol based on superdomains, which always findsa valid path if one exists. Both strong and weak constraints are maintained for each visiblesuperdomain. If the strong constraints of the superdomains on a path are satisfied, then thepath is valid. If only the weak constraints are satisfied for some superdomains on the path, thesource uses a query protocol to obtain a more detailed "internal" view of these superdomains,and searches again for a valid path. Our protocol handles topology changes, including node/linkfailures that partition superdomains. Evaluation results indicate our protocol scales well to largeinternetworks. </abstract>
<keyword> Categories and Subject Descriptors: C.2.1 [Computer-Communication Networks]: Network Architecture and Design|packet networks; store and forward networks; C.2.2 [Computer-Communication Networks]: Network Protocols|protocol architecture; C.2.m [Routing Protocols]; F.2.m [Computer NetworkRouting Protocols]. </keyword>
<note> This work is supported in part by ARPA and Philips Labs under contract DASG60-92-0055 to Departmentof Computer Science, University of Maryland, and by National Science Foundation Grant No. NCR 89-04590. Theviews, opinions, and/or findings contained in this report are those of the author(s) and should not be interpreted asrepresenting the official policies, either expressed or implied, of the Advanced Research Projects Agency, PL, NSF,or the U.S. Government. Computer facilities were provided in part by NSF grant CCR-8811954. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Finite State Machines and Recurrent Neural Networks -Automata and Dynamical Systems Approaches </title>
<author> Peter Tino a;b , Bill G. Horne b , C. Lee Giles b;c </author>
<affiliation> a Department of Computer Science and EngineeringSlovak Technical University </affiliation>
<address> Ilkovicova 3, 812 19 Bratislava, Slovakia </address>
<email> Email: tino@decef.elf.stuba.sk </email>
<affiliation> b NEC Research Institute </affiliation>
<address> 4 Independence WayPrinceton, NJ 08540 </address>
<email> Email:ftino,horne,gilesg@research.nj.nec.com </email>
<affiliation> c Institute for Advanced Computer StudiesUniversity of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<pubnum> Technical ReportUMIACS-TR-95-1 and CS-TR-3396 </pubnum>
<affiliation> Institute for Advanced Computer StudiesUniversity of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> University of Maryland College ParkInstitute for Advanced Computer Studies </affiliation>
 <pubnum> TR-95-93 </pubnum>
<affiliation> Department of Computer Science </affiliation>
 <pubnum> TR-3535 </pubnum>
<title> On the Perturbation ofLU and Cholesky Factors  </title>
<author> G. W. Stewart  </author>
<date> October, 1995 </date>
<abstract> ABSTRACTIn a recent paper, Chang and Paige have shown that the usual perturbation bounds for Cholesky factors can systematically overestimatethe errors. In this note we sharpen their results and extend them tothe factors of the LU decomposition. The results are based on a newformula for the first order terms of the error in the factors. </abstract>
<note> This report is available by anonymous ftp from thales.cs.umd.edu in the directorypub/reports. </note>
<affiliation> Department of Computer Science and Institute for Advanced Computer Studies, Universityof Maryland, </affiliation>
 <address> College Park, MD 20742. </address>
 <note> This work was supported in part by the National ScienceFoundation under grant CCR 95503126. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> The Relative Importance ofConcurrent Writers and Weak Consistency Models </title>
<author> Pete Keleher </author>
<affiliation> Department of Computer ScienceUniversity of Maryland </affiliation>
<address> College Park, MD 20742-3255 </address>
<email> keleher@cs.umd.edu </email>
<abstract> AbstractThis paper presents a detailed comparison of the relative importance of allowing concurrent writersversus the choice of the underlying consistency model. Our comparison is based on single- and multiple-writer versions of a lazy release consistent (LRC) protocol, and a single-writer sequentially consistentprotocol, all implemented in the CVM software distributed shared memory system.We find that in our environment, which we believe to be representative of distributed systems todayand in the near future, the consistency model has a much higher impact on overall performance than thechoice of whether to allow concurrent writers. The multiple writer protocol performs an average of 9%better than the single writer LRC protocol, but 34% better than the single-writer sequentially consistentprotocol. Set against this, MW-LRC required an average of 72% memory overhead, compared to 10%overhead for the single-writer protocols. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On Hybrid Synthesis for Hierarchical Structured Petri Nets </title>
<author> Hong Liu Jun-Cheol Park Raymond E. Miller </author>
<affiliation> Department of Computer ScienceUniversity of Maryland, </affiliation>
 <address> College Park, MD 20742 </address>
<email> flhong, jcpark, millerg@cs.umd.edu </email>
<date> April 23, 1996 </date>
<abstract> AbstractWe propose a hybrid method for synthesis of hierarchical structured Petri nets. In a top-down manner, we decompose a system into a set of subsystems at each level of abstraction, eachof these is specified as a blackbox Petri net that has multiple inputs and outputs. We stipulatethat each subsystem satisfies the following I/O constraints: (1) At any instance of time, atmost one of the inputs can be activated; and (2) If one input is activated, then the subsystemmust consume the input and produce exactly one output within a finite length of time. Wegive a stepwise refinement procedure which starts from the initial high-level abstraction of thesystem and expands an internal place of a blackbox Petri net into a more detailed subnet ateach step. By enforcing the I/O constraints of each subsystem in each intermediate abstraction,our refinement maintains the sequencing of transitions prescribed by the initial abstraction ofthe system. Next, for the bottom-up synthesis, we present interconnection rules for sequential,parallel, and loop structures and prove that each rule maintains the I/O constraints. Thus, byincorporating these interconnection rules into our refinement formulation, our approach can beregarded as a hybrid Petri net synthesis technique that employs both top-down and bottom-upmethods. The major advantage of the method is that the modeling details can be introducedincrementally and naturally, while the important logical properties of the resulting Petri net areguaranteed. </abstract>
<note> This research was supported by NASA Grant No. NAG 5-2648. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Exploiting the Temporal Structure of MPEG Videofor the Reduction of Bandwidth Requirements  </title>
<author> Marwan Krunz and Satish Tripathi </author>
<affiliation>  Institute for Advanced Computer StudiesDepartment of Computer ScienceUniversity of Maryland  </affiliation>
<address> College Park, MD 20742 </address>
<email> Email: krunz@cs.umd.edu </email>
<abstract> AbstractWe propose a new bandwidth allocation scheme for VBR video traffic in ATM networks.The scheme is tailored to MPEG-coded video sources that require stringent and deterministicquality-of-service guarantees. By exploiting the temporal structure of MPEG sources, we showthat our scheme results in an effective bandwidth which, in most cases, is less than the sourcepeak rate. The reduction in the bandwidth requirement is achieved without sacrificing anyperceived QoS. Efficient procedures are provided for the computation of the effective bandwidthunder heterogeneous MPEG sources. The effective bandwidth strongly depends on the arrangement of the multiplexed streams which is a measure of the degree of synchronization between theGOP patterns of different streams. Assuming that all possible arrangements are equi-probable,we derive an expression for the asymptotic tail distribution of the effective bandwidth. Fromthe tail distribution, we compute several performance measures for the call blocking probabilitywhen the allocation is made based on the effective bandwidth. In the case of homogeneoussources, we give a closed-form expression for the `best' arrangement that results in the `optimal'effective bandwidth. Numerical examples based on real MPEG traces are used to demonstratethe advantages of our scheme. </abstract>
<keyword> Keywords: bandwidth allocation, MPEG, statistical multiplexing, CAC. </keyword>
<note> This research was partially supported by the NSF grant # CCR 9318933. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> CS-TR-3692 </pubnum>
<date> Sept. 1996 </date>
<title> Putting Visualization to Work:ProgramFinder for Youth Placement </title>
<author> Jason Ellis, Anne Rose, Catherine Plaisant </author>
<affiliation> Human-Computer Interaction LaboratoryInstitute for Advanced Computer StudiesUniversity of Maryland, </affiliation>
 <address> College Park, MD 20742-3255 </address>
<web> http://www/cs.umd.edu/projects/hcil/ </web><email> jellis, rose, plaisant-@cs.umd.edu </email>
<abstract> AbstractThe Human-Computer Interaction Laboratory (HCIL) and the Maryland Department of Juvenile Justice (DJJ) havebeen working together to develop the ProgramFinder, a tool for choosing programs for a troubled youth from drugrehabilitation centers to secure residential facilities. The seemingly straightforward journey of the ProgramFinderfrom an existing user interface technique to a product design required the development of five different prototypeswhich involved user interface design, prototype implementation, and selecting search criterion. While HCILs effortfocused primarily on design and implementation, DJJs attribute selection process was the most time consuming anddifficult task. We also found that a direct link to DJJs workflow was needed in the prototypes to generate thenecessary buy-in. This paper analyzes the interaction between the efforts of HCIL and DJJ and the amount of buy-in by DJJ staff and management. Lesson learned are presented for developers. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> In: Multimedia Systems, Volume 2, Number 6, (January 1995) pages 267-279. </note>
<title> An Empirical Study of Delay Jitter Management Policies * </title>
<author> Donald L. Stone Kevin Jeffay </author>
<affiliation> University of North Carolina at Chapel HillDepartment of Computer Science </affiliation>
<address> Chapel Hill, NC 27599-3175 USA </address>
<email> stone, jeffay-@cs.unc.edu </email>
<date> July 1994 </date>
<abstract> Abstract: This paper presents an empirical study of several policies for managing the effectof delay jitter on the playout of audio and video in computer-based conferences. The problemaddressed is that of managing the fundamental tradeoff between display with low latency anddisplay with few gaps. We describe a particular policy called queue monitoring whichobserves delay jitter over time and dynamically adjusts display latency in order to supportlow-latency conferences with an acceptable gap rate. Queue monitoring is evaluated bycomparing it with two policies from the literature in a study based on measurements from acomputer-based conferencing system. Our results show that queue monitoring performs aswell or better than the other policies over the range of observed network loads. Moreimportantly, we show that queue monitoring performs better on those network loads forwhich the other policies exhibit poor performance. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Real-Time Computing with Lock-Free Shared Objects </title>
<author> James H. Anderson Srikanth Ramamurthy Kevin Jeffay </author>
<affiliation> Department of Computer Science, University of North Carolina, </affiliation>
 <address> Chapel Hill, NC 27599-3175 </address>
<abstract> AbstractThis paper considers the use of lock-free shared objectswithin hard real-time systems. As the name suggests,lock-free shared objects are distinguished by the factthat they are not locked. As such, they do not giverise to priority inversions, a key advantage over conventional, lock-based object-sharing approaches. Despite this advantage, it is not immediately apparentthat lock-free shared objects can be employed if tasksmust adhere to strict timing constraints. In particular,lock-free object implementations permit concurrent operations to interfere with each other, and repeated interferences can cause a given operation to take an arbitrarily long time to complete.The main contribution of this paper is to show thatsuch interferences can be bounded by judicious scheduling. This work pertains to periodic, hard real-timetasks that share lock-free objects on a uniprocessor. Inthe first part of the paper, scheduling conditions are derived for such tasks, for both static and dynamic priority schemes. Based on these conditions, it is formallyshown that lock-free object-sharing approaches can beexpected to incur much less overhead than approachesbased on wait-free objects or lock-based schemes. Inthe last part of the paper, this conclusion is validated experimentally through work involving a real-time desktop videoconferencing system. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Sync: A System for Mobile Collaborative Applications </title>
<author> Jonathan P. Munson and Prasun Dewan </author>
<affiliation> Department of Computer Science, University of North Carolina at Chapel Hill </affiliation>
<date> March 14, 1997 </date>
<abstract> ABSTRACTSync is a new Java-based framework for developing collaborative applications for wireless mobilesystems. Sync is based on objectoriented replication and offers high-level synchronization-aware classesbased on existing Java classes. Programmers may also extend the Sync-provided classes to create newreplicated classes, either to add functionality or to modify a classs merge policy. Sync supports fullydisconnected operation and employs centralized, asynchronous synchronization. Application programmersuse the Sync framework to define conflicts and specify conflict resolution on the basis of the applicationsstructure and semantics.We discuss the general needs of wireless mobile applications, and present a high-function exampleapplication that would be useful to mobile users, to be used for illustration throughout the paper. Next wediscuss related work, and evaluate each work relative to its ability to support the example application. Wethen present the Sync framework, motivating each feature with its use in the example application. </abstract>
<intro> INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Pages 61 to 70 of W. Daelemans, A. van den Bosch, and A. Weijters (Editors),Workshop Notes of the ECML/MLnet Workshop on Empirical Learning of NaturalLanguage Processing Tasks, April 26, 1997, Prague, Czech Republic </note>
<title> Automatic Phonetic Transcription of WordsBased On Sparse Data </title>
<author> Maria Wolters (i) and Antal van den Bosch (ii) </author>
<affiliation> (i) Institut fur Kommunikationsforschung und Phonetik, Universitat Bonn </affiliation>
<author> Poppelsdorfer Allee 47, 53113 Bonn, Germany </author>
<email> mwo@asl1.ikp.uni-bonn.de </email>
<affiliation> (ii) Department of Computer Science, Universiteit Maastricht </affiliation>
<author> PO Box 616, 6200 MD Maastricht, The Netherlands </author>
<email> antal@cs.unimaas.nl </email>
<abstract> AbstractThe relation between the orthography and the phonology of a language hastraditionally been modelled by hand-crafted rule sets. Machine-learning (ML)approaches offer a means to gather this knowledge automatically. Problemsarise when the training material is sparse. Generalising from sparse datais a well-known problem for many ML algorithms. We present experimentsin which connectionist, instance-based, and decision-tree learning algorithmsare applied to a small corpus of Scottish Gaelic. instance-based learning in theib1-ig algorithm yields the best generalisation performance, and that mostalgorithms tested perform tolerably well. Given the availability of a lexicon,even if it is sparse, ML is a valuable and efficient tool for automatic phonetictranscription of written text. </abstract>
<intro> 1 The Problem </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Strange Bedfellows: Issues in Object Naming Under Unix </title>
<author> Douglas B. Orr, Robert W. Mecklenburg and Ravindra Kuramkote </author>
<affiliation> Department of Computer ScienceUniversity of Utah </affiliation>
<address> Salt Lake City, UT 84112 USA </address>
<email> E-mail: dbo@cs.utah.edu, mecklen@cs.utah.edu, kuramkot@cs.utah.edu </email>
<abstract> AbstractNaming plays a key role in the design of any system that exports services or resources. Object systemsmay export many different categories of names: instances, components of records, types, etc. Operatingsystems export the names of files, devices, and services. Integrating an object base with existing operating system facilities can improve accessibility of theobject base resources. We consider the benefits andpitfalls of integrating an object base namespace withthe Unix namespace. 1 </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Persistence is Hard, Then You Die!orCompiler and Runtime Support for a PersistentCommon Lisp </title>
<author> J. H. JacobsM. R. SwansonR. R. Kessler </author>
<pubnum> UUCS-94-003 </pubnum>
<affiliation> Department of Computer ScienceUniversity of Utah </affiliation>
<address> Salt Lake City, UT 84112 USA </address>
<date> January 26, 1994 </date>
<abstract> AbstractIntegrating persistence into an existing programming language is a serious undertaking. Preserving the essence of the existing language, adequately supporting persistence, and maintaining efficiency require low-level support from the compiler and runtime systems. Pervasive,low-level changes were made to a Lisp compiler and runtime system to introduce persistence.The result is an efficient language which is worthy of the name Persistent Lisp. 1 </abstract>
<note> 1  This research was sponsored by the Advanced Research Projects Agency (DOD), monitored by the  </note>
</NEW_HEADER>
<NEW_HEADER>
<title> Testing the FM9001 Microprocessor </title>
<author> Kenneth L. Albin, Bishop C. Brock,Warren A. Hunt, Jr., Lawrence M. Smith </author>
<pubnum> Technical Report 90 </pubnum>
<date> January 6, 1995 </date>
<affiliation> Computational Logic, Inc. </affiliation>
<address> 1717 West Sixth Street, Suite 290Austin, Texas 78703-4776 </address>
<phone> TEL: +1 512 322 9951 </phone><email> EMAIL: hunt@cli.com </email>
<note> This work was supported in part at Computational Logic, Inc. and by theDefense Advanced Research Projects Agency, ARPA Orders 6082 and 9151. Theviews and conclusions contained in this document are those of the author(s) andshould not be interpreted as representing the official policies, either expressed orimplied, of Computational Logic, Inc. </note>
<note> Copyright c 1995 Computational Logic, Inc. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> On Automatically Generating and UsingExamples in a Computational Logic System@shortTitle(Generating and Using Examples ) </title>
<author> @authorbox(Myung Won Kim) </author>
<pubnum> @reportnumbox(Technical Report #57) </pubnum>
<date> March 1987) </date>
<note> The contents of this technical report originallyappeared as the author's dissertation. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Secure Group Communications Using Key Graphs </title>
<author> Chung Kei Wong Mohamed Gouda Simon S. Lam </author>
<affiliation> Department of Computer SciencesUniversity of Texas at Austin </affiliation>
<address> Austin, TX 78712-1188 </address>
<email> fckwong,gouda,lamg@cs.utexas.edu </email>
<abstract> AbstractMany emerging applications (e.g., teleconference, real-timeinformation services, pay per view, distributed interactivesimulation, and collaborative work) are based upon a groupcommunications model, i.e., they require packet deliveryfrom one or more authorized senders to a very large numberof authorized receivers. As a result, securing group communications (i.e., providing confidentiality, integrity, and authenticity of messages delivered between group members)will become a critical networking issue.In this paper, we present a novel solution to the scalability problem of group/multicast key management. Weformalize the notion of a secure group as a triple (U; K; R)where U denotes a set of users, K a set of keys held by theusers, and R a user-key relation. We then introduce keygraphs to specify secure groups. For a special class of keygraphs, we present three strategies for securely distributing rekey messages after a join/leave, and specify protocolsfor joining and leaving a secure group. The rekeying strategies and join/leave protocols are implemented in a prototypegroup key server we have built. We present measurementresults from experiments and discuss performance comparisons. We show that our group key management service, using any of the three rekeying strategies, is scalable to largegroups with frequent joins and leaves. In particular, theaverage measured processing time per join/leave increaseslinearly with the logarithm of group size. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Integrating Explanation-Based and Inductive Learning Techniquesto Acquire Search-Control for Planning  </title>
<author> Tara A. Estlin </author>
<affiliation> Department of Computer SciencesUniversity of Texas at Austin </affiliation>
<address> Austin, TX 78712 </address>
<email> estlin@cs.utexas.edu </email>
<pubnum> Technical Report AI96-250 </pubnum>
<date> September 1996 </date>
<abstract> AbstractPlanning systems have become an important tool for automating a wide varietyof tasks. Control knowledge guides a planner to find solutions quickly and is crucialfor efficient planning in most domains. Machine learning techniques enable a planningsystem to automatically acquire domain-specific search-control knowledge for differentapplications. Past approaches to learning control information have usually employedexplanation-based learning (EBL) to generate control rules. Unfortunately, EBL aloneoften produces overly complex rules that actually decrease rather than improve overallplanning efficiency. This paper presents a novel learning approach for control knowledgeacquisition that integrates explanation-based learning with techniques from inductivelogic programming. In our learning system Scope, EBL is used to constrain an inductive search for control heuristics that help a planner choose between competing planrefinements. Scope is one of the few systems to address learning control information for newer, partial-order planners. Specifically, this proposal describes how Scopelearns domain-specific control rules for the UCPOP planning algorithm. The resultingsystem is shown to produce significant speedup in two different planning domains, andto be more effective than a pure EBL approach. Future research will be performedin three main areas. First, Scope's learning algorithm will be extended to includeadditional techniques such as constructive induction and rule utility analysis. Second,Scope will be more thoroughly tested; several real-world planning domains have beenidentified as possible testbeds, and more in-depth comparisons will be drawn betweenScope and other competing approaches. Third, Scope will be implemented in a different planning system in order to test its portability to other planning algorithms. Thiswork should demonstrate that machine-learning techniques can be a powerful tool inthe quest for tractable real-world planning. </abstract>
<note> This research was supported by the NASA Graduate Student Researchers Program, grant number NGT51332. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Products of Domain Models </title>
<author> Don Batory </author>
<affiliation> Department of Computer SciencesThe University of Texas </affiliation>
<address> Austin, Texas 78712 </address>
<email> batory@cs.utexas.edu </email>
<abstract> AbstractWe argue that domain models should produce four basic products: identification of reusable software components, definition of software architectures that explain how components can be composed, a demonstration of architecture scalability, and a direct relationship of these results tosoftware generation of target systems. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Family of 2-process Mutual Exclusion AlgorithmsNotes on UNITY: 13-90 </title>
<author> Jayadev Misra  </author>
<affiliation> Department of Computer SciencesThe University of Texas at Austin </affiliation>
<address> Austin, Texas 78712 </address>
<phone> (512) 471-9547 </phone><email> misra@cs.utexas.edu </email>
<date> March 7, 1994 </date>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Verifying adder circuits using powerlists </title>
<author> William Adams  </author>
<affiliation> Department of Computer SciencesThe University of Texas at Austin </affiliation>
<address> Austin, TX 78712-1188USA </address>
<email> e-mail: will@cs.utexas.edu </email>
<date> March 29, 1994 </date>
<abstract> AbstractWe define the ripple-carry and the carry-lookahead adder circuits in thepowerlist notation and we use the powerlist algebra to prove that thesecircuits correctly implement addition for natural numbers represented asbit vectors. </abstract>
<intro> 0 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Loop Optimizations for Acyclic Object-Oriented Queries </title>
<author> Vasilis Samoladas Daniel P. Miranker </author>
<affiliation> The University of Texas at AustinDepartment of Computer Sciences </affiliation>
<address> Taylor Hall 2.124Austin, TX 78712-1188 </address>
<email> fvsam,mirankerg@cs.utexas.edu </email>
<phone> Tel: (512)-471-9541 </phone><abstract> AbstractNested loop execution of object-oriented queries retainsthe promise of maintaining the full generality of the object paradigm, independent of the specifics of any singleobject model. Thus, from this starting point we havedeveloped an object-oriented query optimizer and execution engine. The methods, developed to date for onlyacyclic queries, augment nested loops structures with asimple marking mechanism such that unnecessary loopiterations are not repeated. In the case of acyclic queries,the executions are asymptotically optimal. In contrast tooptimal query methods based on semijoin reductions ourmethod involves no preprocessing step and thus avoidsthe extra I/O associated with semijoins and prevents theformal benefits of semijoin reduction from appearing as apractical improvement. Empirical results comparing ourquery environment with a commercially available productdemonstrate significant performance improvement. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Algorithms for Fence Design </title>
<author> Robert-Paul Berretty </author>
 <affiliation> University of Utrecht, </affiliation>
 <address>  Utrecht, The Netherlands </address>
<author> Ken Goldberg </author>
 <affiliation> University of California at Berkeley, </affiliation>
 <address> CA, USA </address>
<author> Mark H. Overmars </author>
 <affiliation> University of Utrecht, </affiliation>
 <address>  Utrecht, The Netherlands </address>
<author> A. Frank van der Stappen </author>
 <affiliation> University of Utrecht, </affiliation>
 <address> Utrecht, The Netherlands </address>
<abstract> AbstractA common task in automated manufacturing processes is to orient parts prior toassembly. We address sensorless orientation of a polygonal part on a conveyor belt bya sequence of stationary fences across this belt. Since fences can only push against themotion of the belt, it is a challenging problem to compute fence designs which orientsa given part. In this paper, we give several polynomial-time, algorithms to computefence designs which are optimal with respect to various criteria. We address bothfrictionless and frictional fences. We also compute modular fence designs in whichthe fence angles are restricted to a discrete set of angles instead of an interval. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To Appear: Proc. IEEE ICC'96 Conference, Dallas, June 1996. </note>
<title> A Bandwidth Control Scheme for Connectionless ATMTraffic with Multiple Traffic Classes </title>
<author> Jorg Liebeherr Ian F. Akyildiz Debapriya Sarkar ? </author>
<affiliation> Computer Science Department, University of Virginia, </affiliation>
 <address> Charlottesville, VA 22903. </address>
<affiliation> School of ECE, Georgia Institute of Technology, </affiliation>
 <address> Atlanta, GA 30332. </address>
<affiliation> ? Hughes Network Systems, Hughes Network Systems, </affiliation>
 <address> Germantown, MD 20876. </address>
<abstract> AbstractA bandwidth control mechanism is proposed for ATMnetworks that can control the usage of bandwidth in thepresence of both connection-oriented and connection-less traffic, as well as multiple classes of connectionlesstraffic. The bandwidth control mechanism operates atthree levels. At the topmost level, bandwidth is dynamically regulated between connection-oriented andconnectionless traffic based on the utilization of eachtraffic type. At the next level, bandwidth is controlledbetween different classes of connectionless traffic, suchas real-time traffic, bulk data traffic, and so on. At thelowest level, bandwidth is distributed among flows belonging to the same connectionless traffic class. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Software EngineeringBeginning InThe First Computer Science Course 1 </title>
<author> Jane C. Prey James P. Cohoon Greg Fife </author>
<affiliation> Department of Computer ScienceSchool of Engineering and Applied SciencesUniversity of Virginia </affiliation>
<address> Charlottesville, VA 22903 </address>
<abstract> Abstract. The demand for computing and computing power is increasing at a rapid pace. With this demand,the ability to develop, enhance and maintain software is a top priority. Educating students to do competentwork in software development, enhancement and maintenance has become a complex problem. Softwareengineering concepts are typically not introduced in beginning computer science courses. Students do not seesoftware engineering until the third or fourth year of the curriculum. We do not believe students can acquirean adequate software engineering foundation with the present approach. We believe an emphasis on softwareengineering should begin in the very first course and continue throughout the curriculum. We are redesigningour curriculum to reect this. The first course of the new curriculum is complete. This article focuses on twoof the laboratory activities we have developed which deal with specific software engineering concepts. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Isotach Networks </title>
<author> Paul F. Reynolds, Jr.Craig WilliamsRaymond R. Wagner, Jr. </author>
<abstract> Abstract We introduce a class of networks called isotach networks designed to reduce thecost of concurrency control in asynchronous computations. Isotach networks support severalproperties important to the correct execution of parallel and distributed computations: atomi-city, causal message delivery, sequential consistency, and memory coherence in systems inwhich shared data can replicate and migrate. They allow processes to execute atomic actionswithout locks and to pipeline memory accesses without sacrificing sequential consistency. Iso-tach networks can be implemented in a wide variety of configurations, including NUMA (nonuniform memory access) multiprocessors and distributed as well as parallel systems. Networksthat implement isotach time systems are characterized not by their topology, but by the guarantees they make about the relative order in which messages appear to be delivered. Theseguarantees are expressed in logical time, not physical time. Physical time guarantees would beprohibitively expensive, whereas logical time guarantees can be enforced cheaply, using purelylocal knowledge, and yet are powerful enough to support efficient techniques for coordinatingasynchronously executing processes. Empirical and analytic studies of isotach systems showthat they outperform conventional systems under realistic workloads, in some cases by an orderof magnitude or more. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Shade: A Fast Instruction-Set Simulatorfor Execution Profiling </title>
<author> Bob Cmelik </author>
<affiliation> Sun Microsystems, Inc. </affiliation>
<email> rfc@eng.sun.com </email>
<author> David Keppel </author>
<affiliation> University of Washington </affiliation>
<email> pardo@cs.washington.edu </email>
<abstract> AbstractTracing tools are used widely to help analyze, design, and tuneboth hardware and software systems. This paper describes a toolcalled Shade which combines efficient instruction-set simulationwith a flexible, extensible trace generation capability. Efficiencyis achieved by dynamically compiling and caching code to simulate and trace the application program. The user may control theextent of tracing in a variety of ways; arbitrarily detailed application state information may be collected during the simulation, buttracing less translates directly into greater efficiency. CurrentShade implementations run on SPARC systems and simulate theSPARC (Versions 8 and 9) and MIPS I instruction sets. Thispaper describes the capabilities, design, implementation, and performance of Shade, and discusses instruction set emulation ingeneral. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Appears in "Proceedings of the First Symposium on Operating Systems Design and Implementation," Usenix Association, November 1994. </note>
<title> Dynamic Page Mapping Policies for Cache Conflict Resolution onStandard Hardware </title>
<author> Theodore H. RomerDennis LeeBrian N. Bershad </author>
<affiliation> Department of Computer Scienceand EngineeringUniversity of Washington </affiliation>
<address> Seattle, WA 98195 </address>
<email> fromer,dlee,bershadg@cs.washington.edu </email>
<author> J. Bradley Chen </author>
<affiliation>  Division of Applied Sciences </affiliation>
<address> 29 Oxford Street </address>
<affiliation> Harvard University </affiliation>
<address> Cambridge MA 02138  </address>
<email> bchen@das.harvard.edu </email>
<abstract> AbstractIn computer systems with large, physically-indexed,direct-mapped caches, a poor mapping from virtual tophysical pages causes excessive cache conflict misses.In a previous paper we proposed a simple hardware device, the Cache Miss Lookaside (CML) Buffer, whichidentifies pages that are suffering from conflict misses.The operating system can use this information to implement a dynamic page mapping policy that resolvesconflicts by performing an in-memory copy of one ofthe conflicting pages, and updating the virtual to physical mappings. In this paper, we propose several dynamic page mapping policies that detect and resolvecache conflicts using hardware available in existing systems, such as a TLB and cache miss counter, to locatepossible cache conflicts. We evaluate the simulatedperformance of a variety of mapping policies, and showthat a dynamic page mapping policy using standardhardware can improve upon the performance of a staticpolicy, but is not as effective as special-purpose hardware such as an associative cache or a CML buffer.We also describe the implementation and performanceof a software-based dynamic policy on a DEC Alphaworkstation running DEC OSF/1. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Portable Parallel N-body Solver </title>
<author> E Christopher Lewis Calvin Lin Lawrence Snyder George Turkiyyah  </author>
<abstract> AbstractWe present parallel solutions for direct and fast n-body solvers written in the ZPLlanguage. We describe the direct solver, compare its performance against a sequentialC program, and show performance results for two very different parallel machines: theKSR-2 and the Paragon. We also discuss the implementation of the fast solver in ZPL,including factors pertinent to data movement. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Timing Analysis of Concurrent SystemsAn Algorithm for Determining Time Separation of Events </title>
<author> Tod Amon, Henrik Hulgaard, Gaetano Borriello, Steve Burns </author>
<affiliation> Department of Computer Science and Engineering, FR-35University of Washington </affiliation>
<address> Seattle, WA 98195 USA </address>
<abstract> AbstractA fundamental problem in the synthesis and optimization of concurrent systems is the determination of the separation time between system events. We present a theoretical frameworkfor solving this problem for arbitrary process graphs without conditional behavior and develop an efficient and exact algorithm based on this theoretical foundation. Examples areused to demonstrate the operation and generality of the algorithm. </abstract>
<intro> 1  Introduction  </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> User-Level Threads and Interprocess Communication </title>
<author> Michael J. Feeley, Jeffrey S. Chase, and Edward D. Lazowska </author>
<affiliation> Department of Computer Science and Engineering, FR-35University of Washington </affiliation>
<address> Seattle, WA 98195 </address>
<pubnum> Technical Report 93-02-03 </pubnum>
<abstract> AbstractUser-level threads have performance and flexibility advantages over both Unix-like processesand kernel threads. However, the performance of user-level threads may suffer in multipro-grammed environments, or when threads block in the kernel (e.g., for I/O). These problemscan be particularly severe in tasks that communicate frequently using IPC (e.g., multithreadedservers), due to interactions between the user-level thread scheduler and the operating systemIPC primitives. Efficient IPC typically involves processor handoff that blocks the caller andunblocks a thread in the callee; when combined with user-level threads, this can cause problemsfor both caller and callee, particularly if the caller thread should subsequently block.In this paper we describe a new user-level thread package, called OThreads, designed tosupport blocking and efficient IPC for a system based on traditional kernel threads. We discussthe extent to which these problems can be solved at the user level without kernel changessuch as scheduler activations. Our conclusion is that problems caused by application-controlledblocking and IPC can be resolved in the user-level thread package, but that problems dueto multiprogramming workload and unanticipated blocking such as page faults require kernelchanges such as scheduler activations. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Utility Models for Goal-DirectedDecision-Theoretic Planners </title>
<author> Peter Haddawy 1 , Steve Hanks </author>
<affiliation> Department of Computer Science and EngineeringUniversity of Washington </affiliation>
<address> Seattle, WA 98195 </address>
<pubnum> Technical Report 93-06-04 </pubnum>
<date> June 15, 1993 </date>
<affiliation> Department of EE &amp; CS, University of Wisconsin-Milwaukee, </affiliation>
 <address> Milwaukee WI 53201 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Interface Timing Verification withCombined Max and Linear Constraints </title>
<author> Elizabeth Walkup, Gaetano Borriello </author>
<affiliation> Department of Computer Science and EngineeringUniversity of Washington </affiliation>
<address> Seattle, WA 98195 </address>
<pubnum> Technical Report 94-03-04 </pubnum>
<date> June 3, 1994 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Hierarchical Image Caching for AcceleratedWalkthroughs of Complex Environments </title>
<author>  Jonathan Shade Dani Lischinski David H. Salesin Tony DeRose John Snyder  </author>
<affiliation> Department of Computer Science and EngineeringUniversity of Washington </affiliation>
<affiliation> Microsoft Research </affiliation>
<pubnum> Technical Report UW-CSE-96-01-06 </pubnum>
<date> January 1996 </date>
<abstract> AbstractWe present a new method for accelerating walkthroughs of geometrically complex staticscenes. As a preprocessing step, our method constructs a BSP-tree that hierarchically partitions the geometric primitives in the scene. In the course of a walkthrough, images of nodesat various levels of the hierarchy are cached for reuse in subsequent frames. A cached image is applied as a texture map to a single quadrilateral that is drawn instead of the geometrycontained in the corresponding node. Visual artifacts are kept under control by using an error metric that quantifies the discrepancy between the appearance of the geometry containedin a node and the cached image. The new method is shown to achieve significant speedupsfor a walkthrough of a complex outdoor scene, with little or no loss in rendering quality. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Fast Rendering of Subdivision Surfaces </title>
<author> Kari Pulli </author>
<affiliation> University of Washington </affiliation>
<address> Seattle, WA </address>
<author> Mark Segal </author>
<affiliation> Silicon Graphics Inc. </affiliation>
<abstract> AbstractSubdivision surfaces provide a curved surface representation that is useful in a number of applications, including modeling surfaces of arbitrary topological type [5] , fitting scattered data [6] , and geometric compressionand automatic level-of-detail generation using wavelets [8] . Subdivision surfaces also provide an attractive representation for fast rendering, since they can directly represent complex surfaces of arbitrary topology. This directrepresentation contrasts with traditional approaches such as trimmed NURBS, in which tesselating trim regionsdominates rendering time, and algebraic implicit surfaces, in which rendering requires resultants, root finders, orother computationally expensive techniques.We present a method for subdivision surface triangulation that is fast, uses minimum memory, and is simpler instructure than a naive rendering method based on direct subdivision. These features make the algorithm amenableto implementation on dedicated geometry engine processors, allowing high rendering performance on appropriately equipped graphics hardware. </abstract>
<keyword> CR Categories and Subject Descriptors: I.3.6 [Computer Graphics]: Methodology and Techniques.Additional Key Words: subdivision surfaces, surface rendering. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Emerging Opportunities for Theoretical Computer Science </title>
<author> Alfred V. Aho </author>
<affiliation> Columbia University </affiliation>
<author> David S. Johnson </author>
<affiliation> AT &amp; T Research </affiliation>
<author> Richard M. Karp (Chair) </author>
<affiliation> University of Washington </affiliation>
<author> S. Rao Kosaraju </author>
<affiliation> Johns Hopkins University </affiliation>
<author> Catherine C. McGeoch </author>
<affiliation> Amherst College </affiliation>
<author> Christos H. Papadimitriou </author>
<affiliation> University of California at Berkeley </affiliation>
<author> Pavel Pevzner </author>
<affiliation> University of Southern California </affiliation>
<date> October 15, 1996 </date>
<abstract> AbstractThe principles underlying this report can be summarized as follows:1. A strong theoretical foundation is vital to computer science. </abstract>
</NEW_HEADER>
<NEW_HEADER>
<title> Random Striping forNews on Demand Servers </title>
<author> Juan Alemany and Jayram S. Thathachar </author>
<pubnum> Technical Report UW-CSE-97-02-02 </pubnum>
<date> February, 1997 </date>
<affiliation> Department of Computer Science and EngineeringUniversity of Washington </affiliation>
<address> Box 352350Seattle, WA 98195 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> The Cassowary Linear Arithmetic Constraint SolvingAlgorithm: Interface and Implementation </title>
<author> Greg J. Badros Alan Borning </author>
<pubnum> Technical Report UW-CSE-98-06-04 </pubnum>
<affiliation> Department of Computer Science and EngineeringUniversity of Washington </affiliation>
<address> Box 352350, Seattle, WA 98195-2350 USA </address>
<email> fgjb,borningg@cs.washington.edu </email>
<date> 29 June 1998 </date>
<abstract> AbstractLinear equality and inequality constraints arise naturally in specifying many aspects of userinterfaces, such as requiring that one window be to the left of another, requiring that a paneoccupy the leftmost 1/3 of a window, or preferring that an object be contained within a rectangle if possible. Current constraint solvers designed for UI applications cannot efficientlyhandle simultaneous linear equations and inequalities. This is a major limitation. We describeCassowary|an incremental algorithm based on the dual simplex method that can solve suchsystems of constraints efficiently. </abstract>
<note> This informal technical report describes the latest version of the Cassowary algorithm. It isderived from the paper "Solving Linear Arithmetic Constraints for User Interface Applications"by Alan Borning, Kim Marriott, Peter Stuckey, and Yi Xiao [7], published in the UIST'97Proceedings. The UIST paper also contains a description of QOCA, a closely related solverthat finds least-squares solutions to linear constraints. This technical report, which is intendedto be self-contained, includes material on Cassowary from the UIST paper, plus a descriptionof the Java, C++, and Smalltalk implementations and their interfaces. along with additionaldetails, corrections, and clarifications.An earlier technical report also discussed QOCA and the similarities between Cassowary andthat algorithm [6]. </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Error in Polynomial Tensor-Product,and Chung-Yao, Interpolation </title>
<author> Carl de Boor </author>
<abstract>  Abstract. A formula for the error in Chung-Yao interpolation announced earlier is proved (by induction). In the process, a bivariate divided difference identity of independent interest is proved. Also, an inductive proof of an error formula for polynomial interpolation by tensor-products is given. The main tool is a (convenient notation for a) multi-variate divided difference. </abstract>
<note> Surface Fitting and Multiresolution Methods 35A. Le Mehaute, C. Rabut, and L. L. Schumaker (eds.), pp. 35-50.Copyright o c 1997 by Vanderbilt University Press, Nashville, TN.ISBN 0-8265-1294-1.All rights of reproduction in any form reserved. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> On multivariate polynomial interpolation </title>
<author> Carl de Boor 1 &amp; Amos Ron </author>
<abstract> ABSTRACTWe provide a map fi 7! fi which associates each finite set fi of points in C s with a polynomialspace fi from which interpolation to arbitrary data given at the points in fi is possible and uniquelyso. Among all polynomial spaces Q from which interpolation at fi is uniquely possible, our fiis of smallest degree. It is also D- and scale-invariant. Our map is monotone, thus providing aNewton form for the resulting interpolant. Our map is also continuous within reason, allowing us tointerpret certain cases of coalescence as Hermite interpolation. In fact, our map can be extended tothe case where, with each 2 fi, there is associated a polynomial space P , and, for given smoothf , a polynomial q 2 Q is sought for whichp(D)(f q)() = 0; all p 2 P ; 2 fi:We obtain fi as the "scaled limit at the origin" (Exp fi ) # of the exponential space Exp fi withfrequencies fi, and base our results on a study of the map H 7! H # defined on subspaces H ofthe space of functions analytic at the origin. This study also allows us to determine the localapproximation order from such H and provides an algorithm for the construction of H # from anybasis for H. </abstract>
<note> AMS (MOS) Subject Classifications: primary 41A05, 41A63, 41A10; secondary 65D05, 41A30 </note>
<keyword> Key Words: exponentials, polynomials, multivariate, interpolation, Newton form, Birkhoff interpolation </keyword>
<note> Authors' affiliation and address: </note>
<affiliation> Center for Mathematical SciencesUniversity of Wisconsin-Madison </affiliation>
<address> 610 Walnut St.Madison WI 53705 </address>
<note> 1 supported in part by the National Science Foundation under Grant No. DMS-8701275 and bythe United States Army under Contract No. DAAL03-87-K-0030 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Recovering Shape by Purposive Viewpoint Adjustment </title>
<author> Kiriakos N. Kutulakos Charles R. Dyer </author>
<affiliation> Computer Sciences DepartmentUniversity of Wisconsin </affiliation>
<address> Madison, Wisconsin 53706 </address>
<pubnum> Technical Report #1035 </pubnum>
<date> August 1991 </date>
<abstract> AbstractWe present an approach for recovering surface shape from the occluding contour using an active (i.e., moving) observer. It is based on a relation between the geometries ofa surface in a scene and its occluding contour: If the viewing direction of the observeris along a principal direction for a surface point whose projection is on the contour,surface shape (i.e., curvature) at the surface point can be recovered from the contour.Unlike previous approaches for recovering shape from the occluding contour, we use anobserver that purposefully changes viewpoint in order to achieve a well-defined geometric relationship with respect to a 3D shape prior to its recognition. We show that thereis a simple and efficient viewing strategy that allows the observer to align their viewingdirection with one of the two principal directions for a point on the surface. This strategy depends on only curvature measurements on the occluding contour and thereforedemonstrates that recovering quantitative shape information from the contour does notrequire knowledge of the velocities or accelerations of the observer. Experimental resultsdemonstrate that our method can be easily implemented and can provide reliable shapeinformation from the occluding contour. </abstract>
<note> The support of the National Science Foundation under Grant No. IRI-9002582 is gratefully acknowledged. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> Appears in Working Notes, Integrating Multiple Learned Models for Improving and Scaling Machine Learning AlgorithmsWorkshop, Thirteenth National Conference on Artificial Intelligence, Portland, OR: AAAI Press (1996). </note>
<title>  Human Expert-Level Performance on a Scientific Image Analysis Task by a System Using Combined Artificial Neural Networks </title>
<author> Kevin J. Cherkauer </author>
<affiliation> Department of Computer SciencesUniversity of Wisconsin-Madison </affiliation>
<address> 1210 West Dayton StreetMadison, WI 53706, USA </address>
<email> cherkauer@cs.wisc.edu </email>
<abstract> AbstractThis paper presents the Plannett system, whichcombines artificial neural networks to achieve expert-level accuracy on the difficult scientific task of recognizing volcanos in radar images of the surface of theplanet Venus. Plannett uses ANNs that vary alongtwo dimensions: the set of input features used to trainand the number of hidden units. The ANNs are combined simply by averaging their output activations.When Plannett is used as the classification moduleof a three-stage image analysis system called JAR-tool, the end-to-end accuracy (sensitivity and specificity) is as good as that of a human planetary geologist on a four-image test suite. JARtool-Plannettalso achieves the best algorithmic accuracy on theseimages to date. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Team Learning of Formal Languages </title>
<author> Sanjay Jain </author>
<affiliation> Dept. of Info. Systems &amp; Computer ScienceNational University of Singapore </affiliation>
<address> Singapore 0511, Republic of Singapore </address>
<email> sanjay@iscs.nus.sg </email>
<author> Arun Sharma </author>
<affiliation> School of Computer Science and EngineeringThe University of New South Wales </affiliation>
<address> Sydney, NSW 2052, Australia </address>
<email> arun@cse.unsw.edu.au </email>
<abstract> AbstractA team of learning machines is a multiset oflearning machines. A team is said to successfully learn a concept just in case each memberof some nonempty subset, of predeterminedsize, of the team learns the concept.Team learning of computer programs forcomputable functions from their graphs hasbeen studied extensively. However, teamlearning of languages turns out to be amore suitable theoretical model for studyingcomputational limits on multi-agent machinelearning. The main reason for this is thatlanguage learning can model both learningfrom positive data and learning from positiveand negative data, whereas function learningmodels only learning from positive and negative data.Some theoretical results about learnability offormal languages by teams of algorithmic machines are surveyed. Some new results aboutrestricted classes of languages are presented.These results are mainly about two issues: redundancy and aggregation. The issue of redundancy deals with the impact of increasingthe size of a team and increasing the numberof machines required to be successful. Theissue of aggregation deals with conditions under which a team may be replaced by a singlemachine without any loss in learning ability.Scenarios which can be modeled by teamlearning are also presented. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Mathematical Programming in Machine Learning </title>
 <author> O. L. Mangasarian  </author>
<pubnum> Mathematical Programming Technical Report 95-06 </pubnum>
<date> April 1995 - Revised July 1995 </date>
<abstract> AbstractWe describe in this work a number of central problems of machine learning andshow how they can be modeled and solved as mathematical programs of variouscomplexity. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Clustering via Concave Minimization </title>
<author> P. S. Bradley and O. L. Mangasarian W. N. Street </author>
<affiliation> Computer Sciences Department Computer Science DepartmentUniversity of Wisconsin Oklahoma State University </affiliation>
<address> 1210 West Dayton Street 205 Mathematical SciencesMadison, WI 53706 Stillwater, OK 74078 </address>
<email> email: paulb@cs.wisc.edu, olvi@cs.wisc.edu email:nstreet@cs.okstate.edu </email>
<abstract> AbstractThe problem of assigning m points in the n-dimensional real spaceR n to k clusters is formulated as that of determining k centers inR n such that the sum of distances of each point to the nearestcenter is minimized. If a polyhedral distance is used, the problemcan be formulated as that of minimizing a piecewise-linear concavefunction on a polyhedral set which is shown to be equivalent toa bilinear program: minimizing a bilinear function on a polyhedral set. A fast finite k-Median Algorithm consisting of solvingfew linear programs in closed form leads to a stationary point ofthe bilinear program. Computational testing on a number of real-world databases was carried out. On the Wisconsin DiagnosticBreast Cancer (WDBC) database, k-Median training set correctness was comparable to that of the k-Mean Algorithm, however itstesting set correctness was better. Additionally, on the WisconsinPrognostic Breast Cancer (WPBC) database, distinct and clinically important survival curves were extracted by the k-MedianAlgorithm, whereas the k-Mean Algorithm failed to obtain suchdistinct survival curves for the same database. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> MATHEMATICAL PROGRAMMINGAPPROACHES TO MACHINE LEARNINGAND DATA MINING </title>
<author> ByPaul S. Bradley </author>
<degree> A dissertation submitted in partial fulfillment of therequirements for the degree ofDoctor of Philosophy(Computer Sciences)at the </degree><affiliation> UNIVERSITY OF WISCONSIN - MADISON </affiliation>
<date> 1998 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> High-Bandwidth Address Translationfor Multiple-Issue Processors </title>
<author> Todd M. Austin Gurindar S. Sohi </author>
<affiliation> Computer Sciences DepartmentUniversity of Wisconsin-Madison </affiliation>
<address> 1210 W. Dayton StreetMadison, WI 53706 </address>
<email> faustin,sohig@cs.wisc.edu </email>
<abstract> AbstractIn an effort to push the envelope of system performance, microprocessor designs are continually exploiting higher levels ofinstruction-level parallelism, resulting in increasing bandwidth demands on the address translation mechanism. Most current microprocessor designs meet this demand with a multi-ported TLB. Whilethis design provides an excellent hit rate at each port, its access latency and area grow very quickly as the number of ports is increased.As bandwidth demands continue to increase, multi-ported designswill soon impact memory access latency.We present four high-bandwidth address translation mechanismswith latency and area characteristics that scale better than a multi-ported TLB design. We extend traditional high-bandwidth memorydesign techniques to address translation, developing interleaved andmulti-level TLB designs. In addition, we introduce two new designscrafted specifically for high-bandwidth address translation. Piggyback ports are introduced as a technique to exploit spatial locality insimultaneous translation requests, allowing accesses to the same virtual memory page to combine their requests at the TLB access port.Pretranslation is introduced as a technique for attaching translationsto base register values, making it possible to reuse a single translation many times.We perform extensive simulation-based studies to evaluate ourdesigns. We vary key system parameters, such as processor model,page size, and number of architected registers, to see what effectsthese changes have on the relative merits of each approach. A number of designs show particular promise. Multi-level TLBs with asfew as eight entries in the upper-level TLB nearly achieve the performance of a TLB with unlimited bandwidth. Piggyback portscombined with a lesser-ported TLB structure, e.g., an interleaved ormulti-ported TLB, also perform well. Pretranslation over a single-ported TLB performs almost as well as a same-sized multi-levelTLB with the added benefit of decreased access latency for physically indexed caches. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> PARALLEL CONSTRAINT DISTRIBUTION </title>
<author> M. C. FERRIS AND O. L. MANGASARIAN  </author>
<abstract> Abstract. Constraints of a mathematical program are distributed among parallel processors together with an appropriately constructed augmented Lagrangian for each processor, which containsLagrangian information on the constraints handled by the other processors. Lagrange multiplier information is then exchanged between processors. Convergence is established under suitable conditionsfor strongly convex quadratic programs and for general convex programs. </abstract>
<keyword> Key words. Parallel Optimization, Augmented Lagrangians, Quadratic Programs, Convex Programs </keyword>
<intro> 1. Introduction. We are concerned with the problem </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> OPTIMAL PROCESSOR ASSIGNMENT FOR PARALLELDATABASE DESIGN  </title>
<author>  SHAHRAM GHANDEHARIZADEH , ROBERT R. MEYER , GARY L. SCHULTZ AND JONATHAN YACKEL  </author>
<abstract> Abstract. The computing time benefits of parallelism in database systems (achieved by using multiple processors to execute a query) must be weighed against communication, startup, andtermination overhead costs that increase as a function of the number of processors used. We consider problems of minimizing overhead subject to allocating data among the processors accordingto specified loads. We present lower bounds for these combinatorial problems and demonstrate howprocessors may be optimally assigned for some problem classes. </abstract>
<intro> 1. Introduction. In highly-parallel database machines (e.g., Gamma [2], Bubba </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> PIECEWISE LINEAR HOMOTOPIES ANDAFFINE VARIATIONAL INEQUALITIES </title>
<author> ByMenglin Cao </author>
<degree> A thesis submitted in partial fulfillment of therequirements for the degree ofDoctor of Philosophy(Computer Sciences)at the </degree><affiliation> UNIVERSITY OF WISCONSIN - MADISON </affiliation>
<date> 1994 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> 1995 Computer Science Department MQPReview </title>
<author> Robert E. KinickiCraig E. Wills </author>
<affiliation> Computer Science DepartmentWorcester Polytechnic Institute </affiliation>
<address> Worcester, MA 01609 </address>
<pubnum> WPI-CS-TR-95-01 </pubnum>
<date> August 1, 1995 </date>
<abstract> AbstractThis report presents results of a peer review of MQPs conducted withinthe Computer Science Department during the Summer of 1995 as part of acampus-wide MQP review. The goal of the report is to assess whether thedepartment MQPs are accomplishing their educational goals. The reportidentifies problems that need to be addressed and trends that need to becontinued to make the MQPs a worthwhile learning experience. It reflectsdata and evaluations for 27 MQPs, involving 43 computer science students,that were completed between the Summer of 1994 and the Spring of 1995.The report also makes comparisons to similar reviews done in 1991 and 1993.Overall, the large majority of the projects are meeting the educationalgoals of the department as good learning experiences. The reviews indicatethe overall quality of the projects is good, about the same as in 1993 anda little better than 1991. The report draws a number of conclusions aboutthe success of the projects based upon the data collected and evaluationsdone for this review. The report concludes with recommendations for futureprojects. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> What Tasks Can Be Performed with an UncalibratedStereo Vision System?  </title>
<author> J. P. Hespanha, Z. Dodds, G. D. Hager, and A. S. Morse </author>
<affiliation> Center for Computational Vision and Controlc/o Computer Science Department </affiliation>
<address> P.O. Box 208285Yale UniversityNew Haven, CT, 06520 </address>
<phone> Phone: (203) 432-6432 </phone><email> E-mail: (gregory.hager, joao.hespanha, zachary.dodds, as.morse)@yale.edu </email>
<abstract> AbstractThis article studies the following question: "When is it possible to decide, on the basis of images of point features observed by an imprecisely modeled two-camera stereovision system, whether or not a prescribed robot positioning task has been accomplished with precision?" It is shown that for a stereo vision system with known epipo-lar geometry, whether or not such a positioning task has been accomplished can bedecided with available data, just in case the task function which specifies the task is aprojective invariant. </abstract>
<note> Submitted to IJCV special issue on vision research at Yale.This research was supported by the National Science Foundation, the Army Research Office, and theAir Force Office of Scientific Research </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> In Proc. 8th IASTED Int'l Conf. on Parallel and Distributed Computing and Systems (Chicago, IL, USA),c IASTED/ACTA Press (Anaheim/Calgary/Z urich), pp. 144-148, Oct. 1996. [ISBN: 0-88986-213-3] </note>
<title>  HPF and MPI Implementation of the NAS Parallel Benchmarks Supported by Integrated Program Engineering Tools </title>
<author>  Christian Cl emencon Karsten M. Decker Vaibhav R. Deshpande Akiyoshi Endo Josef Fritscher Paulo A. R. LorenzoNorio Masuda Andreas Muller Roland R uhlWilliam Sawyer Brian J. N. Wylie Frank Zimmermann  </author>
<affiliation> Centro Svizzero di Calcolo Scientifico (CSCS/SCSC) andNEC European Supercomputer Systems, Swiss Branch </affiliation>
<address> CH-6928 Manno, Switzerland </address>
<web> http://www.cscs.ch/Official/Project CSCS-NEC.html </web><abstract> Abstract: High Performance Fortran (HPF) compilersand communication libraries with the standardized Message Passing Interface (MPI) are becoming widely available, easing the development of portable parallel applications on distributed-memory parallel processor systems.The recently developed Annai tool environment supportsprogramming, debugging and tuning of both HPF- andMPI-based applications. Considering code developmentand subsequent maintenance time to be as important as ultimate performance, we address how sequential Fortran-77versions of the familiar NAS Parallel Benchmark kernelscan be expediently parallelized with appropriate tool support. While automatic parallelization of scientific applications written in traditional sequential languages remainslargely impractical, Annai provides users with high-levellanguage extensions and integrated program engineeringsupport tools. In this paper, Annai support is demonstrated primarily focusing on the MG (multigrid) kernel,with complementary examples selected from the other fourkernels. Respectable performance and good scalabilityin most cases are obtained with this straightforward par-allelization strategy, even without recourse to platform-specific optimizations or major program transformations. </abstract>
<keyword> Keywords: HPF &amp; MPI parallelization; parallel programengineering tools. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Explaining Anomalies as a Basis for Knowledge Base Refinement </title>
<author> Neli P. Zlatareva </author>
<affiliation> Department of Computer ScienceCentral Connecticut State University </affiliation>
<address> New Britain, CT 06050 </address>
<abstract> AbstractExplanations play a key role in operationalization-based anomaly detection techniques. In this paperwe show that their role is not limited to anomaly detection; they can also be used for guiding automatedknowledge base refinement. We introduce a refinement procedure which takes: (i) a small number ofrefinement rules (rather than test cases), and (ii) explanations constructed in an attempt to reveal thecause (or causes) for inconsistencies detected duringthe verification process, and returns rule revisionsaiming to recover the consistency of the KB-theory.Inconsistencies caused by more than one anomalyare handled at the same time, which improves theefficiency of the refinement process. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Confluent Preorder Parsing </title>
<pubnum> CS-TR-95-03 </pubnum>
<author> HO, Kei Shiu Edward and CHAN, Lai Wan </author>
<affiliation> Department of Computer ScienceThe Chinese University of Hong Kong </affiliation>
<address> Shatin, N.T., Hong Kong </address>
<email> email : ho052@cs.cuhk.hk and lwchan@cs.cuhk.hk </email>
<keyword> KEYWORDS: Neural Networks, Connectionist Syntactic Parsing, RAAM, Holistic Transformation, ConfluentPreorder Parser, Linearization of a Hierarchical Parse Tree, Parsing Erroneous Sentences, SyntacticDisambiguation </keyword>
<abstract> AbstractIn this paper, syntactic parsing is discussed in the context of connectionism. A new model - the ConfluentPreorder Parser (CPP), is proposed which exemplifies the holistic parsing paradigm. Holistic parsing has theadvantage that little assumption has to be made concerning the detailed parsing algorithm, which is oftenunknown or debatable, especially when human language understanding is concerned. In the CPP, syntacticparsing is achieved by transforming in a oneshot manner, from the connectionist representation of the sentenceto the connectionist representation of the preorder traversal of its parse tree, instead of the parse tree itself. Asrevealed by the simulation experiments, generalization performance is excellent (as high as 90%). Besides, theCPP is also capable of parsing erroneous sentences and resolving syntactic ambiguities. A systematic study isconducted to explore the range of factors which can affect the effectiveness of it. This error-recovery capabilityis especially useful in natural language processing when incomplete or even ungrammatical sentences are to bedealt with. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Assessing Responses to Situated Cognition </title>
<author> Tim Menzies </author>
<affiliation> Dept. of Artifical Intelligence, School of Computer Science and Engineering,The University of New South Wales, </affiliation>
 <address> Sydney, Australia, 2052 </address>
<email> timm@cse.unsw.edu.au; </email>
 <web> http://www.cse.unsw.edu.au/~timm </web> <date> September 17, 1996 </date>
<abstract> AbstractSituated cognition (SC) claims that knowledge is mostly context-dependent and that symbolic descriptions elicited prior to direct experience are less important than functional units developed via directexperience with the current problem. If this were true, then we would need to modify the knowledgemodeling approaches of KA which assume that re-using old symbolic descriptions are a productivity toolfor new applications. There are numerous tools which, if added to conventional knowledge modeling,could be said to handle SC (e.g. machine learning, abduction, verification &amp; validation tools, repertorygrids, certain frameworks for decision support systems, expert critiquing systems, and ripple-down-rules).However, we require an experiment to assess the effectiveness of these tools as a response to SC. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> DRAFT </note>
 <date> June 2, 1996: </date>
<title> Learning stable concepts in domains with hidden changes in context </title>
<author> Michael Harries </author>
<affiliation>  Department of Artificial IntelligenceSchool of Computer Science and Engineering University of NSW, </affiliation>
 <address> Australia </address>
<email> mbh@cse.unsw.edu.au </email>
<author> Kim Horn </author>
<affiliation> Predictive Strategies UnitAustralian Gilt Securities Limited </affiliation>
<address> Australia </address>
<email> kim@ags.com.au </email>
<abstract> AbstractThis paper presents Splice, a batch meta-learning system, designed to learn locally stable concepts in domains with hidden changesin context. The majority of machine learningalgorithms assume that target concepts remain stable over time. In many domains thisassumption is invalid. For example, financial prediction, medical diagnosis, and network performance are domains in which target concepts may not remain stable. Unstable target concepts are often due to changesin a hidden context. Existing works on learning in the presence of hidden changes in context use an incremental learning approach. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Minimum Encoding Approaches for Predictive Modeling </title>
<author> Peter Grunwald </author>
<affiliation>  CWI Dept. of Algorithms and Architectures </affiliation>
<address> P.O.Box 94079NL-1090 GB Amsterdam, The Netherlands </address>
<web> http://www.cwi.nl/~pdg/ </web><author>  Petri Kontkanen, Petri Myllymaki, Tomi Silander, Henry Tirri </author>
<affiliation> Complex Systems Computation Group (CoSCo) </affiliation>
<address> P.O.Box 26, Department of Computer ScienceFIN-00014 University of Helsinki, Finland </address>
<web> http://www.cs.Helsinki.FI/research/cosco/ </web><note> To appear in the Proceedings of the Fourteenth International Conference on Uncertainty in Artificial Intelligence(Madison, WI, July 1998). </note>
<abstract> AbstractWe analyze differences between twoinformation-theoretically motivated approaches to statistical inference and modelselection: the Minimum Description Length(MDL) principle, and the Minimum MessageLength (MML) principle. Based on thisanalysis, we present two revised versions ofMML: a pointwise estimator which givesthe MML-optimal single parameter model,and a volumewise estimator which givesthe MML-optimal region in the parameterspace. Our empirical results suggest thatwith small data sets, the MDL approachyields more accurate predictions than theMML estimators. The empirical resultsalso demonstrate that the revised MMLestimators introduced here perform betterthan the original MML estimator suggestedby Wallace and Freeman. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Space of Presentation Emphasis Techniques for Visualizing Graphs </title>
<author> Emanuel G. Noik </author>
<affiliation> Computer Systems Research InstituteUniversity of Toronto </affiliation>
<address> 6 King's College RoadToronto, Ontario, Canada m4s 1a1 </address>
<email> e-mail: noik@db.toronto.edu </email>
<phone> Telephone: (416) 978 8609 </phone><abstract> AbstractThe graph topo-visual formalism has been shown tobe well-suited to the task of visualizing complex relations on a set of elements. Unfortunately, most visualformalisms do not scale very well. This observation isparticularly true of graphs, which even when hand-drawnby an artist, are seldom meaningful when the number ofnodes or links exceeds a very modest threshold typically only a few hundred elements. This severe limitationhas prompted many researchers to seek alternative visualization techniques that may eliminate, or, at the veryleast, raise this threshold.In this paper we analyze these recent efforts, describean abstract space of presentation emphasis techniques,and locate the current approaches within this space. Thecontributions of this paper are several: (1) a significantportion of recent work is collected and reviewed; (2) acommon set of criteria and a taxonomy of graph viewsare proposed; these, (3) permit a more direct comparisonof previous work; which helps to, (4) identify commonshortcomings and limitations; which in turn, (5) suggestfuture directions. </abstract>
<keyword> Keywords: presentation emphasis techniques, fisheyeviews, relational data visualization, graphs, nestedgraphs. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Proving Properties of Logic Programs byAbstract Diagnosis </title>
<author> Marco Comini 1 , Giorgio Levi 1 , Maria Chiara Meo 2 , and Giuliana Vitiello 3 </author>
<affiliation> 1 Dipartimento di Informatica, Universita di Pisa, </affiliation>
 <address> Corso Italia 40, 56125 Pisa, Italy, </address>
</NEW_HEADER>
<NEW_HEADER>
<title> The Semantics of the C Programming Language </title>
<author> Yuri Gurevich and James K. Huggins  </author>
<affiliation> EECS Department, University of Michigan, </affiliation>
 <address> Ann Arbor, MI 48109-2122, USA </address>
<date> February 19, 1993 </date>
<note> This paper first appeared in [GH2], and incorporates the corrections indicated in [GH3]. </note>
<intro> 0 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Evolving Algebra Abstract Machine </title>
<author> Giuseppe Del Castillo 1 , Igor D - urd -anovic 2 , Uwe Glasser 1 </author>
<affiliation> 1 Heinz Nixdorf Institut, Universitat-GH Paderborn, </affiliation>
 <address>  Furstenallee 11, 33102 Paderborn, Germany, </address>
 <email> fgiusp,glaesserg@uni-paderborn.de </email>
<affiliation> 2 FB Mathematik-Informatik, Universitat-GH Paderborn, </affiliation>
 <address> Warburger Str. 100,33098 Paderborn, Germany, </address>
 <email> igor@uni-paderborn.de </email>
<abstract> Abstract. Evolving algebras (EAs) as defined by Yuri Gurevich constitute the basis of a powerful and elegant specification and verificationmethod which has successfully been applied to the design and analysis ofvarious kinds of discrete dynamic systems. Aiming at the developmentof a comprehensive EA-based specification and design environment, weintroduce the concept of an evolving algebra abstract machine (EAM ) asa platform for the systematic development of EA tools; for instance, asrequired for machine based analysis and execution of EA specifications.We give a formal definition of the EAM ground model in terms of auniversal evolving algebra, where we validate the correctness of the relation between evolving algebras (their theoretical foundations) and theirEAM representation and interpretation. Our approach covers sequentialas well as distributed evolving algebras. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Defining the Java Virtual Machine as Platformfor Provably Correct Java Compilation ? </title>
<author> Egon Borger 1 and Wolfram Schulte 2 </author>
<affiliation> 1 Universita di Pisa, Dipartimento di Informatica, </affiliation>
 <address> I-56125 Pisa, Italy </address>
<email> boerger@di.unipi.it </email>
<affiliation> 2 Universitat Ulm, Fakultat fur Informatik, </affiliation>
 <address> D-89069 Ulm, Germany </address>
<email> wolfram@informatik.uni-ulm.de </email>
<abstract> Abstract. We provide concise abstract code for running the Java Virtual Machine (JVM) to execute compiled Java programs, and define ageneral compilation scheme of Java programs to JVM code. These definitions, together with the definition of an abstract interpreter of Javaprograms given in our previous work [3], allow us to prove that anycompiler that satisfies the conditions stated in this paper compiles Javacode correctly. In addition we have validated our JVM and compilerspecification through experimentation.The modularity of our definitions for Java, the JVM and the compilationscheme exhibit orthogonal language, machine and compiler components,which fit together and provide the basis for a stepwise and provably correct design-for-reuse. As a by-product we provide a challenging realisticcase study for mechanical verification of a compiler correctness proof. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Refining Abstract Machine Specifications of theSteam Boiler Control to Well DocumentedExecutable Code </title>
<author> Christoph Beierle, Egon Borger, Igor D - urd -anovic, Uwe Glasser, ElviniaRiccobene </author>
<affiliation> 1 Fernuniversitat-GH Hagen, </affiliation>
 <address> Germany, </address>
 <email> christoph.beierle@fernuni-hagen.de </email>
<affiliation> 2 Universita di Pisa, </affiliation>
 <address> Italy, </address>
 <email> boerger@di.unipi.it </email>
<affiliation> 3 Universitat-GH Paderborn, </affiliation>
 <address> Germany, </address>
 <email> igor@uni-paderborn.de </email>
<affiliation> 4 Universitat-GH Paderborn, </affiliation>
 <address> Germany, </address>
 <email> glaesser@uni-paderborn.de </email>
<affiliation> 5 Universita di Catania, </affiliation>
 <address> Italy, </address>
 <email> riccobene@dipmat.unict.it </email>
<abstract> Abstract. We use the steam boiler control specification problem to illustrate how the evolving algebra approach to the specification and theverification of complex systems can be exploited for a reliable and welldocumented development of executable, but formally inspectable andsystematically modifiable code. A hierarchy of stepwise refined abstractmachine models is developed, the ground version of which can be checkedfor whether it faithfully reflects the informally given problem. The sequence of machine models yields various abstract views of the system,making the various design decisions transparent, and leads to a C++program. This program has been demonstrated during the Dagstuhl-Meeting on Methods for Semantics and Specification, in June 1995, tocontrol the Karlsruhe steam boiler simulator satisfactorily.The abstract machines are evolving algebras and thereby have a rigoroussemantical foundation, allowing us to formalize and prove, under precisely stated assumptions, some typical sample properties of the system.This provides insight into the structure of the system which supportseasily maintainable extensions and modifications of both the abstractspecification and the implementation. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Reasoning about Other Agents: Philosophy,Theory, and Implementation. </title>
<author> Piotr J. Gmytrasiewicz and Edmund H. Durfee  </author>
<affiliation> Department of Computer ScienceHebrew University, </affiliation>
 <address> Jerusalem, Israel </address>
<affiliation> Department of Electrical Engineering and Computer ScienceUniversity of Michigan, </affiliation>
 <address> Ann Arbor, Michigan 48109 </address>
<email> piotr@cs.huji.ac.il, durfee@engin.umich.edu </email>
<abstract> AbstractDrawing on on our work in the area of Distributed Artificial Intelligence, we propose the rudiments of a view of multiagent reasoning that relates current philosophicalintuitions, theoretical foundations, and preliminary implementation. The philosophicalposition we take is a combination of Daniel Dennett's philosophy of the ladder of per-sonhood (consisting of rationality, intentionality, stance, reciprocity, communication,and consciousness) on one hand, and the utilitarian philosophy of selfish utility maximization on the other hand. The theories we incorporate are logics of knowledge andbelief, which in addressing the multiagent issues can be developed based on a recursiveversion of the Kripke structure, and the related fields of utility, decision and gametheories. Our preliminary implementation, the Recursive Modeling Method (RMM),lets an agent coordinate its actions with the actions of other agents, cooperate withthem when appropriate, and rationally choose an optimal form of communication withthem. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Observational Uncertainty in Plan Recognition Among InteractingRobots  </title>
<author> Marcus J. HuberEdmund H. Durfee </author>
<affiliation> Distributed Intelligent Agents Group (DIAG)Artificial Intelligence LaboratoryThe University of Michigan </affiliation>
<address> Ann Arbor, Michigan 48109-2110 </address>
<email> marcush@engin.umich.edu, durfee@engin.umich.edu </email>
<date> May 16, 1994 </date>
<abstract> AbstractPlan recognition is the process of observing another agent's behavior(s) and inferring what, andpossibly why, the agent is acting as it is. Plan recognition becomes a very important means of acquiringsuch information about other agents in situations and domains where explicit communication is eithervery costly, dangerous, or impossible. Performing plan recognition in a physical domain (i.e. the realworld) forces the world's ubiquitous uncertainty upon the observing agent because of the necessity touse real sensors to make the observations. We have developed a multiple resolution, hierarchical planrecognition system to coordinate the motion of two interacting mobile robots. Uncertainty arises in thesystem from dead reckoning errors that accumulate while the robots are moving, as well as by errorsin the computer vision system that is used to detect the other agent's behaviors. Based upon beliefnetworks, the plan recognition system gracefully degrades in performance as the level of uncertaintyabout observations increase. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Using MICE to Study Intelligent Dynamic Coordination </title>
<author> Edmund H. Durfee and Thomas A. Montgomery </author>
<affiliation> Department of Electrical Engineering and Computer ScienceUniversity of Michigan </affiliation>
<address> Ann Arbor, Michigan 48109 </address>
<phone> (313) 936-1563 </phone><email> durfee@caen.engin.umich.edu </email>
<abstract> AbstractWe describe a flexible experimental testbed, called MICE, for distributed artificial intelligenceresearch. We argue that the adoption of MICE (or some other standard testbed) by the distributedartificial intelligence community can draw together the community and permit a much greater levelof exchange of ideas, formalisms, and techniques. MICE allows an experimenter to specify theconstraints and characteristics of an environment in which agents are simulated to act and interact,and does not assume any particular implementation of an agent's reasoning architecture. MICEtherefore provides a platform for investigating and evaluating alternative reasoning architecturesand coordination mechanisms in many different simulated environments. We outline the designof MICE and illustrate its flexibility by describing simulated environments that model the coordination issues in domains such as predators chasing prey, predators attacking each other, agentsfighting a fire, and diverse robots that are working together. In addition, we note that MICE'sability to simulate multi-agent environments makes it an ideal platform for studying reasoning indynamic worlds; we can associate functionality to arbitrary objects in order to trigger changes inthe environment. We conclude by discussing the status of MICE and how we are using MICE inour current research. </abstract>
<note> 0 This research was sponsored, in part, by the University of Michigan under a Rackham Faculty ResearchGrant, and by a Bell Northern Research Postgraduate Award. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> PENALIZED LIKELIHOOD EMISSION IMAGE RECONSTRUCTIONWITH UNCERTAIN BOUNDARY INFORMATION </title>
<author> Stephen R. Titus, Alfred O. Hero III, Jeffrey A. Fessler </author>
<address> 4401 EECS, University of Michigan, Ann Arbor, MI 48109 </address>
<abstract> ABSTRACTIn this paper, a method is introduced for incorporating perfectly registered MRI boundary information intoa penalized likelihood emission reconstruction scheme.The boundary curve is modeled as a periodic splinewhose coefficients are estimated from the MRI image.The resulting boundary estimate is mapped to a spatially variant set of Gibbs weights. When incorporated into a quadratic roughness penalty, these weightsimprove emission reconstruction bias/variance performance by preventing smoothing across the estimatedboundary. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Observational Uncertainty in Plan Recognition Among InteractingRobots  </title>
<author> Marcus J. HuberEdmund H. Durfee </author>
<affiliation> Distributed Intelligent Agents Group (DIAG)Artificial Intelligence LaboratoryThe University of Michigan </affiliation>
<address> Ann Arbor, Michigan 48109-2110 </address>
<email> marcush@engin.umich.edu, durfee@engin.umich.edu </email>
<date> May 16, 1994 </date>
<abstract> AbstractPlan recognition is the process of observing another agent's behavior(s) and inferring what, andpossibly why, the agent is acting as it is. Plan recognition becomes a very important means of acquiringsuch information about other agents in situations and domains where explicit communication is eithervery costly, dangerous, or impossible. Performing plan recognition in a physical domain (i.e. the realworld) forces the world's ubiquitous uncertainty upon the observing agent because of the necessity touse real sensors to make the observations. We have developed a multiple resolution, hierarchical planrecognition system to coordinate the motion of two interacting mobile robots. Uncertainty arises in thesystem from dead reckoning errors that accumulate while the robots are moving, as well as by errorsin the computer vision system that is used to detect the other agent's behaviors. Based upon beliefnetworks, the plan recognition system gracefully degrades in performance as the level of uncertaintyabout observations increase. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Route Guidance Support in Intelligent TransportationSystems: An Encoded Path View Approach  </title>
<pubnum> University of Michigan Technical Report 1995. </pubnum>
<author> Yun-Wu Huangy, Ning Jingz, and Elke A. Rundensteinery </author>
<email> e-mail: [ywh j jning j rundenst] @eecs.umich.edu </email>
<affiliation> Department of Electrical Engineering and Computer ScienceUniversity of Michigan, </affiliation>
 <address> Ann Arbor, MI 48109 </address>
<affiliation> Department of Electrical EngineeringChangsha Institute of Technology, </affiliation>
 <address> Changsha, Hunan, P.R. China </address>
<abstract> AbstractEfficient path computation necessary for route guidance has been identified as one of the key requirementsfor Intelligent Transportation Systems (ITS) applications. While the current ITS literature has focused onthe application of search algorithms (typically, heuristic A* algorithms) to provide for compute-on-demandpath finding, we propose an encoded path view approach that precomputes optimal paths. Advantages ofour approach include (1) route search is efficient and less dependent on system load, (2) alternative pathsare materialized in addition to the optimal paths, simplifying the process of global optimization, (3) thestorage overhead is manageable and less than for the full enumeration of all possible paths. In this paper,we present algorithms for incrementally updating the encoded path view structure in response to weightchanges on the traffic links of the underlying network. Despite non-optimal paths also being materialized, ouralgorithms are designed to operate on cyclic planar graphs | given that ITS maps typically correspond tohighly interconnected grid structures. In this paper, we show that while our approach does not encode allpaths, it omits some non-optimal paths to resolve cycle ambivalence and will recover them once they becomeoptimal. Proofs of correctness and of complexity are also given. We demonstrate the potential of our approachby presenting experimental results of evaluating our approach both on randomly generated as well as on realcity map data. Our experiments furthermore compare the proposed approach against more conventional pathsearching algorithms, which correspond to the state-of-the-art for route guidance in ITS. </abstract>
<keyword> Index Terms | View Materialization, Encoded Path Structure, Route Guidance, Path Retrieval, Map Databases,Cycle Detection. </keyword>
<note> This work was supported in part by the University of Michigan ITS Center of Excellence grant (DTFH61-93-X-00017-Sub)sponsored by the U.S. Department of Transportation and by the Michigan Department of Transportation. Ning Jing, on leavefrom the Changsha Institute of Technology, is currently visiting the University of Michigan and likes to thank the State EducationCommission of P.R. China. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Hierarchical Path Views: A Model Based on Fragmentation andTransportation Road Types  </title>
<author> Yun-Wu Huangy, Ning Jingz, and Elke A. Rundensteinery </author>
<email> e-mail: [ywh j jning j rundenst] @eecs.umich.edu </email>
<affiliation> Dept. of Electrical Engineering and Computer Science, Univ. of Michigan, </affiliation>
 <address> Ann Arbor, MI48109 </address>
<affiliation> Dept. of Electrical Engineering, Changsha Institute of Technology, </affiliation>
 <address> Changsha, Hunan, China </address>
<abstract> AbstractEfficient path query processing necessary for route guidance has been identified as one of the key requirementsfor Intelligent Transportation Systems (ITS) applications.While precomputing the view of all shortest paths providesthe most efficient path retrieval, the view maintenance andstorage costs become unrealistic for large ITS networks. Basedon ITS road type classification, we propose a hierarchicalpath view approach, in which the path view maintenanceand storage costs are dramatically reduced at the cost ofnegligible loss of path optimality. Comparing with the traditional ITS path finding approaches that use A or hierarchical A , our hierarchical approach is superior in threeareas: 1) path search is more efficient, 2) the connectingpoint from the low-level roads to the high-level roads andvice versa are dynamically determined based on the mostrecent traffic, 3) within one region, the high-level traffic canbe dynamically rerouted through the low-level roads. Inthis paper, we conduct experiments to gain insight into theperformance of our proposed algorithms and model, as wellas to contrast the difference in computational resource requirements between the hierarchical path view and the A algorithms. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Hierarchical Optimization of Optimal Path Finding forTransportation Applications  </title>
<author> Ning Jing  </author>
<affiliation> Changsha Institute of Technology </affiliation>
<email> jning@eecs.umich.edu </email>
<author> Yun-Wu Huang </author>
<affiliation> University of Michigan </affiliation>
<email> ywh@eecs.umich.edu </email>
<author> Elke A. Rundensteiner </author>
<affiliation> University of Michigan </affiliation>
<email> rundenst@eecs.umich.edu </email>
<abstract> AbstractEfficient path query processing is a key requirement for advanceddatabase applications including GIS (Geographic Information Systems) and ITS (Intelligent Transportation Systems). We study theproblem in the context of automobile navigation systems where alarge number of path requests can be submitted over the transportation network within a short period of time. To guarantee efficient re-sponsefor path queries, we employ a path view materialization strategy for precomputing the best paths. We tackle the following threeissues: (1) memory-resident solutions quickly exceed current computer storage capacity for networks of thousands of nodes, (2) disk-based solutions have been found inefficient to meet the stringentperformance requirements, and (3) path views become too costlyto update for large graphs. We propose the HEP V (HierarchicalEncoded Path View) approach that addresses these problems whileguaranteeing the optimality of path retrieval. Our experimental results reveal that HEP V is more efficient than previously knownpath finding approaches. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> In Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence (UAI-96),Portland, OR, USA, August 1996 </note>
<title> Optimal Factory Scheduling using Stochastic Dominance A* </title>
<author> Peter R. Wurman and Michael P. Wellman </author>
<affiliation> University of MichiganArtificial Intelligence Laboratory </affiliation>
<address> 1101 Beal AvenueAnn Arbor, MI, 48109-2110 </address>
<email> fpwurman, wellmang@umich.edu </email>
<abstract> AbstractWe examine a standard factory schedulingproblem with stochastic processing and setuptimes, minimizing the expectation of theweighted number of tardy jobs. Becausethe costs of operators in the schedule arestochastic and sequence dependent, standarddynamic programming algorithms such asA* may fail to find the optimal schedule.The SDA* (Stochastic Dominance A*) algorithm remedies this difficulty by relaxing thepruning condition. We present an improvedstate-space search formulation for these problems and discuss the conditions under whichstochastic scheduling problems can be solvedoptimally using SDA*. In empirical testingon randomly generated problems, we foundthat in 70%, the expected cost of the optimal stochastic solution is lower than that ofthe solution derived using a deterministic approximation, with comparable search effort. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Eaton's Markov Chain, its Conjugate Partnerand P-admissibility </title>
<author> James P. Hobert  </author>
<affiliation> Department of StatisticsUniversity of Florida </affiliation>
<address> Gainesville, FL 32611 </address>
<email> jhobert@stat.ufl.edu </email>
<author> C. P. Robert </author>
<affiliation> Laboratoire de StatistiqueCREST, INSEE </affiliation>
<address> 75675 Paris cedex 14, France </address>
<email> robert@ensae.fr </email>
<date> August 1997 </date>
<note> The first author acknowledges partial support from the Center for Research in Economics andStatistics (CREST) at the French National Institute of Statistics and Economic Studies (INSEE),Paris, France. </note>
<note> AMS 1991 subject classifications. Primary 62C15; secondary 60J05 </note>
<keyword> Key words and phrases. Bilinear model, Branching process with immigration, Exponentialfamily, Improper prior, Null recurrence, Random walk, Stochastic difference equation, TransienceAbbreviated title. Markov Chains and P-admissibility </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Dynamic Generation and Refinement of Concept Hierarchies forKnowledge Discovery in Databases  </title>
<author> Jiawei Han and Yongjian Fu </author>
<affiliation> School of Computing ScienceSimon Fraser University </affiliation>
<address> Burnaby, B.C., Canada V5A 1S6 </address>
<email> fhan, yongjiang@cs.sfu.ca </email>
<abstract> AbstractConcept hierarchies organize data and concepts in hierarchical forms or in certain partial order, whichhelps expressing knowledge and data relationships in databases in concise, high level terms, and thus, playsan important role in knowledge discovery processes. Concept hierarchies could be provided by knowledgeengineers, domain experts or users, or embedded in some data relations. However, it is sometimes desirable to automatically generate some concept hierarchies or adjust some given hierarchies for particularlearning tasks. In this paper, the issues of dynamic generation and refinement of concept hierarchies arestudied. The study leads to some algorithms for automatic generation of concept hierarchies for numerical attributes based on data distributions and for dynamic refinement of a given or generated concepthierarchy based on a learning request, the relevant set of data and database statistics. These algorithmshave been implemented in the DBLearn knowledge discovery system and tested against large relationaldatabases. The experimental results show that the algorithms are efficient and effective for knowledgediscovery in large databases. </abstract>
<keyword> Keywords: Knowledge discovery in large databases, discovery methods, KDD system implementation, algorithms, dynamic generation and refinement of concept hierarchies. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Multi-Agent Planning as a Dynamic Search for Social Consensus </title>
<author> Eithan EphratiJeffrey S. Rosenschein  </author>
<affiliation> Computer Science DepartmentHebrew University </affiliation>
<address> Givat Ram, Jerusalem, Israel </address>
<abstract> AbstractWhen autonomous agents attempt to coordinate action, it is often necessary that they reachsome kind of consensus. Reaching consensushas traditionally been dealt with in the Distributed Artificial Intelligence literature via negotiation. Another alternative is to have agentsuse a voting mechanism; each agent expressesits preferences, and a group choice mechanismis used to select the result. Some choice mechanisms are better than others, and ideally wewould like one that cannot be manipulated byuntruthful agents.Coordination of actions by a group of agentscorresponds to a group planning process. Wehere introduce a new multi-agent planningtechnique, that makes use of a dynamic, iterative search procedure. Through a process ofgroup constraint aggregation, agents incrementally construct a plan that brings the group toa state maximizing social welfare. At each step,agents vote about the next joint action in thegroup plan (i.e., what the next transition statewill be in the emerging plan). Using this technique agents need not fully reveal their preferences, and the set of alternative final statesneed not be generated in advance of a vote.With a minor variation, the entire procedurecan be made resistant to untruthful agents. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> SUPPORTING TECHNOLOGY TRANSFER OF FORMAL TECHNICAL REVIEWTHROUGH A COMPUTER SUPPORTED COLLABORATIVE REVIEW SYSTEM </title>
<author> Philip M. Johnson </author>
<affiliation> Department of Information and Computer SciencesUniversity of Hawaii </affiliation>
<address> Honolulu, HI 96822 </address>
<phone> (808) 956-3489 </phone><email> johnson@hawaii.edu </email>
<abstract> AbstractFormal technical review (FTR) is an essential component of all modern software quality assessment, assurance,and improvement techniques, and is acknowledged to bethe most cost-effective form of quality improvement whenpracticed effectively. However, traditional FTR methodssuch as inspection are very difficult to adopt in organizations: they introduce substantial new up-front costs,training, overhead, and group process obstacles. Sustained commitment from high-level management alongwith substantial resources is often necessary for successfultechnology transfer of FTR.Since 1991, we have been designing and evaluatinga series of versions of a system called CSRS: an instrumented, computer-supported cooperative work environment for formal technical review. The current version ofCSRS includes an FTR method definition language, whichallows organizations to design their own FTR method,and to evolve it over time. This paper describes how ourapproach to computer supported FTR can address someof the issues in technology transfer of FTR. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Experiences with CLARE: a Computer-SupportedCollaborative Learning Environment </title>
<author> Dadong Wan </author>
<affiliation> Center for Information Technology &amp; ManagementWalter A. Haas School of BusinessUniversity of California </affiliation>
<address> Berkeley, CA 94720-1900, USA </address>
<author> Philip M. Johnson </author>
<affiliation> Department of Information and Computer SciencesUniversity of Hawaii </affiliation>
<address> Honolulu, HI 96822, USA </address>
<date> September 2, 1994 </date>
<abstract> AbstractCurrent collaborative learning systems focus on maximizing shared information.However, meaningful learning is not simply information sharing but also knowledgeconstruction. CLARE is a computer-supported learning environment that facilitatesmeaningful learning through collaborative knowledge construction. It provides a semiformal representation language called RESRA and an explicit process model calledSECAI. Experimental evaluation through 300 hours of classroom usage indicates thatCLARE does support meaningful learning. It also shows that a major bottleneck tocomputer-mediated knowledge construction is summarization. Lessons learned throughthe design and evaluation of CLARE provide new insights into both collaborative learningsystems and collaborative learning theories. </abstract>
<note> This paper is a revised and expanded version of one appearing in the Proceedings of the 1994 ACMConference on Computer Supported Cooperative Work, October 22-26, 1994, Chapel Hill, North Carolina,U.S.A. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Combinatory Differential Fields:An Algebraic Approach toApproximate Computation andConstructive Analysis  </title>
<author> Karl Aberer  </author>
<pubnum> TR-91-061 </pubnum>
<date> November 1991 </date>
<abstract> AbstractThe algebraic structure of combinatory differential fields is constructed to provide a semantics for computations in analysis. In this setting programs, approximations, limits and operations of analysis are representedas algebraic terms. Analytic algorithms can be derived by algebraic methods. The main tool in this construction are combinatory models which are inner algebras of Engeler graph models. As an universal domainof denotational semantics the lattice structure of the graph models allows to give a striking simple semanticsfor computations with approximations. As models of combinatory algebra they provide all essential computational constructs, including recursion. Combinatory models are constructed as extensions of first ordertheories. The classical first order theory to describe analysis is the theory of differential fields. It turns outthat two types of computational constructs, namely composition and piecewise definition of functions, arepreferably introduced as extensions of the differential fields theory. Combinatory differential fields are thenthe combinatory models of these enriched differential fields. We show for basic algorithms of computationalanalysis how their combinatory counterparts are derived in the algebraic setting. We illustrate how thesealgorithms are suitable to be implemented in a computer algebra environment like mathematica. </abstract>
<note> Part of this work was done while the author was at ETH Zurich. Submitted to Journal of SymbolicComputation. </note>
<address> International Computer Science Institute, Berkeley, CA 94704. </address>
<email>  email: aberer@icsi.berkeley.edu. </email>
 <note> Supported by Schweizerische Gesellschaft zur Forderung der Informatik und ihrer Anwendungen </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Study of PerceptuallyGrounded Polysemy in a SpatialMicrodomain </title>
<author> Jordan Zlatev  </author>
<pubnum> TR-92-048 </pubnum>
<date> August 1992 </date>
<abstract> AbstractThis paper attempts to exemplify the advantages of perceptually grounded semantics with respect to traditional formalist approaches in elucidating the nature of thecontroversial notion of linguistic polysemy, or multiplicity of meaning. It is also suggested how some aspects of language typically associated with compositionality couldbe modeled, without there being a strictly "compositional semantics".This is done through a series of experiments, using modifications of Terry Regier'sconnectionist system for learning spatial relations [Regier, 1992] which constitutes apart of the L 0 project concerned with associating descriptions in an arbitrary languagewith an analog environment, (sequences of) pictures of simple 2-dimensional scenes.The emphasis is above all on the English preposition `over', famous for its poly-semy, and analyzed in detail by [Brugman, 1981] and [Lakoff, 1987], but some modeling has been also done of the meaning of `under', as well as some rudimentarysemantics for simple verbs such as `be', `go' and `fly' that combine with the twoprepositions. </abstract>
<note> The author has been supported by a scholarship from The Swedish Institute and may be reached bye-mail as zlatev@icsi.Berkeley.EDU or jordan@ling.su.se. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> An Efficient Parallel Algorithmfor Computing a MaximalIndependent Set in aHypergraph of Dimension 3 </title>
<author> Elias Dahlhaus 1Marek Karpinski 2Peter Kelsen 3 </author>
<pubnum> TR-92-071 </pubnum>
<date> October, 1992 </date>
<abstract> AbstractThe paper considers the problem of computing a maximal independent setin a hypergraph (see [3] and [7]). We present an efficient deterministic NCalgorithm for finding a maximal independent set in a hypergraph of dimension3: the algorithm runs in time O(log 4 n) time on n + m processors of anEREW PRAM and is optimal up to a polylogarithmic factor. Our algorithmadapts the technique of Goldberg and Spencer ([5]) for finding a maximalindependent set in a graph (or hypergraph of dimension 2). It is the firstefficient NC algorithm for finding a maximal independent set in a hypergraphof dimension greater than 2. </abstract>
<affiliation>  Department of Computer Science, University of Bonn, </affiliation>
 <address> 5300 Bonn 1. </address>
</NEW_HEADER>
<NEW_HEADER>
<title> Efficient PRAM Simulation on aDistributed Memory Machine </title>
<author> Richard M. Karp  </author>
<affiliation> University of California at Berkeley andInternational Computer Science Institute, </affiliation>
 <address> Berkeley, CA </address>
<author> Michael Luby  </author>
<affiliation> International Computer Science Institute, </affiliation>
 <address> Berkeley, CA  </address>
<affiliation> and UC Berkeley </affiliation>
<author> Friedhelm Meyer auf der Heide  </author>
<affiliation> Heinz Nixdorf Institute and Computer Science Department, </affiliation>
<affiliation> University of Paderborn, </affiliation>
 <address>  Germany </address>
<pubnum> TR-93-040 </pubnum>
<date> August 1993 </date>
<abstract> AbstractWe present algorithms for the randomized simulation of a shared memory machine(PRAM) on a Distributed Memory Machine (DMM). In a PRAM, memory conflictsoccur only through concurrent access to the same cell, whereas the memory of aDMM is divided into modules, one for each processor, and concurrent accesses tothe same module create a conflict. The delay of a simulation is the time needed tosimulate a parallel memory access of the PRAM. Any general simulation of an mprocessor PRAM on a n processor DMM will necessarily have delay at least m=n. Arandomized simulation is called time-processor optimal if the delay is O(m=n) withhigh probability. Using a novel simulation scheme based on hashing we obtain atime-processor optimal simulation with delay O(loglog(n)log (n)). The best previoussimulations use a simpler scheme based on hashing and have much larger delay:fi(log(n)= loglog(n)) for the simulation of an n processor PRAM on an n processorDMM, and fi(log(n)) in the case where the simulation is time-processor optimal. </abstract>
<note> Research partially supported by NSF/DARPA Grant CCR-9005448Research partially supported by NSF operating grant CCR-9016468 and by grant No. 89-00312 fromthe United States-Israel Binational Science Foundation (BSF), Jerusalem, Israel.Part of work was done during a visit at the International Computer Science Institute at Berkeley;supported in part by DFG-Forschergruppe "Effiziente Nutzung massiv paralleler Systeme, Teilprojekt 4",and by the Esprit Basic Research Action Nr. 7141 (ALCOM II). </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Modeling a Copier Paper Path:A Case Study in ModelingTransportation Processes </title>
<author> Vineet Gupta Peter Struss  </author>
<pubnum> TR-95-019 </pubnum>
<abstract> AbstractWe present a compositional model of paper transportation in a photocopier that is meant tosupport different problem solving tasks like simulation and diagnosis, and to be applicable toa variety of configurations. Therefore, we try to avoid making hard-wired implicit assumptionsabout design principles and possible scenarios. In order to simplify our analysis, the modelabstracts away from the physical forces and reasons only about velocities. Nonetheless, itsucceeds in determining essential features of the motion of the sheet of paper like bucklingand tearing. The framework provided is quite generic and can be used as a starting point fordeveloping models of other transportation domains. </abstract>
<affiliation> Xerox Palo Alto Research Center, </affiliation>
 <address> 3333 Coyote Hill Road, Palo Alto CA 94304 USA. </address>
 <email> (vgupta@parc.xerox.com) </email>
<affiliation> Technical University of Munich, </affiliation>
 <address> Orleansstr. 34, D-81667 Munich, Germany. </address>
 <email> (struss@informatik.tu-muenchen.de) </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Parallel Sorting With LimitedBandwidth </title>
<author> Micah Adler John W Byers Richard M Karp  </author>
<pubnum> TR-TR-95-031 </pubnum>
<date> July 1995 </date>
<abstract> AbstractWe study the problem of sorting on a parallel computer with limited communicationbandwidth. By using the recently proposed PRAM(m) model, where p processorscommunicate through a small, globally shared memory consisting of m bits, we focuson the trade-off between the amount of local computation and the amount of inter-processor communication required for parallel sorting algorithms. We prove a lowerbound of ( n log mm ) on the time to sort n numbers in an exclusive-read variant ofthe PRAM(m) model. We show that Leighton's Columnsort can be used to givean asymptotically matching upper bound in the case where m grows as a fractionalpower of n. The bounds are of a surprising form, in that they have little dependenceon the parameter p. This implies that attempting to distribute the workload acrossmore processors while holding the problem size and the size of the shared memoryfixed will not improve the optimal running time of sorting in this model. We alsoshow that both the upper and the lower bound can be adapted to bridging modelsthat address the issue of limited communication bandwidth: the LogP model andthe BSP model. The lower bounds provide convincing evidence that efficient parallelalgorithms for sorting rely strongly on high communication bandwidth. </abstract>
<note> Supported by a Schlumberger Foundation Graduate Fellowship.Supported by a GAANN Graduate Fellowship.Supported by NSF grant number CCR-9005448 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Smoothing and MultiplexingTradeoffs for DeterministicPerformance Guarantees to VBRVideo </title>
<author> Edward W. Knightly and Paola Rossaro </author>
<affiliation> Also with EECS Department, U.C. Berkeley </affiliation>
<pubnum> TR-95-033 </pubnum>
<abstract> AbstractThe burstiness of variable bit rate traffic makes it difficult to both efficiently utilize network resources and provide end-to-end network performance guarantees to the traffic sources.Generally, smoothing or shaping traffic sources at the entrance of the network reduces theirburstiness to allow higher utilization within the network. However, this buffering introducesan additional delay so that, in effect, lossless smoothing trades queueing delay inside thenetwork for smoothing delay at the network edge. In this paper, we consider the net effectof smoothing on end-to-end performance guarantees where a no-loss, no-delay-violation deterministic guarantee is provided with the D-BIND traffic model. We analytically quantifythese tradeoffs and provide a set of general rules for determining under which conditionssmoothing provides a net gain. We also empirically investigate these tradeoffs using tracesof MPEG compressed video. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> INTERNATIONAL COMPUTER SCIENCE INSTITUTE </affiliation>
<address> I 1947 Center St. * Suite 600 * Berkeley, California 94704-1198 </address>
 <phone> * (510) 643-9153 * FAX (510) 643-7684 </phone><title> Elementary Proofs of someResults on Representations ofp-groups </title>
<author> M.A. Shokrollahi </author>
<pubnum> TR-95-054 </pubnum>
<date> September 1995 </date>
<abstract> AbstractA result of Roquette [3] states that if D is an absolutely irreducible representationof a p-group G over the field of complex numbers, then D can be realized in K((g) jg 2 G), where is the character of D and K = Q or K = Q(i) according to whetherp 6= 2 or p = 2. Based on Baum and Clausen's [1] algorithm for computing theirreducible representations of supersolvable groups, we give an elementary proof of atheorem which, among other well-known facts on representations of p-groups, impliesRoquette's result. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> INTERNATIONAL COMPUTER SCIENCE INSTITUTE </affiliation>
<address> I 1947 Center St. * Suite 600 * Berkeley, California 94704-1198 * </address>
 <phone> (510) 643-9153 * FAX (510) 643-7684 </phone><title> Managing ABR Capacity inReservation-based SlottedNetworks </title>
<author> Roya Ulrich and Pieter Kritzinger </author>
 <email> fulrich@icsi.berkeley.edu, psk@cs.uct.ac.zag </email>
<affiliation> The Networks GroupInternational Computer Science Institute, andThe Computer Science DepatrmentUniversity of Cape Town </affiliation>
<pubnum> TR-96-006 </pubnum>
<date> January 1996 </date>
<abstract> AbstractFor slotted networks carrying full multi-media traffic to work successfully, it is essential that connection setup and management is done well under all traffic conditions.Major challenges remain with the current state of the technology, however, particularly on how one copes with traffic bursts. Existing reservation-based networks do notallow the user to dynamically adjust his bandwidth requirements on demand. In thispaper we propose a new scheme, called the reservoir scheme, which allows dynamicand distributed resource allocation. The basic idea behind the scheme is to reservebandwidth with a guaranteed bit rate for each virtual circuit. The user is allowed todecentrally allocate additional bandwidth from an Available Bit Rate (ABR) reservoir to satisfy dynamic changes of Variable Bit Rate (VBR) traffic. The duration andbandwidth of this dynamic access are negotiated in the call setup phase and do notrequire any renegotiation with the service provider so that this solution overcomes therigidity of current static bandwidth reservation schemes. The additional managementrequirements are low compared to other dynamic bandwidth reservation schemes. Wealso describe an analytic model and simulation which we used to determine whetherit would be practical to apply the proposed scheme in a slotted network. </abstract>
<note> Pieter Kritzinger is in the Computer Science Depatrment, University of Cape Town, privateBag, Rondbosch 7700 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> INTERNATIONAL COMPUTER SCIENCE INSTITUTE </affiliation>
<address> I 1947 Center St. * Suite 600 * Berkeley, California 94704-1198 </address>
 <phone> * (510) 643-9153 * FAX (510) 643-7684 </phone><title> Structural Grobner BasisDetection </title>
<author> Bernd Sturmfels and Markus Wiegelmann </author>
<pubnum> TR-96-017 </pubnum>
<affiliation> Department of Mathematics, UC Berkeley </affiliation>
<address> Berkeley, California 94720, USA </address>
<email> bernd@math.berkeley.edu </email>
<affiliation> Fachbereich Mathematik, Universitat Trier </affiliation>
<address> Universitatsring 15, D-54286 Trier, Germany </address>
<email> wiegelm@uni-trier.de </email>
<abstract> AbstractWe determine the computational complexity of deciding whether m polynomials in n variables have relatively prime leading terms with respect to someterm order. This problem is NP-complete in general, but solvable in polynomial time for m fixed and for nm fixed. Our new algorithm for the latter casedetermines a candidate set of leading terms by solving a maximum matchingproblem. This reduces the problem to linear programming. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> INTERNATIONAL COMPUTER SCIENCE INSTITUTE </affiliation>
<address> I 1947 Center St. * Suite 600 * Berkeley, California 94704-1198  </address>
 <phone> * (510) 643-9153 * FAX (510) 643-7684 </phone><title> A Management Platform forGlobal Area ATM Networks </title>
<author> Roya Ulrich </author>
<email> ulrich@icsi.berkeley.edu </email>
<pubnum> TR-96-018 </pubnum>
<abstract> AbstractTechnological progress has made providing numerous new services to large numberof users possible. Concurrently, we also experience an increased interest in real-timeand interactive applications, e. g. teleseminaring, video conferencing and applicationsharing, in particular, because of the worldwide and decentralized character of today'sresearch and development organizations.The International Computer Science Institute (ICSI) is a participant of the firsttransatlantic ATM link which is an integral part of the Multimedia Applicationson Intercontinental Highways (MAY) Project. Additionally, ICSI is attached to theBay Area Gigabit Network (BAGNet) providing ATM connectivity at the best-effortbasis. Both projects provide platforms to identify the key research and developmenttopics in cooperative real-time communication.The technical report gives a brief introduction to the ATM infrastructure at ICSI andaddresses challenging management issues of multimedia applications in such globalarea ATM networks. We explore three management areas: performance, configuration,and fault management with respect to the user's point of view. Finally, we introducea management platform and tools we have been developing which help the user tobetter predict the quality of service provided and to recover from faults occurred inthe system or during a transmission. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Design and Implementationof a Web-based Tool forATM Connection Management </title>
<author> Martin Bernhardt </author>
<email> mbhard@icsi.berkeley.edu </email>
<pubnum> TR-96-041 </pubnum>
<date> August 1996 </date>
<abstract> AbstractAt the International Computer Science Institute (ICSI), there is an ongoing effortto gain experience on ATM and multi-media applications. ICSI is participating intwo ATM pilots called Bay Area Gigabit Network (BAGNet) and Multimedia Applications on Intercontinental Highway (MAY). Beside these wide-area trial ICSI'sATM network is used for local multi-media experiments. The ATM environment atICSI is heterogeneous. Both, local and long distance traffic is based on permanentvirtual connections. The management of this environment has often been cumbersome and time-consuming for a number of reasons: The ATM devices have to beaccessed separately in an unintegrated manner. Different vendor-specific tools withdifferent user interfaces are used. Configuration data is stored unstructured, redundant and not centralized. Users cannot setup or verify a connection without knowingdevice-specific details. Hence, the need for a software tool arose that can minimize theadministrative work spent on connection management. This technical report containsmy master's thesis which is about the design and implementation of TOMCAD atool for monitoring and configuration of ATM devices. Being a web-based softwaretool it can support local and wide-area connectivity and provide access for local andremote users. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> On-line Load Balancing forRelated Machines </title>
<author> Piotr Berman Moses Charikar Marek Karpinski  </author>
<pubnum> TR-97-007 </pubnum>
<date> January 1997 </date>
<abstract> AbstractWe consider the problem of scheduling permanent jobs on related machines in anon-line fashion. We design a new algorithm that achieves the competitive ratio of 3 +p8 5:828 for the deterministic version, and 3:31= ln 2:155 4:311 for its randomizedvariant, improving the previous competitive ratios of 8 and 2e 5:436. We also provelower bounds of 2:4380 on the competitive ratio of deterministic algorithms and 1:8372on the competitive ratio of randomized algorithms for this problem. </abstract>
<affiliation> Dept. of Computer Science &amp; Eng., Pennsylvania State University, </affiliation>
 <address> University Park, PA16802, USA </address>
<email> Email:berman@cse.psu.edu </email>
<affiliation> Department of Computer Science, Stanford University, </affiliation>
 <address> Stanford, CA 94305-9045. </address>
 <note> Supported by StanfordSchool of Engineering Groswith Fellowship, an ARO MURI Grant DAAH04-96-1-0007 and NSF AwardCCR-9357849, with matching funds from IBM, Schlumberger Foundation, Shell Foundation, and XeroxCorporation. </note>
 <email> E-mail: moses@cs.stanford.edu. </email>
<affiliation> Dept. of Computer Science, University of Bonn, </affiliation>
  <address> 53117 Bonn, </address>
 <affiliation> and International Computer Science Institute, </affiliation>
   <address> Berkeley. </address>
  <note>  This research was partially supported by the DFG Grant KA 673/4-1, by the ESPRIT BRGrants 7097 and EC-US 030. </note>
 <email> Email:marek@cs.uni-bonn.de </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Towards the Assessment of Logics forConcurrent Actions </title>
<author> Choong-Ho Yi </author>
<affiliation>  Department of Computer and Information Science Linkoping University </affiliation>
<address> 581 83 Linkoping, Sweden </address>
<email> E-mail: choyi@ida.liu.se </email>
<abstract> AbstractWe have introduced concurrency into the framework of Sandewall. The resulting formalism is capable of reasoning about interdependent as wellas independent concurrent actions. FollowingSandewall's systematical method, we have thenapplied the entailment criterion PCM to selectingintended models of common sense theories whereconcurrent actions are allowed, and proved thatthe criterion leads to only intended models for asubset of such theories. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On Learning Soccer Strategies </title>
<author> Rafa l Sa lustowicz, Marco Wiering, Jurgen Schmidhuber </author>
<affiliation> IDSIA, </affiliation>
 <address> Corso Elvezia 36, 6900 Lugano, Switzerland </address>
<email> e-mail: frafal, marco, juergeng@idsia.ch </email>
<note> In W. Gerstner, A. Germond, M. Hasler, and J.-D. Nicoud, editors,Proceedings of the Seventh International Conference on ArtificialNeural Networks (ICANN'97), volume 1327 of Lecture Notes in ComputerScience, pages 769-774. Springer-Verlag Berlin Heidelberg, 1997. </note>
<abstract> Abstract. We use simulated soccer to study multiagent learning. Eachteam's players (agents) share action set and policy but may behave differently due to position-dependent inputs. All agents making up a teamare rewarded or punished collectively in case of goals. We conduct simulations with varying team sizes, and compare two learning algorithms:TD-Q learning with linear neural networks (TD-Q) and ProbabilisticIncremental Program Evolution (PIPE). TD-Q is based on evaluationfunctions (EFs) mapping input/action pairs to expected reward, whilePIPE searches policy space directly. PIPE uses an adaptive probabilitydistribution to synthesize programs that calculate action probabilitiesfrom current inputs. Our results show that TD-Q has difficulties to learnappropriate shared EFs. PIPE, however, does not depend on EFs andfinds good policies faster and more reliably. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> PMoct: A Policy management tool for OCT based Design Systems for Multiple Domains </title>
<pubnum> ISI Research ReportISI/RR-93-387 </pubnum>
<date> October, 1993 </date>
<title> PMoct: A Policy management tool for OCTbased Design Systems for Multiple Domains </title>
<author> John Granacki and Tauseef Kazi </author>
<pubnum> ISI/RR-93-387 </pubnum>
<date> October, 1993 </date>
<affiliation> University of Southern CaliforniaInformation Science Institute </affiliation>
<address> 4676 Admiralty Way, Marina del Rey, CA 90292 </address>
<note> Unclassified/Unlimited </note>
<affiliation> UNIVERSITY OF SOUTHERN CALIFORNIA INFORMATION SCIENCES INSTITUTE </affiliation>
<address> 4676 Admiralty Way Marina del Rey, CA 90292 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Induction as Knowledge Integration </title>
<author> Benjamin D. Smith </author>
<affiliation> Jet Propulsion LaboratoryCalifornia Institute of Technology </affiliation>
<address> 4800 Oak Grove Drive M/S 525-3660Pasadena, CA 91109-8099 </address>
<email> smith@aig.jpl.nasa.gov </email>
<author> Paul S. Rosenbloom </author>
<affiliation> Information Sciences Institute &amp; Computer Science Dept.University of Southern California </affiliation>
<address> 4676 Admiralty WayMarina del Rey, CA 90292 </address>
<email> rosenbloom@isi.edu </email>
<abstract> AbstractTwo key issues for induction algorithms are the accuracy of the learned hypothesis and the computationalresources consumed in inducing that hypothesis. Oneof the most promising ways to improve performancealong both dimensions is to make use of additionalknowledge. Multi-strategy learning algorithms tacklethis problem by employing several strategies for handling different kinds of knowledge in different ways.However, integrating knowledge into an induction algorithm can be difficult when the new knowledge differs significantly from the knowledge the algorithmalready uses. In many cases the algorithm must berewritten.This paper presents KII, a Knowledge Integrationframework for Induction, that provides a uniformmechanism for integrating knowledge into induction.In theory, arbitrary knowledge can be integrated withthis mechanism, but in practice the knowledge representation language determines both the knowledgethat can be integrated, and the costs of integrationand induction. By instantiating KII with various setrepresentations, algorithms can be generated at different trade-off points along these dimensions.One instantiation of KII, called RS-KII, is presentedthat can implement hybrid induction algorithms, depending on which knowledge it utilizes. RS-KII isdemonstrated to implement AQ-11 (Michalski 1978),as well as a hybrid algorithm that utilizes a domaintheory and noisy examples. Other algorithms are alsopossible. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Hybrid Intelligent Architecture for Refining Input Characterization andDomain Knowledge </title>
<author> Ismail Taha and Joydeep Ghosh </author>
<affiliation>  Department of Electrical and Computer Engineering, University of Texas, </affiliation>
 <address> Austin, TX 78712-1084 </address>
<email> E-mail: fIsmail,Ghoshg@pine.ece.utexas.edu </email>
<abstract> Abstract: A Hybrid Intelligent Architecture that aims to exploit the complementary features ofexpert systems and connectionist architecture, is proposed to revise input characterization and initialdomain knowledge. HIA has two building blocks, a Rule-Based module and a Connectionist Architecturemodule. A specific format for the rule-based description of the initial theory acquired from the applicationdomain enables its mapping into a uniform, three layer network. Continuous inputs are discretized intoinput vectors using a new coarse coding scheme. An extension of the Backpropagation Algorithm allowsrefinement of the discretization functions. A successful application to the control of dams on the Coloradoriver near Austin, is described. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Generality and Difficulty in Genetic Programming:Evolving a Sort </title>
<author> Kenneth E. Kinnear, Jr. </author>
<affiliation> Adaptive Computing Technology </affiliation>
<address> 62 Picnic Rd.Boxboro, MA 01719 USA </address>
<email> kim.kinnear@adapt.com </email>
<abstract> AbstractGenetic Programming is applied to the task ofevolving general iterative sorting algorithms. Aconnection between size and generality was discovered. Adding inverse size to the fitness measure along with correctness not only decreasesthe size of the resulting evolved algorithms, butalso dramatically increases their generality andthus the effectiveness of the evolution process. Inaddition, a variety of differing problem formulations are investigated and the relative probabilityof success for each is reported. An example of anevolved sort from each problem formulation ispresented, and an initial attempt is made tounderstand the variations in difficulty resultingfrom these differing problem formulations. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Representation Requirements for SupportingDecision Model Formulation </title>
<author> Tze-Yun Leong </author>
<affiliation> MIT Laboratory for Computer Science </affiliation>
<address> 545 Technology Square, room 420Cambridge, MA 02139 </address>
<email> (leong@lcs.mit.edu) </email>
<abstract> AbstractThis paper outlines a methodology foranalyzing the representational supportfor knowledge-based decision-modelingin a broad domain. A relevant set of inferencepatterns and knowledge types are identified.By comparing the analysis results to existing representations, some insights are gainedinto a design approach for integrating categorical and uncertain knowledge in a contextsensitive manner. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> ACM Sigplan Notices 27,3 (March 1992),66-70.Copyright 1991 by Nimble Computer Corporation 1 </note>
<title> The Treadmill:Real-Time Garbage Collection Without Motion Sickness </title>
<author> Henry G. Baker </author>
<affiliation> Nimble Computer Corporation, </affiliation>
 <address> 16231 Meadow Ridge Way, Encino, CA 91436 </address>
<phone> (818) 501-4956 (818) 986-1360 FAX </phone><abstract> A simple real-time garbage collection algorithm is presented which does not copy, thereby avoidingsome of the problems caused by the asynchronous motion of objects. This in-place "treadmill"garbage collection scheme has approximately the same complexity as other nonmoving garbagecollectors, thus making it usable in a high-level language implementation where some pointerscannot be traced. The treadmill is currently being used in a Lisp system built in Ada. </abstract>
<intro> INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Multilayer perceptrons may learn simple rules quickly </title>
<author> R. Urbanczik </author>
<affiliation> Institut fur theoretische PhysikUniversitat Wurzburg </affiliation>
<address> Am HublandD-97074 WurzburgGermany </address>
<date> November 27, 1997 </date>
<abstract> AbstractZero temperature Gibbs learning is considered for a connected committee machinewith K hidden units. For large K, the scale of the learning curve strongly dependson the target rule. When learning a perceptron, the sample size P needed for optimalgeneralization scales so that N t P t KN, where N is the dimension of the input.This even holds for a noisy perceptron rule if a new input is classified by the majorityvote of all students in the version space. When learning a committee machine with Mhidden units, 1 t M t K, optimal generalization requiresp </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> Appears in the Proceedings of the ACM SIGMOD International Conference on Management of Data, San Jose, CA, May 1995 </note>
<title> Efficient Optimistic Concurrency ControlUsing Loosely Synchronized Clocks </title>
<author> Atul Adya Robert Gruber Barbara Liskov Umesh Maheshwari </author>
<affiliation> Laboratory for Computer Science,Massachusetts Institute of Technology, </affiliation>
<address> 545 Technology Square, Cambridge, MA 02139 </address>
<email> fadya,gruber,liskov,umeshg@lcs.mit.edu </email>
<abstract> AbstractThis paper describes an efficient optimistic concurrency controlscheme for use in distributed database systems in which objects arecached and manipulated at client machines while persistent storageand transactional support are provided by servers. The schemeprovides both serializability and external consistency for committedtransactions; it uses loosely synchronized clocks to achieve globalserialization. It stores only a single version of each object, andavoids maintaining any concurrency control information on a per-object basis; instead, it tracks recent invalidations on a per-clientbasis, an approach that has low in-memory space overhead and noper-object disk overhead. In addition to its low space overheads,the scheme also performs well. The paper presents a simulationstudy that compares the scheme to adaptive callback locking, thebest concurrency control scheme for client-server object-orienteddatabase systems studied to date. The study shows that ourscheme outperforms adaptive callback locking for low to moderatecontention workloads, and scales better with the number of clients.For high contention workloads, optimism can result in a high abortrate; the scheme presented here is a first step toward a hybrid schemethat we expect to perform well across the full range of workloads. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Decision-Theoretic Troubleshooting: A Framework forRepair and Experiment </title>
<author> John S. BreeseDavid Heckerman </author>
<email> &amp;lt;breese|heckerma@microsoft.com&amp;gt; </email>
<date> March, 1996(revised May 1996) </date>
<pubnum> Technical ReportMSR-TR-96-06 </pubnum>
<affiliation> Microsoft ResearchAdvanced Technology DivisionMicrosoft Corporation </affiliation>
<address> One Microsoft WayRedmond, WA 98052 </address>
<note> Also appears in the Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence,August, 1996 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Context-Insensitive Alias AnalysisReconsidered </title>
<author> Erik Ruf </author>
<email> erikruf@microsoft.com </email>
<date> May 16, 1995 </date>
<pubnum> Technical ReportMSR-TR-95-20 </pubnum>
<affiliation> Microsoft ResearchAdvanced Technology DivisionMicrosoft Corporation </affiliation>
<address> One Microsoft WayRedmond, WA 98052 </address>
<note> This report is a preprint of the paper "Context-Insensitive Alias Analysis Reconsidered," to appear in ACM SIGPLAN'95 Conference on Programming Language Design and Implementation (PLDI'95), La Jolla, California, June 1995.Copyright c 1995 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies of all orpart of this work for personal or classroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrightsfor components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. Tocopy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or afee. Request permissions from Publications Dept, ACM Inc., fax + 1 (212) 869-0481, or permissions@acm.org. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Global Tree Optimization:A Non-greedy Decision Tree Algorithm </title>
<author> Kristin P. Bennett </author>
<email> Email bennek@rpi.edu </email>
<affiliation> Department of Mathematical SciencesRensselaer Polytechnic Institute </affiliation>
<address> Troy, NY 12180  </address>
<abstract> AbstractA non-greedy approach for constructing globally optimalmultivariate decision trees with fixed structure is proposed. Previous greedy tree construction algorithms arelocally optimal in that they optimize some splitting criterion at each decision node, typically one node at a time.In contrast, global tree optimization explicitly considersall decisions in the tree concurrently. An iterative linearprogramming algorithm is used to minimize the classification error of the entire tree. Global tree optimizationcan be used both to construct decision trees initially andto update existing decision trees. Encouraging computational experience is reported. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> DEPARTMENT OF STATISTICSUniversity of Wisconsin </affiliation>
<address> 1210 West Dayton St.Madison, WI 53706 </address>
<pubnum> TECHNICAL REPORT NO. 910 </pubnum>
<date> December 21, 1993 </date>
<title> Behavior Near Zero of the Distribution of GCV SmoothingParameter Estimates 1 </title>
<author> byGrace Wahba and Yuedong Wang </author>
<note> 1 Supported by the National Science Foundation under Grant DMS-9121003 and the National Eye Institute underGrant R01 EY09946. </note>
 <email> e-mail wahba@stat.wisc.edu, wang@stat.wisc.edu </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Selecting Tense, Aspect, and Connecting WordsIn Language Generation </title>
<author> Bonnie J. Dorr  </author>
<affiliation> Department of Computer ScienceUniversity of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<email> bonnie@cs.umd.edu </email>
<author> Terry Gaasterland  </author>
<affiliation> Mathematics and Computer Science DivisionArgonne National Laboratory </affiliation>
<address> Argonne, IL 60432 </address>
<email> gaasterland@mcs.anl.gov </email>
<abstract> AbstractGenerating language that reflects the temporal organization of represented knowledge requires a language generation model that integrates contemporary theories of tense and aspect, temporal representations, and methodsto plan text. This paper presents a modelthat produces complex sentences that reflecttemporal relations present in underlying temporal concepts. The main result of this workis the successful application of constrained linguistic theories of tense and aspect to a generator which produces meaningful event combinations and selects appropriate connecting wordsthat relate them. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Machine Translation, 10:1-2, 139-180 (1995)c 1995 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. </note>
<title> Toward a Lexicalized Grammar for Interlinguas </title>
<author> CLARE VOSS </author>
<email>  voss@cs.umd.edu </email>
<author> BONNIE J. DORR </author>
 <email> bonnie@cs.umd.edu </email>
<affiliation> Department of Computer Science, University of Maryland, </affiliation>
 <address> College Park, MD 20742 </address>
<date> Received September 1,1994; Revised July 15, 1995 </date>
<abstract> Abstract. In this paper we present one aspect of our research on machine translation (MT):capturing the grammatical and computational relation between (i) the interlingua (IL) as defineddeclaratively in the lexicon and (ii) the IL as defined procedurally by way of algorithms thatcompose and decompose pivot IL forms. We begin by examining the interlinguas in the lexicons ofa variety of current IL-based approaches to MT. This brief survey makes it clear that no consensusexists among MT researchers on the level of representation for defining the IL. In the section thatfollows, we explore the consequences of this missing formal framework for MT system builders whodevelop their own lexical-IL entries. The lack of software tools to support rapid IL respecificationand testing greatly hampers their ability to modify representations to handle new data and newdomains. Our view is that IL-based MT research needs both (a) the formal framework to specifypossible IL grammars and (b) the software support tools to implement and test these grammars.With respect to (a), we propose adopting a lexicalized grammar approach, tapping researchresults from the study of tree grammars for natural language syntax. With respect to (b), wesketch the design and functional specifications for parts of ILustrate, the set of software toolsthat we need to implement and test the various IL formalisms that meet the requirements of alexicalized grammar. In this way, we begin to address a basic issue in MT research, how to defineand test an interlingua as a computational language | without building a full MT system foreach possible IL formalism that might be proposed. </abstract>
<keyword> Keywords: interlingua, machine translation, lexicon, lexicalized grammar </keyword>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> v4.9 1 </note>
<title> Binding as an Interface Condition:An Investigation of Hindi Scrambling </title>
<author> byDouglas Arnold Jones </author>
<degree> Bachelor of Arts in Linguistics, Stanford University (1987)Master of Arts in Linguistics, Stanford University (1989)Submitted to the Department of Linguistics and Philosophy inPartial Fulfillment of the Requirements for the Degree ofDoctor of Philosophyat the </degree><affiliation> MASSACHUSETTS INSTITUTE OF TECHNOLOGY </affiliation>
<author> Douglas Arnold Jones </author>
<degree> The author hereby grants to M.I.T permission to reproduce andto distribute copies of this thesis document in whole or inpart.Signature of Author Department of Linguistics and Philosophy </degree><date> July 22, 1993 </date>
<degree> Certified by Noam ChomskyInstitute ProfessorAccepted by Wayne O'NeilHead, Department of Linguistics and Philosophy </degree><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> GROWING RADIAL BASIS FUNCTION NETWORKS </title>
<author> E. BLANZIERI , P. KATENKAMP flfl and A. GIORDANA flflfl </author>
<affiliation> Centro di Scienza Cognitiva, Universita di Torino, </affiliation>
 <address> Via Lagrange 3, 10100 Torino, Italy. </address>
 <email> e-mail:blanzier@psych.unito.it </email>
<affiliation> flfl Institute for Real Time Systems and Robotics, University of Karlsruhe, </affiliation>
 <address> Germany. </address>
<affiliation> flflfl Dipartimento di Informatica, Universita di Torino, </affiliation>
 <address> C.so Svizzera 185, 10149 Torino, Italy. </address>
 <email> email: attilio@di.unito.it </email>
<abstract> Abstract. This paper presents and evaluates two algorithms for incrementally constructing RadialBasis Function Networks, a class of neural networks which looks more suitable for adtaptive controlapplications than the more popular backpropagation networks. The first algorithm has been derivedby a previous method developed by Fritzke, while the second one has been inspired by the CARTalgorithm developed by Breiman for generation regression trees. Both algorithms proved to workwell on a number of tests and exhibit comparable performances. An evaluation on the standard casestudy of the Mackey-Glass temporal series is reported. </abstract>
<keyword> Key Words. Machine Learning, Robotics, Neural Nets </keyword>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> MULTIMEDIA MEETS MACHINE LEARNING </title>
<author> STEFAN M UNCH  </author>
<affiliation> Institute for Real-Time Computer Systems &amp; Robotics, University of Karlsruhe, </affiliation>
  <address> Kaiserstr. 12,D-76128 Karlsruhe, Germany. </address>
<abstract> Abstract. The application of Machine Learning techniques to multimedia and multimodal systems,resp., seems to be a promising approach in order to enhance the systems' capabilities. Especiallyin multimodal systems which support human-computer interaction (HCI) via several input/outputchannels in parallel, intelligent mechanisms are needed in order to process the user's inputs and toselect the best output modality.In this paper, we will deal with a multi-agent system which introduces some kind of haptic feedbackto the user interface. The main task of the system is to predict the next user action in order to launchthe haptic feedback selectively and to adapt this capability over time to both, the user's behaviorand the application's user interface structure. Therefore, a statistical interaction model is generatedand managed based on stochastic classification methods. </abstract>
<keyword> Key Words. Multimedia, Multimodality, Haptic Output, Man-Machine-Systems, Human-Computer Interaction, Classification, User Modelling </keyword>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On Scheduling Two Classes of Real Time Traffic With IdenticalDeadlines  </title>
<author> Sridhar Pingali </author>
<affiliation> Dept. of Electrical and Computer EngineeringUniversity of Masschusetts </affiliation>
<address> Amherst, MA 01003 </address>
<author> James F. Kurose </author>
<affiliation> Dept. of Computer and Information ScienceUniveristy of Massachusetts </affiliation>
<address> Amherst, MA 01003 </address>
<abstract> AbstractThe problem of scheduling two classes of real-time traffic with correlated time constraintsis considered. Three scheduling disciplines are studied: a priority discipline which gives strictpriority to one class of traffic, a threshold-based scheme in which priority is given to one classof traffic when the minimum laxity of its queued packets falls below some threshold, and a"balancing" scheme which assigns priority on the basis of the differences in minimum laxities inthe two classes of traffic. Analytic results are obtained by using a discrete time model to obtainthe state occupancy probabilities for the system. Here, the state is defined using the laxities ofthe queued real time packets. Parameters are defined to study the tradeoff in the performanceof the two classes of traffic. Results are obtained to demonstrate how the balancing schemepermits us to achieve significant improvement in the performance of one class of traffic withonly minimal effect on the performance of other class. A video application is suggested for thiswork. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Real-Time Reliable Multicast Using Proactive Forward Error Correction </title>
<author> Dan Rubenstein, Jim Kurose, and Don Towsley </author>
<affiliation> Computer Science DepartmentUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003 </address>
<email> fdrubenst, kurose, towsleyg@cs.umass.edu </email>
<pubnum> Technical Report 98-19 </pubnum>
<affiliation> Department of Computer Science </affiliation>
<date> March 1998 </date>
<abstract> AbstractReal-Time reliable multicast over a best-effort service network remains a challenging research problem. Mostprotocols for reliable multicast use repair techniques that result in significant and variable delay, which can lead tomissed deadlines in real-time scenarios. This paper presents a repair technique that combines forward error correction(FEC) with automatic repeat request (ARQ). The novel aspect of the technique is its ability to reduce delay in reliablemulticast delivery by sending repairs proactively (i.e., before they are required). The technique requires minimalstate at senders and receivers, and no additional active router functionality beyond what is required by the currentmulticast service model. Furthermore, the technique uses only end-to-end mechanisms, where all data and repairs aretransmitted by the data-originating source, leaving receivers free from any burden of sending repairs. We simulatea simple round-based version of a protocol embodying this technique to show its effectiveness in preventing repairrequest implosion, reducing the expected time of reliable delivery of data, and keeping bandwidth usage for repairslow. We show how a protocol using the technique can be adapted to provide delivery that is reliable before a real-timedeadline with probabilities extremely close to one. Finally, we develop several variations of the protocol that use thetechnique in various fashions for high rate data streaming applications, and present results from additional simulationsthat examine performance in a variety of Internet-like heterogeneous networks. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in Proc. IEEE INFOCOM, March 1996 </note>
<title> The Effectiveness of Affinity-Based Scheduling in Multiprocessor Networking  </title>
<author> James D. Salehi, James F. Kurose, and Don Towsley </author>
<affiliation> Computer Science Department, University of Massachusetts, </affiliation>
 <address> Amherst MA 01003, USA </address>
<email> -salehi,kurose,towsley-@cs.umass.edu </email>
<abstract> AbstractTechniques for avoiding the high memory overheads found onmany modern shared-memory multiprocessors are of increasingimportance in the development of high-performance multiprocessor protocol implementations. One such technique is processor-cache affinity scheduling, which can significantly lower packetlatency and substantially increase protocol processing throughput[20]. In this paper, we evaluate several aspects of the effectiveness of affinity-based scheduling in multiprocessor networkprotocol processing, under packet-level and connection-level par-allelization approaches. Specifically, we evaluate the performanceof the scheduling technique 1) when a large number of streams areconcurrently supported, 2) when processing includes copying ofuncached packet data, 3) as applied to send-side protocol processing, and 4) in the presence of stream burstiness and source locality, two well-known properties of network traffic. We find thataffinity-based scheduling performs well under these conditions,emphasizing its robustness and general effectiveness in multiprocessor network processing. In addition, we explore a techniquewhich improves the caching behavior and available packet-levelconcurrency under connection-level parallelism, and find performance improves dramatically. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Loss Correlation for Queues with Bursty Input Streams </title>
<author> Henning Schulzrinne James F. Kurose and Donald F. Towsley </author>
<affiliation> Dept. of ECE Dept. of Computer ScienceUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003 </address>
<email> hgschulz,kurose,towsley@cs.umass.edu </email>
<abstract> AbstractThe loss probability of a queueing system provides, in many cases, insufficient information for performance evaluation, for example, of data link layer protocols and applications with forwarderror correction.This paper evaluates and characterizes the correlation between packet losses for two queueing systems in discrete timethat are motivated by BISDN applications. The first, a two-class discrete-time queueing system, approximates the outputqueue of an ATM switch. The queue serves periodic foregroundtraffic and random background traffic. The background trafficis modeled as i.i.d. batches of arbitrary distribution. It is shownthat the conditional loss probability (CLP) is independent of thebuffer size if the buffer size is at least as large as the period ofthe foreground traffic. Example calculations indicate that lossesoccur essentially randomly as long as the foreground traffic usesless than 10% of the channel capacity.The second analysis derives the CLP seen by a selectedstream in a slotted finite-buffer system with a superposition ofinterrupted Poisson sources. Here, the total number of arrivalsmay be correlated from slot to slot. Traffic correlation is seento have a strong influence on loss correlation, while buffer sizeis seen to have virtually none. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Optimal Smoothing of Stored Video and the Impact onNetwork Resource Requirements fly </title>
<author> James D. Salehi, Zhi-Li Zhang, James F. Kurose, and Don Towsley </author>
<affiliation> Department of Computer ScienceUniversity of Massachusetts </affiliation>
<address>   Amherst, MA 01003, U.S.A </address>
<phone> (413) 545-3179 (voice), (413) 545-1249 (fax) </phone><email> fsalehi,zhzhang,kurose,towsleyg@cs.umass.edu </email>
<abstract> AbstractVBR compressed video is known to exhibit significant, multiple-time-scale bit rate variability. In this paper, we consider the transmission of stored video from a server to a client across ahigh speed network, and explore how the client buffer space can be used most effectively towardreducing the variability of the transmitted bit rate.We present two basic results. First, we show how to achieve the greatest possible reduction inrate variability when sending stored video to a client with given buffer size. We formally establishthe optimality of our optimal smoothing approach, and illustrate its performance over a set oflong MPEG-1 encoded video traces. Second, we evaluate the impact of optimal smoothing on thenetwork resources needed for video transport, under two network service models: DeterministicGuaranteed service [1, 11] and Renegotiated CBR (RCBR) service [9, 8]. Under both models, wefind the impact of optimal smoothing to be dramatic. </abstract>
<note> An earlier version of this paper appeared at the 1996 ACM SIGMETRICS conference.This work was supported by NSF under grant NCR-9206908 and by ARPA under ESD/AVS contract F-19628-92-C0089. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Acquiring and validating background knowledgefor machine learning using functiondecomposition </title>
<author> Blaz Zupan and Saso Dzeroski </author>
<affiliation> Department of Intelligent Systems, Jozef Stefan Institute </affiliation>
<address> 1000 Ljubljana, Slovenia </address>
 <email> (E-mail: Blaz.Zupan@ijs.si, Saso.Dzeroski@ijs.si) </email>
<abstract> Abstract. Domain or background knowledge is often needed in orderto solve difficult problems of learning medical diagnostic rules. Earlierexperiments have demonstrated the utility of background knowledgewhen learning rules for early diagnosis of rheumatic diseases. A particular form of background knowledge comprising typical co-occurrencesof several groups of attributes was provided by a medical expert. Thispaper explores the possibility to automate the process of acquiring background knowledge of this kind. A method based on function decomposition is proposed that identifies typical co-occurrences for a given setof attributes. The method is evaluated by comparing the typical co-occurrences it identifies, as well as their contribution to the performanceof machine learning algorithms, to the ones provided by a medical expert. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Appears in: "Supercomputing '94," Nov. 1994.Reprinted by permission of IEEE. </note>
<title> Paging Tradeoffs in Distributed-Shared-Memory Multiprocessors </title>
<author> Douglas C. Burger, Rahmat S. Hyder, Barton P. Miller, David A. Wood </author>
<affiliation> Computer Sciences DepartmentUniversity of Wisconsin-Madison </affiliation>
<address> 1210 W. Dayton StreetMadison, WI 53706 USA </address>
<email> wwt@cs.wisc.edu </email>
<abstract> AbstractMassively parallel processors have begun using commodity operating systems that support demand-pagedvirtual memory. To evaluate the utility of virtualmemory, we measured the behavior of seven shared-memory parallel application programs on a simulateddistributed-shared-memory machine. Our results (i)confirm the importance of gang CPU scheduling, (ii)show that a page-faulting processor should spin ratherthan invoke a parallel context switch, (iii) show thatour parallel programs frequently touch most of theirdata, and (iv) indicate that memory, not just CPUs,must be "gang scheduled". Overall, our experimentsdemonstrate that demand paging has limited valueon current parallel machines because of the applications' synchronization and memory reference patternsand the machines' high page-fault and parallel-context-switch overheads. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Runtime Support to Parallelize Adaptive IrregularPrograms  </title>
<author>  Yuan-Shin Hwang 1 Bongki Moon 1 Shamik Sharma 1 Raja Das 1 Joel Saltz 1 </author>
<abstract> AbstractThis paper describes how a runtime support library can be used as compiler runtimesupport in irregular applications. The CHAOS runtime support library carries outoptimizations designed to reduce communication costs by performing software caching,communication coalescing and inspector/executor preprocessing. CHAOS also suppliesspecial purpose routines to support specific types of irregular reduction and runtimesupport for partitioning data and work between processors. A number of adaptiveirregular codes have been parallelized using the CHAOS library and performance resultsfrom these codes are also presented in this paper. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Supporting Irregular Distributions in FORTRAN 90D/HPFCompilers  </title>
<author> Ravi Ponnusamy yz Yuan-Shin Hwang Raja Das Joel Saltz Alok Choudhary Geoffrey Fox  </author>
<affiliation> UMIACS and Computer Science Department Northeast Parallel Architectures CenterUniversity of Maryland Syracuse University </affiliation>
<address> College Park, MD 20742 Syracuse, NY 13244 </address>
<abstract> AbstractThis paper presents methods that make it possible to efficiently support irregular problems using dataparallel languages. The approach involves the use of a portable, compiler-independent, runtime supportlibrary called CHAOS. The CHAOS runtime support library contains procedures that* support static and dynamic distributed array partitioning,* partition loop iterations and indirection arrays,* remap arrays from one distribution to another, and* carry out index translation, buffer allocation and communication schedule generation.The CHAOS runtime procedures are used by a prototype Fortran 90D compiler as runtime support for irregular problems. This paper also presents performance results of compiler-generated andhand-parallelized versions of two stripped down applications codes. The first code is derived froman unstructured mesh computational fluid dynamics flow solver and the second is derived from themolecular dynamics code CHARMM.A method is described that makes it possible to emulate irregular distributions in HPF by reordering elements of data arrays and renumbering indirection arrays. The results suggest that an HPFcompiler could use reordering and renumbering extrinsic functions to obtain performance comparableto that achieved by a compiler for a language (such as Fortran 90D) that directly supports irregulardistributions. </abstract>
<note> This work was sponsored in part by ARPA (NAG-1-1485), NSF (ASC 9213821), and ONR (SC292-1-22913). </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Semi-Analytical Techniques for Substrate Characterization in theDesign of Mixed-Signal ICs </title>
<author> Edoardo Charbon, Ranjit Gharpurey ,Robert G. Meyer , and Alberto Sangiovanni-Vincentelli  </author>
<affiliation> Cadence Design Systems Inc., </affiliation>
 <address> San Jose, CA Texas Instruments Inc., Dallas, TX </address>
<affiliation> Department of EECS, University of California, </affiliation>
 <address> Berkeley, CA </address>
<abstract> AbstractA number of methods are presented for highly efficient calculationof substrate current transport. A three-dimensionalGreen's Functionbased substrate representation, in combination with the use of theFast Fourier Transform, significantly speeds up the computation ofsensitivities with respect to all parameters associated with a givenarchitecture. Substrate sensitivity analysis is used in a number ofphysical optimization tools, such as placement and trend analysis forthe estimation of the impact of technology migration and/or layoutre-design. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> High Performance Verification Algorithms </title>
<author> byJagesh V. Sanghavi </author>
<degree> B.Tech. (Indian Institute of Technology, Bombay) 1989M.S. (University of California at Berkeley, California) 1993A dissertation submitted in partial satisfaction of therequirements for the degree ofDoctor of Philosophyin </degree><affiliation> Engineering Electrical Engineeringand Computer Sciences </affiliation>
<degree> in theGRADUATE DIVISIONof the </degree><affiliation> UNIVERSITY of CALIFORNIA at BERKELEY </affiliation>
<degree> Committee in charge:Professor Alberto L. Sangiovanni-VincentelliProfessor Robert K. BraytonProfessor Phillip Colella </degree><date> 1996 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Interpretable Neural Networks with BP-SOM </title>
<author> Ton Weijters 1 , Antal van den Bosch 2 , and Jaap van den Herik 3 </author>
<affiliation> 1 Information Technology, Eindhoven University of Technology, </affiliation>
 <address> The Netherlands </address>
<affiliation> 2 ILK / Computational Linguistics, Tilburg University, </affiliation>
 <address> The Netherlands </address>
<affiliation> 3 Department of Computer Science, Universiteit Maastricht, </affiliation>
 <address> The Netherlands </address>
<abstract> Abstract. Interpretation of models induced by artificial neural networks is often a difficult task. In this paper we focus on a relativelynovel neural network architecture and learning algorithm, bp-som, thatoffers possibilities to overcome this difficulty. It is shown that networkstrained with bp-som show interesting regularities, in that hidden-unitactivations become restricted to discrete values, and that the som partcan be exploited for automatic rule extraction. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> THE PAPIA2 MACHINE: HARDWARE AND SOFTWARE ARCHITECTURE </title>
<author> A. Biancardi, V. Cantoni, M. Ferretti and M. Mosconi </author>
<affiliation> Dipartimento di Informatica e SistemisticaUniversity of Pavia </affiliation>
<address> Via Abbiategrasso 209I-27100 PAVIA, ITALY </address>
<phone> Tel: int +39.382.391350 </phone><abstract> ABSTRACTThis paper presents the overall structure of PAPIA2, a pyramidsystem belonging to the family of massive parallel machines. It embedsthe topology of the quad-pyramid into a highly regular, fault tolerant,eight-connected proces sor array by means of specially reconfigurablenear-neighbor interconnections. The system comes with a fully-fledgedsoftware environment designed to optimize the use of machine resources.The highly interactive graphic tools help in understanding the machine'scapabilities, provide a valuable testbed for the machine instruction set,and offer a suitable context for monitoring program execution. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> TO APPEAR IN COMPUTATIONAL OPTIMIZATION AND APPLICATIONS JOURNAL, 1997 </note>
<title> METAHEURISTICS FOR HIGHSCHOOLTIMETABLING </title>
<author> Alberto Colorni </author>
<affiliation> Centro di Teoria dei Sistemi del CNRDipartimento di Elettronica e InformazionePolitecnico di Milano </affiliation>
<address> Piazza Leonardo da Vinci 3220133 Milano, Italy </address>
<phone> tel. +39-2-2399-3567 </phone><email> email: colorni@elet.polimi.it </email>
<author> Marco Dorigo </author>
<affiliation> IRIDIAUniversit Libre de Bruxelles, </affiliation>
 <address> CP 194/6Avenue Franklin Roosevelt 501050 Bruxelles, Belgium, European Union </address>
<phone> tel. +32-2-6503169 </phone><email> email: mdorigo@ulb.ac.be </email>
<web> http://iridia.ulb.ac.be/dorigo/dorigo.html </web><author> Vittorio Maniezzo </author>
<affiliation> Scienze dellInformazioneUniversit di Bologna </affiliation>
<address> Contrada Sacchi, 347023 Cesena, Italy </address>
<phone> tel. +39-547-642830 </phone><email> email: maniezzo@csr.unibo.it </email>
<web> http://www.csr.unibo.it/~maniezzo </web><keyword> Subject categories:Programming: heuristic, stochastic;Mathematics: combinatorics. </keyword>
<abstract> The paper presents an application of simulated annealing, tabu search and an adaptedgenetic algorithm to a real world instance of the timetable problem. The computationalresults obtained are compared and discussed. </abstract>
<keyword> Other keywords: timetable problem, tabu search, simulated annealing, genetic algorithms </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Simulations with an Evolvable Fitness Formula </title>
<author>   Henrik Hautop Lund Domenico Parisi </author>
 <affiliation> Institute of PsychologyNational Research Council, </affiliation>
 <address> Viale Marx 15, 00137 Rome, Italy </address>
<phone> tel.: (+39) 6 88 94 596 </phone><affiliation> - DAIMIUniversity of Aarhus, </affiliation>
 <address> Ny Munkegade, 8000 Aarhus C., Denmark </address>
<phone> tel.: (+45) 89 42 32 21 </phone><email> e-mail: hhl@daimi.aau.dk domenico@gracco.irmkant.rm.cnr.it </email>
<abstract> AbstractThe concept of a fitness formula as a property of an organism is proposed. Inartificial life simulations with organisms living in an environment, the fitness formulacan be interpreted as the ability of organisms to extract energy from potential foodsources distributed in the environment. In simulations where the goal of the geneticalgorithm is that of developing systems which exhibit a certain type of behavior in aparticular environment, the fitness formula becomes an independent variable which canbe manipulated in order to obtain the desired behavior. The fitness formula can beviewed as an evolvable trait of organisms, and therefore not fixed and decided by theresearcher. Simulations with fixed and evolvable fitness formulae show that the fitnessformula, the sensory apparatus, and the behavior of organisms may co-evolve and beco-adapted. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Foundations for the Learning Web </title>
<author> Brian R. Gaines, Douglas H. Norrie and Mildred L. G. Shaw </author>
<affiliation> University of Calgary </affiliation>
<address> Calgary, Alberta, Canada T2N 1N4 </address>
<email> gaines@cpsc.ucalgary.ca, norrie@enme.ucalgary.ca, mildred@cpsc.ucalgary.ca </email>
<abstract> Abstract: The learning web was presented [Norrie and Gaines, 1995] at EdMedia95as a systemic approach to the modeling and support of knowledge processes in alearning society. This article addresses the rationale for, and systemic foundations of,the learning web, its implications for restructuring the higher education system, andthe role of information technology in supporting that restructuring. Two associatedarticles report on the implementation of some of the technologies necessary tosupport the learning web [Gaines and Shaw, 1996], and some preliminary experiencein applying them in undergraduate education [Shaw and Gaines, 1996]. </abstract>
<intro> 1 Reengineering the Educational System </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Layered, Server-based Supportfor Object-Oriented Application Development </title>
<author> Guruduth Banavar Douglas Orr Gary Lindstrom </author>
<affiliation> Department of Computer ScienceUniversity of Utah, </affiliation>
 <address> Salt Lake City, UT 84112 USA </address>
<email> fbanavar,dbo,lindstromg@cs.utah.edu </email>
<abstract> AbstractThis paper advocates the idea that the physical modularity (file structure) of application components supported by conventional OS environments can be elevated to the level of logical modularity, which in turncan directly support application development in anobject-oriented manner. We demonstrate this ideathrough a system-wide server that manages the manipulation of such components effectively. The serveris designed to be a fundamental operating system service responsible for binding and mapping componentinstances into client address spaces.We show how this model solves some longstandingproblems with the management of application components in existing application development environments. We demonstrate that this model's effectiveness derives from its support for the cornerstones ofOO programming: classes and their instances, encapsulation, and several forms of inheritance. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Structured Markov Chain Monte Carlo </title>
<author> by Daniel J. SARGENT 1 , James S. HODGES 2 , and Bradley P. CARLIN 2 </author>
<affiliation> 1 Section of Biostatistics, Mayo Clinic </affiliation>
<affiliation> 2 Division of Biostatistics, School of Public Health, University of Minnesota </affiliation>
<date> January 9, 1998 </date>
<abstract> AbstractIn this paper we introduce a general method for Bayesian computing in richly-parameterizedmodels, Structured Markov Chain Monte Carlo (SMCMC), that is based on a blocked hybrid of theGibbs sampling and Metropolis-Hastings algorithms. SMCMC speeds algorithm convergence byusing the structure that is present in the problem to suggest an appropriate Metropolis-Hastingscandidate distribution. While the approach is easiest to describe for hierarchical normal linearmodels, we show its extension to both non-normal and nonlinear cases to be straightforward.After describing the method in detail we compare its performance (both in terms of runtime andautocorrelation in the samples produced) to several other existing methods, including the traditionalsingle-site updating Gibbs sampler available in the popular BUGS software package. Our resultssuggest significant improvements in convergence for many problems using SMCMC, as well asbroad applicability of the method, including previously intractable hierarchical nonlinear modelsettings. </abstract>
<keyword> KEY WORDS: Blocking; Convergence acceleration; Gibbs sampling; Hierarchical model; Metropolis-Hastings algorithm. </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> To Appear in the ACM Multimedia Journal </note>
<title> Dynamic Management of Guaranteed Performance Multimedia Connections </title>
<author> Colin Parris, Hui Zhang , and Domenico Ferrari </author>
<email> parris, hzhang, ferrari@tenet.Berkeley.EDU </email>
<affiliation> Computer Science DivisionUniversity of California at Berkeley </affiliation>
<address> Berkeley, CA 94720 </address>
<keyword> Keywords: Multimedia, Network Management, Quality of Service, High Speed Networks. </keyword>
<abstract> AbstractMost of the solutions proposed to support real-time (i.e. guaranteed performance) communication services in packet-switching networks adopt a connection-oriented and reservation-oriented approach. In such an approach, resource allocationand route selection decisions are made before the start of the communication on the basis of resource availability and real-time network load at that time, and are usually kept for the duration of the communication. This rather static resourcemanagement approach has certain limitations: it does not take into account (a) the dynamics of the communicating clients;(b) the dynamics of the network state; and (c) the tradeoff between quality of service and network availability, thus affectingthe availability and flexibility of the real-time network services. Availability is the ability of the network to accommodateas many real-time clients as possible, while flexibility is the ability to adapt the real-time services to changing network stateand client demands. In this paper, we present the Dynamic Connection Management (DCM) scheme, which addresses theseissues by providing the network with the capability to dynamically modify the performance parameters and the routes ofany existing real-time connection. With these capabilities, DCM can be used to increase the availability and flexibility ofthe guaranteed performance service offered to the clients. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Estimating the Selectivity of Spatial Queries Usingthe `Correlation' Fractal Dimension </title>
<author> Alberto Belussi </author>
<affiliation> Dipartimento di Elettronica e InformaticaPolitecnico di Milano </affiliation>
<address> Milano (Italy) </address>
<email> e-mail: belussi@elet.polimi.it </email>
<author> Christos Faloutsos  </author>
<affiliation>  Institute for Systems Research (ISR) andDept. of Computer Science Univ. of Maryland, </affiliation>
 <address> College Park </address>
<email> e-mail: christos@cs.umd.edu </email>
<date> February 24, 1995 </date>
<abstract> AbstractWe examine the estimation of selectivities for range and spatial join queries in real spatialdatabases. As we have shown earlier [FK94a], real point sets: (a) violate consistently the"uniformity" and "independence" assumptions, (b) can often be described as "fractals", withnon-integer (fractal) dimension. In this paper we show that, among the infinite family of fractaldimensions, the so called "Correlation Dimension" D 2 is the one that we need to predict theselectivity of spatial join.The main contribution is that, for all the real and synthetic point-sets we tried, the averagenumber of neighbors for a given point of the point-set follows a power law, with D 2 as the exponent. This immediately solves the selectivity estimation for spatial joins, as well as for "biased"range queries (i.e., queries whose centers prefer areas of high point density).We present the formulas to estimate the selectivity for the biased queries, including an integration constant (K `shape 0 ) for each query shape. Finally, we show results on real and syntheticpoint sets, where our formulas achieve very low relative errors (typically about 10%, versus40%-100% of the uniform assumption). </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> MASSACHUSETTS INSTITUTE OF TECHNOLOGYARTIFICIAL INTELLIGENCE LABORATORYandCENTER FOR BIOLOGICAL AND COMPUTATIONAL LEARNINGDEPARTMENT OF BRAIN AND COGNITIVE SCIENCES </affiliation>
<pubnum> A.I. Memo No. 1565 </pubnum>
<date> February 2, 1996 </date>
<pubnum> C.B.C.L. Memo No. 132 </pubnum>
<title> Probabilistic Independence Networks for HiddenMarkov Probability Models </title>
<author> Padhraic Smyth, David Heckerman, and Michael Jordan </author>
<abstract> bstractGraphical techniques for modeling the dependencies of random variables have been explored in a varietyof different areas including statistics, statistical physics, artificial intelligence, speech recognition, imageprocessing, and genetics. Formalisms for manipulating these models have been developed relativelyindependently in these research communities. In this paper we explore hidden Markov models (HMMs)and related structures within the general framework of probabilistic independence networks (PINs). Thepaper contains a self-contained review of the basic principles of PINs. It is shown that the well-knownforward-backward (F-B) and Viterbi algorithms for HMMs are special cases of more general inferencealgorithms for arbitrary PINs. Furthermore, the existence of inference and estimation algorithms formore general graphical models provides a set of analysis tools for HMM practitioners who wish to explorea richer class of HMM structures. Examples of relatively complex models to handle sensor fusion andcoarticulation in speech recognition are introduced and treated within the graphical model frameworkto illustrate the advantages of the general approach. </abstract>
<note> Copyright c Massachusetts Institute of Technology, 1996This report describes research done at the Department of Information and Computer Science, University ofCalifornia, Irvine, the Jet Propulsion Laboratory, California Institute of Technology, Microsoft Research, theCenter for Biological and Computational Learning, and the Artificial Intelligence Laboratory of the MassachusettsInstitute of Technology. The authors can be contacted as pjs@aig.jpl.nasa.gov, heckerma@microsoft.com,and jordan@psyche.mit.edu. Support for CBCL is provided in part by a grant from the NSF (ASC-9217041).Support for the laboratory's artificial intelligence research is provided in part by the Advanced Research ProjectsAgency of the Dept. of Defense. MIJ gratefully acknowledges discussions with Steffen Lauritzen on the applicationof the IPF algorithm to UPINs. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title>  Visualisation of Large Networks in 3-D Space:Issues inImplementation and Experimental Evaluation  </title>
<author> Yan Xiao Paul Milgram </author>
<abstract> AbstractThree dimensional visualisation has become awidespread scheme for helping users to accessand manage large information network. In thisreport, various techniques for displaying depthinformation are reviewed, with an emphasis onstereoscopic displays. Input devices used to interact with a 3-D space are also examined. Issues in 3-D network visualisation are elicited fromthree viewpoints: psychological, task-related andimplementational. Consideration of these issuesleads to the design of a preliminary experimentalprogramme for evaluating various network visu-alisation techniques. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> MASSACHUSETTS INSTITUTE OF TECHNOLOGYARTIFICIAL INTELLIGENCE LABORATORYandCENTER FOR BIOLOGICAL INFORMATION PROCESSINGWHITAKER COLLEGE </affiliation>
<pubnum> A.I. Memo No. 1164 </pubnum>
<date> October 1989 </date>
<pubnum> C.B.I.P. Paper No. 45 </pubnum>
<title> Networks and the Best Approximation Property </title>
<author> Federico Girosi and Tomaso Poggio </author>
<abstract> AbstractNetworks can be considered as approximation schemes. Multilayer networks of thebackpropagation type can approximate arbitrarily well continuous functions (Cybenko,1989; Funahashi, 1989; Stinchcombe and White, 1989). We prove that networks derived from regularization theory and including Radial Basis Functions (Poggio andGirosi, 1989), have a similar property. From the point of view of approximation theory, however, the property of approximating continuous functions arbitrarily well is notsufficient for characterizing good approximation schemes. More critical is the propertyof best approximation. The main result of this paper is that multilayer networks, of thetype used in backpropagation, are not best approximation. For regularization networks(in particular Radial Basis Function networks) we prove existence and uniqueness ofbest approximation. </abstract>
<note> c Massachusetts Institute of Technology,1994This paper describes research done within the Center for Biological Information Processing, in the Department of Brain and Cognitive Sciences, and at the Artificial IntelligenceLaboratory. This research is sponsored by a grant from the Office of Naval Research(ONR), Cognitive and Neural Sciences Division; by the Artificial Intelligence Center ofHughes Aircraft Corporation; by the Alfred P. Sloan Foundation; by the National Science Foundation. Support for the A. I. Laboratory's artificial intelligence research is provided by the Advanced Research Projects Agency of the Department of Defense underArmy contract DACA76-85-C-0010, and in part by ONR contract N00014-85-K-0124. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Virtual Model Control of a Biped Walking Robot </title>
<author> byJerry E. Pratt </author>
<degree> Submitted to the Department of Electrical Engineering and Computer Sciencein partial fulfillment of the requirements for the degree ofMaster of Engineering in Electrical Engineering and Computer Scienceat the </degree><affiliation> MASSACHUSETTS INSTITUTE OF TECHNOLOGY </affiliation>
<date> August 1995 </date>
<degree> c Jerry E. Pratt, MCMXCV. All rights reserved.The author hereby grants to MIT permission to reproduce and distribute publiclypaper and electronic copies of this thesis document in whole or in part, and to grantothers the right to do so.Author : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :Department of Electrical Engineering and Computer ScienceAugust 25, 1995Certified by : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :Gill A. PrattAssistant Professor of Electrical Engineering and Computer ScienceThesis SupervisorAccepted by : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :F. R. MorgenthalerChairman, Department Committee on Graduate Theses </degree><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<author> Jonathan E. Hazanand Richard G. Morgan </author>
<pubnum> Technical Report no. 3/92 </pubnum>
<affiliation> Artificial Intelligence Systems Research GroupComputer Science DivisionSchool of Engineering and Computer ScienceUniversity of Durham, </affiliation>
 <address> DH1 3LE, UK </address>
<date> 12th July 1993 </date>
<abstract> AbstractProgrammers using imperative languages have a number of well-established debugging tools available to them; functional programmers have few, if any, tools available.Many of the tools and techniques developed for debugging functional programs arebased on those for imperative programming and lack a theoretical basis relevant tofunctional programming. In addition, the techniques used are typically very time-consuming. A theoretical foundation on which to base the study of errors and debugging in functional programming is presented in this report. Using this theoreticalfoundation, a set of program transformation schemes has been developed which facilitate the location of the type of error which results in an evaluation-time error messageand the termination of evaluation. A brief description of the practical experience obtained using the tool is also presented. </abstract>
<note> The authors can be contacted by emailing J.E.Hazan@durham.ac.uk. FAX: +44 (0)91 374 3741. Thisresearch is funded by a grant from the Science and Engineering Research Council of Great Britain. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Real-time Communication in Multi-hop Networks </title>
<author> Dilip D. Kandlur, Kang G. Shin </author>
<affiliation> Real-Time Computing LaboratoryDepartment of Elec. Engr. and Computer ScienceThe University of Michigan </affiliation>
<address> Ann Arbor, Michigan 48109-2122. </address>
<email> email: kgshin@alps.eecs.umich.edu </email>
<author> Domenico Ferrari </author>
<affiliation> Computer Science DivisionEE &amp; CS DepartmentUniversity of California </affiliation>
<address> Berkeley, CA 94720. </address>
<abstract> ABSTRACTCommunication in real-time systems has to be predictable, because unpredictable delays inthe delivery of messages can adversely affect the execution of tasks dependent on these messages.In this paper, we develop a scheme for providing predictable inter-process communication inreal-time systems with (partially connected) point-to-point interconnection networks, whichprovides guarantees on the maximum delivery time for messages. This scheme is based on theconcept of a real-time channel, a unidirectional connection between source and destination. Areal-time channel has parameters which describe the performance requirements of the source-destination communication, e.g., from a sensor station to a control site. Once such a channelis established, the communications subsystem guarantees that these performance requirementswill be met. In this paper, we concentrate on methods to compute guarantees for the delivery time of messages belonging to real-time channels. We also address problems associatedwith allocating buffers for these messages and develop a scheme which preserves delivery timeguarantees. </abstract>
<keyword> Index Terms | Real-time systems, communication, scheduling, guaranteed delay, point-to-point networks. </keyword>
<note> The work reported here is supported in part by an IBM Graduate Fellowship and by the Office of NavalResearch under Contract N00014-85-K-0122. Any opinions, findings, and conclusions or recommendationsexpressed in this paper are those of the authors and do not necessarily reflect the views of the funding agencies. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> SEQUOIA 2000 -- A REFLECTION ON THE FIRST THREE YEARS </title>
<author> Michael Stonebraker </author>
<affiliation> EECS DepartmentUniversity of California, Berkeley </affiliation>
<abstract> AbstractThis paper describes the SEQUOIA 2000 projectand its implementation efforts during the first three years.Included are the objectives we had, how we chose toaddress them and some of the lessons we learned fromthis endeavor. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Chinook Hardware/Software Co-Synthesis System </title>
<author> Pai H. Chou Ross B. Ortega Gaetano Borriello </author>
<affiliation> Department of Computer Science &amp; EngineeringUniversity of Washington </affiliation>
<address> Seattle, WA 98195-2350 </address>
<abstract> AbstractDesigners of embedded systems are facing ever tighterconstraints on design time, but computer aided design toolsfor embedded systems have not kept pace with these trends.The Chinook co-synthesis system addresses the automation of the most time-consuming and error-prone tasks inembedded controller design, namely: the synthesis of interface hardware and software needed to integrate systemcomponents; the migration of functions between processorsor custom logic; and the co-simulation of the design before,during, and after synthesis. This paper describes the principal elements of Chinook and discuss its application to avariety of embedded designs. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Parallelization of LinearizedApplications in Fortran D </title>
<author> Lorie M. LiebrockKen Kennedy </author>
<pubnum> CRPC TR93342-S </pubnum>
<date> November, 1993 </date>
<affiliation> Center for Research on Parallel ComputationRice University </affiliation>
<address> P.O. Box 1892Houston, TX 77251-1892 </address>
<note> This research was supported by: Center for Research onParallel Computation, a National Science Foundation Science and Technology Center, through Cooperative Agreement No. CCR-9120008, NSF/NASA Agreement No.ASC-9213821, and ONR Agreement No. N00014-93-1-0158. Use of the Intel i860 was provided under a TexasCER Grant No. CISE 8619893. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Dispersion Analysis of Numerical Wave Propagationand its Computational Consequences </title>
<author> Alain Sei and William Symes  </author>
<note> (Submitted to the Journal of Scientific Computing) </note>
<abstract> AbstractWe present in this paper a comparison of the dispersion properties for several finite-difference approximations of the acoustic wave equation. We investigate the compact andstaggered schemes of fourth order accuracy in space and of second order or fourth order accuracy in time. We derive the computational cost of the simulation implied by a precisioncriterion on the numerical simulation (maximum allowed error in phase or group velocity).We conclude that for moderate accuracy the staggered scheme of second order in time is moreefficient, whereas for very precise simulation the compact scheme of fourth order in time isa better choice. The comparison increasingly favors the lower order staggered scheme as thedimension increases. In three dimensional simulation, the cost of extremely precise simulation with any of the schemes is very large, whereas for simulation of moderate precision thestaggered scheme is the least expensive. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Deterministic Parallel Fortran </title>
<author> K. Mani Chandy Ian Foster  </author>
<abstract> AbstractWe describe Fortran M, message-passing extensions to Fortran 77 that providedeterministic execution and information hiding while preserving desirable properties ofmessage passing. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Trust-region interior-point algorithms for minimization problemswith simple bounds  </title>
<author> J. E. Dennis Lus N. Vicente  </author>
<abstract> AbstractTwo trust-region interior-point algorithms for the solution of minimization problemswith simple bounds are presented. The algorithms scale the local model in a way proposedby Coleman and Li [1], but they are new otherwise. The first algorithm is more usual inthat the trust region and the local quadratic model are consistently scaled. The secondalgorithm proposed here uses an unscaled trust region. A first-order convergence result forthese algorithms is given and dogleg and conjugate-gradient algorithms to compute trialsteps are introduced. Some numerical examples that show the advantages of the the secondalgorithm are presented. </abstract>
<keyword> Keywords. trust-region methods, interior-point algorithms, Dikin-Karmarkar ellipsoid,Coleman and Li scaling, simple bounds. </keyword>
<note> AMS subject classification. 49M37, 90C20, 90C30 </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> RICE UNIVERSITY </affiliation>
<title> Optimizing Fortran90D/HPF forDistributed-Memory Computers </title>
<author> byGerald H. Roth </author>
<degree> A Thesis Submittedin Partial Fulfillment of theRequirements for the DegreeDoctor of PhilosophyApproved, Thesis Committee:Ken Kennedy, Noah Harding ProfessorComputer ScienceJohn Mellor-Crummey, Faculty FellowComputer ScienceWilliam W. Symes, ProfessorComputational and Applied MathematicsR. Gregg Brickner, Technical Staff MemberLos Alamos National LaboratoryHouston, Texas </degree><date> April, 1997 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Space-time domain decomposition for parabolicproblems </title>
<author> Eldar Giladi  </author>
<affiliation> Applied Mathematics 217-50Caltech, </affiliation>
 <address> Pasadena CA 91125. </address>
<author> Herbert B. Keller  </author>
<affiliation> Applied Mathematics 217-50Caltech, </affiliation>
<address>  Pasadena CA 91125. </address>
<date> March 25, 1997 </date>
<abstract> AbstractWe analyze a space-time domain decomposition iteration, for a model advectiondiffusion equation in one and two dimensions. The asymptotic convergence rate issuperlinear, and it is governed by the diffusion of the error across the overlap betweensubdomains. Hence, it depends on both the size of this overlap and the diffusioncoefficient in the equation. However, it is independent of the number of subdomains.The convergence rate for the heat equation in a large time window is initially linear andit deteriorates as the number of subdomains increases. The duration of the transientlinear regime is proportional to the length of the time window. For advection dominatedproblems, the convergence rate is initially linear and it improves as the the ratio ofadvection to diffusion increases. Moreover, it is independent of the size of the timewindow and of the number of subdomains. In two space dimensions, the iterationpossesses the smoothing property: high modes of the error are damped much fasterthen low modes. This is a result of the natural smoothing property of the heat equation.Numerical calculations illustrate our analysis. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Reference: Proceedings of the IASTED International Conference on Artificial Intelligence, Expert Systems and Neural Networks, pp.249-252, 1996. </note>
<title> Using Multiple Node Types to Improve thePerformance of DMP (Dynamic Multilayer Perceptron) </title>
<author> Tim L. Andersen and Tony R. Martinez </author>
<affiliation> Computer Science Department, Brigham Young University, </affiliation>
 <address> Provo, Utah 84602 </address>
<email> email: tim@axon.cs.byu.edu, martinez@cs.byu.edu </email>
<abstract> ABSTRACTThis paper discusses a method for training multilayerperceptron networks called DMP2 (Dynamic MultilayerPerceptron 2). The method is based upon a divide and conquerapproach which builds networks in the form of binary trees,dynamically allocating nodes and layers as needed. The focusof this paper is on the effects of using multiple node typeswithin the DMP framework. Simulation results show thatDMP2 performs favorably in comparison with other learningalgorithms, and that using multiple node types can bebeneficial to network performance. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Proceedings of the International Conference on Artificial Intelligence, Expert Systems and Neural Networks(AIE96), pp. 11-14, 1996. </note>
<title> Instance-Based Learning with Genetically Derived Attribute Weights </title>
<author> D. Randall Wilson, Tony R. Martinez </author>
<email> e-mail: randy@axon.cs.byu.edu, martinez@cs.byu.edu </email>
<affiliation> Computer Science Department, Brigham Young University, </affiliation>
 <address> Provo, UT 84602, U.S.A. </address>
<keyword> Key words: instance-based learning, genetic algorithms, instance weights, generalization </keyword>
<abstract> Abstract. This paper presents an inductive learning system called the Genetic Instance-BasedLearning (GIBL) system. This system combines instance-based learning approaches withevolutionary computation in order to achieve high accuracy in the presence of irrelevant orredundant attributes. Evolutionary computation is used to find a set of attribute weights thatyields a high estimate of classification accuracy. Results of experiments on 16 data sets areshown, and are compared with a non-weighted version of the instance-based learning system.The results indicate that the generalization accuracy of GIBL is somewhat higher than that of thenon-weighted system on regular data, and is significantly higher on data with irrelevant orredundant attributes. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The weakest reasonable memory model </title>
<author> byMatteo Frigo </author>
<degree> Laurea, Universit a di Padova (1992)Dottorato di Ricerca, Universit a di Padova (1996)Submitted to the Department of Electrical Engineering and ComputerSciencein partial fulfillment of the requirements for the degree ofMaster of Scienceat the </degree><affiliation> MASSACHUSETTS INSTITUTE OF TECHNOLOGY </affiliation>
<date> October 1997 </date>
<degree> c Matteo Frigo, MCMXCVII. All rights reserved.The author hereby grants to MIT permission to reproduce and distributepublicly paper and electronic copies of this thesis document in whole or inpart, and to grant others the right to do so.Author . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Department of Electrical Engineering and Computer ScienceJanuary 28, 1998Certified by . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Charles E. LeisersonProfessor of Computer Science and EngineeringThesis SupervisorAccepted by . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .PUT NAME HEREChairman, Departmental Committee on Graduate Students </degree><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Incremental Cryptography and Application to Virus Protection </title>
<author> Mihir Bellare Oded Goldreich Shafi Goldwasser  </author>
<abstract> AbstractThe goal of incremental cryptography is to design cryptographic algorithms with the property that having appliedthe algorithm to a document, it is possible to quickly updatethe result of the algorithm for a modified document, ratherthan having to re-compute it from scratch. In settings wherecryptographic algorithms such as encryption or signaturesare frequently applied to changing documents, dramatic efficiency improvements can be achieved. One such setting isthe use of authentication tags for virus protection.We consider documents that can be modified by powerful (and realistic) document modification operations such asinsertion and deletion of character-strings (or equivalentlycut and paste of text). We provide efficient incrementalsignature and message authentication schemes supportingthe above document modification operations. They meet astrong notion of tamper-proof security which is appropriatefor the virus protection setting. We initiate a study of incremental encryption, providing definitions as well as solutions.Finally, we raise the novel issue of "privacy" of incrementalauthentication schemes. </abstract>
<note> Abstract to appear in Proceedings of the 27th ACM Symposium on the Theory of Computing, May 1995. </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> ON THE POWER OF TWO-POINTS BASED SAMPLING </title>
<author> Benny Chor Oded Goldreich flfl </author>
<affiliation> MIT Laboratory for Computer Science </affiliation>
<address> Cambridge, Massachusetts 02139 </address>
<abstract> Abstract | The purpose of this note is to present a new sampling technique and to demonstratesome of its properties. The new technique consists of picking two elements at random, and deterministically generating (from them) a long sequence of pairwise independent elements. Thesequence is guarantees to intersect, with high probability, any set of non-negligible density. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On Yao's XOR-Lemma </title>
<author> Oded Goldreich Noam Nisan Avi Wigderson x </author>
<date> March 1995 (corrected Dec. 1995 and March 1998) </date>
<abstract> AbstractA fundamental Lemma of Yao states that computational weak-unpredictabilityof functions gets amplified if the results of several independent instances are XORtogether. We survey two known proofs of Yao's Lemma and present a third alternative proof. The third proof proceeds by first proving that a function constructedby concatenating the values of the function on several independent instances is muchmore unpredictable, with respect to specified complexity bounds, than the originalfunction. This statement turns out to be easier to prove than the XOR-Lemma.Using a result of Goldreich and Levin and some elementary observation, we derivethe XOR-Lemma. </abstract>
<note> Work done in part while the authors were visiting BRICS, Basic Research in Computer Science, Centerof the Danish National Research Foundation.Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot,Israel. Partially supported by grant No. 92-00226 from the United States - Israel Binational ScienceFoundation (BSF), Jerusalem, Israel. </note>
<affiliation> Institute for Computer Science, Hebrew University, </affiliation>
 <address> Jerusalem, Israel. </address>
<affiliation> x Institute for Computer Science, Hebrew University, </affiliation>
 <address> Jerusalem, Israel. </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Eventually-Serializable Data Services </title>
<author> Alan Fekete David Gupta Victor Luchangco Nancy Lynch Alex Shvartsman  </author>
<abstract> AbstractWe present a new specification for distributed data services that trade-off immediate consistency guaranteesfor improved system availability and efficiency, whileensuring the long-term consistency of the data. Aneventually-serializable data service maintains the operations requested in a partial order that gravitates overtime towards a total order. It provides clear and unambiguous guarantees about the immediate and long-termbehavior of the system. To demonstrate its utility, wepresent an algorithm, based on one of Ladin, Liskov,Shrira, and Ghemawat [12], that implements this specification. Our algorithm provides the interface of theabstract service, and generalizes their algorithm by allowing general operations and greater flexibility in specifying consistency requirements. We also describe howto use this specification as a building block for applications such as directory services. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Incoercible Multiparty Computation </title>
<note> (Extended Abstract)  </note>
<author> Ran Canetti Rosario Gennaro  </author>
<date> May 17, 1996 </date>
<abstract> AbstractCurrent secure multiparty protocols have the following deficiency. The public transcript of the communication can be used as an involuntary commitment of the parties to their inputs and outputs. Thusparties can be later coerced by some authority to reveal their private data. Previous work that haspointed this interesting problem out contained only partial treatment.In this work we present the first general and rigorous treatment of the coercion problem in secure computation. First we present a general definition of protocols that provide resilience to coercion. Ourdefinition constitutes a natural extension of the general paradigm used for defining secure multipartyprotocols. Next we show that if trapdoor permutations exist then any function can be incoerciblycomputed (i.e., computed by a protocol that provides resilience to coercion) in the presence of com-putationally bounded adversaries and only public communication channels. This holds as long as lessthan half the parties are coerced (or corrupted). In particular, ours are the first incoercible protocolswithout physical assumptions. Also, our protocols constitute an alternative solution to the recentlysolved adaptive security problem.Our techniques are quite surprising and include non-standard use of deniable encryptions. </abstract>
<affiliation> Laboratory for Computer Science, Massachusetts Institute of Technology, </affiliation>
 <address>  545 Technology Square, Cambridge MA 02139, U.S.A. </address>
 <email> canetti,rosario@theory.lcs.mit.edu </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Proactive RSA </title>
<author> Yair Frankel Peter Gemmell Philip D. MacKenzie Moti Yung x </author>
<date> August 4, 1996 </date>
<abstract> AbstractThe notion of "proactive security" of basic primitives and cryptosystems that are distributedamongst various servers, was introduced in order to tolerate a very strong "mobile adversary." Thisadversary may corrupt all participants throughout the lifetime of the system in a non-monotonicfashion (i.e. recoveries are possible) but the adversary is unable to corrupt too many participantsduring any short time period [OstrovskyYung]. The notion assures increased security and availabilityof the cryptographic primitive.We present a proactive RSA system in which a threshold of servers applies the RSA signature(or decryption) function in a distributed manner; RSA is perhaps the most important trapdoorfunction in use. Employing new combinatorial and elementary number theoretic techniques, ourprotocol enables the dynamic updating of the servers (which hold the RSA key distributively);it is secure even when a linear number of the servers are corrupted during any time period (linearredundancy); it efficiently "self-maintains" the security of the function and its messages (ciphertextsor signatures); and it enables continuous availability, namely, correct function application using theshared key is possible at any time.We present an efficient way in which l servers can share an RSA private function so that, given0 &amp;lt; &amp;lt; t &amp;lt; 1:* Proactive (Dynamic) Robustness: A gateway G can combine information from any set of lt(honest) servers to deduce the RSA signature for any authorized message at any period.* Proactive Security (against mobile adversary): Our protocol is secure against a polynomialtime adversary who controls the gateway G and time-variant sets of up to minfl(1 t ); lgservers, and can obtain the shares of up to l servers (including those that it corrupts).* Uniform Boundedness: The share-size is always bounded by the size of an RSA private key(i.e., logarithmically in N ).We also present special practical instances based on designs; some of these instances were recentlyimplemented as part of a highly secure application testbed at Sandia National Laboratories.A major technical difficulty in "proactivizing" RSA was the fact that the servers have to updatethe "distributed representation" of an RSA key, while not learning the order of the group fromwhich keys are drawn (in order not to compromise the RSA security). </abstract>
<affiliation> Sandia National Labs, </affiliation>
 <address> P.O Box 5800, Albuquerque, NM 87185-1110, </address>
 <email> yair@cs.sandia.gov </email>
<affiliation> Sandia National Labs, </affiliation>
 <address> P.O Box 5800, Albuquerque, NM 87185-1110, </address>
 <email> psgemme@cs.sandia.gov </email>
<affiliation> Sandia National Labs, </affiliation>
 <address> P.O Box 5800, Albuquerque, NM 87185-1110, </address>
 <email> philmac@cs.sandia.gov. </email>
<affiliation> x IBM T. J. Watson Research Center, </affiliation>
<address>  Yorktown Heights, NY, </address>
 <email> moti@watson.ibm.com, moti@cs.columbia.edu </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Forward and Backward SimulationsPart I: Untimed Systems </title>
<author> Nancy Lynch </author>
<affiliation> MITLaboratory for Computer Science </affiliation>
<address> Cambridge, MA 02139, USA </address>
<email> lynch@theory.lcs.mit.edu </email>
<author> Frits Vaandrager </author>
<address> CWIP.O. Box 94079, NL-1090 GB Amsterdam </address>
<email> fritsv@cwi.nl </email>
<affiliation> University of AmsterdamProgramming Research Group </affiliation>
<address> Kruislaan 403, NL-1098 SJ Amsterdam </address>
<date> October 31, 1994 </date>
<abstract> AbstractA unified, comprehensive presentation of simulation techniques for verification of concurrent systems is given, in terms of a simple untimed automaton model. In particular,(1) refinements, (2) forward and backward simulations, (3) hybrid forward-backwardand backward-forward simulations, and (4) history and prophecy relations are defined.History and prophecy relations are abstract versions of the history and prophecy variables of Abadi and Lamport, as well as the auxiliary variables of Owicki and Gries.Relationships between the different types of simulations, as well as soundness andcompleteness results, are stated and proved. Finally, it is shown how invariants can beincorporated into all the simulations.Even though many results are presented here for the first time, this paper canalso be read as a survey (in a simple setting) of the research literature on simulationtechniques.The development for untimed automata is designed to support a similar development for timed automata. In Part II of this paper, it is shown how the results of thispaper can be carried over to the setting of timed automata. </abstract>
<note> 1991 Mathematics Subject Classification: 68Q60, 68Q68.1991 CR Categories: F.1.1, F.3.1. </note>
<keyword> Keywords and Phrases: Simulations, automata, refinement mappings, forward simulations, backward simulations, forward-backward simulations, backward-forward simulations, history variables, prophecy variables, history relations, prophecy relations,verification, invariants. </keyword>
<note> Notes: This work was supported by ONR contracts N00014-85-K-0168 and N00014-91-J-1988, by NSF grants CCR-8915206 and CCR-9225124, by DARPA contracts N00014-89-J-1988 and N00014-92-J-4033, and ONR-AFOSR contract F49620-94-1-0199. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<pubnum>  M.I.T Media Laboratory Perceptual Computing Section   Technical Report No. 307  </pubnum>
<note> Appears: International Conference on Computer Vision '95, Cambridge, MA, June 20-23, 1995 </note>
<title> Facial Expression Recognition using a Dynamic Model and Motion Energy </title>
<author> Irfan A. Essa and Alex P. Pentland </author>
<affiliation> Perceptual Computing Group, The Media Laboratory,Massachusetts Institute of Technology </affiliation>
<address> Cambridge, MA 02139, U.S.A. </address>
<abstract> AbstractPrevious efforts at facial expression recognition havebeen based on the Facial Action Coding System (FACS), arepresentation developed in order to allow human psychologists to code expression from static facial mugshots. Inthis paper we develop new, more accurate representationsfor facial expression by building a video database of facialexpressions and then probabilistically characterizing thefacial muscle activation associated with each expressionusing a detailed physical model of the skin and muscles.This produces a muscle-based representation of facial motion, which is then used to recognize facial expressions intwo different ways. The first method uses the physics-basedmodel directly, by recognizing expressions through comparison of estimated muscle activations. The second methoduses the physics-based model to generate spatio-temporalmotion-energy templates of the whole face for each differentexpression. These simple, biologically-plausible motionenergy templates are then used for recognition. Bothmethods show substantially greater accuracy at expressionrecognition than has been previously achieved. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 358 </pubnum>
<note> Also to appear: Springer Verlag Workshops in Computing, MIRO 95, Invited Paper, Glasgow, Sep. 95 </note>
<title> Toward a Visual Thesaurus </title>
<author> Rosalind W. Picard </author>
<affiliation> MIT Media Laboratory, </affiliation>
 <address> 20 Ames St., Cambridge, MA 02139 </address>
<email> picard@media.mit.edu, </email>
 <web> http://www.media.mit.edu/~picard/ </web><abstract> AbstractA thesaurus is a book containing synonyms in agiven language; it provides similarity links whentrying to retrieve articles or stories about a particular topic. A "visual thesaurus" works withpictures, not words. It aids in recognizing visually similar events, "visual synonyms," includingboth spatial and motion similarity. This paperdescribes a method for building such a tool, andrecent research results in the MIT Media Labwhich contribute toward this goal. The heartof the method is a learning system which gathers information by interacting with a user of adatabase. The learning system is also capable ofincorporating audio and other perceptual information, ultimately constructing a representationof common sense knowledge. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Multimodal Person Recognition usingUnconstrained Audio and Video </title>
<author> Tanzeem Choudhury, Brian Clarkson, Tony Jebara, Alex Pentland </author>
<affiliation> Perceptual Computing GroupMIT Media Laboratory </affiliation>
<address> Cambridge, MA 02139 </address>
<email> ftanzeem,clarkson,jebara,sandyg@media.mit.edu </email>
<abstract> AbstractWe propose a person identification technique thatcan recognize and verify people from unconstrainedvideo and audio. We do not expect fully frontal faceimage or clean speech as our input. Our recognition algorithm can detect and compensate for pose variationand changes in the auditory background and also select the most reliable video frame and audio clip to usefor recognition. We also use 3D depth information ofa human head to detect the presence of an actual person as opposed to an image of that person. Our system achieves 100% recognition and verification rateson natural real-time input with 26 registered clients. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Building Query Optimizers with Combinators: </title>
<note> Dissertation Proposal </note>
<author> Mitch Cherniack </author>
<abstract> AbstractQuery optimizers generate plans to retrieve data specified by queries. Query optimizationfor object databases (i.e., object-oriented and object-relational databases) is an immature field,and stands to benefit from adaptation of techniques that have proved useful for relations. Onetechnique uses query-to-query transformations to rewrite queries into queries that are potentiallymore amenable to plan generation. For transformations to be useful, they must preserve thesemantics of the queries they rewrite (correctness) and usually result in queries that generatebetter plans (effectiveness). Object databases complicate the expression of correct and effectivetransformations.Transformation correctness is problematic even for relational queries. Especially error-proneare transformations that rewrite complex nested queries (queries containing other queries) orqueries that return duplicates. Objects make correctness more difficult because object queriescan be far more complex than relational queries.The effectiveness of a relational transformation typically depends on the syntax of a queryrather than the semantics of of its data or functions. On the other hand, the lack of uniformityin data functions and collections in an object query makes effectiveness more subtle. The effectiveness of a transformation for object queries may depend on the semantics of data functions,and may vary from object to object in a collection. Therefore, optimizers may have to performsophisticated reasoning and apply transformations on a per object basis to ensure that they areused only when appropriate.This thesis considers the correctness and effectiveness of optimizer transformations. Toaddress correctness, we propose a formally specified query algebra and two-tiered language(COKO-KOLA) for expressing transformations that can be verified with a theorem prover. Toaddress effectiveness, we propose semantic and dynamic extensions to the traditional optimizerarchitecture. The high-level contribution of the thesis is the observation that the choice ofquery representation impacts the quality of the optimizer. Specifically, a combinator-based(variable-free) query representation simplifies the query manipulations that are required to maketransformations correct and effective. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> PARTIAL SHAPE MATCHING USING GENETICALGORITHMS </title>
<author> Ender Ozcan and Chilukuri K. Mohan </author>
<email> eozcan/mohan@top.cis.syr.edu </email>
<address> 2-120 Center for Science and Technology, </address>
<affiliation> Department of Electrical Engineering and Computer Science,Syracuse University, </affiliation>
 <address> Syracuse, NY 13244-4100, U.S.A. </address>
<phone> 315-443-2322/(fax) 1122 </phone><abstract> AbstractShape recognition is a challenging task when images contain overlapping, noisy, occluded, partial shapes.This paper addresses the task of matching input shapes with model shapes described in terms of featuressuch as line segments and angles. The quality of matching is gauged using a measure derived from attributedshape grammars. We apply genetic algorithms to the partial shape-matching task. Preliminary results, usingmodel shapes with 6 to 70 features each, are extremely encouraging. </abstract>
<keyword> Key words : Partial Shape Matching, Genetic Algorithms, Attributed Strings, Pattern Recognition. </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Description Logics are not just for the Flightless-Birds:A New Look at the Utility and Foundations of Description Logics </title>
<author> Alex Borgida </author>
<affiliation> Dept. of Computer ScienceRutgers University </affiliation>
<address> New Brunswick, NJ 08904 </address>
<date> June 1992 </date>
<abstract> AbstractThis paper presents some of the underlying principles of description logics (also knownas terminological logics or kl-one-style languages), grounding them in the lattice of termsorganized by the so-called "subsumption" relationship. A survey of the increasingly varied usesof description logics, including industrial applications, is presented by considering their role ina number of different operations that one can apply to a knowledge base, including languagesfor queries, answers, updates, rules, and constraints. Finally, we discuss some of the complexityresults related to the logics of descriptions, and survey a spectrum of responses to the manyintractability proofs. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Finding pattern matchings for permutations </title>
<author> Louis Ibarra </author>
<affiliation> Dept. of Computer ScienceHill Center, Busch CampusRutgers University </affiliation>
<address> Piscataway, NJ 08855 </address>
<email> ibarra@paul.rutgers.edu </email>
<date> January 19, 1995 </date>
<abstract> AbstractGiven a permutation P of f1; : : : ; kg and T of f1; : : : ; ng, the pattern matching problem for permutations is to determine whether there is a length k subsequence of T whose elements are orderedin the same way as the elements of P . We present an O(kn 4 ) time and O(kn 3 ) space algorithmfor finding a match of P into T or determining that no match exists, given that P is separable, i.e.contains neither (2, 4, 1, 3) nor (3, 1, 4, 2) as a subpattern. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On Algorithms for Simplicial Depth </title>
<author> Andrew Y. Cheng </author>
<affiliation> Department of Industrial Engineering </affiliation>
<author> Ming Ouyang </author>
<affiliation>  Department of Computer Science  Rutgers University  </affiliation>
<address> New Brunswick, New Jersey 08903 </address>
<abstract> ABSTRACTSimplicial depth is a way to measure how deep a point is among a set of points. Efficientalgorithms to compute it are important to the usefulness of its applications, such as inmultivariate analysis in statistics. A straightforward method takes O(n d+1 ) time when thepoints are in d-dimensional space. We discuss an algorithm that takes O(n 2 ) time when thepoints are in three-dimensional space, and we generalize it to four-dimensional space witha time complexity of O(n 4 ). For spaces higher than four-dimensional, there are no knownalgorithms faster than the straightforward method. </abstract>
<intro> 1 Simplicial depth </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Algorithm for Bayesian Belief Network Construction from Data </title>
<author> Jie Cheng, David A. Bell, Weiru Liu </author>
<affiliation> School of Information and Software EngineeringUniversity of Ulster at Jordanstown </affiliation>
<address> Northern Ireland, UK, BT37 0QB </address>
<email> email: -j.cheng, da.bell, w.liu-@ulst.ac.uk </email>
<abstract> AbstractThis paper presents an efficient algorithm for constructing Bayesian belief networks from databases. Thealgorithm takes a database and an attributes ordering (i.e., the causal attributes of an attribute should appear earlierin the order) as input and constructs a belief network structure as output. The construction process is based on thecomputation of mutual information of attribute pairs. Given a data set which is large enough and has a DAG-Isomorphic probability distribution, this algorithm guarantees that the perfect map [1] of the underlying dependencymodel is generated, and at the same time, enjoys the time complexity of O N( ) 2 on conditional independence (CI)tests. To evaluate this algorithm, we present the experimental results on three versions of the well-known ALARMnetwork database, which has 37 attributes and 10,000 records. The correctness proof and the analysis ofcomputational complexity are also presented. We also discuss the features of our work and relate it to previousworks. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Planning information gathering under uncertainty </title>
<author> Joshua Grass and Shlomo Zilberstein </author>
<affiliation> Computer Science DepartmentUniversity of Massachusetts at Amherst </affiliation>
<pubnum> CMPSCI Technical Report 97-32 </pubnum>
<date> May 21, 1997 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Evaluation of Architectural Support for Global Address-Based Communicationin Large-Scale Parallel Machines </title>
<author> Arvind Krishnamurthy , Klaus E. Schauser , Chris J. Scheiman ,Randolph Y. Wang , David E. Culler , and Katherine Yelick  </author>
<abstract> AbstractLarge-scale parallel machines are incorporating increasingly sophisticated architectural support for user-level messaging and global memory access. We provide a systematicevaluation of a broad spectrum of current design alternativesbased on our implementations of a global address languageon the Thinking Machines CM-5, Intel Paragon, Meiko CS-2, Cray T3D, and Berkeley NOW. This evaluation includesa range of compilation strategies that make varying use ofthe network processor; each is optimized for the target architecture and the particular strategy. We analyze a familyof interacting issues that determine the performance tradeoffs in each implementation, quantify the resulting latency,overhead, and bandwidth of the global access operations,and demonstrate the effects on application performance. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Improved Algorithm for Performance Optimal TechnologyMapping with Retiming in LUT-Based FPGA Design </title>
<author> Jason Cong and Chang Wu </author>
<affiliation> Department of Computer ScienceUniversity of California, </affiliation>
 <address> Los Angeles, CA 90024 </address>
<abstract> AbstractA novel algorithm, named SeqMapII, of technologymapping with retiming for optimal clock period for K-LUT based FPGAs was recently proposed by Pan andLiu [13]. The time complexity of their algorithm, however, is O(K 3 n 4 log(Kn 2 ) log n) for sequential circuitswith n gates, which is too high for medium and largesize designs in practice. In this paper, we presentthree strategies to improve the performance of the approach in [13]: 1) efficient label update with singleK-cut computation based on the monotone propertyof labels that we showed for sequential circuits, 2) anovel approach for the K-cut computation on partialflow networks, which are much smaller in practice, 3)SCC (strongly connected component) partition to further speedup the algorithm. In practice, our algorithmworks in O(K 2 n 3 log n) time and O(Kn) space according to our experimental results. It is 2fi10 4 times fasterthan SeqMapII-opt for computing optimal solutions and2 times faster than SeqMapII-heu which uses very smallexpanded circuits as a heuristic. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<author> Extended Capabilities forVisual Cryptography </author>
<author>  Giuseppe Ateniese 1 , Carlo Blundo 2 , Alfredo De Santis 2 , and Douglas R. Stinson 3  </author>
<affiliation> 1 Dipartimento di Informatica e Scienze dell'Informazione,Universita di Genova, </affiliation>
 <address> via Dodecaneso 35, 16146 Genova, Italy </address>
<email> E-mail: ateniese@disi.unige.it </email>
<web> URL: http://www.disi.unige.it/phd/ateniese/ateniese.html </web><affiliation> 2 Dipartimento di Informatica ed Applicazioni,Universita di Salerno, </affiliation>
 <address> 84081 Baronissi (SA), Italy </address>
<email> E-mail: fcarblu,adsg@dia.unisa.it </email>
<web> URL: http://www.unisa.it/f~carblu, ~adsg </web><affiliation> 3 Department of Combinatorics and OptimizationUniversity of Waterloo, </affiliation>
 <address> Waterloo Ontario, N2L 3G1, Canada </address>
<abstract> AbstractAn extended visual cryptography scheme, EVCS for short, for an access structure( Qual ; Forb ) on a set of n participants, is a technique to encode n images in such away that when we stack together the transparencies associated to participants in anyset X 2 Qual we get the secret message with no trace of the original images, but anyX 2 Forb has no information on the shared image. Moreover, after the original imagesare encoded they are still meaningful, that is, any user will recognize the image on histransparency.The main contributions of this paper are the following:* A trade-off between the contrast of the reconstructed image and the contrast of theimage on each transparency for (k; k)-threshold EVCS (in a (k; k)-threshold EVCSthe image is visible if and only if k transparencies are stacked together). This yieldsa necessary and sufficient condition for the existence of (k; k)-threshold EVCS forthe values of such contrasts. In case a scheme exists we explicitly construct it.* A general technique to implement extended visual cryptography schemes, whichuses hypergraph colourings. This technique yields (k; k)-threshold EVCS whichare optimal with respect to the pixel expansion. Finally, we discuss some applications of this technique to various interesting classes of access structures by usingrelevant results from the theory of hypergraph colourings. </abstract>
<keyword> Keywords: Visual Cryptography, Secret Sharing Schemes. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Intelligent Sensors for Atomization Processingof Molten Metals and Alloys </title>
<author> * G. Jiang* H. Heneinand** M.W. Siegel </author>
<affiliation> (*) Department of Metallurgical Engineering and Materials Science(**) The Robotics InstituteCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> Final Version, </note>
 <date> 94-Mar-17, </date>
 <note> 1 of 9  </note>
<title> Automation Tools forNonDestructive Inspection of Aircraft:Promise of Technology Transfer from theCivilian to the Military Sector </title>
<author> Chris Seher 1 , Mel Siegel 2 , and William M. Kaufman 3 </author>
<affiliation> 1 Federal Aviation Administration, Technical Center, </affiliation>
 <address> Atlantic City NJ 08201 </address>
<affiliation> 2 Carnegie Mellon University, Robotics Institute, </affiliation>
 <address> Pittsburgh PA 15213 </address>
<affiliation> 3 Carnegie Mellon University, CMRI, </affiliation>
 <address> Pittsburgh PA 15213 </address>
<abstract> AbstractThe FAA Aging Aircraft Research Program issupporting the development of a robotic mobilenondestructive inspection (NDI) instrumentdeployment tool at Carnegie Mellon University(CMU) with the active participation of USAir. Theprogram has spawned several new relationshipsand entities: an alliance with an ARPA-fundedresearch program at CMU having the capability toadd 3D-stereoscopic enhanced visual inspectioncapability, a start-up company organized tocommercialize the combined technologies, andState of Pennsylvania funding to foster thiscommercialization. As a result of these activitiesand connections the civilian sector appears to beahead of the military sector in important aspects ofautomation for deployment of aircraft inspectionequipment. A partnership between the universityresearchers, the airline operator, the start-upcompany, and the state government is thusemerging as the likely agent for transfer of thecivilian-developed technology to the military sector. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> CARNEGIE MELLON UNIVERSITY </affiliation>
<title> EFFICIENT COMPRESSION OF ARBITRARYMULTI-VIEW VIDEO SIGNALS </title>
<degree> A DISSERTATIONSUBMITTED TO THE GRADUATE SCHOOLIN PARTIAL FULFILLMENT OF THE REQUIREMENTSfor the degreeDOCTOR OF PHILOSOPHYinELECTRICAL AND COMPUTER ENGINEERING </degree><author> byJeffrey Scott McVeigh </author>
<address> Pittsburgh, Pennsylvania </address>
<date> June, 1996 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Feature selection for classification based on text hierarchy </title>
<author> Dunja Mladenic and Marko Grobelnik </author>
<affiliation> Department of Intelligent Systems, J.Stefan Institute, </affiliation>
<address> Jamova 39, 1111 Ljubljana, Slovenia </address>
<phone> Phone: (+386)(61) 1773 272, Fax: (+386)(61) 1258-158 </phone><email> E-mail: Dunja.Mladenic@ijs.si, Marko.Grobelnik@ijs.si </email>
<abstract> AbstractThis paper describes automatic document categorization based on large text hierarchy. Wehandle the large number of features and training examples by taking into account hierarchicalstructure of examples and using feature selection for large text data. We experimentally evaluatefeature subset selection on real-world text data collected from the existing Web hierarchy namedYahoo. In our learning experiments naive Bayesian classifier was used on text data using feature-vector document representation that includes word sequences (n-grams) instead of just single words(unigrams). Experimental evaluation on real-world data collected form the Web shows that ourapproach gives promising results and can potentially be used for document categorization on theWeb. Additionally the best result on our data is achieved for relatively small feature subset, while forlarger subset the performance substantially drops. The best performance among six tested featurescoring measure was achieved by the feature scoring measure called Odds ratio that is known frominformation retrieval. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Unification and Polymorphism in Region Inference </title>
<author> Mads Tofte, </author>
 <affiliation> Department of Computer Science, University of Copenhagen </affiliation>
<author> Lars Birkedal, </author>
 <affiliation> School of Computer Science, Carnegie Mellon University </affiliation>
<note> Dedicated to Robin Milner on the occasion of his 60th birthday. </note>
<abstract> AbstractRegion Inference is a technique for inferring lifetimes of values in strict, higher-order programming languages such as Standard ML. The purpose of this paper is to show how ideasfrom Milner's polymorphic type discipline can serve as a basis for region inference, even in thepresence of a limited form of polymorphic recursion. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Introduction to Software Architecture </title>
<author> David Garlan and Mary Shaw </author>
<date> January 1994 </date>
<pubnum> CMU-CS-94-166 </pubnum>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213-3890 </address>
<note> Also published as An Introduction to Software Architecture, Advances in Software Engineeringand Knowledge Engineering, Volume I, edited by V.Ambriola and G.Tortora, World ScientificPublishing Company, New Jersey, 1993.Also appears as CMU Software Engineering Institute Technical ReportCMU/SEI-94-TR-21, ESC-TR-94-21.1994 by David Garlan and Mary ShawThis work was funded in part by the Department of Defense Advanced Research Project Agency under grantMDA972-92-J-1002, by National Science Foundation Grants CCR-9109469 and CCR-9112880, and by a grantfrom Siemens Corporate Research. It was also funded in part by the Carnegie Mellon University School ofComputer Science and Software Engineering Institute (which is sponsored by the U.S. Department of Defense).The views and conclusions contained in this document are those of the authors and should not be interpretedas representing the official policies, either expressed or implied, of the U.S. Government, the Department ofDefense, the National Science Foundation, Siemens Corporation, or Carnegie Mellon University. </note>
<keyword> Keywords: Software architecture, software design, software engineering </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> An Agenda for Research inLarge-Scale Distributed Data Repositories </title>
<author> M. Satyanarayanan </author>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<note> Invited Paper forWorkshop on Operating Systems of the 90s and BeyondDagstuhl Castle, Germany, </note>
 <date> July 1991 </date>
<abstract> AbstractAccess to shared data is provided today by distributed file systems anddatabases. In this paper, we explore certain usage and technological trends thatwill radically change the way shared data is used in the future. The usage trendsinclude the growing need to access shared data from anywhere, increasing scale,and the increasing importance of efficient search. The technology trends includethe advent of portable machines, the availability of software and hardware forusing diverse types of data, and the growing diversity of network speeds andcapabilities. These trends induce fundamental research problems in the areas ofadaptive system behavior, secure remote execution and extensibility. </abstract>
<note> This work has been supported by the Defense Advanced Research Projects Agency (Avionics Lab, Wright Research and Development Center,Aeronautical Systems Division (AFSC), U.S. Air Force, Wright-Patterson AFB, Ohio, 45433-6543 under Contract F33615-90-C-1465, ARPAOrder No. 7597), the National Science Foundation (PYI Award), and the IBM Corporation (Research Initiation Grant). The views andconclusion expressed in this paper are those of the author, and should not be interpreted as those of the funding agencies or Carnegie MellonUniversity. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in the Proceedings of the 16th ACM Symposium on Operating System Principles </note>
<title> Agile Application-Aware Adaptation for Mobility </title>
<author> Brian D. Noble, M. Satyanarayanan, Dushyanth Narayanan, James Eric Tilton, Jason Flinn, Kevin R. Walker </author>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<abstract> AbstractIn this paper we show that application-aware adaptation, acollaborative partnership between the operating system andapplications, offers the most general and effective approachto mobile information access. We describe the design ofOdyssey, a prototype implementing this approach, and showhow it supports concurrent execution of diverse mobile applications. We identify agility as a key attribute of adaptive systems, and describe how to quantify and measure it.We present the results of our evaluation of Odyssey, indicating performance improvements up to a factor of 5 on abenchmark of three applications concurrently using remoteservices over a network with highly variable bandwidth. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Automatic Program Specialization forInteractive Media </title>
<author> Scott Draves </author>
<date> July 23, 1997 </date>
<pubnum> CMU-CS-97-159 </pubnum>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<degree> Submitted in partial fulfillment of the requirementsfor the degree of Doctor of Philosophy.Thesis Committee:Peter Lee, ChairWilliam ScherlisAndy WitkinOlivier Danvy </degree><note> c fl1997 Scott DravesThis research was sponsored in part by the Defense Advanced Research Projects AgencyCSTO under the title The Fox Project: Advanced Languages for Systems Software, ARPA Order No. C533, issued by ESC/ENS under Contract No. F19628-95-C-0050. The views andconclusions contained in this document are those of the authors and should not be interpreted asrepresenting the official policies, either expressed or implied, of the Defense Advanced ResearchProjects Agency or the U.S. Government. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> RECENT ADVANCES IN JANUS:A SPEECH TRANSLATION SYSTEM </title>
<author> M.Woszczyna, N.Coccaro, A.Eisele, A.Lavie, A.McNair, T.Polzin, I.Rogina,C.P.Rose,T.Sloboda, M.Tomita, J.Tsutsumi, N.Aoki-Waibel, A.Waibel, W. Ward </author>
<affiliation> Carnegie Mellon UniversityUniversity of Karlsruhe </affiliation>
<abstract> ABSTRACTWe present recent advances from our efforts in increasing coverage, robustness, generality and speed of JANUS, CMU'sspeech-to-speech translation system. JANUS is a speaker-independent system which translates spoken utterances inEnglish and also in German into one of German, English orJapanese. The system has been designed around the taskof conference registration (CR). It has initially been builtbased on a speech database of 12 read dialogs, encompassing a vocabulary of around 500 words. We have since beenexpanding the system along several dimensions to improvespeed, robustness and coverage and to move toward spontaneous input. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> AURORA: A Vision-Based RoadwayDeparture Warning System </title>
<author> Mei Chen, Todd Jochem, Dean Pomerleau </author>
<email> -meichen, tjochem, pomerlea-@ri.cmu.edu </email>
<affiliation> The Robotics Institute, Carnegie Mellon University, </affiliation>
 <address> Pittsburgh PA 15213 </address>
<abstract> AbstractAURORA is a vision-based system designed to warn a vehicle driver of possible impending roadway departure accidents. It employs a downward looking color video camera with a wide anglelens, a digitizer, and a portable Sun Sparc workstation. Using a binormalized adjustable templatecorrelation algorithm, it reliably detects lane markers on structured roads at 60 Hz. A time-to-lane-crossing (TLC) measurement is calculated for each image based on the estimation of vehicles lateral position and velocity. This measurement is used to trigger an alarm when the TLC falls belowa preset threshold. Promising results have been achieved under a variety of weather and lightingconditions, on many road types. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Combinatorial Approach to Trajectory Planning for BinaryManipulators </title>
<author> David S. Lees Gregory S. Chirikjian  </author>
<affiliation> Department of Mechanical Engineering, Johns Hopkins University, </affiliation>
 <address> Baltimore, MD 21218 </address>
<abstract> AbstractBinary manipulators are powered by actuatorswhich have only two stable states. Therefore, theycan reach only a discrete (but possibly large) numberof locations. Compared to a manipulator built withcontinuous actuators, a binary manipulator providesreasonable performance, and is relatively inexpensive(up to an order of magnitude cheaper). The numberof states of a binary manipulator grows exponentiallywith the number of actuators. This makes the calculation of its inverse kinematics quite difficult. Thispaper presents a combinatorial method for computingthe inverse kinematics of a binary manipulator thatreduces the search space to a manageable size. It alsocreates extremely smooth motions that follow a specified trajectory very accurately (in both position andorientation), despite the discrete nature of binary actuation. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Overview of a Compiler forScalable Parallel Machines </title>
<author> Saman P. Amarasinghe, Jennifer M. Anderson,Monica S. Lam and Amy W. Lim </author>
<affiliation> Computer Systems LaboratoryStanford University, </affiliation>
 <address> CA 94305 </address>
<abstract> Abstract. This paper presents an overview of a parallelizing compilerto automatically generate efficient code for large-scale parallel architectures from sequential input programs. This research focuses on loop-levelparallelism in dense matrix computations. We illustrate the basic techniques the compiler uses by describing the entire compilation process fora simple example.Our compiler is organized into three major phases: analyzing array references, allocating the computation and data to the processors to optimizeparallelism and locality, and generating code.An optimizing compiler for scalable parallel machines requires more sophisticated program analysis than the traditional data dependence analysis. Our compiler uses a precise data-flow analysis technique to identifythe producer of the value read by each instance of a read access. In order to allocate the computation and data to the processors, the compilerfirst transforms the program to expose loop-level parallelism in the computation. It then finds a decomposition of the computation and datasuch that parallelism is exploited and the communication overhead isminimized. The compiler will trade off extra degrees of parallelism toreduce or eliminate communication. Finally, the compiler generates codeto manage the multiple address spaces and to communicate data acrossprocessors. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> CC++ : A Declarative ConcurrentObject Oriented Programming Notation </title>
<author> K. Mani Chandy Carl Kesselman </author>
<affiliation> California Institute of Technology </affiliation>
<date> September 18, 1992 </date>
<abstract> AbstractCC ++ is Compositional C ++ , a parallel object-oriented notationthat consists of C ++ with six extensions. The goals of the CC ++project are to provide a theory, notation and tools for developing reliable scalable concurrent program libraries, and to provide a frameworkfor unifying:1. distributed reactive systems, batch-oriented numeric and symbolic applications, and user-interface systems,2. declarative programs and object-oriented imperative programs,and3. deterministic and nondeterministic programs.This paper is a brief description of the motivation for CC ++ , theextensions to C ++ , a few examples of CC ++ programs with reasoningabout their correctness, and an evaluation of CC ++ in the context ofother research on concurrent computation. A short description ofC ++ is provided. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Distributed Simulation of DEVS-Based Multiformalism Models </title>
<author> Herbert Praehofer and Gernot Reisinger </author>
<affiliation> Institute of Systems ScienceSystems Theory and Information EngineeringJohannes Kepler University Linz </affiliation>
<address> A-4040 Linz, Austria </address>
<abstract> AbstractIn this paper we introduce a new approach for parallel, distributed simulation of modular, hierarchicalDEVS and DEVS-based combined discrete/continuousmultiformalism models. The algorithm combinesconservative and optimistic distributed simulationstrategies and is able to optimally exploit lookaheadcapabilities of the model. The object oriented implementation in C++ is intended to serve as a powerfulsimulator in the STIMS modeling and simulation environment. </abstract>
<intro> 1 Introduction and Motivation </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Building Scalable Parallel Processors UsingNetworked Computers - A Tutorial ForSynergy V2.0 </title>
<author> Yuan Shi </author>
<date> January 1994 </date>
<date> @1994 </date>
<affiliation>  Temple UniversitySYNERGY </affiliation>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Tolerating Latency with Dagger </title>
<author> Attila Gursoy and L.V.Kale </author>
<affiliation> Department of Computer ScienceUniversity of Illinois at Urbana-Champaign </affiliation>
<note> Urbana IL 61801, USA </note>
<email> fgursoy,kaleg@cs.uiuc.edu </email>
<abstract> AbstractThe communication latency is a major issue that must be dealt with in parallelcomputing. The parallel computation model therefore must provide the ability to toleratesuch latencies. Communication using blocking receives is the commonly used mechanismin parallel programming today. Message driven execution is an alternate mechanismwhich does not use receive style statements at all. The message driven execution stylepromotes the overlap of computation and communication: Programs written in this styleexhibit increased latency tolerance. However, they are often difficult to develop anddebug. We present a coordination language called Dagger to alleviate this problem. Thelanguage has a mechanism which is called expect, that replaces the receive statement.It has been implemented in the Charm parallel programming system, and runs programsportably on a variety of parallel machines. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Projections: A Preliminary Performance Tool for Charm </title>
<author> Amitabh B. Sinha Laxmikant V. Kale </author>
<affiliation> Department of Computer Science Department of Computer ScienceUniversity of Illinois University of Illinois </affiliation>
<address> Urbana, IL 61801 Urbana, IL 61801 </address>
<email> email: sinha@cs.uiuc.edu email: kale@cs.uiuc.edu </email>
<abstract> AbstractThe advent and acceptance of massively parallelmachines has made it increasingly important to havetools to analyze the performance of programs running on these machines. Current day performancetools suffer from two drawbacks: they are not scalableand they lose specific information about the user program in their attempt for generality. In this paper,we present Projections, a scalable performance tool,for Charm that can provide program-specific information to help the users better understand the behaviorof their programs. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Inference Networks for Document Retrieval </title>
<degree> A Dissertation Presentedby </degree><author> Howard Robert Turtle </author>
<degree> Submitted to the Graduate School of the </degree><affiliation> University of Massachusetts </affiliation>
 <degree> in partial fulfillmentof the requirements for the degree ofDoctor of Philosophy </degree><date> February 1991 </date>
<affiliation> Department of Computer and Information Science </affiliation>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Comparison of Distributed Concurrency Control Protocolson a Distributed Database Testbed  </title>
<author> Chia-Shiang Shih and Asit Dan </author>
<affiliation> ECE Department, University of Massachusetts </affiliation>
<address> Amherst, MA 01003 </address>
<author> Walter H. Kohler  </author>
<affiliation> Digital Equipment Corporation </affiliation>
<address> 200 Forest Street, MRO1-1/A65Marlboro, MA 01752-9101 </address>
<author> John A. Stankovic and Don Towsley </author>
<affiliation> COINS Department, University of Massachusetts </affiliation>
<address> Amherst, MA 01003 </address>
<note> This work was supported by the National Science Foundation, grant number SDB-8418216 and by a grant fromDigital Equipment Corporation.Walter H. Kohler is manager of High Performance Transaction Processing System group at Digital EquipmentCorporation. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Resolving Ambiguity for Cross-language Retrieval </title>
<author> Lisa Ballesteros </author>
<email> balleste@cs.umass.edu </email>
<affiliation> Center for Intelligent Information RetrievalComputer Science DepartmentUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003-4610 USA </address>
<web> http://ciir.cs.umass.edu/ </web><author> W. Bruce Croft </author>
<email> croftcs.umass.edu </email>
<affiliation> Center for Intelligent Information RetrievalComputer Science DepartmentUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003-4610 USA </address>
<web> http://ciir.cs.umass.edu/ </web><abstract> Abstract One of the main hurdles to improved CLIR effectiveness is resolving ambiguity associated with translation.Availability of resources is also a problem. First we present atechnique based on co-occurrence statistics from unlinked corpora which can be used to reduce the ambiguity associated withphrasal and term translation. We then combine this methodwith other techniques for reducing ambiguity and achieve morethan 90% monolingual effectiveness. Finally, we compare theco-occurrence method with parallel corpus and machine translation techniques and show that good retrieval effectiveness canbe achieved without complex resources. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On computing global similarity in images </title>
<author> S. Ravela and R. Manmatha </author>
<affiliation> Computer Science DepartmentUniversity of Massachusetts, </affiliation>
 <address> Amherst, MA 01003 </address>
<email> Email: fravela,manmathag@cs.umass.edu </email>
<abstract> AbstractThe retrieval of images based on their visual similarityto an example image is an important and fascinating area ofresearch. Here, a method to characterize visual appearancefor determining global similarity in images is described.Images are filtered with Gaussian derivatives and geometric features are computed from the filtered images.The geometric features used here are curvature and phase.Two images may be said to be similar if they have similar distributions of such features. Global similarity may,therefore, be deduced by comparing histograms of thesefeatures. This allows for rapid retrieval and examples fromcollection of gray-level and trademark images are shown. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Kinetic Binary Space Partitions forIntersecting Segments and Disjoint Triangles </title>
<note> (Extended Abstract) </note>
<author> Pankaj K. Agarwal Jeff Erickson Leonidas J. Guibas  </author>
<abstract> AbstractWe describe randomized algorithms for efficiently maintaining a binary space partition of continuously moving, possiblyintersecting, line segments in the plane, and of continuouslymoving but disjoint triangles in space. Our two-dimensionalBSP has depth O(log n) and size O(n log n + k) and can beconstructed in expected O(n log 2 n + k log n) time, where kis the number of intersecting pairs. We can detect combinatorial changes to our BSP caused by the motion of the segments, and we can update our BSP in expected O(log n) timeper change. Our three-dimensional BSP has depth O(log n),size O(n log 2 n+k 0 ), construction time O(n log 3 n+k 0 log n),and update time O(log 2 n) (all expected), where k 0 is thenumber of intersections between pairs of edges in the xy-projection of the triangles. Under reasonable assumptionsabout the motion of the segments or triangles, the expectednumber of number of combinatorial changes to either BSP isO(mn s (n)), where m is the number of moving objects ands (n) is the maximum length of an (n; s) Davenport-Schinzelsequence for some constant s. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Raising Roofs, Crashing Cycles, and Playing Pool:Applications of a Data Structure for Finding Pairwise Interactions  </title>
<author> David Eppstein Jeff Erickson  </author>
<note> Submitted to Discrete &amp; Computational Geometry </note>
<date> July 1, 1998 </date>
<abstract> AbstractThe straight skeleton of a polygon is a variant of the medial axis, introduced byAichholzer et al., defined by a shrinking process in which each edge of the polygonmoves inward at a fixed rate. We construct the straight skeleton of an n-gon with rreflex vertices in time O(n 1+" + n 8=11+" r 9=11+" ), for any fixed " &amp;gt; 0, improving theprevious best upper bound of O(nr log n). Our algorithm simulates the sequence ofcollisions between edges and vertices during the shrinking process, using a technique ofEppstein for maintaining extrema of binary functions to reduce the problem of findingsuccessive interactions to two dynamic range query problems: (1) maintain a changingset of triangles in IR 3 and answer queries asking which triangle would be first hit bya query ray, and (2) maintain a changing set of rays in IR 3 and answer queries askingfor the lowest intersection of any ray with a query triangle. We also exploit a novelcharacterization of the straight skeleton as a lower envelope of triangles in IR 3 . The sametime bounds apply to constructing non-self-intersecting offset curves with mitered orbeveled corners, and similar methods extend to other problems of simulating collisionsand other pairwise interactions among sets of moving objects. </abstract>
<note> An extended abstract of this paper was presented at the 14th Annual ACM Symposium on ComputationalGeometry [29]. See http://www:cs:duke:edu/ ~ jeffe/pubs/cycles:html for the most recent version of this paper. </note>
<affiliation> Department of Information and Computer Science, University of California, </affiliation>
 <address> Irvine, CA 92697, USA; </address>
 <email> epp-stein@ics.uci.edu; </email>
 <web> http://www:ics:uci:edu/ ~ eppstein. </web> <note> Research partially supported by NSF grant CCR-9258355 andby matching funds from Xerox Corporation. </note>
<affiliation> Center for Geometric Computing, Department of Computer Science, Duke University, </affiliation>
 <address> Box 90129, Durham,NC 27708-0129, USA; </address>
 <email> jeffe@cs.duke.edu; </email>
 <web> http://www:cs:duke:edu/ ~ jeffe. </web><note>  Research supported by NSF grant DMS-9627683 and by U. S. Army Research Office MURI grant DAAH04-96-1-0013. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Transis: A Communication Sub-SystemforHigh Availability </title>
<author> Yair Amir, Danny Dolev, Shlomo Kramer, Dalia Malki </author>
<affiliation> Computer Science departmentThe Hebrew University of Jerusalem </affiliation>
<address> Jerusalem, Israel </address>
<pubnum> Technical Report CS91-13 </pubnum>
<date> April 30, 1992 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> From Ordinal to Euclidean Reconstruction with Partial SceneCalibration  </title>
<author> Daphna Weinshall </author>
<affiliation> Inst. of Computer Sci.Hebrew University </affiliation>
<address> 91904 Jerusalem, Israel </address>
<email> daphna@cs.huji.ac.il </email>
<author> P. Anandan </author>
<affiliation> Microsoft Research </affiliation>
<address> One Microsoft WayRedmond, WA 98052 </address>
<email> anandan@microsoft.com </email>
<author> Micahl Irani </author>
<affiliation> Dept. of Appl. Math and CSThe Weizmann Inst. of Sci. </affiliation>
<address> Rehovot, Israel </address>
<email> irani@wisdom.weizmann.ac.il </email>
<abstract> AbstractSince uncalibrated images permit only projective reconstruction, metric information requires eithercamera or scene calibration. We propose a stratified approach to projective reconstruction, in whichgradual increase in domain information for scene calibration leads to gradual increase in 3D information.Our scheme includes the following steps: (1) Register the images with respect to a reference plane; thiscan be done using limited scene information, e.g., the knowledge that two pairs of lines on the plane areparallel. We show that this calibration is sufficient for ordinal reconstruction sorting the points by theirheight over the reference plane. (2) If available, use the relative height of two additional out-of-planepoints to compute the height of the remaining points up to constant scaling. Our scheme is based on thedual epipolar geometry in the reference frame, which we develop below. We show good results with fivesequences of real images, using mostly scene calibration that can be inferred directly from the imagesthemselves. </abstract>
<keyword> Keywords: projective reconstruction, affine reconstruction, partial calibration, qualitative depth </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Iterative Optimization and Simplification ofHierarchical Clusterings </title>
<pubnum> Technical Report CS-95-01 </pubnum>
<author> Doug Fisher </author>
<affiliation> Department of Computer Science </affiliation>
<address> Box 1679, Station B </address>
<affiliation> Vanderbilt University </affiliation>
<address> Nashville, TN 37235 </address>
<email> dfisher@vuse.vanderbilt.edu </email>
<web> http://www.vuse.vanderbilt.edu/~dfisher/dfisher.html </web><phone> (615) 343-4111 </phone><abstract> Abstract: Clustering is often used for discovering structure in data. Clustering systemsdiffer in the objective function used to evaluate clustering quality and the control strategyused to search the space of clusterings. Ideally, the search strategy should consistentlyconstruct clusterings of high quality, but be computationally inexpensive as well. In general,we cannot have it both ways, but we can partition the search so that a system inexpensivelyconstructs a `tentative' clustering for initial examination, followed by iterative optimization,which continues to search in background for improved clusterings. Given this motivation, weevaluate an inexpensive strategy for creating initial clusterings, coupled with several controlstrategies for iterative optimization, each of which repeatedly modifies an initial clusteringin search of a better one. One of these methods appears novel as an iterative optimizationstrategy in clustering contexts. Once a clustering has been constructed it is judged byanalysts often according to task-specific criteria. Several authors have abstracted thesecriteria and posited a generic performance task akin to pattern completion, where the errorrate over completed patterns is used to `externally' judge clustering utility. Given thisperformance task we adapt resampling-based pruning strategies used by supervised learningsystems to the task of simplifying hierarchical clusterings, thus promising to ease post-clustering analysis. Finally, we propose a number of objective functions, based on attribute-selection measures for decision-tree induction, that might perform well on the error rate andsimplicity dimensions. </abstract>
<keyword> Keywords: clustering, iterative optimization, cluster validation, resampling, pruning, objective functions. </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> On the Analysis of Indexing Schemes </title>
<author> Joseph M. Hellerstein  </author>
<affiliation> Division of Computer ScienceUC Berkeley, </affiliation>
 <address> Berkeley, CA 94720 </address>
<email> jmh@cs.berkeley.edu </email>
<author> Elias Koutsoupias  </author>
<affiliation> Department of Computer ScienceUCLA, </affiliation>
 <address> Los Angeles, CA 90095 </address>
<email> elias@cs.ucla.edu </email>
<author> Christos H. Papadimitriou  </author>
<affiliation> Division of Computer ScienceUC Berkeley, </affiliation>
 <address> Berkeley, CA 94720 </address>
<email> christos@cs.berkeley.edu </email>
<abstract> AbstractWe consider the problem of indexing general databaseworkloads (combinations of data sets and sets of potential queries). We define a framework for measuring theefficiency of an indexing scheme for a workload based ontwo characterizations: storage redundancy (how manytimes each item in the data set is stored), and accessoverhead (how many times more blocks than necessarydoes a query retrieve). Using this framework we presentsome initial results, showing upper and lower boundsand trade-offs between them in the case of multi-dimensional range queries and set queries. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> -- IBROW3 -- An Intelligent Brokering Service forKnowledge-Component Reuse on the World-Wide Web </title>
<author> V. Richard Benjamins 3,4 , Enric Plaza 4 , Enrico Motta 2 , Dieter Fensel 1 , Rudi Studer 1 , Bob Wielinga 3 ,Guus Schreiber 3 , Zdenek Zdrahal 2 and Stefan Decker 1  </author>
<affiliation> 1 University of Karlsruhe, </affiliation>
 <address> Institute AIFB, 76128 Karlsruhe, Germany, </address>
<email> -dfe,studer-@aifb.uni-karlsruhe.de  </email>
<affiliation> 2 Knowledge Media Institute, The Open University, </affiliation>
 <address> Walton Hall, Milton Keynes, United Kingdom, </address>
<email> -E.Motta,Z.Zdrahal-@open.ac.uk  </email>
<affiliation> 3 Dept. of Social Science Informatics (SWI), University of Amsterdam, </affiliation>
 <address>  Roetersstraat 15, 1018 WB Amsterdam, The Netherlands, </address>
 <email> -richard,schreiber,wielinga-@swi.psy.uva.nl  </email>
<affiliation> 4 Artificial Intelligence Research Institute (IIIA), Spanish Council for Scientific Research (CSIC), </affiliation>
<address> Campus UAB, 08193 Bellaterra, Barcelona, Spain, </address>
 <email> enric@iiia.csic.es  </email>
<abstract> The World-Wide Web is changing the nature of software development to a distributiveplug &amp; play process. This requires a new way of managing software by so-called intelligentsoftware brokers. The aim of the European IBROW3 project is to develop an intelligentbrokering service that enables third party knowledge-component reuse through theWorld-Wide Web. Suppliers provide libraries of knowledge components adhering to somestandard, and customers can consult these libraries -- through intelligent brokers -- toconfigure a knowledge system suited to their needs by selection and adaptation. IBROW3integrates research on heterogeneous databases, interoperability and web technology withknowledge-system technology and ontologies. The aim is to develop a broker that can handleweb requests for classes of knowledge system (e.g. diagnostic systems) by accessinglibraries of reusable problem-solving methods on the Web, and selecting, adapting andconfiguring these methods in accordance with the domain at hand. The aim of this paper is to give a general overview of the project and to presents its mainideas and approach. IBROW3 has started on January 1, 1998 and thus we can only presentpreliminary results.  </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> DIMACS Technical Report 93-8 </pubnum>
<date> February 1993 </date>
<title> Hilbert Series of Group Representations andGrobner Bases for Generic Modules </title>
<author> byShmuel Onn 1 </author>
<affiliation> DIMACSRutgers University </affiliation>
<address> Piscataway, New Jersey 08855-1179 </address>
<email> E-mail: onn@dimacs.rutgers.edu </email>
<note> 1 Research was supported by the Mittag-Le*er Institute, by the Mathematical Sciences Instituteat Cornell University, and by the Center for Discrete Mathematics and Theoretical ComputerScience at Rutgers University.DIMACS is a cooperative project of Rutgers University, Princeton University, AT&amp;T BellLaboratories and Bellcore.DIMACS is an NSF Science and Technology Center, funded under contract STC-88-09648;and also receives support from the New Jersey Commission on Science and Technology. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Finding a Shortest Diagonal of a Simple Polygon in LinearTime </title>
<author> John Hershberger </author>
<affiliation> DEC/SRC </affiliation>
<address> 130 Lytton Avenue,Palo Alto, California 94301 </address>
<author> Subhash Suri </author>
<affiliation> Bellcore </affiliation>
<address> 445 South Street,Morristown, New Jersey 07960 </address>
<date> August 16, 1993 </date>
<abstract> AbstractA diagonal of a planar, simple polygon P is an open line segment that connectstwo non-adjacent vertices and lies in the relative interior of P . We present a lineartime algorithm for finding a shortest diagonal (in the L 2 norm) of a simple polygon,improving the previous best result by a factor of log n. Our result provides an interestingcontrast to a known (n log n) lower bound for finding a closest pair of vertices in asimple polygon|observe that a shortest diagonal is defined by a closest pair of verticessatisfying an additional visibility constraint. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Randomized Linear-Time Algorithm for Finding Minimum SpanningTrees </title>
<author> Philip N. Klein Robert E. Tarjan  </author>
<date> October 12, 1993 </date>
<abstract> AbstractWe present a randomized linear-time algorithm for finding a minimum spanning tree in a connectedgraph with edge weights. The algorithm is a modification of one proposed by Karger and uses randomsampling in combination with a recently discovered linear-time algorithm for verifying a minimum spanning tree. Our computational model is a unit-cost random-access machine with the restriction that theonly operations allowed on edge weights are binary comparisons. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Markov Chain Algorithms for Planar Lattice Structures </title>
<note> (Extended Abstract) </note>
<author> Michael Luby Dana Randall Alistair Sinclair  </author>
<abstract> AbstractConsider the following Markov chain, whose statesare all domino tilings of a 2n fi 2n chessboard: starting from some arbitrary tiling, pick a 2 fi 2 windowuniformly at random. If the four squares appearing inthis window are covered by two parallel dominoes, rotate the dominoes in place. Repeat many times. Thisprocess is used in practice to generate a random tiling,and is a key tool in the study of the combinatorics oftilings and the behavior of dimer systems in statistical physics. Analogous Markov chains are used torandomly generate other structures on various two-dimensional lattices. This paper presents techniqueswhich prove for the first time that, in many interesting cases, a small number of random moves suffice toobtain a uniform distribution. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> HIGH PERFORMANCE IMPLEMENTATIONOF SERVER DIRECTED I/O </title>
<author> BYMAHESH SUBRAMANIAM </author>
<degree> B.E, Birla Institute of Technology &amp; Science, 1993M.Sc, Birla Institute of Technology &amp; Science, 1993THESISSubmitted in partial fulfillment of the requirementsfor the degree of Master of Science in Computer Sciencein the Graduate College of the </degree><affiliation> University of Illinois at Urbana-Champaign, </affiliation>
 <date> 1996 </date>
<address> Urbana, Illinois </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Constraint Based Design of ATMNetworks, an Experimental Study </title>
<author> Hongzhou Ma, Inderjeet Singh, Jonathan Turner </author>
<pubnum> wucs-97-15 </pubnum>
<date> April 97 </date>
<affiliation> Department of Computer Science </affiliation>
<address> Campus Box 1045 </address>
<affiliation> Washington University </affiliation>
<address> One Brookings DriveSt. Louis, MO 63130-4899 </address>
<abstract> AbstractThis paper describes an experimental study of constraint-based network design. We used anovel network design tool, implemented in Java, to design representative networks joiningmajor U.S. cities. The cost of three topologies: Best Star, Minimum Spanning Tree (MST),and Delaunay Triangulation, are compared, with and without localized traffic constraints.The best star network gives near optimal result when the traffic is only constrained by sourceand sink capacity of switches (flat traffic constraints). With localized traffic constraints, themost cost effective network has a structure similar to the MST. The cheapest network has atree structure when there are only flat traffic constraints, but can have cycles when localizedtraffic constraints are present. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Efficient Scheduling of Branching Computations on Rings ofProcessors: An Empirical Study </title>
<author> Lixin Gao Dawn E. Gregory Arnold L. Rosenberg Paul R. Cohen </author>
<affiliation> Department of Computer ScienceUniversity of Massachusetts </affiliation>
<address> Amherst, Mass. 01003, USA </address>
<email> fgao,gregory,rsnbrg,coheng@cs.umass.edu </email>
<abstract> AbstractWe empirically analyze and compare two simple, deterministic policies for scheduling dynamically evolving tree-structured computations on parallel architectures that are rings of identicalprocessing elements (PEs). Our computations have each task either halt or spawn two independent children; they abstract, for instance, computations generated by multigrid methods. Oursimpler policy, called koso, has each PE keep one child of a spawning task and pass the otherto its clockwise neighbor in the ring; our more sophisticated policy, called koso ? , operates similarly, but allows child-passing only from a more heavily loaded PE to a more lightly loaded one.Both policies execute waiting tasks in increasing order of their depths in the evolving task-tree.Based on partial (mathematical) analyses of our policies' behaviors, we conjectured that bothyield good parallel speedup on large classes of the computations we study, but that policykoso ? outperforms policy koso in many important situations. Not having been able to verifythese conjectures analytically, we study them in this paper via a suite of carefully designed andanalyzed experiments. Our experiments largely substantiate both of our conjectures. We findthat both policies give close to optimal parallel speedup on large classes of computations, andthat koso ? outperforms koso on these computations, except on very small processor rings.We believe that our methodology of experimental design and analysis will prove useful in othersuch studies. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Using Real-Valued Genetic Algorithms to Evolve Rule Sets forClassification  </title>
<author> Arthur L. Corcoran Sandip Sen </author>
<abstract> Abstract| In this paper, we use a genetic algorithm to evolve a set of classification rules withreal-valued attributes. We show how real-valuedattribute ranges can be encoded with real-valuedgenes and present a new uniform method for representing don't cares in the rules. We view supervised classification as an optimization problem,and evolve rule sets that maximize the number ofcorrect classifications of input instances. We use avariant of the Pitt approach to genetic-based machine learning system with a novel conflict resolution mechanism between competing rules withinthe same rule set. Experimental results demonstrate the effectiveness of our proposed approachon a benchmark wine classifier system. </abstract>
<intro> I. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Interaction ofArchitecture and Operating System Design </title>
<author> Thomas E. Anderson, Henry M. Levy, Brian N. Bershad, and Edward D. Lazowska </author>
<affiliation> Department of Computer Science and EngineeringUniversity of Washington </affiliation>
<address> Seattle, WA 98195 </address>
<abstract> AbstractToday's high-performance RISC microprocessors have beenhighly tuned for integer and floating point application performance. These architectures have paid less attention tooperating system requirements. At the same time, new operating system designs often have overlooked modern architectural trends which may unavoidably change the relativecost of certain primitive operations. The result is that operating system performance is well below application codeperformance on contemporary RISCs.This paper examines recent directions in computer architecture and operating systems, and the implications ofchanges in each domain for the other. The requirements ofthree components of operating system design are discussedin detail: interprocess communication, virtual memory, andthread management. For each component, we relate operating system functional and performance needs to the mechanisms available on commercial RISC architectures such asthe MIPS R2000 and R3000, Sun SPARC, IBM RS6000,Motorola 88000, and Intel i860.Our analysis reveals a number of specific reasons whythe performance of operating system primitives on RISCshas not scaled with integer performance. In addition,we identify areas in which architectures could better (andcost-effectively) accommodate operating system needs, andareas in which operating system design could accommodate certain necessary characteristics of cost-effective high-performance microprocessors. </abstract>
<note> This work was supported in part by the National ScienceFoundation under Grants No. CCR-8703049, CCR-8619663, andCCR-8907666, by the Washington Technology Center, by the Digital Equipment Corporation Systems Research Center and External Research Program, and by IBM and AT&amp;T Fellowships.Bershad is now with the School of Computer Science, CarnegieMellon University. </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Multi-Agent Referral System for Matchmaking </title>
<author> Leonard N. Foner </author>
<affiliation> MIT Media Lab </affiliation>
<address> 20 Ames St, E15-305Cambridge, MA 02139 </address>
<phone> 617/253-9601 </phone><abstract> ABSTRACTMany important and useful applications for software agentsrequire multiple agents on a network that communicate witheach other. Such agents must find each other and perform auseful joint computation without having to know about everyother such agent on the network. This paper describes amatchmakersystem, designed to find people with similar interests and introduce them to each other. The matchmaker isdesigned to introduce everyone, unlike conventional Internetmedia which only allow those who take the time to speakpublic to be known.The paper details how the agents that make it up the match-making system can function in a decentralized fashion, yetcan group themselves into clusters which reflect their usersinterests; these clusters are then used to make introductions orallow users to send messages to others who share their interests. The algorithm uses referralsfrom one agent to anotherin the same fashion that word-of-mouth is used when peopleare looking for an expert. A prototype of the system has beenimplemented, and results of its use are presented. </abstract>
<keyword> KEYWORDS:agents, collaborative filtering, CSCW, jointcomputation, ecology of computation, user modeling, intelligent systems, information retrieval, distributed AI, Internet. </keyword>
<intro> INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Translucent Sums: A Foundation forHigher-Order Module Systems </title>
<author> Mark Lillibridge </author>
<date> May, 1997 </date>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<degree> Submitted in partial fulfillment of the requirementsfor the degree of Doctor of Philosophy.Thesis Committee:Robert Harper, ChairPeter LeeJohn ReynoldsLuca Cardelli, DEC SRC </degree><note> Copyright c fl1997 Mark LillibridgeThis research was sponsored by the Air Force Materiel Command (AFMC) and the Defense Advanced Research Projects Agency (DARPA) under contract number, F19628-95-C-0050. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstandingany copyright notation thereon.The views and conclusions contained in this document are those of the author and should not beinterpreted as representing the official policies or endorsements, either expressed or implied, of the U.S.Government. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Optimizing ML with Run-Time Code Generation </title>
<author> Peter Lee Mark Leone </author>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, Pennsylvania 15213-3891 </address>
<email> petel@cs.cmu.edu mleone@cs.cmu.edu </email>
<abstract> AbstractWe describe the design and implementation of a compilerthat automatically translates ordinary programs written ina subset of ML into code that generates native code at runtime. Run-time code generation can make use of values andinvariants that cannot be exploited at compile time, yieldingcode that is often superior to statically optimal code. Butthe cost of optimizing and generating code at run time canbe prohibitive. We demonstrate how compile-time specialization can reduce the cost of run-time code generation byan order of magnitude without greatly affecting code quality.Several benchmark programs are examined, which exhibit anaverage cost of only six cycles per instruction generated atrun time. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Tutorial on Visual Servo Control </title>
<author> Seth Hutchinson </author>
<affiliation> Department of Electrical and Computer EngineeringThe Beckman Institute for Advanced Science and TechnologyUniversity of Illinois at Urbana-Champaign </affiliation>
<address> 405 N. Mathews AvenueUrbana, IL 61801 </address>
<email> Email: seth@uiuc.edu </email>
<author> Greg Hager </author>
<affiliation> Department of Computer ScienceYale University </affiliation>
<address> New Haven, CT 06520-8285 </address>
<phone> Phone: 203 432-6432 </phone><email> Email: hager@cs.yale.edu </email>
<author> Peter Corke </author>
<affiliation> CSIRO Division of Manufacturing Technology </affiliation>
<address> P.O. Box 883,Kenmore. Australia, 4069. </address>
<email> pic@brb.dmt.csiro.au </email>
<date> May 14, 1996 </date>
<abstract> AbstractThis paper provides a tutorial introduction to visual servo control of robotic manipulators.Since the topic spans many disciplines our goal is limited to providing a basic conceptual framework. We begin by reviewing the prerequisite topics from robotics and computer vision, includinga brief review of coordinate transformations, velocity representation, and a description of thegeometric aspects of the image formation process. We then present a taxonomy of visual servocontrol systems. The two major classes of systems, position-based and image-based systems, arethen discussed. Since any visual servo system must be capable of tracking image features in asequence of images, we include an overview of feature-based and correlation-based methods fortracking. We conclude the tutorial with a number of observations on the current directions ofthe research field of visual servo control. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Implementing Parallel Shortest Paths Algorithms </title>
<author> Marios Papaefthymiou </author>
<affiliation> Department of Electrical Engineering andDepartment of Computer ScienceYale University </affiliation>
<author> Joe Rodrigue </author>
<affiliation> Department of Computer ScienceYale University </affiliation>
<abstract> AbstractWe have implemented a parallel version of the Bellman-Ford algorithm for the single-source shortest pathsproblem. Our software has been developed on the CM-5 using C with CMMD communication primitives.We have empirically compared the efficiency of our implementation with a sequential implementation ofthe Bellman-Ford-Moore algorithm developed by Cherkassky, Goldberg and Radzik. We have performedour experiments using fifty randomly generated graphs with vertex counts in the range between 2 10 and2 15 and edge counts in the range between 2 11 and 2 21 . In our experiments, the parallel implementationbecomes faster than the sequential implementation when the average degree of the input graphs exceeds2 5 or 2 6 . For the dense graphs in our test suite, we obtain speedups of up to 3.3 on 32 processors and upto 8.3 on 128 processors.In the implementation we discuss in this paper, several design decisions were taken in view of the limitedtime we had to complete a working version of our software. For example, instead of performing any kindof dynamic load balancing, we try to keep the computation load balanced by applying a straightforwarddata distribution scheme at the beginning of the computation. Moreover, in the code that runs oneach processor, we avoid any sophisticated data structures and only use linear arrays. We are currentlyexperimenting with alternative implementations that may lead to improved speedups, particularly on thedenser graphs of our test suite. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Belief Networks, Hidden Markov Models, and MarkovRandom Fields: a Unifying View  </title>
<author> Padhraic Smyth </author>
<affiliation> Information and Computer Science DepartmentUniversity of California, Irvine </affiliation>
<address> CA 92697-3425. </address>
<email> smyth@ics.uci.edu </email>
<date> March 20, 1998 </date>
<abstract> AbstractThe use of graphs to represent independence structure in multivariate probabilitymodels has been pursued in a relatively independent fashion across a wide variety ofresearch disciplines since the beginning of this century. This paper provides a briefoverview of the current status of such research with particular attention to recent developments which have served to unify such seemingly disparate topics as probabilisticexpert systems, statistical physics, image analysis, genetics, decoding of error-correctingcodes, Kalman filters, and speech recognition with Markov models. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Theory and Design of Multidimensional QMF Sub-Band Filters From1-D Filters and Polynomials Using Transforms </title>
<author> I.A. Shah A.A.C. Kalker </author>
<affiliation> Philips Research Laboratories, </affiliation>
<address> P.O. Box 80.000, 5600 JA Eindhoven, The Netherlands </address>
<email> Net: kalker@prl.philips.nl, shah@prl.philips.nl </email>
<abstract> AbstractThe paper presents the general theory of designing multidimensional Quadrature Mirror Filters (QMF),for use in sub-band coding (SBC) systems, using the McClellan transform [1]. It was recently shown thatMcClellan transform could be used to generate 2-D diamond shape QMF filters [2]. In this paper we willformalize the proofs of the diamond shape case, and generalize it to other shapes, sampling rasters anddimensions.Moreover we show that we do not really need the 1-D QMF filters: it is also possible and even moreconvenient to design QMF filter banks by performing transformations on a class of real valued polynomials.Examples are given of two dimensional diamond and fan-shape filters and three dimensional tetrad filtersdesigned using this transformation technique. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Once Upon an Object...Computationally-Augmented Toys for Storytelling </title>
<author> Jennifer W. Glos and Marina Umaschi </author>
<affiliation> MIT Media Lab </affiliation>
<address> 20 Ames Street, E15-320R/NCambridge, MA 02139 USA </address>
<phone> +1 617 253 6096 </phone><email> - jenglos, marinau-@media.mit.edu </email>
<abstract> AbstractWe are developing design principles applying tangible interfaces to storytelling. This paper describes an underlyingphilosophy and three resultant designs for computer-mediated toys, exploring how the merging of physical objectswith computer technology can enhance childrens storytelling. Each prototype aims to develop a specific set of bothoral and written storytelling skills, as well as collaboration, sharing, and the notion of revision. By creatingnarratives, children learn about culture and identity, and develop a sense of self. In addition, narrative can be used asa gateway to draw girls into technology. The use of multi-sensory interfaces allows for richer interaction. </abstract>
<keyword> Keywordsstorytelling, children, computer-mediated toys, identity, education, gender, tangible interfaces. </keyword>
<intro> Motivation </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> 3D Morphing </title>
<author> by Matt Blum, Krzysztof Gajos, Manolis Kamvysselis, Hooman Vassef  </author>
<abstract> AbstractThis paper presents our work towards achieving a model based approach to three dimensionalmorphing. It describes the initial algorithms and ideas that we envisioned, the final algorithm wedeveloped and implemented, the environment we worked in, our visualization techniques, and futurework planned on the subject.  </abstract>
<intro> Introduction: Different types of morphing </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> MPI-FM: High Performance MPI on WorkstationClusters </title>
<author> Mario Lauria  </author>
<affiliation> Dipartimento di Informatica e SistemisticaUniversita di Napoli "Federico II" </affiliation>
<address> via Claudio 2180125 Napoli, Italy </address>
<email> lauria@nadis.dis.unina.it. </email>
<author> Andrew Chien </author>
<affiliation> Department of Computer ScienceUniversity of Illinois at Urbana-Champaign </affiliation>
<address> 1304 W. Springfield Ave.Urbana, IL 61801, USA </address>
<email> achien@cs.uiuc.edu </email>
<abstract> AbstractDespite the emergence of high speed LANs, the communication performance available to applications on workstation clusters still falls short of that available on MPPs.A new generation of efficient messaging layers is needed to take advantage of the hardware performance and to deliver it to the application level. Communication softwareis the key element in bridging the communication performance gap separating MPPsand workstation clusters.MPI-FM is a high performance implementation of MPI for networks of workstations connected with a Myrinet network, built on top of the Fast Messages (FM) library.Based on the FM version 1.1 released in Fall 1995, MPI-FM achieves a minimum one-way latency of 19 s and a peak bandwidth of 17.3 MByte/s with common MPI sendand receive function calls. A direct comparison using published performance figuresshows that MPI-FM running on SPARCstation 20 workstations connected with a relatively inexpensive Myrinet network outperforms the MPI implementations availableon the IBM SP2 and the Cray T3D, both in latency and in bandwidth, for messagesup to 2 KByte in size. </abstract>
<note> Visiting at time of writing </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Register Windows and User-Space Threads on the SPARC </title>
<author> David Keppel </author>
<pubnum> Technical Report #91-08-01 </pubnum>
<affiliation> Department of Computer Science and EngineeringUniversity of Washington </affiliation>
<address> Seattle, Washington 98195 </address>
<date> 1 August 1991 </date>
<abstract> AbstractMultiple lightweight processes or threads have multiple stacks, and a thread context switch movesexecution from one stack to another. On the SPARC 1 architecture, parts of a thread's stack can becached in register windows while the thread is running. The cached data must be flushed to memorywhen the thread is suspended. Doing the flushing both efficiently and correctly can be tricky. Thisdocument discusses the implementation of a non-preemptive user-space threads package under SunOS 2 . </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> 104 </pubnum>
<title> New-Value Logging in the EchoReplicated File System </title>
<author> Andy Hisgen, Andrew Birrell, Charles Jerian,Timothy Mann, Garret Swart </author>
<date> June 23, 1993 </date>
<affiliation> Systems Research Center </affiliation>
<address> 130 Lytton AvenuePalo Alto, California 94301 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<date> February 21, 1994 </date>
<pubnum> SRCResearchReport 121 </pubnum>
<title> Extensible Syntax with Lexical Scoping </title>
<author> Luca Cardelli, Florian Matthes, and Martn Abadi </author>
<affiliation> Systems Research Center </affiliation>
<address> 130 Lytton AvenuePalo Alto, California 94301 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Using Global Consistency to Recognise Euclidean Objects with anUncalibrated Camera </title>
<author> D.A. Forsyth J.L. Mundy A. Zisserman C.A. Rothwell </author>
<affiliation> Computer Science General Electric Robotics Research Group Robotics Research GroupUniversity of Iowa Center for Research and Development Oxford University Oxford University </affiliation>
<address> Iowa City, IA 52242 Schenectady, NY 12345 Oxford, UK Oxford, UK </address>
<abstract> AbstractA recognition strategy consisting of a mixture of indexing on invariants and search, allows objects to be recog-nised up to a Euclidean ambiguity with an uncalibratedcamera. The approach works by using projective invariants to determine all the possible projectively equivalentmodels for a particular imaged object; then a system ofglobal consistency constraints is used to determine which ofthese projectively equivalent, but Euclidean distinct, models corresponds to the objects viewed. These constraintsfollow from properties of the imaging geometry. In particular, a recognition hypothesis is equivalent to an assertion about, among other things, viewing conditions and geometric relationships between objects, and these assertionsmust be consistent for hypotheses to be correct. The approach is demonstrated to work on images of real scenesconsisting of polygonal objects and polyhedra. </abstract>
 <keyword> Keywords:Recognition, Computer Vision, Invariant Theory, Indexing, Model-based Vision </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> DRAFT 1 </note>
 <date> January 23, 1996 </date>
<title> The Impact of Trends in Technology onFile System Design </title>
<author> Michael D. Dahlin </author>
<affiliation> University of California, Berkeley </affiliation>
<email> dahlin@cs.berkeley.edu </email>
<abstract> AbstractThis paper describes several key trends in technology that will inuence the design of file systems for the next decade. It first outlines the basic trends to hardware performance that underliefile system design. These trends affect both user demands on file systems and trade-offs in theirdesign. It then considers how technologies will drive more demanding file system workloads thatwill require scalable file systems. Next, it outlines how opportunities raised by these low-leveltechnology trends impact specific aspects of the xFS file systems serverless design [Dahlinet al., 1994b, Anderson et al., 1996]. Finally, to put xFSs serverless approach in context, it discusses other technology trends that affect file systems but that are not explicitly addressed in theserverless design. </abstract>
<intro> 1. Trends in Technology </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Importing Pre-packaged Software into Lisp: Experience withArbitrary-Precision Floating-Point Numbers </title>
<author> Richard J. Fateman </author>
<affiliation> University of California at Berkeley </affiliation>
<abstract> AbstractWe advocate the use of Common Lisp as a powerful glue forbuilding scientific computing environments. Naturally onethen has to address mixing pre-existing (non Lisp) code intothis system. We provide a specific example as an elaborateFORTRAN system written by David Bailey for arbitrary-precision floating-point numeric calculation. We discuss theadvantages and disadvantages of wholesale importing intoLisp. A major advantage is being able to use state-of-theart packaged software sooner, while overcoming the disadvantages caused by FORTRAN's traditional batch orientation and weak storage model. In this paper we emphasize inparticular how effective use of imported systems may requireone to address the contrast between the functional (Lisp-like) versus state-transition-based (Fortran-like) approachesto dealing with compound objects. While our example ishigh-precision floats, other highly useful packages including those for simulation, PDE solutions, signal processing,statistical computation, etc. may also benefit by similarconsideration. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Modeling and Optimization of a MultiresolutionImage Retrieval System  </title>
<author> Antonio Ortega , </author>
<affiliation> Dept. of Electrical Eng.-SystemsUniversity of Southern California </affiliation>
<address> Los Angeles, California </address>
<author> Zhensheng Zhang, </author>
<affiliation> Dept. of Electrical Engineering and Center for Telecom. ResearchColumbia University, </affiliation>
 <address> New York </address>
<author> Martin Vetterli </author>
<affiliation> Dept. of Electrical Engineering and Computer ScienceUniversity of California, </affiliation>
<address> Berkeley, California </address>
<date> July 15, 1994 </date>
<note> IEEE/ACM Transactions on Networking, Submitted, July 1994 </note>
<abstract> AbstractIn this paper, we study the tradeoffs involved in choosing the bit allocation in amultiresolution remote image retrieval system. Such a system uses a multiresolutionimage coding scheme so that a user accessing the database will first see a coarseversion of the images and will be able to accept or discard a given image faster,without needing to receive all the image data. We formalize the problem of choosingthe bit allocation (e.g., in the two resolution case, how many bits should be givento the coarse image and the additional information, respectively?) so that theoverall delay in the query is minimized. We provide analytical methods to find theoptimal solution under different configurations and show how a good choice of thebit allocation results in a significant reduction of the overall delay in the query (byup to a factor of two in some cases). </abstract>
<note> This work was presented in part at the IS&amp;T/SPIE Symp. on Electronic Imaging Science &amp; Technology '94, San Jose, CA, Feb. 94 and at Infocom '94, Toronto, Canada, Jun. 94.Work supported in part by the Fulbright Commission and the Ministry of Education of Spain. Thiswork was done while at the Dept. of Electrical Eng. and Center for Telecom. Research, ColumbiaUniversity. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<abstract> AbstractTCP is a reliable transport protocol tuned to perform wellin traditional networks made up of wired links with stationary hosts. Networks with wireless links and mobilehosts violate many of the assumptions made by TCP, causing degraded performance. In this paper, we describe asimple protocol that improves TCP performance by modifying network-layer software only at a basestation withoutviolating end-to-end TCP semantics. The main idea is tocache packets at the basestation and perform localretransmissions. Simulations of this protocol show that itis significantly more robust in the presence of multiplepacket losses in a single transmission window as compared to TCP. This enables our protocol to tolerate at least10 times as high an error rate without any performancedegradation. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Reducing Branch Costs via Branch Alignment </title>
<author> Brad Calder and Dirk Grunwald  </author>
<affiliation> Department of Computer Science </affiliation>
<address> Campus Box 430 </address>
<affiliation> University of Colorado </affiliation>
<address> Boulder, CO 80309-0430 USA </address>
<email> fcalder,grunwaldg@cs.colorado.edu </email>
<abstract> AbstractSeveral researchers have proposed algorithms for basic block reordering. We call these branch alignment algorithms. The primaryemphasis of these algorithms has been on improving instructioncache locality, and the few studies concerned with branch prediction reported small or minimal improvements. As wide-issue architectures become increasingly popular the importance of reducingbranch costs will increase, and branch alignment is one mechanismwhich can effectively reduce these costs.In this paper, we propose an improved branch alignment algorithm that takes into consideration the architectural cost model andthe branch prediction architecture when performing the basic blockreordering. We show that branch alignment algorithms can improvea broad range of static and dynamic branch prediction architectures.We also show that a programs performance can be improved by approximately 5% even when using recently proposed, highly accuratebranch prediction architectures. The programs are compiled by anyexisting compiler and then transformed via binary transformations.When implementing these algorithms on a Alpha AXP 21604 up toa 16% reduction in total execution time is achieved. </abstract>
<keyword> Keywords: Branch Prediction, Profile-based Optimization,Branch Target Buffers, Trace Scheduling. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Empirical Study of a Dataflow Language on the CM-5 </title>
<author> David E. CullerSeth Copen GoldsteinKlaus Erik SchauserThorsten von Eicken </author>
<affiliation> Computer Science DivisionDepartment of Electrical Engineering and Computer SciencesCollege of EngineeringUniversity of California, Berkeley </affiliation>
<abstract> Abstract: This paper presents empirical data on the behavior of large dataflow programs ona distributed memory multiprocessor. The programs, written in the dataflow language Id90, arecompiled via a Threaded Abstract Machine (TAM) for the CM-5. TAM refines dataflow executionmodels by addressing critical constraints that modern parallel architectures place on the compilationof general-purpose parallel programming languages. It exposes synchronization, scheduling, andnetwork access so that the compiler can optimize against the cost of these operations.The data presented in this paper evaluates the TAM approach in compiling dataflow languageson stock hardware. We present data on the instruction mix, speedup, scheduling behavior, andlocality of large ID90 programs. It is shown that the TAM scheduling hierarchy is able to toleratelong communication latencies, especially when some degree of I-structure locality is present. We investigate how frame allocation strategies, k-bounded loops, and I-structure caching and distributiontogether affect the overall efficiency. Finally we document some scheduling anomalies. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<date> May 17, 1993 </date>
<title> An Efficient Network Interface for the RAID-II File Server </title>
<author> Srinivasan Seshan </author>
<note> A masters report </note>
<abstract> 1.0 AbstractDistributed systems in use today depend heavily on network communications between clients and servers. In this report, we describe thedesign and implementation of the network architecture (hardware, software and protocols) of the RAID-II system. RAID-II is a high speed network file server connected to an UltraNetwork. In order to support highbandwidth network transfers with the RAID-II server, we partitioned thenetworking software among the various processors in the system. Measurements of the system show that the RAID-II server can sustain 21MB/s of data bandwidth to the Ultranet. </abstract>
<intro> 2.0 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Comparing Data Forwarding and Prefetchingfor Communication-Induced Misses in Shared-Memory MPs 1 </title>
<author> David Koufaty 2 and Josep Torrellas </author>
<affiliation> Department of Computer ScienceUniversity of Illinois at Urbana-Champaign, </affiliation>
 <address> IL 61801 </address>
<email> dkoufaty@ichips.intel.com torrella@cs.uiuc.edu </email>
<web> http://iacoma.cs.uiuc.edu </web><abstract> AbstractAs the difference in speed between processor and memory system continues to increase, it is becoming crucial to developand refine techniques that enhance the effectiveness of cachehierarchies. Two such techniques are data prefetching anddata forwarding. With prefetching, a processor hides the latency of cache misses by requesting the data before it actuallyneeds it. With forwarding, a producer processor hides thelatency of communication-induced cache misses in the consumer processors by sending the data to the caches of thelatter. These two techniques are complementary approachesto hiding the latency of communication-induced misses.This paper compares the effectiveness of data forwardingand data prefetching to hide communication-induced misses.Although both techniques require comparable hardware support, forwarding usually has a lower instruction overhead. Weevaluate prefetching and forwarding algorithms in a paralleliz-ing compiler using execution-driven simulations of a shared-memory multiprocessor. Both data forwarding and prefetch-ing reduce the execution time of applications significantly (30-40% on average). Forwarding performs better on average,while prefetching is more robust to changes in cache and memory parameters. Finally, we propose two ways of integratingthe two techniques. The integration of the two techniques reduces the execution time even more (43-48% on average) andis very robust. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Optimizing Primary Data Caches for ParallelScientific Applications: The Pool Buffer Approach 1 </title>
<author> Liuxi Yang and Josep Torrellas </author>
<affiliation> Center for Supercomputing Research and DevelopmentUniversity of Illinois at Urbana-Champaign, </affiliation>
 <address> IL 61801 </address>
<email> Email: lyang,torrella@csrd.uiuc.edu </email>
<abstract> AbstractOptimizing on-chip primary data caches for parallel scientific applications is challenging because different applicationsexhibit different behavior. Indeed, while some applicationsexhibit good spatial locality, others have accesses with longstrides that prevent the effective use of cache lines. Finally,other applications cannot exploit long lines because they exhibit false sharing. To help processors execute these threetypes of applications efficiently, we introduce the Pool Buffer,a small direct-mapped cache accessed in parallel with the primary cache. The function of the pool buffer is to fetch longsectors of relatively short cache lines from memory on a miss,while only letting into the cache the lines that the processoractually references. The pool buffer can also perform sequential prefetching of sectors.An evaluation of the pool buffer based on simulations offive 32-processor Perfect Club codes yields encouraging results. Adding a pool buffer of one-quarter the size of thecache causes a small increase in area while usually achievinglarge reductions in execution time. For example, for a rangeof caches with 32-byte lines, the execution time decreases byan average of about 20%. We also show that small 1-Kbytebuffers are often large enough to get most of the potentialbenefits. Finally, caches with pool buffers are more effectivethan caches with long lines and no pool buffer. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Analysis of Message Sequence Charts </title>
<author> Peter B. Ladkin Stefan Leue </author>
<affiliation> University of BerneInstitute for Informatics and Applied Mathematics </affiliation>
<address> Langgassstrasse 51CH-3012 Bern, Switzerland </address>
<email> ladkin@iam.unibe.ch, leue@iam.unibe.ch </email>
<pubnum> IAM 92-013 </pubnum>
<date> June 1992 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Relating Test Purposes to Formal Specifications:Towards a Theoretical Foundation of Practical Testing </title>
<author>  Jens Grabowski, Dieter Hogrefe Robert Nahm, Andreas Spichiger </author>
<pubnum> IAM-93-014 </pubnum>
<date> June 1993 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> SDL and MSC Based Test Case Generation -An Overall View of the SAMSTAG Method </title>
<author> Jens Grabowski </author>
<pubnum> IAM-94-005 </pubnum>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Automated Decomposition of Model-based Learning Problems </title>
<author> Brian C. Williams and Bill Millar </author>
<affiliation> Recom Technologies, Caelum ResearchNASA Ames Research Center, </affiliation>
 <address> MS 269-2Moffett Field, CA 94305 USA </address>
<email> E-mail: williams, millar@ptolemy.arc.nasa.gov </email>
<abstract> AbstractA new generation of sensor rich, massively distributedautonomous systems is being developed that hasthe potential for unprecedented performance, suchas smart buildings, reconfigurable factories, adaptivetraffic systems and remote earth ecosystem monitoring. To achieve high performance these massive systems will need to accurately model themselves andtheir environment from sensor information. Accomplishing this on a grand scale requires automating theart of large-scale modeling. This paper presents aformalization of decompositional, model-based learning(DML), a method developed by observing a modeler'sexpertise at decomposing large scale model estimationtasks. The method exploits a striking analogy betweenlearning and consistency-based diagnosis. Moriarty,an implementation of DML, has been applied to thermal modeling of a smart building, demonstrating asignificant improvement in learning rate. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Generation of task-specific segmentationprocedures as a model selection task </title>
<author> Ralf Herbrich and Tobias Scheffer </author>
<affiliation> Technische Universitat Berlin,Artificial Intelligence Research Group, </affiliation>
 <address> Sekr. FR 5-8,Franklinstr. 28/29. D-10587 Berlin, Germany </address>
<email> email: ralfh|scheffer@cs.tu-berlin.de </email>
<date> December 1, 1997 </date>
<abstract> AbstractIn image segmentation problems, there is usually a vast amount of filteroperations available, a subset of which has to be selected and instantiatedin order to obtain a satisfactory segmentation procedure for a particular domain. In supervised segmentation, a mapping from features, such as filteroutputs for individual pixels, to classes is induced automatically. However,since the sample size required for supervised learning grows exponentiallyin the number of features it is not feasible to learn a segmentation procedurefrom a large amount of possible filters. But we argue that automatic modelselection methods are able to select a region model in terms of some filters.We propose a wrapper algorithm that performs this task. We present resultson artificial textured images (Brodatz) and report on our experiences withx-ray images. </abstract>
<keyword> Keywords: model based image segmentation, automatic model selection,learning pixel classifier, texture segmentation </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Neural Net for Determining StructuralSimilarity of Recursive Programs </title>
<author> Kristina Schadler, Ute Schmid, Hendrik Lubben, BerndMachenschalk </author>
<affiliation> Research Group "Methods of Artificial Intelligence"Institute for Applied Computer Science, Technische UniversitatBerlin </affiliation>
<address> email: schaedle,schmid,compuman,herold@cs.tu-berlin.de </address>
<abstract> Abstract. In this work it will be shown, how the comparison of recursive program schemata (RPS) can be reduced to an only slightly modifiedtype of the search for maximal isomorphic subgraphs by interpreting theRPS as directed, cyclic, labelled graphs. The quality of the mapping oftwo RPS can be used as a quantitative measure for similarity of RPSamong each other. The simultaneously calculated graph morphism canserve as a basis for the detection of analogies between the RPS. A specialneural net, developed for the solution of general graph-matching problems, realizes the search for a sensible and as comprising as possiblemapping between two RPS. It is shown, which special properties of RPShave to be accounted for in the modeling and how these can be incorporated into the algorithms when using a special neural approach for thesolution. </abstract>
<intro> 1. Structural similarities in case-based reason </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> ICOPS 97ICOPS 97 </pubnum>
<title> Nonlinear Poisson Solve for Boltzmann Electrons </title>
<author> K. L. Cartwright , J. P. Verboncoeur , and C. K.Birdsall  </author>
<affiliation> Electronics Research LaboratoryUniversity of California, </affiliation>
 <address> Berkeley, CA 94720 </address>
<date> October 29, 1997 </date>
<abstract> AbstractKinetic simulation of plasmas in which equilibrium occurs over ion timescales posesa computational challenge due to the disparate timescales of the electron plasma frequency (~ 10 9 ), the ion plasma frequency (~ 10 7 ), ion transit frequency (~ 10 6 ), andthe ionization frequency (~ 10 7 ). Hybrid electrostatic PIC algorithms are presentedin which the electrons reach thermodynamic equilibrium with the ions each time step.There are two different approximations for the electrons. First, the nonlinear Boltzmann relationship for the electrons can be applied to the bulk of a plasma. Second,there is a truncated Maxwellian which is used in sheaths; this approximation truncatesthe electron distribution at the wall potential. The error associated with neglectingthis second approximation in the sheath is small. The collision cross section, (E), canbe a tabulated or fitted function; the method is implemented with He cross sections.These approximations neglect effects faster than ion time-scales, decreasing the computer time used by over an order of magnitude; however, they increase the complexityof the boundary conditions and the simulation is no longer self-consistent. Theoreticalramifications of these approximations are examined, and results are compared with full </abstract>
<note> Supported by ONR-AASERT N100014-94-1-1033Supported by the Air Force Office of Scientific Research-MURI under grant F49620-95-1-0253Supported by the Air Force Office of Scientific Research-under grant FDF49620-96-1-0154 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Refraction and Reflection of Ion Acoustic Solitons by Space Charge Sheath </title>
<author> K. L. Cartwright and C. K. Birdsall </author>
<affiliation> Electronics Research LaboratoryUniversity of California, </affiliation>
 <address> Berkeley, CA 94720-1774 </address>
<note> Acknowledgments: This research is supported by ONR grant number N00014-90-J-1198 and ONR-AASERT 23057. </note>
<abstract> AbstractExperiments have shown[1],[2] that ion acoustic solitons tunnel through the space charge sheathin front of a grid without time delay. They are absorbed resonantly when the spatial width of thewave is close to the characteristic gradient scale length of the sheath. The reflection and transmissioncoefficients found in these experiments have compared well with theory in the long wavelength limit[3].However, to achieve this comparison, two parameters were added that were not in the original theory.These parameters allow for the absorption of wave energy by the space charge sheath. The goal of ournumerical simulations, designed to reproduce the experimental results, is to uncover the mechanism ofthis energy loss and large speed of propagation through the sheath. </abstract>
<intro> 1 Photo Ionization-Steady State </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Survey Paper </note>
<title> Update-in-place Analysis for Sets </title>
<author> Chung Yung </author>
<affiliation> Computer Science DepartmentCourant Institute of Mathematical SciencesNew York University </affiliation>
<email> yung@cs.nyu.edu </email>
<date> December 15, 1997 </date>
<abstract> AbstractThis survey paper describes the current approaches on the update-in-place analysisfor sets. Pure functional languages do not allow mutations, destructive updates, or selective updates so that straightforward implementations of functional language compilersmay induce large amounts of copying to preserve program semantics. The unnecessarycopying of data can increase both the execution time and the memory requirements ofan application. Introducing sets to functional languages as a primitive data constructor posts a new problem of update-in-place analysis in functional languages. Moreover, most of the compiler optimization techniques depend on the side-effects and theupdate-in-place analysis serves as the premise of applying such optimization techniques.Among other compiler optimization techniques, finite differencing captures common yetdistinctive program constructions of costly repeated calculations and transforms theminto more efficient incremental program constructions. This dissertation is an attemptto explore the update-in-place analysis for sets in functional languages in order to apply finite differencing to compiling pure functional languages. In this survey paper,we will describe the approaches of update-in-place analysis and the finite differencingtechniques. </abstract>
<intro> 1 Motivation and Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Economic Allocation of Computation Timewith Computation Markets </title>
<author> Nathaniel Rockwood Bogan </author>
<date> May, 1994 </date>
<note> c Copyright 1994 by Nathaniel R. BoganThis report is a reset version of a masters thesis submitted to the Department of ElectricalEngineering and Computer Science on May 15, 1994 in partial fulfillment of the requirementsfor the degree of Master of Engineering. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Improving the Performance of Radial BasisFunction Networks by Learning Center Locations </title>
<author> Dietrich Wettschereck and Thomas Dietterich </author>
<affiliation> Department of Computer ScienceOregon State University </affiliation>
<address> Corvallis, OR 97331-3202 </address>
<note> Advances in Neural Information Processing Systems 4Edited by J.E.Moody, S.J.Hanson, and R.P.Lippmann,Morgan Kaufmann Publishers, San Mateo, CA, 1992 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> EUROPEAN ORGANISATION FOR NUCLEAR RESEARCHCERN-PPE/96-xxx </note>
<date> 25 January 1996 </date>
<title> Search for Chargino and NeutralinoProduction Using the OPAL Detectorats = 130 136 GeV at LEPThe OPAL Collaboration </title>
<abstract> AbstractA search for charginos and neutralinos, predicted by supersymmetric theories, has beenperformed using a data sample of 2.6 pb 1 at a centre-of-mass energy of p s =130 GeV and2.6 pb 1 at 136 GeV collected with the OPAL detector at LEP during November 1995. Nocandidate events were observed. The 95% C.L. lower limit on the lightest chargino massin the Minimal Supersymmetric Standard Model is 65.4 GeV if the universal scalar massm 0 is greater than 1 TeV, and 58.7 GeV for the smallest m 0 compatible with slepton andsneutrino mass limits obtained at centre-of-mass energies near the Z peak. These limitswere obtained under the conditions that the lightest chargino is heavier than the lightestneutralino by more than 10 GeV and tan fi is larger than 1.5. The results of a modelindependent search for charginos and neutralinos are also given. </abstract>
<note> Submitted to Physics Letters </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> System Administration: Monitoring, Diagnosing, and Repairing </title>
<author> Eric Anderson </author>
<abstract> We first describe the general goals of system administration explaining therelationship to monitoring, diagnosing, and repairing (MDR). Then, we describe thefunctional and environmental concerns for a MDR system, and use these concerns toexplain how previous approaches have failed to fully address the problem. Next, wedescribe the major pieces of our approach, and identify the research questionsassociated with each piece. Finally we present a method for testing the system whenit is created. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Path integral approach to no-Coriolisapproximation in heavy-ion collisions </title>
<author> K. Hagino, 1 N. Takigawa, 1 , A.B. Balantekin 2 , and J.R. Bennett 3 </author>
<affiliation> 1 Department of Physics, Tohoku University, </affiliation>
 <address> 980-77 Sendai, Japan </address>
<affiliation> 2 Physics Department, University of Wisconsin, </affiliation>
<address> Madison, Wisconsin 53706, USA </address>
<affiliation> 3 Department of Physics and Astronomy,University of North Carolina at Chapel Hill, </affiliation>
 <address> Chapel Hill, NC 27599-3255 </address>
<date> June 26, 1995 </date>
<abstract> AbstractWe use the two time influence functional method of the path integral approach inorder to reduce the dimension of the coupled-channels equations for heavy-ion reactionsbased on the no-Coriolis approximation. Our method is superior to other methods in thatit easily enables us to study the cases where the initial spin of the colliding particle is notzero. It can also be easily applied to the cases where there is a spin-orbit force, and wherethe internal degrees of freedom are not necessarily collective coordinates. It also clarifiesthe underlying assumption of the approximation. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> ACM SIGPLAN Workshop on Languages, Compilers and Tools for Real-Time Systems, La Jolla, California, June 1995. </note>
<title> RTsynchronizer: Language Support for Real-Time Specifications in Distributed Systems  </title>
<author> Shangping Ren and Gul A. Agha </author>
<affiliation> Department of Computer Science </affiliation>
<address> 1304 W. Springfield Avenue </address>
<affiliation> University of Illinois at Urbana-Champaign </affiliation>
<address> Urbana, IL 61801, USA </address>
<email> Email: f ren j agha g@cs.uiuc.edu </email>
<abstract> AbstractWe argue that the specification of an object's functional behavior and the timing constraints imposedon it may be separated. Specifically, we describeRTsynchronizer, a high-level programming languageconstruct for specifying real-time constraints betweenobjects in a distributed concurrent system. During program execution, RTsynchronizers affect thescheduling of distributed objects to enforce real-timerelations between events. Objects in our system aredefined in terms of the actor model extended withtiming assumptions. Separation of the functionalbehaviors of actors and the timing constraints onpatterns of actor invocation provides at least threeimportant advantages. First, it simplifies code development by separating design concerns. Second,multiple timing constraints can be independentlyspecified and composed. And finally, a specificationof timing constraints can be reused even if therepresentation of the functional behavior of actors haschanged, and conversely.A number of examples are given to illustrate theuse of RTsynchronizers. These examples illustratehow real-time constraints for periodic events, simultaneous events, exception handling, and producer-consumer may be specified. </abstract>
<note> The research described has been made possible by support from the Office of Naval Research (ONR contract numbers N00014-90-J-1899 and N00014-93-1-0273), by an Incentives for Excellence Award from the Digital Equipment Corporation Faculty Program, and by joint support from the DefenseAdvanced Research Projects Agency and the National ScienceFoundation (NSF CCR 90-07195). The authors would like tothank Mark Astley, Brian Nielsen, Masahiko Saitoh and DanielSturman for helpful discussions concerning the manuscript. </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Visualization Model for Concurrent Systems </title>
<author> Mark Astley and Gul A. Agha  </author>
<affiliation> Open Systems LaboratoryDepartment of Computer Science </affiliation>
<address> 1304 W. Springfield Avenue </address>
<affiliation> University of Illinois at Urbana-Champaign </affiliation>
<address> Urbana, IL 61801, USA </address>
<phone> Phone: (217) 244-3087Fax: (217) 333-3501 </phone><email> Email: fastley j aghag@cs.uiuc.edu </email>
<keyword> Keywords: Actors, Distributed Systems, Program Visualization </keyword>
<abstract> AbstractConcurrent systems maintain a distributed state and thus require coordination and synchronization betweencomponents to ensure consistency. To provide a coherent design approach to concurrent systems, recent workhas employed an object-based methodology which emphasizes interactions through well-defined interfaces. TheActor model has provided formal reasoning about distributed object systems. Nonetheless, due to the complexinteractions among components and the high volume of observable information produced, understanding andreasoning about concurrent algorithms in terms of simple interactions is a difficult task. Coordination patterns,which abstract over simple interactions, are not biased by low-level event orderings and are the appropriatemechanism for reasoning about concurrent algorithms. We outline a methodology for visualizing coordinationpatterns in concurrent algorithms which emphasizes observable interactions and causal connections betweenobjects. We introduce visualizers as a linguistic mechanism for mapping coordination patterns to visualization.Visualizers are specified separately from algorithm code and thus respect code integrity. Moreover, visualizersmay be implemented strictly in terms of object interfaces and thus preserve object encapsulation. </abstract>
<note> Author for contact. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 13, NO. 7, SEPTEMBER 1995 1 </note>
<title> Billing Users and Pricing for TCP </title>
<author> Richard J. Edell, Nick McKeown and Pravin P. Varaiya </author>
<abstract> Abstract| This paper presents a system for billing usersfor their TCP traffic. This is achieved by postponing theestablishment of connections while the user is contacted,verifying in a secure way that they are prepared to pay. Bypresenting the user with cost and price information, the system can be used for cost recovery and to encourage efficientuse of network resources. The system requires no changes toexisting protocols or applications and can be used to recovercosts between cooperating sites. Statistics collected from afour day trace of traffic between the University of Califor-nia, Berkeley and the rest of the Internet demonstrate thatsuch a billing system is practical and introduces acceptablelatency. An implementation based on the BayBridge prototype router is described. Our study also indicates thatpricing schemes may be used to control network congestioneither by rescheduling time-insensitive traffic to a less expensive time of the day, or by smoothing packet transfers toreduce traffic peaks. </abstract>
<keyword> Keywords| Internet economics, network tracing, usage-accounting </keyword>
<intro> I. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Appears in Proceedings of the 4thInternational Conference on Knowledge Discovery and Data Mining,AAAI Press, 1998, 359-363. </note>
<title> Learning to Predict Rare Events in Event Sequences </title>
<author> Gary M. Weissand Haym Hirsh </author>
<affiliation> Department of Computer ScienceRutgers University </affiliation>
<address> New Brunswick, NJ 08903 </address>
<email> gmweiss@att.com, hirsh@cs.rutgers.edu </email>
<abstract> Abstract Learning to predict rare events from sequences of eventswith categorical features is an important, real-world,problem that existing statistical and machine learningmethods are not well suited to solve. This paper describestimeweaver, a genetic algorithm based machine learningsystem that predicts rare events by identifying predictivetemporal and sequential patterns. Timeweaver is applied tothe task of predicting telecommunication equipment failuresfrom 110,000 alarm messages and is shown to outperformexisting learning methods. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Comparative Study of Three Paradigms for ObjectRecognition Bayesian Statistics, Neural Networks andExpert Systems.  </title>
<author> J. K. Aggarwal, Joydeep Ghosh, Dinesh Nair and Ismail Taha </author>
<affiliation> Computer and Vision Research CenterThe University of Texas at Austin, </affiliation>
 <address> Austin, TX, USA </address>
<email> email: aggarwaljk@mail.utexas.edu </email>
<abstract> AbstractObject recognition, which involves the classification of objects into one of many a priori known object types, and determining object characteristics such as pose, is a difficultproblem. A wide range of approaches have been proposed and applied to this problem withlimited success. This paper presents a brief comparative study of methods from three different paradigms for object recognition: Bayesian, Neural Network and Expert Systems. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Evaluation and Ordering of Rules Extracted from FeedforwardNetworks  </title>
<author> Ismail Taha and Joydeep Ghosh </author>
<affiliation> Laboratory of Artificial Neural SystemsUniversity of Texas </affiliation>
<address> Austin, TX. 78712-1084 </address>
<email> fismail,ghoshg@pine.ece.utexas.edu </email>
<abstract> AbstractRules extracted from trained feedforward networkscan be used for explanation, validation, and cross-referencing of network output decisions. This paperintroduces a rule evaluation and ordering mechanismthat orders rules extracted from feedforward networksbased on three performance measures. Detailed experiments using three rule extraction techniques as appliedto the Wisconsin breast cancer database, illustrate thepower of the proposed methods. Moreover, a methodof integrating the output decisions of both the extractedrule-based system and the corresponding trained network is proposed. The integrated system provides further improvements. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> DART/HYESS Users Guide </title>
<author> Jerome H. Friedman </author>
<affiliation> Department of Statistics andStanford Linear Accelerator CenterStanford University </affiliation>
<email> jhf@stat.stanford.edu </email>
<date> December 20, 1996 </date>
<abstract> AbstractThis note provides information for using the Fortran program [Friedman (1996b)] that implements the recursive covering approach to local learning described in Friedman (1996a). </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Network of Workstations Active Messages Target forPtolemy C Code Generation </title>
<author> by Patrick Warner </author>
<pubnum> Memorandum No. UCB/ERL M97/8 </pubnum>
<date> January 24, 1997 </date>
<note> Submitted to the Department of Electrical Engineering and Computer Science, University of Cal-ifornia at Berkeley, in partial satisfaction of the requirements for the degree of Master of Science,Plan II. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> DEPARTMENT OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCEUNIVERSITY OF CALIFORNIA </affiliation>
<address> BERKELEY, CALIFORNIA 94720 </address>
 <date> August 17, 1997 </date>
<title> A PRELIMINARY STUDY OFHIERARCHICAL FINITE STATE MACHINESWITH MULTIPLE CONCURRENCY MODELS </title>
<author> byAlain Girault, Bilung Lee, and Edward A. Lee </author>
<pubnum> Memorandum No. UCB/ERL M97/57 </pubnum>
<affiliation> ELECTRONICS RESEARCH LABORATORYCollege of Engineering </affiliation>
<address> University of California, Berkeley94720 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Digital Communication Over RayleighFading Channels </title>
<author> T. M. Parks </author>
<date> 15 December 1992 </date>
<abstract> AbstractThe properties of Rayleigh fading channels are derived and theireffects on various QAM signal constellations are explored. A simplifiedchannel model for an urban radio environment is justified in orderto simplify the analysis of error performance for the constellations.Finally, arguments are made for extending the results to more generalchannel models. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Switching through Singularities </title>
<author> C. J. Tomlin and S. S. Sastry </author>
<affiliation> Department of Electrical Engineering and Computer SciencesUniversity of California, </affiliation>
 <address> Berkeley CA 94720 </address>
<email> fclairet, sastryg@eecs.berkeley.edu </email>
<abstract> AbstractAsymptotic tracking is studied for systems in which the relative degree is not well defined,meaning that the control law derived from exact input-output linearization has singularities inthe state space. We propose a tracking control law which switches between approximate tracking[1] close to the singularities, and exact tracking away from the singularities, and we study theapplicability of this law based on the behavior of the system's zero dynamics at the switchingboundary. As in [1], the ball and beam example is used to motivate the study. </abstract>
<keyword> Keywords: Switching, nonlinear control, zero dynamics, exact and asymptotic tracking,nonminimum phase. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Simulation as a Tool for Hybrid System Design </title>
<author> John Lygeros, Datta Godbole &amp; Shankar Sastry </author>
<affiliation> Intelligent Machines and Robotics LaboratoryDepartment of Electrical Engineering and Computer SciencesUniversity of California, </affiliation>
 <address> Berkeley, CA 94720 </address>
<email> lygeros,godbole,sastry@eecs.berkeley.edu </email>
<abstract> AbstractA case study of the use of simulation as a toolfor design and validation of hybrid systems is presented. We use the Intelligent Vehicle Highway Systems (IVHS) architecture of [1], a system that involvesboth continuous state and discrete event controllers asour example of a hierarchical hybrid system. We pointout that even though analytical methods do not existfor verification of hybrid control system, a simulationtool can be useful to (in)validate that the the hybridsystem operates properly. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Construction of Fuzzy Linguistic Model </title>
<author> Tak-Kuen John Koo </author>
<affiliation> Robotics and Intelligent Machines Laboratory </affiliation>
<address> 211-85 Cory Hall, </address>
 <affiliation> Department of EECS </affiliation>
<affiliation> University of California at Berkeley </affiliation>
<address> Berkeley, CA94720 </address>
<email> koo@robotics.eecs.berkeley.edu </email>
<abstract> AbstractUsing linguistic variables to describe the behavior of ahybrid system, which consists of a discrete event system and a continuous system, could make the designof the controller and verification of the system performon an unified framework. In this paper, we show theconstruction of a fuzzy linguistic model from a givenmathematical model of a physical system. By considering the state-space realization of the model, the systemconstruction problem can be transformed into a function approximation problem. We propose to use projection theorem in obtaining an optimal fuzzy systemwhich is the best approximation of a given nonlinearfunction in L 2 (U ) space. We show that the existenceand uniqueness of the optimal solution is assured whenthe Fuzzy Basis Functions(FBFs) are linearly independent. We demonstrate that the dependence of the basisfunctions can be examined by checking the condition ofthe Gram determinant associated to the FBFs. Finally,a method is proposed in converting the optimal coefficients into fuzzy sets to obtain a fuzzy linguistic model. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Hybrid Control in Air Traffic Management Systems </title>
<author> S. Sastry, G. Meyer , C. Tomlin, J. Lygeros, D. Godbole and G. Pappas </author>
<affiliation> Department of Electrical Engineering &amp; Computer Sciences,University of California, </affiliation>
 <address> Berkeley, CA 94720 </address>
<address> MS 210-3, </address>
 <affiliation> NASA Ames Research Center, </affiliation>
 <address> Moffett Field CA 94035 </address>
<email> fsastry, gmeyer, clairet, lygeros, godbole, gpappas@eecs.berkeley.edug </email>
<abstract> ABSTRACTIn a new collaborative project involving the University of California, Berkeley, NASA Ames ResearchCenter, and Honeywell Systems Research Center, wehave begun the study of hierarchical, hybrid controlsystems in the framework of air traffic managementsystems (ATMS). The need for a new ATMS arisesfrom the overcrowding of large urban airports andthe need to more efficiently land and take off largernumbers of aircraft, without building new runways.Technological advances that make a more advancedair traffic control system a reality include the availability of relatively inexpensive and fast real timecomputers (both on board the aircraft and in the control tower) and global positioning systems. The usefulness of these technological advances is currentlylimited by today's air traffic control system, whichinvolves the use of "freeways" in the Terminal RadarApproach Control (TRACON) region around urbanairports. These freeways are set approach patternsto runways which do not allow for the possibility ofso-called "free flight" by an aircraft to its destination.Limiting the aircraft trajectories in this manner results in the addition of both planned and unplanneddelays to air travel. </abstract>
<keyword> Keywords: hybrid systems, air traffic management,flight control. </keyword>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Fault Tolerant Control Architecturefor Automated Highway Systems  </title>
<author> John Lygeros, Datta N. Godbole, Mireille Broucke </author>
<affiliation> Department of Electrical Engineering and Computer SciencesUniversity of California, Berkeley </affiliation>
<address> Berkeley, CA 94720 </address>
<email> lygeros, godbole, mire@robotics.eecs.berkeley.edu </email>
<abstract> AbstractWe propose a hierarchical control architecture for dealing with faults and adverse environmental conditions on an Automated Highway System (AHS). Our design extendsa previous control architecture that works under normal conditions of operation. Thefaults that are considered in our design are classified according to the capabilities remaining on the vehicle or roadside after the fault has occurred. Information about thesecapabilities is used by supervisors in each of the layers of the architecture to select appropriate control strategies. We outline the extended control strategies that are neededby these supervisors and, in certain cases, give examples of their detailed operation. </abstract>
<keyword> KeywordsAutomated Highway System Design, Fault Tolerant Control, Safety </keyword>
<note> Research supported by the California PATH program, Institute of Transportation Studies, University ofCalifornia, Berkeley, under MOU-135 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Motion Recovery From Image Sequences: Discrete Viewpoint vs.Differential Viewpoint  </title>
<author> Yi Ma Jana Kosecka Shankar Sastry x </author>
<affiliation> Electronics Research LaboratoryUniversity of California at Berkeley </affiliation>
<address> Berkeley, CA 94720-1774 </address>
<email> fmayi, janka, sastryg@robotics.eecs.berkeley.edu </email>
<date> November 3, 1997 </date>
<abstract> AbstractThe aim of this paper is to explore intrinsic geometric methods of recovering the threedimensional motion of a moving camera from a sequence of images. Generic similarities betweenthe discrete approach and the differential approach are revealed through a parallel developmentof their analogous motion estimation theories.We begin with a brief review of the (discrete) essential matrix approach, showing how torecover the 3D displacement from image correspondences. The space of normalized essentialmatrices is characterized geometrically: the unit tangent bundle of the rotation group is adouble covering of the space of normalized essential matrices. This characterization naturallyexplains the geometry of the possible number of 3D displacements which can be obtained fromthe essential matrix.Second, a differential version of the essential matrix constraint previously explored by [19, 20]is introduced. We then present the precise characterization of the space of differential essentialmatrices, which gives rise to a novel eigenvector-decomposition-based 3D velocity estimationalgorithm from the optical flow measurements. This algorithm gives a unique solution to themotion estimation problem and serves as a differential counterpart of the SVD-based 3D displacement estimation algorithm from the discrete case.Finally, simulation results are presented evaluating the performance of our algorithm in termsof bias and sensitivity of the estimates with respect to the noise in optical flow measurements.The presented unifying theory of the motion estimation using discrete and differential version of the Longuet-Higgins (essential) constraint can be extended to the case of uncalibratedcameras. </abstract>
<keyword> Keywords: optical flow, epipolar constraint, motion estimation. </keyword>
<note> Research is supported by ARO under the MURI grant DAAH04-96-1-0341, "An Integrated Approach to IntelligentSystems". </note>
<address> Address: 211-109 Cory Hall, EECS, UC Berkeley, Berkeley, CA 94720-1772, USA. </address>
 <phone> Tel: (USA) 510-643-2383. </phone><address> Address: 211- 98 Cory Hall, EECS, UC Berkeley, Berkeley, CA 94720-1772, USA. </address>
 <phone> Tel: (USA) 510-643-5806. </phone><address> x Address: 269M Cory Hall, EECS, UC Berkeley, Berkeley, CA 94720-1772, USA. </address>
 <phone> Tel: (USA) 510-642-1857. </phone><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> SmartATMS : A SIMULATOR FOR AIR TRAFFIC MANAGEMENT SYSTEMS </title>
<author> Tak-Kuen John KooYi MaGeorge J. PappasClaire Tomlin </author>
<affiliation> Robotics and Intelligent Machines LaboratoryDepartment of Electrical Engineering and Computer SciencesUniversity of California at Berkeley </affiliation>
<address> Berkeley, CA 94720 </address>
<email> koo,mayi,gpappas,clairet@eecs.berkeley.edu </email>
<abstract> ABSTRACTAir Traffic Management Systems (ATMS) of the future will feature Free Flight, in which aircraft choosetheir own routes, altitude, and speed, and automated conflict resolution methods in which aircraftwill coordinate to resolve conflicts. The resulting distributed control architecture is a hybrid system, withmixed discrete event and continuous time dynamics.SmartATMS is an object oriented modeling and simulation facility which accounts for these hybrid issuesand will serve as a uniform modeling framework forthe design and evaluation of various ATMS concepts. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Depth Discontinuities by Pixel-to-Pixel Stereo </title>
<author> Stan Birchfield Carlo Tomasi </author>
<affiliation> Computer Science DepartmentStanford University </affiliation>
<address> Stanford, California 94305 </address>
<email> [birchfield, tomasi]@cs.stanford.edu </email>
<note> This research was supported by the National Science Foundation under a Graduate Research Fellowship and under contract IRI-9506064, and by the Department of Defense underMURI contract DAAH04-96-1-0007 monitored by ARO and under a subcontract of STTRcontract F49620-95-C-0078 monitored by AFOSR. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> FROM KNOWLEDGE TO BELIEF </title>
<degree> a dissertationsubmitted to the department of computer scienceand the committee on graduate studiesof stanford universityin partial fulfillment of the requirementsfor the degree ofdoctor of philosophy </degree><author> ByDaphne Koller </author>
<date> October 1994 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> Appears in KDD-97 </note>
<title> MineSet: An Integrated System for Data Mining </title>
<author> Cliff Brunk James Kelly Ron Kohavi </author>
<affiliation> Data Mining and VisualizationSilicon Graphics, Inc. </affiliation>
<address> 2011 N. Shoreline BlvdMountain View, CA 94043-1389 </address>
<email> fbrunk,jkelly,ronnykg@engr.sgi.com </email>
<abstract> AbstractMineSet TM , Silicon Graphics' interactive system fordata mining, integrates three powerful technologies:database access, analytical data mining, and data visualization. It supports the knowledge discovery process from data access and preparation through iterative analysis and visualization to deployment. Mine-Set is based on a client-server architecture that scalesto large databases. The database access componentprovides a rich set of operators that can be used topreprocess and transform the stored data into formsappropriate for visualization and analytical mining.The 3D visualization capabilities allow direct data visualization for exploratory analysis, including toolsfor displaying high-dimensional data containing geographical and hierarchical information. The analytical mining algorithms help identify potentially interesting models of the data, which can be viewed usingvisualization tools specialized for the learned models.Third party vendors can interface to the MineSet toolsfor model deployment and for integration with otherpackages. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Tioga: Providing Data Management Support forScientific Visualization Applications  </title>
<author> Michael Stonebraker, Jolly Chen, Nobuko Nathan, Caroline Paxson, Jiang Wu </author>
<affiliation> Computer Science Division, EECS DepartmentUniversity of California </affiliation>
<address> Berkeley, CA 94720 </address>
<abstract> AbstractWe present a user interface paradigm fordatabase management systems that is motivatedby scientific visualization applications. Ourgraphical user interface includes a "boxes and arrows" notation for database access and a flightsimulator model of movement through information space. We also provide means to specify ahierarchy of abstracts of data of different typesand resolutions, so that a "zoom" capability canbe supported. The underlying DBMS support forthis system is described and includes the compilation of query plans into megaplans, new algorithms for data buffering, and provisions fora guaranteed rate of data delivery. The current state of the Tioga implementation is also described. </abstract>
<note> This research was sponsored by NSF Grant IRI-9107455, ARO Grant DAAL03-91-G-0183, and DARPAContract DABT63-92-C-0007. Additional support wasprovided by the University of California and Digital Equipment Corporation under Research Grant #1243.Other industrial and government partners include theState of California Department of Water Resources, UnitedStates Geological Survey, Construction Engineering Research Laboratory (CERL) of the U.S. Army Corps ofEngineers, the National Aeronautics and Space Administration (NASA), Epoch Systems, Inc., Hewlett-PackardCorp., Hughes Aircraft Company, MCI, Metrum Corporation, PictureTel Corporation, Research Systems Inc., Science Applications International Corporation, Siemens Inc.,and TRW Space and Electronics. </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> BigSur:A System For the Management of Earth Science Data </title>
<author> Paul Brown </author>
<affiliation> EECS DepartmentUniversity of California, Berkeley </affiliation>
<author> Michael Stonebraker </author>
<affiliation> EECS DepartmentUniversity of California, Berkeley </affiliation>
<abstract> ABSTRACTIn this paper we present a prototype system forthe management of earth science data which isnovel in that it takes a DBMS centric view of thethe task. Our prototype -- called "BigSur" -- isshown in the context of its use by two geographically distributed scientific groups with demanding data storage and processing requirements.BigSur currently stores 1 Terabyte of data, aboutone thousandth of the volume EOSDIS muststore. We claim that the design principlesembodied in BigSur provide sufficient exibilityto achieve the difficult scientific and technicalobjectives of Mission to Planet Earth. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> GEN++ | an analyzer generator for C++ programs </title>
<author> Prem Devanbu </author>
<affiliation> Articifial Intelligence Principles Research Department </affiliation>
<email> prem@research.att.com </email>
<author> Laura Eaves </author>
<affiliation> Object Oriented and Artificial Intelligence Technologies Group, </affiliation>
<email> laurae@mozart.att.com </email>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Use of Description Logics in KBSE systemsSurvey Paper </title>
<author> Premkumar T. Devanbu &amp; Mark A. Jones </author>
<affiliation> Artificial Intelligence Principles Research DepartmentAT&amp;T Bell Laboratories </affiliation>
<email> fprem,jonesg@research.att.com </email>
<address> Murray Hill, NJ 07063 </address>
<date> February 9, 1994 </date>
<abstract> AbstractThe increasing size and complexity of many softwaresystems demand a greater emphasis on capturing andmaintaining knowledge at many different levels withinthe software development process. This knowledge includes descriptions of the hardware and software components and their behavior, external and internal design specifications, and support for system testing.The knowledge-based software engineering (KBSE) research paradigm is concerned with systems that useformally represented knowledge, with associated inference procedures, to support the various subactivi-ties of software development. As they grow in scale,KBSE systems must balance expressivity and inferential power with the real demands of knowledge baseconstruction, maintenance, performance and comprehensibility. Description Logics (DL's) possess severalfeatures a terminological orientation, a formal semantics and efficient reasoning procedures which offer an effective tradeoff of these factors. We discussthree KBSE systems in which DL's capture some ofthe requisite knowledge needed to support design, coding and testing activities. We close with a discussionof the benefits of DL's and ways to address some oftheir limitations. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> The following paper was originally published in theProceedings of the USENIX 2nd Symposium onOperating Systems Design and ImplementationSeattle, Washington, October 1996For more information about USENIX Association contact: </note>
<phone> 1. Phone: 510 528-8649 </phone><phone> 2. FAX: 510 548-5738 </phone><email> 3. Email: office@usenix.org </email>
<web> 4. WWW URL: http://www.usenix.org </web><title> Dealing With Disaster:Surviving Misbehaved Kernel Extensions </title>
<author> Margo I. Seltzer, Yasuhiro Endo, Christopher Small, Keith A. Smith </author>
<affiliation> Harvard University </affiliation>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> 5th Midwest Artificial Intelligence and Cognitive Science Conference </note>
<title> Identifying Language from Raw Speech An Application of Recurrent Neural Networks </title>
<author> Weilan Wu, Stan C. Kwasny, Barry L. Kalman, E. Maynard Engebretson </author>
<affiliation> Department of Computer ScienceWashington Unversity </affiliation>
<address> St. Louis, MO 63130 </address>
<abstract> AbstractPeople can differentiate spoken languageswithout understanding them, and, in somesense, this differentiation can only be donewithout understanding the language. Whenwe consider a multi-lingual person trying tounderstand an utterance spoken in one of thelanguages with which they are familiar, theywill first decide which language this utterancebelongs to, before trying to interpret it.The language identification task is oneexample of high-level feature abstraction fromraw speech. Speech samples are classifiedinto categories according to what languagewas spoken. We conjecture that this classification can be performed reliably and in realtime. To be successful, such a system shouldbe speaker-independent as well as context-independent. A large amount of training isrequired to achieve a satisfactory level of performance.We present a continuation of previouswork (Kwasny et al., 1992) which introducestwo important improvements to the system:(1) replacement of the non-recurrent, feed-forward network with a recurrent one, whichis smaller, but still classifies correctly; (2)development of a frontend processor on aNextfi workstation to facilitate samplerecording and data acquisition. This is important for large-scale data acquisition, training,and testing of the network. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Efficient Restoration of Multicolor Images withIndependent Noise </title>
<author> Yuri Boykov Olga Veksler Ramin Zabih  </author>
<affiliation> Cornell University, </affiliation>
 <address> USA </address>
<keyword> Keywords: Bayesian image restoration; Markov random fields; max flow-min cut </keyword>
<abstract> AbstractWe consider the problem of maximum a posteriori (MAP) restoration of multicolor imageswhere each pixel has been degraded by independent arbitrary noise. We assume that theprior distribution is given by a Markov random field with only pairwise site interactions.Two classes of site interactions are considered: two-valued site interactions, which form ageneralized Potts model; and linear site interactions. We give efficient algorithms based ongraph cuts for both classes. The MAP estimate for a generalized Potts model can be computed by solving a multiway minimum cut problem on a graph. While this graph problem iscomputationally intractable, there are fast algorithms for computing provably good approximations. The MAP estimate with linear site interactions can be computed exactly by solvinga minimum cut problem on a graph. This can be performed in nearly linear time. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Coherence of an inference is equivalent toexistence of a countably additive prior </title>
<author> Yuri Boykov </author>
<date> August 1996 </date>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Client/Server Architectures for Business Information Systems Page 1 </note>
<title> Client/Server Architectures for BusinessInformation SystemsA Pattern Language </title>
<author> Klaus Renzel </author>
<affiliation> sd&amp;m GmbH &amp; Co. KGProject ARCUS 1 </affiliation>
<address> Thomas-Dehler-Str. 27D-81737 Mnchen, Germany </address>
<email> email: Klaus.Renzel@sdm.de </email>
<phone> Phone: +49-89-63812-251 </phone><web> http://www.sdm.de/g/arcus </web><title> Wolfgang Keller </title>
<affiliation> EA Generali </affiliation>
<address> Reumannplatz 7A-1100 Vienna, Austria </address>
<email> email: WofgangWKeller@compuserve.com </email>
<phone> Phone: +43-1-53401-0 </phone><note> Copyright 1997, Klaus Renzel, Wolfgang KellerPermission granted to copy for PLoP97 Conference.All other rights reserved. </note>
<abstract> Abstract: This paper presents several patterns for distributing business information systems that are structured according to a layered architecture. 2 Each distribution pattern cuts the architecture into different client and server components. Allthe patterns presented give an answer to the same question: How do I distribute abusiness information system? However, the consequences of applying the patternsare very different with regards to the forces influencing distributed systems design. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<date> 07/17/97 </date>
 <note> 10:13 1 of 8 </note>
<title> The Abstract Class Pattern </title>
<author> Bobby Woolf </author>
<affiliation> Knowledge Systems Corp. </affiliation>
<address> 4001 Weston Pkwy, Cary, NC 27513-2303 </address>
<phone> 919-677-1119 x541, </phone> <email> bwoolf@ksccary.com </email>
<title> ABSTRACT CLASS Class Behavioral </title>
<abstract> IntentDefine the interface for a hierarchy of classes while deferring the implementation to subclasses.Abstract Class lets subclasses redefine the implementation of an interface while preserving thepolymorphism of those classes.Also Known AsLiskov Substitution Principle [LW93], Design by Contract [Meyer91], Base Class [Auer95] ,Template Class [Woolf97] </abstract>
<intro> Motivation </intro><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Semantic Query Caching for Heterogeneous Databases </title>
<author> Parke Godfrey </author>
<affiliation> U.S. Army Research Laboratory </affiliation>
<address> 2800 Powder Mill RoadAdelphi, Maryland 20783-1197U.S.A. </address>
<email> godfrey@arl.mil </email>
<author> Jarek Gryz </author>
<affiliation> Department of Computer ScienceYork University </affiliation>
<address> Toronto, Ontario M3J 1P3Canada </address>
<email> jarek@cs.yorku.ca </email>
<abstract> AbstractQuery caching can play a vital role in heterogeneous, multi-database environments. Answers to a query that are available in cacheat the local client can be returned to the userquickly, while the rest of the query is evaluated. The use of caches can optimize queryevaluation. By caching certain sensitive datalocally, caches can be used to answer the partsof queries that involve the sensitive data, so itneed not be shipped across the network. Mostprior cache schemes have been tuple-based orpage-based. It is unclear, however, how thesemight be adapted for multi-databases. We explore a more flexible semantic query caching(SQC) approach. In SQC, caches are the answer sets of previous queries, labeled by thequery expressions that produced them. Wepromote developing the technology, based onlogic, to manipulate semantic caches, to determine when and how caches can be used to answer subsequent queries, and to optimize viacache use. </abstract>
<note> The copyright of this paper belongs to the papers authors. Permission to copy without fee all or part of this material is grantedprovided that the copies are not made or distributed for directcommercial advantage.Proceedings of the 4th KRDB WorkshopAthens, Greece, 30-August-1997(F. Baader, M.A. Jeusfeld, W. Nutt, eds.) </note>
<web> http://sunsite.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-8/ </web><intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Revisiting the Paxos algorithm </title>
<author> Roberto De Prisco ? , Butler Lampson, Nancy Lynch </author>
<affiliation> MIT Laboratory for Computer Science </affiliation>
<address> 545 Technology Square NE43, Cambridge, MA 02139, USA. </address>
<abstract> Abstract. This paper develops a new I/O automaton model called theClock General Timed Automaton (Clock GTA) model. The Clock GTAis based on the General Timed Automaton (GTA) of Lynch and Vaan-drager. The Clock GTA provides a systematic way of describing timing-based systems in which there is a notion of "normal" timing behavior,but that do not necessarily always exhibit this "normal" behavior. It canbe used for practical time performance analysis based on the stabilizationof the physical system.We use the Clock GTA automaton to model, verify and analyze thepaxos algorithm. The paxos algorithm is an efficient and highly fault-tolerant algorithm, devised by Lamport, for reaching consensus in a distributed system. Although it appears to be practical, it is not widelyknown or understood. This paper contains a new presentation of thepaxos algorithm, based on a formal decomposition into several interacting components. It also contains a correctness proof and a time performance and fault-tolerance analysis. </abstract>
<keyword> Keywords: I/O automata models, formal verification, distributed consensus, partially synchronous systems, fault-tolerance </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Finding Maximum Flows in Undirected Graphs Seems Easier thanBipartite Matching +L </title>
+<author> David R. Karger and Matthew S. Levine  </author>
<abstract> AbstractConsider an n-vertex, m-edge, undirected graph with maximum flow value v. We give a method to find augmentingpaths in such a graph in amortized sub-linear (O(npv)) timeper path. This lets us improve the time bound of the classic augmenting path algorithm to O(m + nv 3=2 ) on simplegraphs. The addition of a blocking flow subroutine gives asimple, deterministic O(nm 2=3 v 1=6 )-time algorithm. We alsouse our technique to improve known randomized algorithms,giving O(m+nv 5=4 )-time and O(m+n 11=9 v)-time algorithmsfor capacitated undirected graphs. For simple graphs, inwhich v n, the last bound is O(n 2:2 ), improving on the bestprevious bound of O(n 2:5 ), which is also the best known timebound for bipartite matching. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Bounds on the Time to Detect FailuresUsing Bounded-capacity Message Links </title>
<author> Stephen Ponzio  </author>
<affiliation> MIT Laboratory for Computer Science </affiliation>
<abstract> AbstractWe consider a system of distributed processors thatcommunicate by passing messages and that have inexact information about time. Specifically, a processor knows that a single message is delayed by at mosttime d and the time between any two of its consecutive steps is at least c 1 and at most c 2 ; it has noother way of estimating elapsed time. This simplemodel is very close to traditional models used in distributed computing theory, and has been studied byAttiya and Lynch [2, 1] among others. We extendthe model by making a realistic assumption abouthow the delay of messages is affected by the rate atwhich they are sent. We define a model of messagelinks with bounded capacity, which are guaranteed todeliver messages at only a given rate. If a processor sends messages at a greater rate, they may incurgreater delay.We quantify the effect of this bounded capacity onthe time necessary to detect processor failures. Weconsider a system of two processors connected by abi-directional message link of (integral) capacity .First we give two very simple protocols that guarantee any stopping failure will be detected withintime 2Cd + d and C 2 d= + Cd + d respectively,where C = c 2 =c 1 . The main result is an almost-matching lower bound of 2Cd+d= or C 2 d=+Cd+d,whichever is less. If the link is uni-directional, our result specializes to give a matching upper and lowerbound of C 2 d= + Cd + d. </abstract>
<note> Supported by an NSF Graduate Fellowship </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Electronic Lottery Tickets as Micropayments </title>
<author> Ronald L. Rivest </author>
<affiliation> MIT Lab for Computer Science(RSA / Security Dynamics) </affiliation>
<email> rivest@theory.lcs.mit.edu </email>
<abstract> Abstract. We present a new micropayment scheme based on the use of"electronic lottery tickets." This scheme is exceptionally efficient sincethe bank handles only winning tickets, instead of handling each micropayment. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Design and Implementation of SOLAR,a Portable Library for Scalable Out-of-Core Linear Algebra Computations </title>
<author> Sivan Toledo Fred G. Gustavson </author>
<affiliation> IBM T.J. Watson Research Center </affiliation>
<abstract> AbstractSOLAR is a portable high-performance library for out-of-core densematrix computations. It combines portability with high performanceby using existing high-performance in-core subroutine libraries andby using an optimized matrix input-output library. SOLAR works onparallel computers, workstations, and personal computers. It supportsin-core computations on both shared-memory and distributed-memorymachines, and its matrix input-output library supports both conventional I/O interfaces and parallel I/O interfaces. This paper discussesthe overall design of SOLAR, its interfaces, and the design of severalimportant subroutines. Experimental results show that SOLAR canfactor on a single workstation an out-of-core positive-definite symmetric matrix at a rate exceeding 215 Mflops, and an out-of-core generalmatrix at a rate exceeding 195 Mflops. Less than 16% of the runningtime is spent on I/O in these computations. These results indicatethat SOLAR's portability does not compromise its performance. Weexpect that the combination of portability, modularity, and the use ofa high-level I/O interface will make the library an important platformfor research on out-of-core algorithms and on parallel I/O. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Compiler Technology for Portable Checkpoints </title>
<author> Volker Strumpen  </author>
<affiliation> Laboratory for Computer ScienceMassachusetts Institute of Technology </affiliation>
<address> Cambridge, MA 02139 </address>
<email> strumpen@theory.lcs.mit.edu </email>
<abstract> AbstractWe have implemented a prototype compiler called porch that transforms C programs into C programs supporting portable checkpoints. Portable checkpoints capture the state of a computation ina machine-independent format that allows the transfer of computations across binary incompatible machines. We introduce source-to-source compilation techniques for generating code to save andrecover from such portable checkpoints automatically. These techniques instrument a program with code that maps the state of a computation into a machine-independent representation and vice versa.In particular, the following problems are addressed: (1) providingstack environment portability, (2) enabling conversion of complexdata types, and (3) rendering pointers portable. Experimental results show that the overhead of checkpointing is reasonably small,even if data representation conversion is required for portability. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Regression shrinkage and selection via the lasso </title>
<author> Robert Tibshirani  </author>
<affiliation> Department of StatisticsandDivision of BiostatisticsStanford University </affiliation>
<abstract> AbstractWe propose a new method for estimation in linear models. The "lasso"minimizes the residual sum of squares subject to the sum of the absolutevalue of the coefficients being less than a constant. Because of the natureof this constraint it tends to produce some coefficients that are exactly zeroand hence gives interpretable models. Our simulation studies suggest thatthe lasso enjoys some of the favourable properties of both subset selectionand ridge regression. It produces interpretable models like subset selectionand exhibits the stability of ridge regression. There is also an interestingrelationship with recent work in adaptive function estimation by Donohoand Johnstone. The lasso idea is quite general and can be applied in avariety of statistical models: extensions to generalized regression modelsand tree-based models are briefly described. </abstract>
<keyword> Keywords: regression, subset selection, shrinkage, quadratic programming. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Task Driven Perceptual Organization for Extraction of RooftopPolygons  </title>
<author> Christopher Jaynes Frank Stolle Robert Collins </author>
<affiliation> Computer Science DepartmentUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003 </address>
<email> Email: @cs.umass.edu </email>
<abstract> AbstractA new method for extracting planar polygonal rooftops in monocular aerial imagery is proposed. Through bottom-up and top-down construction of perceptual groups, polygons in asingle aerial image can be robustly extracted.Orthogonal corners and lines are extracted andhierarchically related using perceptual grouping techniques. Top-down feature verification isused so that features, and links between the features, are verified with local information in theimage and weighed in a graph structure according to the underlying support for each feature.Cycles in the graph correspond to possiblebuilding rooftop hypotheses. Virtual featuresare hypothesized for the perceptual completionof partial rooftops. Extraction of the "best"grouping of features into a building rooftop hypothesis is posed as a graph search problem.The maximally weighted, independent set of cycles in the graph is extracted as the final set ofroof boundaries. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 368 </pubnum>
<note> Appears in: Fourth European Conference on Computer Vision, Cambridge, UK, April 1996. </note>
<title> Generalized Image Matching:Statistical Learning of Physically-Based Deformations </title>
<author> Chahab Nastar, Baback Moghaddam and Alex Pentland </author>
<affiliation> Perceptual Computing Section, The Media Laboratory,Massachusetts Institute of Technology </affiliation>
<address> 20 Ames Street, Cambridge MA 02139, U.S.A. </address>
<abstract> AbstractWe describe a novel approach for image matchingbased on deformable intensity surfaces. In thisapproach, the intensity surface of the imageis modeled as a deformable 3D mesh in the(x; ; I(x; )) space. Each surface point has 3degrees of freedom, thus capturing fine surfacechanges. A set of representative deformationswithin a class of objects (e.g. faces) are statistically learned through a Principal Components Analysis, thus providing a priori knowledgeabout object-specific deformations. We demonstrate the power of the approach by examplessuch as image matching and interpolation ofmissing data. Moreover this approach dramatically reduces the computational cost of solvingthe governing equation for the physically basedsystem by approximately three orders of magnitude. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Determining 3-D Hand Motion </title>
<author> James Davis Mubarak Shah </author>
<affiliation> Media Lab Computer Vision LabMassachusetts Institute of Technology University of Central Florida </affiliation>
<address> Cambridge, MA 02139 Orlando, FL 32826 </address>
<abstract> AbstractThis paper presents a glove-free method for trackinghand movements using a set of 3-D models. In thisapproach, the hand is represented by five cylindricalmodels which are fit to the third phalangeal segmentsof the fingers. Six 3-D motion parameters for eachmodel are calculated that correspond to the movementof the fingertips in the image plane. Trajectories ofthe moving models are then established to show the 3-D nature of hand motion. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Optimal Algorithms for Substrate Testingin Multi-Chip Modules  </title>
<author> Andrew B. Kahng, Gabriel Robins and Elizabeth A. Walkup  </author>
<affiliation> Department of Computer Science, UCLA, </affiliation>
 <address> Los Angeles, CA 90024-1596 </address>
<affiliation> y Department of Computer Science, </affiliation>
 <address> University of Virginia, Charlottesville, VA, 22903-2442 </address>
<affiliation> z Department of Computer Science, </affiliation>
 <address> University of Washington, Seattle, WA 98195 </address>
<abstract> AbstractMulti-chip module (MCM) packaging techniques present several new technical challenges, notably substrate testing. We formulate MCM substrate testing as a problem of connectivity verification in trees via k-probes, and present a linear-time algorithm which computes a minimumset of probes achieving complete open fault coverage. Since actual substrate testing also involvesscheduling probe operations, we formulate efficient probe scheduling as a special type of metrictraveling salesman optimization and give a provably-good heuristic. Empirical results using bothrandom and industry benchmarks demonstrate reductions in testing costs of up to 21% over previous methods. We conclude with generalizations to alternate probe technologies and several openproblems. </abstract>
<keyword> Key words: MCMs, testing, graph algorithms, fault detection, circuit probing, TSP. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Efficient Gate Delay Modeling for Large Interconnect Loads </title>
<author> Andrew B. Kahng and Sudhakar Muddu </author>
<affiliation> UCLA Computer Science Department, </affiliation>
 <address> Los Angeles, CA 90095-1596 USA </address>
<email> abk@cs.ucla.edu, sudhakar@cs.ucla.edu </email>
<abstract> AbstractWith fast switching speeds and large interconnect trees (MCMs), theresistance and inductance of interconnect has a dominant impact onlogic gate delay. In this paper, we propose a new P model for distributed RC and RLC interconnects to estimate the driving point admittance at the output of a CMOS gate. Using this model we are able tocompute the gate delay efficiently, within 25% of SPICE-computed delays. Our parameters depend only on total interconnect tree resistanceand capacitance at the output of the gate. Previous effective load capacitance methods [7, 9], applicable only for distributed RC interconnects, are based on P model parameters obtained via a recursive admittance moment computation. Our model should be useful for iterativeoptimization of performance-driven routing or for estimation of gatedelay and rise times in high-level synthesis. </abstract>
<keyword> Keywords: gate delay, reduced-order models, driving point admittance,effective capacitance, interconnect modeling </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Gate Load Delay Computation Using Analytical Models </title>
<author> Andrew B. Kahng Sudhakar Muddu </author>
<affiliation> UCLA Computer Science Department Silicon Graphics, Inc. </affiliation>
<address> Los Angeles, CA 90095-1596 USA Mountain View, CA 94039 USA </address>
<email> abk@cs.ucla.edu muddu@mti.sgi.com </email>
<abstract> AbstractWith submicron technologies, gate delays are dominated by gateload delays rather than intrinsic gate delays. While the common approach for computing gate load delay (or total gate delay) is throughdelay tables (or k-factor equations), there are important methodology problems associated with the delay table approach. In this paper, we propose a gate driver model with a Thevenin equivalent circuit consisting of a ramp voltage source whose slew time is obtainedfrom the gate slew tables, and a driver resistance in series with thegate load. We then develop analytical gate delay formulas using thisThevenin driver model and modeling the load with various gate loadmodels under both rising and falling ramp input. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Robust IP Watermarking Methodologies for Physical Design </title>
<author> Andrew B. Kahng, Stefanus Mantik, Igor L. Markov, Miodrag Potkonjak,Paul Tucker , Huijuan Wang and Gregory Wolfe </author>
<affiliation> UCLA Computer Science Dept., </affiliation>
 <address> Los Angeles, CA 90095-1596 </address>
<affiliation> UCSD Computer Science &amp; Engineering Dept., </affiliation>
 <address> La Jolla, CA 92093-0114 </address>
<abstract> AbstractIncreasingly popular reuse-based design paradigms create a pressing need for authorship enforcement techniques that protect the intellectual property rights of designers. We develop the first intellectual property protection protocols for embedding design watermarks at the physical design level. We demonstrate that these protocols are transparent with respect to existing industrial tools anddesign flows, and that they can embed watermarks into real-worldindustrial designs with very low implementation overhead (as measured by such standard metrics as wirelength, layout area, numberof vias, routing congestion and CPU time). On several industrialtest cases, we obtain extremely strong, tamper-resistant proofs ofauthorship for placement and routing solutions. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Concurrency and Recovery in Generalized Search Trees </title>
<author> Marcel Kornacker  </author>
<affiliation> U. C. Berkeley </affiliation>
<web>  http://www.cs.berkeley.edu/ marcel </web><email> marcel@cs.berkeley.edu </email>
<author> C. Mohan </author>
<affiliation> IBM Research Division </affiliation>
<web>  http://www.almaden.ibm.com/ cs/people/mohan </web><email> mohan@almaden.ibm.com </email>
<author> Joseph M. Hellerstein </author>
<affiliation> U. C. Berkeley </affiliation>
<web>  http://www.cs.berkeley.edu/ jmh </web><email> jmh@cs.berkeley.edu </email>
<abstract> AbstractThis paper presents general algorithms for concurrency control intree-based access methods as well as a recovery protocol and amechanism for ensuring repeatable read. The algorithms are developed in the context of the Generalized Search Tree (GiST) datastructure, an index structure supporting an extensible set of queriesand data types. Although developed in a GiST context, the algorithms are generally applicable to many tree-based access methods.The concurrency control protocol is based on an extension of thelink technique originally developed for B-trees, and completelyavoids holding node locks during I/Os. Repeatable read isolation isachieved with a novel combination of predicate locks and two-phaselocking of data records. To our knowledge, this is the first time thatisolation issues have been addressed outside the context of B-trees.A discussion of the fundamental structural differences between B-trees and more general tree structures like GiSTs explains why thealgorithms developed here deviate from their B-tree counterparts.An implementation of GiSTs emulating B-trees in DB2/CommonServer is underway. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Quick Simulation of ATM Buffers withOn-off Multiclass Markov Fluid Sources 1 </title>
<author> G. Kesidis </author>
<affiliation> E &amp; CE Dept, University of Waterloo, </affiliation>
 <address> Waterloo, Ontario, N2L 3G1, Canada. </address>
<author> J. Walrand </author>
<affiliation> EECS Dept, University of California, </affiliation>
 <address> Berkeley, CA94720. </address>
<note> ACM TOMACS, Vol. 3, No. 3, pp. 269-276, July, 1993. </note>
<abstract> AbstractThe problem we address is how to quickly estimate by simulation the loss in abuffer with multiclass on-off Markov fluid sources. We generate the Markov fluidswith the altered rate matrices given in [11], instead of the originals, to speed upthe simulation. Likelihood ratios are used to recover an estimate of the loss for theoriginal traffic parameters. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Information Theory,Inference,and Learning Algorithms </title>
<author> David J.C. MacKay </author>
<note> c fl1995, 1996, 1997, 1998 </note>
<note> Draft 1.6.1 </note>
 <date> August 31, 1998 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Inferring Reduced Ordered Decision Graphs of Minimal DescriptionLength </title>
<author> Arlindo L. Oliveira Alberto Sangiovanni-Vincentelli </author>
<affiliation> Dept. of EECS, UC Berkeley, </affiliation>
 <address> Berkeley CA 94720 </address>
<date> May 17, 1994 </date>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. </note>
<title> A Method for Automatic Design Error Location andCorrection in Combinational Logic Circuits  </title>
<author> AYMAN M. WAHBA AND DOMINIQUE BORRIONE </author>
<affiliation> Modelisation et Preuves de Circuits, TIMA Laboratory, </affiliation>
 <address> BP 53X, 38041 Grenoble Cedex FRANCE </address>
<email> Ayman.Wahba@imag.fr, Dominique.Borrione@imag.fr </email>
<note> Received ??. Revised ??. </note>
<abstract> Abstract. We present a new diagnostic algorithm, based on backward-propagation, for localising designerrors in combinational logic circuits. Three hypotheses are considered, that cover all single gate replacement and insertion errors. Diagnosis-oriented test patterns are generated in order to rapidly reduce thesuspected area where the error lies. The originality of our method is the use of patterns which do notdetect the error, in addition to detecting patterns. A theorem shows that, in favourable cases, only twopatterns suffice to get a correction. We have implemented the test generation and diagnosis algorithms.Results obtained on benchmarks show that the error is always found, after the application of a smallnumber of test patterns, with an execution time proportional to the circuit size. </abstract>
<keyword> Keywords: design correctness, design debugging, design error diagnosis </keyword>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> VIS : A System for Verification and Synthesis </title>
<author>  Robert K. Brayton Gary D. Hachtel Alberto Sangiovanni-Vincentelli  Fabio Somenzi Adnan Aziz Szu-Tsung Cheng Stephen Edwards Sunil Khatri Yuji Kukimoto Abelardo Pardo Shaz Qadeer Rajeev K. Ranjan Shaker Sarwary Thomas R. Shiple Gitanjali Swamy Tiziano Villa  </author>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> INSTITUT NATIONAL DE RECHERCHE EN INFORMATIQUE ET EN AUTOMATIQUE </affiliation>
<title> Latch Optimization in Circuits Generated from High-levelDescriptions </title>
<author> Ellen M. Sentovich, Horia Toma, Gerard Berry </author>
<note> N 2943 </note>
<date> Juillet 1996 </date>
<note> THE ME 1 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Using Don't Cares in Logic Minimization forLUT-Based FPGAs </title>
<author>  Philip Chong  13327872 </author>
<date> May 25, 1997 </date>
<abstract> AbstractDon't care information has proven to be useful in logic minimization.Here, the use of don't care information in network collapsing for mappingto LUT-based FPGAs is explored. Results are shown which indicate thatthis approach does not result in appreciable improvements in network size. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Assume-Guarantee Rule For Checking Simulation </title>
<author> T.A. Henzinger S. Qadeer S.K. Rajamani S. Ta~sran </author>
<affiliation> EECS Department, University of California at Berkeley, </affiliation>
 <address> CA 94720 </address>
<abstract> AbstractThe simulation preorder on state transition systems is widely accepted as auseful notion of refinement, both in its own right and as an efficiently checkable sufficient condition for trace containment. For composite systems, due tothe exponential explosion of the state space, there is a need for decomposing asimulation check of the form P s Q into simpler simulation checks on the components of P and Q. We present an assume-guarantee rule that enables such adecomposition. To the best of our knowledge, this is the first assume-guaranteerule that applies to a refinement relation different from trace containment. Ourrule is circular, and its soundness proof requires induction on trace-trees. Theproof is constructive: given simulation relations that witness the simulationpreorder between components, we provide a procedure for constructing a witness relation for P s Q. We also extend our assume-guarantee rule to accountfor fairness assumptions on transition systems. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Submitted to ACM SIGCOMM '98 </note>
<title> Modeling TCP Throughput: A Simple Model and its Empirical Validation  </title>
<author> Jitendra Padhye Victor Firoiu Don Towsley Jim Kurose </author>
<email> jitu@cs.umass.edu vfiroiu@cs.umass.edu towsley@cs.umass.edu kurose@cs.umass.edu </email>
<phone> 1-413-545-2447 1-413-545-3179 1-413-545-0207 1-413-545-1585 </phone><affiliation>  Department of Computer Science University of Massachusetts </affiliation>
<address> LGRC, Box 34610Amherst, MA 01003-4610 USA </address>
<date> May 29, 1998 </date>
<abstract> AbstractIn this paper we develop a simple analytic characterization of the steady state throughput, as a function of loss rate and round trip time for a bulk transfer TCP flow, i.e., a flow with an unlimited amountof data to send. Unlike the models in [6, 7, 10], our model captures not only the behavior of TCP's fastretransmit mechanism (which is also considered in [6, 7, 10]) but also the effect of TCP's timeout mechanism on throughput. Our measurements suggest that this latter behavior is important from a modelingperspective, as almost all of our TCP traces contained more timeout events than fast retransmit events.Our measurements demonstrate that our model is able to more accurately predict TCP throughput and isaccurate over a wider range of loss rates.This material is based upon work supported by the National Science Foundation under grants NCR-95-08274, NCR-95-23807and CDA-95-02639. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authorsand do not necessarily reflect the views of the National Science Foundation. </abstract>
<note> Corresponding Author </note>
<web> http://www.cs.umass.edu/~vfiroiu/ </web><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Exotica/FMQM: A PersistentMessage-Based Architecture forDistributed Workflow Management </title>
<author> G. Alonso, C. Mohan, R. Gunthor </author>
<affiliation> IBM Almaden Research Center </affiliation>
<address> 650 Harry Road, San Jose, CA 95120, USA. </address>
<email> E-mail: fgustavoa,rgunther,mohang@almaden.ibm.com </email>
<author> D. Agrawal, A. El Abbadi </author>
<affiliation> Computer Science Department, UC Santa Barbara, </affiliation>
<address> Santa Barbara, CA 93106, USA. </address>
<email> E-mail: fagrawal,amrg@cs.ucsb.edu </email>
<author> M. Kamath </author>
<affiliation> Computer Science Department, UM at Amherst, </affiliation>
<address> Amherst, MA 01003, USA. </address>
<email> E-mail: kamath@cs.umass.edu </email>
<abstract> AbstractIn the past few years there has been an increasing interest in workflow applications as away of supporting complex business processes in modern corporations. Given the natureof the environment and the technology involved, workflow applications are inherentlydistributed and pose many interesting challenges to the system designer. In most cases, aclient/server architecture is used in which knowledge about the processes being executed iscentralized in one node to facilitate monitoring, auditing, and to simplify synchronization.In this paper, we explore a novel distributed architecture, Exotica/FMQM, for workflowsystems in which the need for such a centralized database is eliminated. Instead, we usepersistent messages as the means to store the information relevant to the execution of abusiness process. Our approach is to completely distribute the execution of a process soindividual nodes are independent. The advantages of this approach are increased resilienceto failures and greater scalability and flexibility of the system configuration. </abstract>
<keyword> KeywordsWorkflow Management Systems, Distributed Systems, reliability, scalability. </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Use of Architecture-Altering Operations to DynamicallyAdapt a Three-Way Analog Source Identification Circuit toAccommodate a New Source </title>
<author> John R. Koza </author>
<affiliation> Computer Science Dept.Stanford University </affiliation>
<address> Stanford, California 94305-9020 </address>
<email> koza@cs.stanford.edu </email>
<web> http://www-csfaculty.stanford.edu/~koza/ </web><author> Forrest H Bennett III </author>
<affiliation> Visiting ScholarComputer Science Dept.Stanford University </affiliation>
<address> Stanford, California 94305 </address>
<email> forrest@evolute.com </email>
<author> Jason Lohn </author>
<affiliation> Visiting ScholarComputer Science Dept.Stanford University </affiliation>
<address> Stanford, California 94305 </address>
<email> jlohn7@leland.stanford.edu </email>
<author> Frank Dunlap </author>
<affiliation> Dunlap Consulting </affiliation>
<address> Palo Alto, California </address>
<author> Martin A. Keane </author>
<affiliation> Martin Keane Inc. </affiliation>
<address> 5733 West GroverChicago, Illinois 60630 </address>
<email> makeane@ix.netcom.com </email>
<author> David Andre </author>
<affiliation> Computer Science DivisionUniversity of California </affiliation>
<address> Berkeley, California </address>
<email> dandre@cs.berkeley.edu </email>
<abstract> ABSTRACTThe problem of sourceidentification involves correctlyclassifying an incoming signal intoa category that identifies thesignal's source.The problem is difficult becauseinformation is not provideddistinguishing characteristics andbecause successive signals from thesame source differ. The sourceidentification problem can be mademore difficult by dynamicallychanging the repertoire of sourceswhile the problem is being solved.We used genetic programming toevolve both the topology and thesizing (numerical values) for eachcomponent of an analog electricalcircuit that can correctly classify anincoming analog electrical signalinto three categories. Then, therepertoire of sources wasdynamically changed by adding anew source during the run. Thepaper describe show theenabled genetic programming toadapt, during the run, to thechanged environment. Specifically,a three-way source identificationcircuit was evolved and thenadapted into a four-way classifier,during the run, thereby successfullyhandling the additional new source. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Planar-Adaptive Routing: Low-cost Adaptive Networks forMultiprocessors </title>
<author> Andrew A. Chien and Jae H. Kim </author>
<email> achien@cs.uiuc.edu kim@cs.uiuc.edu </email>
<affiliation> Department of Computer ScienceUniversity of Illinois at Urbana-Champaign </affiliation>
<address> 1304 W. Springfield AvenueUrbana, IL 61801 </address>
<abstract> AbstractNetwork throughput can be increased by allowing mul-tipath, adaptive routing. Adaptive routing allows morefreedom in the paths taken by messages, spreading loadover physical channels more evenly. The flexibility ofadaptive routing introduces new possibilities of deadlock. Previous deadlock avoidance schemes in k-ary n-cubes require an exponential number of virtual channels[17]. We describe a family of deadlock-free routing algorithms, called planar-adaptive routing algorithms whichrequire only a constant number of virtual channels, independent of network size and dimension. Planar-adaptiverouting algorithms reduce the complexity of deadlockprevention by reducing the number of choices at eachrouting step. In the fault-free case, planar-adaptivenetworks are guaranteed to be deadlock-free. In thepresence of network faults, the planar-adaptive routercan be extended with misrouting to produce a working network which remains provably deadlock free andis provably livelock free. In addition, planar adaptivenetworks can simultaneously support both in-order andadaptive, out-of-order packet delivery.Planar-adaptive routing is of practical significance. Itprovides the simplest known support for deadlock-freeadaptive routing in k-ary n-cubes of more than twodimensions (with k &amp;gt; 2). Restricting adaptivity reduces the hardware complexity, improving router speedor allowing additional performance-enhancing networkfeatures. The structure of planar-adaptive routers isamenable to efficient implementation. </abstract>
<keyword> Keywords: Multicomputers, Routing Networks, Adaptive Routing, Deadlock Avoidance, Transmission-OrderPreservation, Fault Tolerance </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Learning to Retrieve Information </title>
<author> Brian Bartell </author>
<affiliation> Encylopdia Britannica andInstitute for Neural ComputationComputer Science &amp; EngineeringUniversity of California, San Diego </affiliation>
<address> La Jolla, California 92093 </address>
<author> Garrison W. Cottrell  </author>
<affiliation> Institute for Neural ComputationComputer Science &amp; EngineeringUniversity of California, San Diego </affiliation>
<address> La Jolla, California 92093 </address>
<author> Rik Belew </author>
<affiliation> Institute for Neural ComputationComputer Science &amp; EngineeringUniversity of California, San Diego </affiliation>
<address> La Jolla, California 92093 </address>
<abstract> AbstractInformation retrieval differs significantly from function approximation in that the goal is for the system to achieve the same rankingfunction of documents relative to queries as the user: the outputs ofthe system relative to one another must be in the proper order. Wehypothesize that a particular rank-order statistic, Guttman's pointalienation, is the proper objective function for such a system, anddemonstrate its efficacy by using it to find the optimal combinationof retrieval experts. In application to a commercial retrieval system,the combination performs 47% better than any single expert. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Segregating Planners and Their Environments </title>
<author> Scott D. AndersonPaul R. Cohen </author>
<affiliation> Experimental Knowledge Systems LaboratoryComputer Science Department, LGRCUniversity of Massachusetts </affiliation>
<address> Amherst MA 01003-4610 </address>
<email> fanderson,coheng@cs.umass.edu </email>
<note> To be published in the proceedings of theSpring Symposium on Integrated Planning Applications </note>
<abstract> AbstractBy implementing agents and environments using a domain-independent, extensible simulation substrate, described in thispaper, agents will have clean interfaces totheir environments. These makes it easierfor agents to be plugged into other environments that have been similarly defined. Ifagents can interact with multiple environments, their behaviors and the associatedexperimental results will be more generaland interesting. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Higher Bandwidth X </title>
<note> (Extended Abstract)Submitted to ACM MULTIMEDIA '94 </note>
<author> John Danskin  </author>
<affiliation> Princeton UniversityComputer Science Department </affiliation>
<address> Princeton NJ, 08540 </address>
<email> jmd@cs.princeton.edu </email>
<abstract> AbstractNetwork bandwidth has always been a key issue for multimedia protocols. Many potential users of networked multimedia protocols will continue to have low bandwidth networkconnections for some time: copper wire ISDN, infra-red, cellular modems, etc.. Compression provides potential relief for users of slow networks by increasing effective bandwidth.HBX introduces a new technique, based on arithmetic coding and statistical modeling, forcompressing structured data. Applied to the X networked graphics protocol, this techniqueyields 4.5:1 compression across a representative set of traces, performing twice as well as thepopular LZW-based Xremote compression protocol. HBX's coding techniques are generallyapplicable to the graphics and imaging subset of multimedia protocols. Future work willdetermine whether HBX's coding techniques can be applied to audio and video streams aswell. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Fast Volume Rendering Using a Shear-Warp Factorizationof the Viewing Transformation </title>
<author> Philippe Lacroute </author>
<affiliation> Computer Systems LaboratoryStanford University </affiliation>
<author> Marc Levoy </author>
<affiliation> Computer Science DepartmentStanford University </affiliation>
<abstract> AbstractSeveral existing volume rendering algorithms operate by factoring the viewing transformation into a 3D shear parallel to the dataslices, a projection to form an intermediate but distorted image,and a 2D warp to form an undistorted final image. We extendthis class of algorithms in three ways. First, we describe a newobject-order rendering algorithm based on the factorization that issignificantly faster than published algorithms with minimal lossof image quality. Shear-warp factorizations have the property thatrows of voxels in the volume are aligned with rows of pixels in theintermediate image. We use this fact to construct a scanline-basedalgorithm that traverses the volume and the intermediate image insynchrony, taking advantage of the spatial coherence present inboth. We use spatial data structures based on run-length encodingfor both the volume and the intermediate image. Our implementation running on an SGI Indigo workstation renders a 256 3 voxelmedical data set in one second. Our second extension is a shear-warp factorization for perspective viewing transformations, andwe show how our rendering algorithm can support this extension.Third, we introduce a data structure for encoding spatial coherencein unclassified volumes (i.e. scalar fields with no precomputedopacity). When combined with our shear-warp rendering algorithm this data structure allows us to classify and render a 256 3voxel volume in three seconds. The method extends to supportmixed volumes and geometry and is parallelizable. </abstract>
<keyword> CR Categories: I.3.7 [Computer Graphics]: Three-DimensionalGraphics and Realism; I.3.3 [Computer Graphics]: Picture/ImageGeneration|Display Algorithms.Additional Keywords: Volume rendering, Coherence, Scientificvisualization, Medical imaging. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<author> David Laur and Pat Hanrahan </author>
<affiliation>  Princeton University </affiliation>
<address> Princeton, NJ 08544, USA </address>
 <abstract> AbstractThis paper presents a progressive refinement algorithm forvolume rendering which uses a pyramidal volume representation. Besides storing average values, the pyramid storesestimated error, so an oct-tree can be fit to the pyramidgiven a user-supplied precision. This oct-tree is then drawnusing a set of splats, or footprints, each scaled to match thesize of the projection of a cell. The splats themselves are approximated with RGBA Gouraud-shaded polygons, so thatthey can be drawn efficiently on modern graphics workstations. The result is a real-time rendering algorithm suitablefor interactive applications. </abstract>
<keyword> CR Categories and Subject Descriptors: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism.Key Words: volume rendering, coherence, progressive refinement, interactive techniques. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Compression Performance of the Xremote Protocol </title>
<author> John Danskin Pat Hanrahan </author>
<affiliation> Department of Computer Science, Princeton University </affiliation>
<abstract> AbstractThe Xremote protocol is a compressed transformation of the X Window System protocol,designed to efficiently implement X connections across relatively slow serial lines. Using anXremote simulator and 11 traces of X sessions, we found that Xremote's overall compressionratio is 2.4:1. This figure varies widely depending on the trace. A study of compressionratio as a function of message type shows text based messages commonly achieving 3:1compression, while geometric messages usually achieve only 1.6:1 compression. By examining bandwidth requirements and compression performance as a function of time, we seethat Xremote performs adequately for some applications which are text based or which usesmall geometric datasets, except at application startup where more bandwidth is required.Further work is required to adequately support the initialization stage of X applications andmedium to large geometric databases. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Robust Meshes from Multiple Range Maps </title>
<author> Kari Pulli Tom Duchamp Hugues Hoppe John McDonald Linda Shapiro Werner Stuetzle  </author>
<affiliation> University of Washington, </affiliation>
 <address> Seattle, WA </address>
<affiliation> Microsoft Research, </affiliation>
 <address> Redmond, WA </address>
<abstract> AbstractThis paper presents a method for modeling the surfaceof an object from a sequence of range maps. Our methodis based on a volumetric approach that produces a compactsurface without boundary. It provides robustness throughthe use of interval analysis techniques and computationalefficiency through hierarchical processing using octrees. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Constraint Satisfaction Problem as a Causal Theory </title>
<author> Robert Rodosek </author>
<affiliation> University of Munich, Department of Computer Science </affiliation>
<address> Theresienstrae 39, 80333 Munich, Germany </address>
<email> rodosek@informatik.uni-muenchen.de </email>
<abstract> AbstractThe aim of this paper is to identify and to characterize the features that render one classof the Constraint Satisfaction Problem (CSP) computationally more efficient. Our approachis to search for a causal structure not only in the topology of the subsets of variables uponwhich the constraints are specified, but also in the nature of the constraints. Basically, thereshould exist an ordering of variables in the system such that an assignment of the variablescan be reached without backtracking. First, an approach of a causal structure is formulated,and second, an efficient procedure is provided (i) for deciding if such an ordering of variablesexists and, (ii) for identifying such an ordering whenever possible. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Dis-equality Constraints in Linear/IntegerProgramming </title>
<author> Mozafar T. Hajian </author>
<affiliation> IC-Parc, William Penny Laboratory, Imperial College, </affiliation>
<address>  London, SW7 2AZ. </address>
<email> mh10@doc.ic.ac.uk </email>
<date> June 21, 1996 </date>
<abstract> AbstractWe have proposed an extension to the definition of general integer linear programs (ILP) to accept dis-equality constraints explicitly. A new class of logicalvariables is introduced to transform the extended ILP in general form to standardform. Branch and Bound algorithm is modified to solve this new class of ILP. </abstract>
<keyword> Keywords: Mathematical Modelling, Linear/Integer Programming, Algorithms,Branch and Bound, Dis-equality Constraints. </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> THE AUTOMATED HIGHWAY SYSTEM: A TRANSPORTATIONTECHNOLOGY FOR THE 21ST CENTURY </title>
<author> M. Broucke and P. Varaiya 1 </author>
<affiliation> Department of Electrical Engineering and Computer ScienceUniversity of California, </affiliation>
 <address> Berkeley CA 94720 </address>
<email> mire, varaiya@eclair.eecs.berkeley.edu </email>
<abstract> Abstract. The current vehicle-highway system has reached a plateau in its abilityto meet the demand for moving goods and people. We sketch an architecture foran automated highway system or AHS. The architecture can be realized by severaldesigns that differ in terms of performance and sophistication. We describe one designthat could triple capacity and reduce travel time; guarantee collision-free operationin the absence of malfunctions; limit performance degradation in the case of faults;and reduce emissions by half. We summarize evidence suggesting that the design canbe implemented. We indicate how the design can be adapted to different urban andrural scenarios and how a standard land use model can show the impact of AHS onurban density. We conclude with a critique of AHS. </abstract>
<keyword> Keywords. Automated vehicles, hierarchical control </keyword>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Parallel Implementation of an MPEG1 Encoder:Faster Than Real-Time! </title>
<author> Ke Shen , Lawrence A. Rowe and Edward J. Delp  </author>
<affiliation> Computer Vision and Image Processing LaboratorySchool of Electrical EngineeringPurdue University </affiliation>
<address> West Lafayette, Indiana </address>
<affiliation> Computer Science DivisionDepartment of Electrical Engineering and Computer ScienceUniversity of California </affiliation>
<address> Berkeley, California </address>
<abstract> ABSTRACTIn this paper we present an implementation of an MPEG1 encoder on the Intel Touchstone Delta and IntelParagon parallel computers. We describe the unique aspects of mapping the algorithm onto the parallelmachines and present several versions of the algorithms. We will show that I/O contention can be a bottleneckrelative to performance. We will also describe how the Touchstone Delta and Paragon can be used to compressvideo sequences faster than real-time. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Kin Recognition, Similarity, and Group Behavior </title>
<author> Maja J Mataric </author>
<affiliation> MIT Artificial Intelligence Laboratory </affiliation>
<address> 545 Technology Square #721Cambridge, MA 02139 </address>
<phone> phone: (617) 253-8839 </phone><phone> fax: (617) 253-0039 </phone><email> maja@ai.mit.edu </email>
<abstract> AbstractThis paper presents an approach to describinggroup behavior using simple local interactionsamong individuals. We propose that for a givendomain a set of basic interactions can be definedwhich describes a large variety of group behaviors.The methodology we present allows for simplifiedqualitative analysis of group behavior through theuse of shared goals, kin recognition, and minimalcommunication. We also demonstrate how thesebasic interactions can be simply combined intomore complex compound group behaviors.To validate our approach we implemented an array of basic group behaviors in the domain of spatial interactions among homogeneous agents. Wedescribe some of the experimental results from twodistinct domains: a software environment, and acollection of 20 mobile robots. We also describea compound behavior involving a combination ofthe basic interactions. Finally, we compare theperformance of homogeneous groups to those ofdominance hierarchies on the same set of basic behaviors. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Structuring Graphical Paradigms in TkGofer </title>
<author> Koen Claessen </author>
<affiliation> OGI and Utrecht University </affiliation>
<email> koen@cse.ogi.edu </email>
<author> Ton Vullinghs </author>
<affiliation> Universitat Ulm </affiliation>
<email> ton@informatik.uni-ulm.de </email>
<author> Erik Meijer </author>
<affiliation> OGI and Utrecht University </affiliation>
<email> erik@cse.ogi.edu </email>
<abstract> AbstractIn this paper we describe the implementation of severalgraphical programming paradigms (Model View Controller,Fudgets, and Functional Animations) using the GUI libraryTkGofer. This library relies on a combination of monadsand multiple-parameter type classes to provide an abstract,type safe interface to Tcl/Tk. We show how choosing theright abstractions makes the given implementations surprisingly concise and easy to understand. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> REWRITING METHODSFOR WORD PROBLEMS  </title>
<author> NACHUM DERSHOWITZ </author>
<affiliation> Department of Computer Science, University of Illinois at Urbana-Champaign, </affiliation>
<address> 1304 West Springfield Ave., Urbana, IL 61801-2987, U.S.A. </address>
<abstract> AbstractThis paper outlines various recent approaches to solving word problems.Term orderings are used to define a terminating rewrite relation. When confluent, that relation defines unique normal forms that can be used to decide wordproblems. Some results obtained by these methods are summarized. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Disk Packings and Planar Separators </title>
<author> Daniel A. Spielman  </author>
<affiliation> U.C. Berkeley/MIT </affiliation>
<author> Shang-Hua Teng  </author>
<affiliation> University of Minnesota </affiliation>
<abstract> AbstractWe demonstrate that the geometric separator algorithm of Miller, Teng, Thurston, and Vavasis finds a3=4-separator of size 1:84pn for every n node planargraph. Our bound is derived from an analysis of diskpackings on the sphere. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> THE PRACTICAL VALUE OF N-GRAMS INGENERATION </title>
<author> Irene Langkilde and Kevin Knight </author>
<affiliation> Information Sciences InstituteUniversity of Southern California </affiliation>
<address> Marina del Rey, CA 90292 </address>
<email> ilangkil@isi.edu and knight@isi.edu </email>
<abstract> AbstractWe examine the practical synergy between symbolic and statistical language processing in a generatorcalled Nitrogen. The analysis provides insight into the kinds of linguistic decisions that bigram frequencystatistics can make, and how it improves scalability. We also discuss the limits of bigram statisticalknowledge. We focus on specific examples of Nitrogen's output. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Building Interpreters by Composing Monads </title>
<author> Guy L. Steele Jr. </author>
<affiliation> Thinking Machines Corporation </affiliation>
<address> 245 First StreetCambridge, Massachusetts 02142 </address>
<phone> (617) 234-2860 </phone><email> gls@think.com </email>
<abstract> Abstract: We exhibit a set of functions coded inHaskell that can be used as building blocks to constructa variety of interpreters for Lisp-like languages. Thebuilding blocks are joined merely through functionalcomposition. Each building block contributes code tosupport a specific feature, such as numbers, continuations, functions calls, or nondeterminism. The result ofcomposing some number of building blocks is a parser,an interpreter, and a printer that support exactly theexpression forms and data types needed for the combined set of features, and no more.The data structures are organized as pseudomonads,a generalization of monads that allows composition.Functional composition of the building blocks impliestype composition of the relevant pseudomonads.Our intent was that the Haskell type resolution system ought to be able to deduce the approprate datatypes automatically. Unfortunately there is a deficiencyin current Haskell implementations related to recursivedata types: circularity must be reflected statically in thetype definitions.We circumvent this restriction by applying a purpose-built program simplifier that performs partial evaluationand a certain amount of program algebra. We constructa wide variety of interpreters in the style of Wadler bystarting with the building blocks and a page of boiler-plate code, writing three lines of code (one to specify thebuilding blocks and two to (redundantly) specify typecompositions), and then applying the simplifier. Theresulting code is acceptable Haskell code.We have tested a dozen different interpreters withvarious combinations of features. In this paper we discuss the overall code structuring strategy, exhibit several building blocks, briefly describe the partial evaluator, and present a number of automatically generatedinterpreters. </abstract>
<note> This is a preprint of a paper that is to appearin the Proceedings of the Twenty-first Annual ACMSIGPLAN-SIGACT Symposium on Principles of Programming Languages, January 1994. </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> RESTORATION OF LOSSY COMPRESSED NOISY IMAGES </title>
<author> Osama K. Al-Shaykh 1 Russell M. Mersereau 2 </author>
<affiliation> School of Electrical and Computer EngineeringGeorgia Institute of Technology </affiliation>
<email> 1 osamakl@eedsp.gatech.edu </email>
<email> 2 rmm@eedsp.gatech.edu </email>
<abstract> ABSTRACTA restoration algorithm for estimating lossy compressedimages that are corrupted by data-dependent Poisson noiseis presented. The algorithm is based on modeling the imageas a Markov random field (MRF) that penalizes the blocking artifact. The effectiveness of the proposed algorithm isillustrated using synthetic and real images. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Theory and Design of Multidimensional QMF Sub-Band Filters From1-D Filters Using Transforms </title>
<author> I.A. Shah A.A.C. Kalker </author>
<affiliation> Philips Research Laboratories, </affiliation>
<address> P.O. Box 80.000, 5600 JA Eindhoven, The Netherlands </address>
<email> Net: kalker@prl.philips.nl, shah@prl.philips.nl </email>
<abstract> AbstractThe paper presents the general theory of designingmultidimensional Quadrature Mirror Filters (QMF),for use in sub-band coding (SBC) systems, using theMcClellan transform [1]. It was recently shown thatMcClellan transform could be used to generate 2-Ddiamond shape QMF filters [2]. In this paper we willformalize the proofs of the diamond shape case, andgeneralize it to other shapes, sampling rasters anddimensions. Examples are given of two dimensionaldiamond shape filters and three dimensional tetradfilters designed using the technique. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Optimal Multiple Description TransformCoding of Gaussian Vectors </title>
<author> Vivek K Goyal </author>
<affiliation> Dept. of Elec. Eng. &amp; Comp. Sci.University of California, Berkeley </affiliation>
<email> v.goyal@ieee.org </email>
<author> Jelena Kovacevic </author>
<affiliation> Bell Laboratories </affiliation>
<address> Murray Hill, NJ </address>
<email> jelena@bell-labs.com </email>
<note> Proc. IEEE Data Compression Conference 1998, pp. 388-397. c fl1998 IEEEIncludes minor corrections. </note>
<abstract> AbstractMultiple description coding (MDC) is source coding for multiple channelssuch that a decoder which receives an arbitrary subset of the channels may produce a useful reconstruction. Orchard et al. [1] proposed a transform codingmethod for MDC of pairs of independent Gaussian random variables. This paper provides a general framework which extends multiple description transformcoding (MDTC) to any number of variables and expands the set of transformswhich are considered. Analysis of the general case is provided, which can beused to numerically design optimal MDTC systems. The case of two variablessent over two channels is analytically optimized in the most general settingwhere channel failures need not have equal probability or be independent. Itis shown that when channel failures are equally probable and independent, thetransforms used in [1] are in the optimal set, but many other choices are possible. A cascade structure is presented which facilitates low-complexity design,coding, and decoding for a system with a large number of variables. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> 16 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 44, NO. 1, JANUARY 1998 </note>
<title> Quantized Overcomplete Expansions in RNAnalysis, Synthesis, and Algorithms </title>
<author> Vivek K Goyal, Student Member, IEEE, Martin Vetterli, Fellow, IEEE,and Nguyen T. Thao, Member, IEEE </author>
<abstract> Abstract|Coefficient quantization has peculiar qualitativeeffects on representations of vectors in R N with respect toovercomplete sets of vectors. These effects are investigatedin two settings: frame expansions (representations obtainedby forming inner products with each element of the set)and matching pursuit expansions (approximations obtainedby greedily forming linear combinations). In both cases,based on the concept of consistency, it is shown that traditional linear reconstruction methods are suboptimal, andbetter consistent reconstruction algorithms are given. Theproposed consistent reconstruction algorithms were in eachcase implemented, and experimental results are included.For frame expansions, results are proven to bound distortion as a function of frame redundancy r and quantizationstep size for linear, consistent, and optimal reconstructionmethods. Taken together, these suggest that optimal reconstruction methods will yield O(1=r 2 ) MSE, and that consistency is sufficient to insure this asymptotic behavior. Aresult on the asymptotic tightness of random frames is alsoproven.Applicability of quantized matching pursuit to lossy vector compression is explored. Experiments demonstrate thelikelihood that a linear reconstruction is inconsistent, theMSE reduction obtained with a nonlinear (consistent) reconstruction algorithm, and generally competitive performanceat low bit rates. </abstract>
<keyword> Keywords| quantization, source coding, frames, matchingpursuit, consistent reconstruction, optimal reconstruction,overcomplete representations, MSE bounds </keyword>
<intro> I. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Planning and Proof Planning </title>
<author> Erica Melis 1 and Alan Bundy 2 </author>
<abstract> Abstract. The paper adresses proof planning as a specific AI planning. It describes some peculiarities of proof planning and discussessome possible cross-fertilization of planning and proof planning. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Role of Learning in Autonomous Robots </title>
<author> Rodney A. Brooks </author>
 <affiliation> MIT Artificial Intelligence Laboratory </affiliation>
 <address> 545 Technology Square Cambridge, MA 02139 </address>
 <email> brooks@ai.mit.edu </email>
<abstract> AbstractApplications of learning to autonomousagents (simulated or real) have often beenrestricted to learning a mapping from perceived state of the world to the next actionto take. Often this is couched in terms oflearning from no previous knowledge. Thisgeneral case for real autonomous robots isvery difficult. In any case, when building areal robot there is usually a lot of a prioriknowledge (e.g., from the engineering thatwent into its design) which doesn't need tobe learned. We describe the behavior-basedapproach to autonomous robots, and then examine four classes of learning problems associated with such robots. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Appears in M. Mozer, M. Jordan and T. Petsche, eds., Advances In Neural Information Processing Systems 9, MIT Press, 1997 </note>
<title> Predicting Lifetimes in DynamicallyAllocated Memory </title>
<author> David A. Cohn </author>
<affiliation> Adaptive Systems GroupHarlequin, Inc. </affiliation>
<address> Menlo Park, CA 94025 </address>
<email> cohn@harlequin.com </email>
<author> Satinder Singh </author>
<affiliation> Department of Computer ScienceUniversity of Colorado </affiliation>
<address> Boulder, CO 80309 </address>
<email> baveja@cs.colorado.edu </email>
<abstract> AbstractPredictions of lifetimes of dynamically allocated objects can be usedto improve time and space efficiency of dynamic memory management in computer programs. Barrett and Zorn [1993] used a simplelifetime predictor and demonstrated this improvement on a varietyof computer programs. In this paper, we use decision trees to dolifetime prediction on the same programs and show significantlybetter prediction. Our method also has the advantage that duringtraining we can use a large number of features and let the decisiontree automatically choose the relevant subset. </abstract>
<intro> 1 INTELLIGENT MEMORY ALLOCATION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Perturbation Scheme for Spherical Arrangementswith Application to Molecular Modeling  </title>
<author> Dan Halperin  </author>
<affiliation> Tel Aviv University </affiliation>
<author> Christian R. Shelton  </author>
<affiliation> Massachusetts Institute of Technology </affiliation>
<date> July 31, 1997 </date>
<abstract> AbstractWe describe a software package for computing and manipulating the subdivision of a sphereby a collection of (not necessarily great) circles and for computing the boundary surface of theunion of spheres. We present problems that arise in the implementation of the software and thesolutions that we have found for them. At the core of the paper is a novel perturbation scheme toovercome degeneracies and precision problems in computing spherical arrangements while usingfloating point arithmetic. The scheme is relatively simple, it balances between the efficiencyof computation and the magnitude of the perturbation, and it performs well in practice. Wereport and discuss experimental results. Our package is a major component in a larger packageaimed to support geometric queries on molecular models; it is currently employed by chemistsworking in `rational drug design.' The spherical subdivisions are used to construct a geometricmodel of a molecule where each sphere represents an atom. We also give an overview of themolecular modeling package and detail additional features and implementation issues. </abstract>
<note> This work has been supported in part by a grant from Pfizer Central Research. Dan Halperin has also beensupported by an Alon Fellowship, by ESPRIT IV LTR Project No. 21957 (CGAL), and by the Hermann Minkowski </note>
<affiliation> - Minerva Center for Geometry at Tel Aviv University. </affiliation>
<affiliation> Department of Computer Science, Tel Aviv University, </affiliation>
 <address> Tel Aviv 69978, Israel. </address>
 <email> E-mail:halperin@math.tau.ac.il. </email>
<affiliation> Department of Computer Science, MIT, </affiliation>
 <address> Cambridge, MA 02139. </address>
 <email> E-mail: cshelton@ai.mit.edu. </email>
 <note> Part of thework on this paper was carried out while Christian Shelton was at the Department of Computer Science, StanfordUniversity </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Observations on Cognitive Judgments </title>
<author> David McAllester </author>
<email> dam@ai.mit.edu </email>
<abstract> AbstractIt is obvious to anyone familiar with the rules of the game of chessthat a king on an empty board can reach every square. It is true, butnot obvious, that a knight can reach every square. Why is the firstfact obvious but the second fact not? This paper presents an analytictheory of a class of obviousness judgments of this type. Whether ornot the specifics of this analysis are correct, it seems that the study ofobviousness judgments can be used to construct integrated theories oflinguistics, knowledge representation, and inference. </abstract>
<note> This report describes research done at the Artificial Intelligence Laboratory of the MassachusettsInstitute of Technology. Support for the work described in this paper was provided in part byMisubishi Electric Research Laboratories, Inc. Support for the laboratory's artificial intelligenceresearch is provided in part by the Advanced Research Projects Agency of the Department ofDefense under Office of Naval Research contract N00014-85-K-0124.This paper appeared in AAAI-91. A postscript electronic source for this paper can be found inftp.ai.mit.edu:/pub/dam/aaai91a.ps. A bibtex reference can be found in ftp.ai.mit.edu:/pub/dam/dam.bib. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Taxonomic Syntax for First Order Inference </title>
<author> DAVID MCALLESTER and ROBERT GIVAN </author>
<affiliation> Massachusetts Institute of Technology, Cambridge Massachusetts </affiliation>
<abstract> Abstract: We identify a new polynomial time decidable fragment of first orderlogic and present a general method for using polynomial time inference proceduresin knowledge representation systems. Our results indicate that a non-standard"taxonomic" syntax is essential in constructing natural and powerful polynomialtime inference procedures. The central role of taxonomic syntax in our polynomial time inference procedures provides technical support for the often expressedintuition that knowledge is better represented in terms of taxonomic relationshipsthan classical first order formulas. To use our procedures in a knowledge representation system we define a "Socratic proof system" which is complete for firstorder inference and which can be used as a semi-automated interface to a firstorder knowledge base. </abstract>
<keyword> Categories and Subject Descriptors: F.4.1 [Mathematical Logic and Formal Languages]: Mathematical logic | computational logic, mechanical theoremproving; I.2.3 [Artificial Intelligence]: Deduction and Theorem Proving | deductionGeneral Terms: Deduction, AlgorithmsAdditional Keywords and Phrases: Proof Theory, Machine Inference, Theorem Proving, Automated Reasoning, Polynomial Time Algorithms, InferenceRules, Proof Systems, Mechanical Verification. </keyword>
<note> This research was supported in part by National Science Foundation Grant IRI-8819624 and in part by the Advanced Research Projects Agency of the Departmentof Defense under Office of Naval Research contract N00014-85-K-0124 and N00014-89-J-3202. </note>
<note> Author's Address: </note>
 <affiliation> MIT Artificial Intelligence Laboratory, </affiliation>
 <address> 545 Technology Square,Cambridge Mass, 02139, </address>
 <email> DAM@ai.mit.edu </email>
<note> This paper appeared in JACM, vol. 40, no. 2, April 1993. A postscript electronic sourcefor this paper can be found in ftp.ai.mit.edu:/pub/dam/jacm1.ps. A bibtex reference canbe found in internet file ftp.ai.mit.edu:/pub/dam/dam.bib. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> MASSACHUSETTS INSTITUTE OF TECHNOLOGYARTIFICIAL INTELLIGENCE LABORATORY </affiliation>
<pubnum> A.I. Memo No. 1591 </pubnum>
<date> November, 1996 </date>
<title> Complex Feature Recognition: ABayesian Approach for Learning toRecognize Objects </title>
<author> Paul A. Viola </author>
<note> This publication can be retrieved by anonymous ftp to publications.ai.mit.edu. </note>
<abstract> AbstractWe have developed a new Bayesian framework for visual objectrecognition which is based on the insight that images of objects can bemodeled as a conjunction of local features. This framework can be usedto both derive an object recognition algorithm and an algorithm forlearning the features themselves. The overall approach, called complexfeature recognition or CFR, is unique for several reasons: it is broadlyapplicable to a wide range of object types, it makes constructing objectmodels easy, it is capable of identifying either the class or the identityof an object, and it is computationally efficient requiring time proportional to the size of the image.Instead of a single simple feature such as an edge, CFR uses a largeset of complex features that are learned from experience with modelobjects. The response of a single complex feature contains much moreclass information than does a single edge. This significantly reduces thenumber of possible correspondences between the model and the image.In addition, CFR takes advantage of a type of image processing calledoriented energy. Oriented energy is used to efficiently pre-process theimage to eliminate some of the difficulties associated with changes inlighting and pose. </abstract>
<note> Copyright c Massachusetts Institute of Technology, 1996This report describes research done at the Artificial Intelligence Laboratory of the MassachusettsInstitute of Technology. Support for this research was provided in part by the Advanced ResearchProjects Agency of the Department of Defense under Office of Naval Research contract N00014-96-1-0311. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Anatomical origin and computational role of diversityin the response properties of cortical neurons  </title>
<author> Kalanit Grill Spectory Shimon Edelmany Rafael Malachz </author>
<affiliation> Departments of Applied Mathematics and Computer Science and Neurobiology </affiliation>
<affiliation> The Weizmann Institute of Science </affiliation>
<address> Rehovot 76100, Israel </address>
<email> fkalanit,edelmang@wisdom.weizmann.ac.il bnmalach@weizmann.weizmann.ac.il </email>
<abstract> AbstractThe maximization of diversity of neuronal response properties has been recently suggestedas an organizing principle for the formation of such prominent features of the functionalarchitecture of the brain as the cortical columns and the associated patchy projection patterns(Malach, 1994). We report a computational study of two aspects of this hypothesis. First, weshow that maximal diversity is attained when the ratio of dendritic and axonal arbor sizes isequal to one, as it has been found in many cortical areas and across species (Lund et al., 1993;Malach, 1994). Second, we show that maximization of diversity leads to better performance intwo case studies: in systems of receptive fields implementing steerable/shiftable filters, and inmatching spatially distributed signals, a problem that arises in visual tasks such as stereopsis,motion processing, and recognition. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Toward an Analysis of Forward Pruning </title>
<author> Stephen J. J. Smith </author>
<affiliation> Computer Science DepartmentUniversity of Maryland </affiliation>
<address> College Park, MD 20740 </address>
<email> sjsmith@cs.umd.edu </email>
<author> Dana S. Nau </author>
<affiliation> Institute for Advanced Computer Studies,Computer Science Department,and Institute for Systems ResearchUniversity of Maryland </affiliation>
<address> College Park, MD 20740 </address>
<email> nau@cs.umd.edu </email>
<date> June 30, 1993 </date>
<abstract> AbstractSeveral early game-playing computer programs used forward pruning (i.e., the practice ofdeliberately ignoring nodes that are believed unlikely to affect a game tree's minimax value),but this technique did not seem to result in good decision-making. The poor performance offorward pruning presents a major puzzle for AI research on game playing, because some versionof forward pruning seems to be "what people do," and the best chess-playing programs still donot play as well as the best humans.As a step toward deeper understanding of how forward pruning affects quality of play, inthis paper we set up a model of forward pruning on two abstract classes of binary game trees,and we use this model to investigate how forward pruning affects the accuracy of the minimaxvalues returned. The primary result of our study is that forward pruning does better when thereis a high correlation among the minimax values of sibling nodes in a game tree.This result suggests that forward pruning may possibly be a useful decision-making techniquein certain kinds of games. In particular, we believe that bridge may be such a game. </abstract>
<note> Address correspondence to </note>
 <author> Dana S. Nau, </author>
 <affiliation> Computer Science Dept., University of Maryland, </affiliation>
<address> College Park, MD 20742. </address>
<note> This work supported in part by an AT&amp;T Ph.D. scholarship to Stephen J. J. Smith, Maryland Industrial Partnerships (MIPS) grant 501.15, Great Game Products, and NSF grants IRI-8907890 and NSFD CDR-88003012. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Parametric Models are Versatile:The Case of Model Based Optimization </title>
<author> P. Fua </author>
<affiliation> Artificial Intelligence CenterSRI International </affiliation>
<address> 333 Ravenswood AvenueMenlo Park, California 94025 </address>
<abstract> AbstractModel-Based Optimization (MBO) is a paradigm in which an objective function is used to expressboth geometric and photometric constraints on features of interest. A parametric model of a feature(such as a road, a building, or coastline) is extracted from one or more images by adjusting the model'sstate variables until a minimum value of the objective function is obtained. The optimization procedureyields a description that simultaneously satisfies (or nearly satisfies) all constraints, and, as a result, islikely to be a good model of the feature. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Data-Flow Graphical User Interface for Querying a ScientificDatabase  </title>
<author> Bosco S. Tjan, Leonard Breslow, Sait Dogru, Vijay Rajan,Keith Rieck, James R. Slagle, and Marius O. Poliac </author>
<affiliation> Computer Science DepartmentUniversity of Minnesota, </affiliation>
 <address> Minneapolis MN 55455 </address>
<abstract> AbstractWe describe the design principles and functionalityof a visual query language called SeeQL that represents data retrieval and analysis operations as a data-flow graph. A query is viewed as a sequence of relational algebra and other data transformation operations applied to database tables. The language is well-suited for large-scale scientific database applications,where data analysis is a major component and the typical queries or data retrieval patterns are unrestricted.The language provides a flexible yet easy-to-use environment for database access and data analysis fornon-programmer research scientists. We have implemented this language in a system being used in a long-term data-intensive highway pavement research project(MnRoad) conducted by the Minnesota Department ofTransportation. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Cooperative Bayesian and Case-Based Reasoningfor Solving Multiagent Planning Tasks  </title>
<author> David W. Aha &amp; Li Wu Chang </author>
<affiliation> Navy Center for Applied Research in AINaval Research Laboratory, </affiliation>
 <address> Code 5510Washington, DC 20375 </address>
<email> faha; liwug@aic.nrl.navy.mil </email>
<phone> (202) 767-2884 / FAX: 767-3172 </phone><date> January 25, 1996 </date>
<abstract> AbstractWe describe an integrated problem solving architecture named INBANCA inwhich Bayesian networks and case-based reasoning (CBR) work cooperatively onmultiagent planning tasks. This includes two-team dynamic tasks, and this paperconcentrates on simulated soccer as an example. Bayesian networks are used to characterize action selection whereas a case-based approach is used to determine how toimplement actions. This paper has two contributions. First, we survey integrationsof case-based and Bayesian approaches from the perspective of a popular CBR taskdecomposition framework, thus explaining what types of integrations have been attempted. This allows us to explain the unique aspects of our proposed integration.Second, we demonstrate how Bayesian nets can be used to provide environmentalcontext, and thus feature selection information, for the case-based reasoner. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Cloud Classification Using Error-Correcting Output Codes </title>
<author> David W. Aha </author>
<affiliation> Navy Center for Applied Research in Artificial IntelligenceNaval Research Laboratory </affiliation>
<address> Washington, DC 20375 </address>
<email> aha@aic.nrl.navy.mil </email>
<author> Richard L. Bankert </author>
<affiliation> Marine Meteorology DivisionNaval Research Laboratory </affiliation>
<address> Monterey, CA 93943 </address>
<email> bankert@nrlmry.navy.mil </email>
<date> October 30, 1996 </date>
<note> Submission to AI Applications: Natural Resources, Agriculture, and Environmental Science.Corresponding author: The first author is the corresponding author for this submission. David'sphone number is (202) 767-9006 and FAX number is (202) 767-3172.Suggested running head: "Cloud Classification Using Error-Correcting Output Codes"Available as NCARAI Technical Note AIC-96-024 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> THE LOAD, CAPACITY AND AVAILABILITY OF QUORUMSYSTEMS  </title>
<author> MONI NAOR AND AVISHAI WOOL  </author>
<abstract> Abstract.A quorum system is a collection of sets (quorums) every two of which intersect. Quorum systemshave been used for many applications in the area of distributed systems, including mutual exclusion,data replication and dissemination of informationGiven a strategy to pick quorums, the load L(S) is the minimal access probability of the busiestelement, minimizing over the strategies. The capacity Cap(S) is the highest quorum accesses ratethat S can handle, so Cap(S) = 1=L(S).The availability of a quorum system S is the probability that at least one quorum survives,assuming that each element fails independently with probability p. A tradeoff between L(S) and theavailability of S is shown.We present four novel constructions of quorum system, all featuring optimal or near optimalload, and high availability. The best construction, based on paths in a grid, has a load of O(1=pand a failure probability of exp((pn)) when the elements fail with probability p &amp;lt; 12 . Moreover,even in the presence of faults, with exponentially high probability the load of this system is stillO(1=n). The analysis of this scheme is based on Percolation Theory. </abstract>
<keyword> Key words. quorum systems, load, fault tolerance, distributed computing, percolation theory,linear programming. </keyword>
<note> AMS subject classifications. 60K35, 62N05, 68M10, 68Q22, 68R05, 90A28, 90C05. </note>
<intro> 1. Introduction. </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Practical Data Breakpoints: Design and Implementation </title>
<author> Robert Wahbe Steven Lucco Susan L. Graham  </author>
<affiliation> Computer Science Division, </affiliation>
 <address> 571 Evans Hall </address>
<affiliation> UC Berkeley, </affiliation>
 <address> Berkeley CA, 94720 </address>
<abstract> AbstractA data breakpoint associates debugging actions withprogrammer-specified conditions on the memory stateof an executing program. Data breakpoints providea means for discovering program bugs that are tedious or impossible to isolate using control breakpointsalone. In practice, programmers rarely use data break-points, because they are either unimplemented or prohibitively slow in available debugging software. In thispaper, we present the design and implementation of apractical data breakpoint facility.A data breakpoint facility must monitor all memoryupdates performed by the program being debugged.We implemented and evaluated two complementarytechniques for reducing the overhead of monitoringmemory updates. First, we checked write instructionsby inserting checking code directly into the programbeing debugged. The checks use a segmented bitmapdata structure that minimizes address lookup complexity. Second, we developed data flow algorithmsthat eliminate checks on some classes of write instructions but may increase the complexity of the remainingchecks.We evaluated these techniques on the Sparc usingthe spec benchmarks. Checking each write instruc </abstract>
<note> This research was sponsored in part by the Defense Advanced Research Projects Agency under grant MDA972-92-J-1028 and contract DABT63-92-C-0026. The content of the paper does not necessarily reflect the position or the policy of theGovernment and no official endorsement should be inferred. </note>
<email> Email: frwahbe, lucco, grahamg@cs.berkeley.edu </email>
<note> To appear in Proceedings of the ACM SIGPLAN'93 Symposium on Programming Language Design and Implementation, Albuquerque, NM, June 23-25 1993. </note>
<abstract> tion using a segmented bitmap achieved an averageoverhead of 42%. This overhead is independent of thenumber of breakpoints in use. Data flow analysis eliminated an average of 79% of the dynamic write checks.For scientific programs such the nas kernels, analysisreduced write checks by a factor of ten or more. On theSparc these optimizations reduced the average overhead to 25%. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<web> URL: http://www.cam.sri.com/tr/crc033/paper.ps.Z </web> <note> Eurospeech, Berlin, 1993 </note>
<title> A SPEECH-BASED ROUTE ENQUIRY SYSTEM BUILT FROMGENERAL-PURPOSE COMPONENTS 1 </title>
<author> Ian Lewin , Martin Russell , David Carter , Sue Browning , Keith Ponting and Stephen Pulman  </author>
<affiliation> SRI International, </affiliation>
 <address> 23 Millers Yard, Cambridge, CB2 1RQ, UK </address>
<affiliation> Speech Research Unit, DRA Malvern, </affiliation>
 <address> St Andrews Road, Malvern, Worcs, WR14 3PS, UK </address>
<abstract> ABSTRACTThe adaptation of existing general-purpose speech recognition and language understanding systems can greatlyreduce the cost of developing applications. However, thecomponents must have appropriate characteristics for thisto be possible.Work is in progress to adapt two task-independentcomponents, the AURIX speech recognizer and the CLARElanguage processor to create a system allowing spokenqueries of the PC-based Autoroute route planning package. </abstract>
<keyword> Keywords: adaptability, general purpose, speech recognition, language understanding, AURIX, CLARE </keyword>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<web> URL: http://www.cam.sri.com/tr/crc044/paper.ps.ZARPA </web> <note> (HLT) Proceedings, Princeton, 1994 </note>
<title> Combining Knowledge Sourcesto Reorder N-Best Speech Hypothesis Lists </title>
<author> Manny Rayner 1 , David Carter 1 , Vassilios Digalakis 2 , Patti Price 2 </author>
<affiliation> (1) SRI International, </affiliation>
 <address> Suite 23, Millers Yard, Cambridge CB2 1RQ, UK </address>
<affiliation> (2) SRI International, </affiliation>
 <address> 333 Ravenswood Ave., Menlo Park, CA 94025, USA </address>
<date> November 29, 1994 </date>
<abstract> AbstractA simple and general method is described that can combine differentknowledge sources to reorder N-best lists of hypotheses produced by aspeech recognizer. The method is automatically trainable, acquiring information from both positive and negative examples. Experiments aredescribed in which it was tested on a 1000-utterance sample of unseenATIS data. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> AAAI-98, Madison, WI, to appear </note>
<title> Needles in a Haystack : Plan Recognition in Large SpatialDomains Involving Multiple Agents </title>
<author> Mark Devaney and Ashwin Ram </author>
<affiliation> College of ComputingGeorgia Institute of Technology </affiliation>
<address> Atlanta, GA 30332-0280 </address>
<email> markd@cc.gatech.eduashwin@cc.gatech.edu </email>
<abstract> AbstractWhile plan recognition research has been applied to awide variety of problems, it has largely made identical assumptions about the number of agents participating in the plan, the observability of the plan execution process, and the scale of the domain. We describe a method for plan recognition in a real-worlddomain involving large numbers of agents performingspatial maneuvers in concert under conditions of limited observability. These assumptions differ radicallyfrom those traditionally made in plan recognition andproduce a problem which combines aspects of the fieldsof plan recognition, pattern recognition, and objecttracking. We describe our initial solution which borrows and builds upon research from each of these areas,employing a pattern-directed approach to recognize individual movements and generalizing these to produceinferences of large-scale behavior. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Multistrategy Learning of Adaptive Reactive Controllers </title>
<author> Juan Carlos Santamara and Ashwin Ram </author>
<affiliation> College of ComputingGeorgia Institute of Technology </affiliation>
<address> Atlanta, Georgia 30332-0280 </address>
<email> E-mail: fcarlos,ashwing@cc.gatech.edu </email>
<phone> Phone: (404) 894-4995Fax: (404) 894-9846 </phone><pubnum> Technical Report GIT-CC-97-05 </pubnum>
<date> January 1997 </date>
<abstract> AbstractReactive controllers has been widely used in mobile robots since they are able to achieve successful performance in real-time. However, the configuration of a reactive controller dependshighly on the operating conditions of the robot and the environment; thus, a reactive controllerconfigured for one class of environments may not perform adequately in another. This paperpresents a formulation of learning adaptive reactive controllers. Adaptive reactive controllersinherit all the advantages of traditional reactive controllers, but in addition they are able to adjust themselves to the current operating conditions of the robot and the environment in order toimprove task performance. Furthermore, learning adaptive reactive controllers can learn whenand how to adapt the reactive controller so as to achieve effective performance under differentconditions. The paper presents an algorithm for a learning adaptive reactive controller thatcombines ideas from case-based reasoning and reinforcement learning to construct a mappingbetween the operating conditions of a controller and the appropriate controller configuration;this mapping is in turn used to adapt the controller configuration dynamically. As a casestudy, the algorithm is implemented in a robotic navigation system that controls a DenningMRV-III mobile robot. The system is extensively evaluated using statistical methods to verifyits learning performance and to understand the relevance of different design parameters on theperformance of the system. </abstract>
<keyword> Keywords: Reactive control, multistrategy learning, case-based reasoning, reinforcement learning,robotic navigation. </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> The State of the Art in Ontology Design:A Survey and Comparative Review </title>
<author> Natalya Fridman NoyCarole D. Hafner </author>
<affiliation> College of Computer ScienceNortheastern University </affiliation>
<address> Boston, MA 02115 </address>
<email> -natasha, hafner-@ccs.neu.edu </email>
<abstract> AbstractIn this paper we develop a framework for comparingontologies, and place a number of the moreprominent ontologies into it. We have selected 10specific projects for this study, including generalontologies, domain specific ones, and one knowledgerepresentation system. The comparison frameworkincludes general characteristics such as the purpose ofan ontology, its coverage (general or domain-specific), its size, and the formalism used. It alsoincludes the design process used in creating anontology and the methods used to evaluate it.Characteristics that describe the content of anontology include taxonomic organization, types ofconcepts covered, top-level divisions, internalstructure of concepts, representation of part-wholerelations, and the presence and nature of additionalaxioms. Finally we consider what experiments orapplications have used the ontologies. Knowledgesharing and reuse will require a common frameworkto support interoperability of independently createdontologies. Our study shows there is great diversityin the way ontologies are designed and the way theyrepresent the world. By identifying the similaritiesand differences among existing ontologies, we clarifythe range of alternatives in creating a standardframework for ontology design. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Adaptive Markov Chain Monte Carlo throughRegeneration </title>
<author> Walter R. Gilks </author>
<affiliation> Medical Research CouncilBiostatistics Unit </affiliation>
<address> Cambridge, CB2 2SR, UK. </address>
<author> Gareth O. Roberts </author>
<affiliation> Statistical LaboratoryUniversity of Cambridge </affiliation>
<address> Cambridge, CB2 1SB, UK. </address>
<author> Sujit K. Sahu </author>
<affiliation> School of MathematicsUniversity of Wales, Cardiff </affiliation>
<address> Cardiff, CF2 4YH, UK. </address>
<date> January 26, 1998 </date>
<abstract> SummaryMarkov chain Monte Carlo (MCMC) is used for evaluating expectations of functions of interestunder a target distribution . This is done by calculating averages over the sample path of aMarkov chain having as its stationary distribution. For computational efficiency, the Markovchain should be rapidly mixing. This can sometimes be achieved only by careful design of thetransition kernel of the chain, on the basis of a detailed preliminary exploratory analysis of . Analternative approach might be to allow the transition kernel to adapt whenever new features of are encountered during the MCMC run. However, if such adaptation occurs infinitely often, thestationary distribution of the chain may be disturbed. We describe a framework, based on theconcept of Markov chain regeneration, which allows adaptation to occur infinitely often, but whichdoes not disturb the stationary distribution of the chain or the consistency of sample-path averages. </abstract>
<keyword> Key Words: Adaptive method; Bayesian inference; Gibbs sampling; Markov chain Monte Carlo; </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> RESONANCE AND THE PERCEPTION OFMUSICAL METER </title>
<author> Edward W. LargeJohn F. Kolen </author>
<affiliation> The Ohio State University </affiliation>
<abstract> AbstractMany connectionist approaches to musical expectancy and music composition let thequestion of What next? overshadow the equally important question of When next?. One cannotescape the latter question, one of temporal structure, when considering the perception of musicalmeter. We view the perception of metrical structure as a dynamic process where the temporalorganization of external musical events synchronizes, or entrains, a listeners internal processingmechanisms. This article introduces a novel connectionist unit, based upon a mathematical modelof entrainment, capable of phase and frequency-locking to periodic components of incomingrhythmic patterns. Networks of these units can self-organize temporally structured responses torhythmic patterns. The resulting network behavior embodies the perception of metrical structure.The article concludes with a discussion of the implications of our approach for theories of metricalstructure and musical expectancy. </abstract>
<note> Connection Science, 6 (1), 177 - 208. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Volumetric Approach to Virtual Simulationof Functional Endoscopic Sinus Surgery </title>
<author> Gregory J. Wiet 1,2 , Roni Yagel 3 , Don Stredney 2 , Petra Schmalbrock 4 , </author>
<author> Dennis J. Sessanna 2 , Yair Kurzion 3 , Louis Rosenberg 5 , Michael Levin 5 , Kenneth Martin 5 </author>
<affiliation> 1 Department of Otolaryngology, The Ohio State University Hospitals, </affiliation>
 <address> Columbus, OH </address>
<affiliation> 2 The Ohio Supercomputer Center, </affiliation>
 <address> Columbus, OH </address>
<affiliation> 3 Department of Computer and Information Science, The Ohio State University, </affiliation>
 <address> Columbus, OH </address>
<affiliation> 4 Department of Radiology, The Ohio State University Hospitals, </affiliation>
 <address> Columbus, OH </address>
<affiliation> 5 Immersion Corporation, </affiliation>
 <address> San Jose, CA </address>
<abstract> AbstractAdvanced display technologies have made the virtual exploration of relatively complex models feasiblein many applications. Unfortunately, only a few human interfaces allow natural interaction with theenvironment. Moreover, in surgical applications, such realistic interaction requires real-time renderingof volumetric data - placing an overwhelming performance burden on the system. We report on acollaboration of an interdisciplinary group developing a virtual reality system that provides intuitiveinteraction with volume data by employing real-time volume rendering and force feedback (haptic)sensations. We describe our rendering methods and the haptic devices and explain its utility of thissystem in the real-world application of Endoscopic Sinus Surgery (ESS) simulation. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Refining Interactions in a Distributed System </title>
<author> Neelam Soundarajan </author>
<affiliation> Computer and Information ScienceThe Ohio State University </affiliation>
<address> 2015 Neil AvenueColumbus, OH 43210USA </address>
<email> e-mail: neelam@cis.ohio-state.edu </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Clustering Methods for Collaborative Filtering </title>
<author> Lyle H. Ungar and Dean P. Foster </author>
<affiliation> CIS Dept. and Dept. of StatisticsUniversity of Pennsylvania </affiliation>
<address> Philadelphia, PA 19104 </address>
<abstract> AbstractGrouping people into clusters based on the items they have purchased allows accurate recommendations of new items for purchase:if you and I have liked many of the same movies, then I will probably enjoy other movies that you like. Recommending items basedon similarity of interest (a.k.a. collaborative filtering) is attractivefor many domains: books, CDs, movies, etc., but does not alwayswork well. Because data are always sparse any given person hasseen only a small fraction of all movies much more accurate predictions can be made by grouping people into clusters with similarmovies and grouping movies into clusters which tend to be liked bythe same people. Finding optimal clusters is tricky because the moviegroups should be used to help determine the people groups and visaversa. We present a formal statistical model of collaborative filtering,and compare different algorithms for estimating the model parametersincluding variations of K-means clustering and Gibbs Sampling. Thisformal model is easily extended to handle clustering of objects withmultiple attributes. </abstract>
<keyword> Keywords: collaborative filtering, clustering, EM, Gibbs sampling </keyword>
<note> Email address of contact author: </note>
 <email> ungar@cis.upenn.edu </email>
<note> Phone number of contact author: </note>
 <phone> 215 898-7449 </phone><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> AUCTION-DRIVEN COORDINATION FORPLANTWIDE OPTIMIZATION </title>
<author> Rinaldo A. Jose and Lyle H. Ungar </author>
<affiliation> University of Pennsylvania </affiliation>
<address> Philadelphia, PA 19104 </address>
<abstract> AbstractModel predictive control strategies generally focus on controlling plant outputs to setpoints; inindustry, however, a more desirable goal is maximizing a plants profitability. In principle, this can bedone by creating a plant model and maximizing profit with respect to the market prices of the plantsinputs and outputs, but in practice, such centralized approaches often cannot effectively be applied atthe operations time scale due to the size and complexity of the problem. One solution is to usedecentralized optimization at the unit operations level by tearing process streams and coordinating theresulting pieces. Such optimization, however, requires that unit inputs and outputs be priced. We showthat a traditional Lagrangean-based approach to this pricing fails for simple systems. Instead, we defineslack resources over the torn process streams and price them using auctions. Unlike Lagrangemultipliers, slack resource prices contain useful information and can be used to make decisionsregarding capital improvements, thus providing a strong tie between the operations and managementlayers in chemical plants. </abstract>
<keyword> Keywordsauctions, distributed optimization, resource prices, process decomposition, optimal coordination,penalty-based methods, Lagrangean decomposition </keyword>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Integrality and Separability of Input Devices </title>
<author> Robert J.K. JacobLinda E. SibertDaniel C. McFarlaneM. Preston Mullen, Jr. </author>
<affiliation> Human-Computer Interaction LabNaval Research Laboratory </affiliation>
<address> Washington, D.C. </address>
<abstract> ABSTRACTCurrent input device taxonomies and other frameworks typically emphasizethe mechanical structure of input devices. We suggest that selecting anappropriate input device for an interactive task requires looking beyond thephysical structure of devices to the deeper perceptual structure of the task, thedevice, and the interrelationship between the perceptual structure of the task andthe control properties of the device. We affirm that perception is key tounderstanding performance of multidimensional input devices onmultidimensional tasks. We have therefore extended the theory of processing ofperceptual structure to graphical interactive tasks and to the control structure ofinput devices. This allows us to predict task and device combinations that lead tobetter performance and hypothesize that performance is improved when theperceptual structure of the task matches the control structure of the device. Weconducted an experiment in which subjects performed two tasks with differentperceptual structures, using two input devices with correspondingly differentcontrol structures, a three-dimensional tracker and a mouse. We analyzed bothspeed and accuracy, as well as the trajectories generated by subjects as they usedthe unconstrained three-dimensional tracker to perform each task. The resultssupport our hypothesis and confirm the importance of matching the perceptualstructure of the task and the control structure of the input device. </abstract>
<keyword> Keywords: Input devices, interaction techniques, gesture input, Polhemustracker, perceptual space, integrality, separability. </keyword>
<intro> INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in Proceedings of Virtual Reality Vienna '93 </note>
<title> Constructing Cyberspace:Virtual Reality and Hypermedia </title>
<author> Keith Andrews </author>
<affiliation> Institute for Information Processing and Computer Supported New Media (IICM)Graz University of Technology, </affiliation>
<address> A-8010 Graz, Austria. </address>
<abstract> AbstractLarge-scale, distributed hypermedia information systems allow fast, structured access to very large, dynamic information bases. The highly perceptual nature of a virtual reality interface has the power to take users both inside information and inside itsstructure. Combining the two takes us a step towards cyberspace, William Gibson'svision of a virtual model of all the world's interconnected data. This paper reviewscurrent work on the boundary of virtual reality and hypermedia. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Proc. UIST '93 (ACM Symp. on User Interface Software and Technology), Atlanta GA, November 3-5, 1993, 145-155 </note>
<title> Windows on the World:2D Windows for 3D Augmented Reality </title>
<author> Steven FeinerBlair MacIntyreMarcus HauptEliot Solomon </author>
<affiliation> Department of Computer ScienceColumbia University </affiliation>
<address> New York, NY 10027 </address>
<phone> 212-939-7000 </phone><email> -feiner, bm, haupt, esolomon-@cs.columbia.edu </email>
<abstract> ABSTRACT INTRODUCTIONWe describe the design and implementation of a prototype When we think of the use of head-mounted displays and 3Dheads-up window system intended for use in a 3D environ- interaction devices to present virtual worlds, it is often inment. Our system includes a see-through head-mounted terms of environments populated solely by 3D objects.display that runs a full X server whose image is overlaid on There are many situations, however, in which 2D text andthe user's view of the physical world. The user's head is graphics of the sort supported by current window systemstracked so that the display indexes into a large X bitmap, can be useful components of these environments. This iseffectively placing the user inside a display space that is especially true in the case of the many applications that runmapped onto part of a surrounding virtual sphere. By under an industry standard window system such as X [13].tracking the user's body, and interpreting head motion rela- While we might imagine porting or enhancing a significanttive to it, we create a portable information surround that X application to take advantage of the 3D capabilities of aenvelopes the user as they move about. virtual world, the effort and cost may not be worth thereturn, especially if the application is inherently 2D.We support three kinds of windows implemented on top of Therefore, we have been exploring how we can incorporatethe X server: windows fixed to the head-mounted display, an existing 2D window system within a 3D virtual world.windows fixed to the information surround, and windowsfixed to locations and objects in the 3D world. Objects can We are building an experimental system that supports a fullalso be tracked, allowing windows to move with them. To X11 server on a see-through head-mounted display. Ourdemonstrate the utility of this model, we describe a small display overlays a selected portion of the X bitmap on thehypermedia system that allows links to be made between user's view of the world, creating an X-based augmentedwindows and windows to be attached to objects. Thus, our reality. Depending on the situation and application, thehypermedia system can forge links between any combina- user may wish to treat a window as a stand-alone entity ortion of physical objects and virtual windows. to take advantage of the potential relationships that can bemade between it and the visible physical world. To makethis possible, we have developed facilities that allow X KEYWORDS: augmented reality, virtual reality, virtualwindows to be situated in a variety of ways relative to the worlds, head-mounted displays, portable computers, mobileuser and the 3D world. computing, window systems, X11, hypertext/hypermedia.In this paper we first present related work and provide anoverview of our system. Next, we describe the differentkinds of windows that we support, and show how thesewindows can be used to advantage by a simple hypermediasystem. Finally, we explain the underlying system architec- </abstract>
 <note> Permission to copy without fee all or part of this material is grantedture and describe our current implementation. provided that the copies are not made or distributed for directcommercial advantage, the ACM copyright notice and the title ofthe publication and its date appear, and notice is given that copyingis by permission of the Association for Computing Machinery. Tocopy otherwise, or to republish, requires a fee and/or specificpermission.1993 ACM 0-89791-628-X/93/0011 ... $1.50November 3-5, 1993 UIST '93 145 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Type classes in Haskell </title>
<author> Cordelia Hall, Kevin Hammond, Simon Peyton Jonesand Philip Wadler </author>
<affiliation> Glasgow University </affiliation>
<abstract> AbstractThis paper defines a set of type inference rules for resolving overloading introduced by type classes. Programs including type classesare transformed into ones which may be typed by the Hindley-Milner inference rules. In contrast to other work on type classes, therules presented here relate directly to user programs. An innovativeaspect of this work is the use of second-order lambda calculus torecord type information in the program. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Measuring the Difficulty of Specific Learning Problems </title>
<author> Chris Thornton </author>
<affiliation> Cognitive and Computing SciencesUniversity of Sussex </affiliation>
<address> Brighton BN1 9QN </address>
<email> Email: Chris.Thornton@cogs.susx.ac.uk </email>
<phone> Tel: (44)273 606755 x 3239 </phone><date> October 21, 1994 </date>
<abstract> AbstractExisting complexity measures from contemporary learning theory cannot be conveniently applied to specific learning problems (e.g., training sets). Moreover, they are typically non-generic,i.e., they necessitate making assumptions about the way in which the learner will operate. The lackof a satisfactory, generic complexity measure for learning problems poses difficulties for researchersin various areas; the present paper puts forward an idea which may help to alleviate these. Itshows that supervised learning problems fall into two, generic, complexity classes only one of whichis associated with computational tractability. By determining which class a particular problembelongs to, we can thus effectively evaluate its degree of generic difficulty. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Crooked Functions, Bent Functions, and DistanceRegular Graphs </title>
<author> T.D. Bending D. Fon-Der-Flaass </author>
<affiliation> School of Mathematical Sciences,Queen Mary and Westfield College, </affiliation>
 <address> London E1 4NS, U.K. </address>
<email> T.Bending@mdx.ac.uk d.g.flaass@writeme.com </email>
<note> Submitted:  March 25, 1998;  Accepted:  June 30, 1998. </note>
<note> 1991 Mathematical Subject Classification: 05E30, 05B20 </note>
<abstract> AbstractLet V and W be n-dimensional vector spaces over GF (2). A mappingQ : V ! W is called crooked if it satisfies the following three properties:Q(0) = 0;Q(x) + Q() + Q() + Q(x + + ) 6= 0 for any three distinct x; ; ;Q(x) + Q() + Q() + Q(x + a) + Q( + a) + Q( + a) 6= 0 if a 6= 0 (x; ; arbitrary).We show that every crooked function gives rise to a distance regular graphof diameter 3 having = 0 and = 2 which is a cover of the completegraph. Our approach is a generalization of a recent construction found byde Caen, Mathon, and Moorhouse. We study graph-theoretical properties ofthe resulting graphs, including their automorphisms. Also we demonstrate aconnection between crooked functions and bent functions. </abstract>
<intro> 1 Crooked functions and bent functions </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Symbiosis of Animation and Music </title>
<author> ROBERT E. PRINGLE BRIAN J. ROSS </author>
<affiliation> Brock UniversityDepartment of Computer Science </affiliation>
<address> St. Catharines, Ontario, Canada L2S 3A1 </address>
<email> frp94bg,brossg@sandcastle.cosc.brocku.ca </email>
<date> December 12, 1995 </date>
<abstract> AbstractThe use of music as a means to automate the sculpting and movement of graphical objects is investigated. An interactive environment for producing musically-controlledcomputer animations is presented. The graphical objects studied are based on Todd'sand Latham's work in evolutionary art. The environment permits the creation of kernel objects using an interactive toolset. In addition to a basic set of morphologicaldefinitions, each object incorporates a script, which is an instance of programminglanguage code and data definitions. Scripts permit the run-time computation of object characteristics, and when done in a temporal setting, allow complex animationcontrol. The script language has a number of functions that can access MIDI information, as read into the system via a MIDI file. The practical consequence of thisis that animations are controllable with music data, in which music determines themovement and morphology of animated objects. The tight integration of music andanimation in an interactive production environment such as this one has a numberof pragmatic consequences, ranging from the ability to automatically synchronizecomplex activities to music, to the use of music as a creative source for graphicalsculptoring and animation. </abstract>
<keyword> Keywords: animation, music, MIDI, evolutionary art. </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> On the Maximum Tolerable Noise forReliable Computation by Formulas </title>
<author> William Evans* </author>
<email> will@cs.arizona.edu </email>
<affiliation> Department of Computer ScienceThe University of Arizona </affiliation>
<address> Tucson, AZ 85721-0077, USA </address>
<author> Nicholas Pippenger** </author>
<email> nicholas@cs.ubc.ca </email>
<affiliation> Department of Computer ScienceThe University of British Columbia </affiliation>
<address> Vancouver, BC V6T 1Z4, Canada </address>
<abstract> Abstract: It is shown that if a formula is constructed from noisy 2-input NAND gates,with each gate failing independently with probability ", then reliable computation can orcannot take place according as " is less than or greater than " 0 = (3 p </abstract>
<note> * This research was supported by an NSERC Canada International Fellowship.** This research was supported by an NSERC Research Grant. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Implementing Atomic Sequences on UniprocessorsUsing Rollforward </title>
<author> David Mosberger, Peter Druschel , and Larry L. Peterson  </author>
<affiliation> Department of Computer ScienceUniversity of Arizona </affiliation>
<address> Tucson, AZ 85721 </address>
<email> fdavidm,druschel,llpg@cs.arizona.edu </email>
<abstract> SummaryThis article presents a software-only solution to the synchronization problem for uniprocessors.The idea is to execute atomic sequences without any hardware protection, and in the rare caseof pre-emption, to roll the sequence forward to the end, thereby preserving atomicity. One ofthe proposed implementations protects atomic sequences without any memory-accesses. Thisis significant as it enables execution at CPU-speeds, rather than memory-speeds. The benefit ofthis method increases with the frequency at which atomic sequences are executed. It thereforeencourages the building of systems with fine-grained synchronization. This has the additionaladvantage of reducing average latency. Experiments demonstrate that this technique has thepotential to outperform even the best hardware mechanisms. The main contribution of this articleis to discuss operating-system related issues of rollforward and to demonstrate its practicality,both in terms of flexibility and performance. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Virtual Radios </title>
<author> Vanu Bose, Mike Ismert, Matt Welborn, John Guttag  </author>
<affiliation> Software Devices and Systems GroupLaboratory for Computer ScienceMassachusetts Institute of Technology </affiliation>
<abstract> AbstractConventional software radios take advantage of vastly improved A/D converters and DSP hardware. Ourapproach, which we refer to as virtual radios, also depends upon high performance A/D converters. However,rather than use DSPs, we have chosen to ride the curve of rapidly improving workstation hardware. We usewideband digitization and then perform all of the digital signal processing in user space on a general purposeworkstation. This approach allows us to experiment with new approaches to signal processing that exploit thehardware and software resources of the workstation. Furthermore, it allows us to experiment with differentways of structuring systems in which the radio component of communication devices are integrated withhigher-level applications.This paper describes the design and performance of an environment we have constructed that facilitates building virtual radios and of two applications built using that environment. The environment consists of an I/Osubsystem that provides high bandwidth low latency user-level access to digitized signals and a programmingenvironment that provides an infrastructure for building applications. The applications, which exemplifysome of the benefits of virtual radios, are a software cellular receiver and a novel wireless network interface. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Optimal Representations of Polymorphic Types withSubtyping </title>
<author> Alexander Aiken Edward L. Wimmers Jens Palsberg </author>
<pubnum> Report No. UCB/CSD-96-909 </pubnum>
<date> July 1996 </date>
<affiliation> Computer Science Division (EECS)University of California </affiliation>
<address> Berkeley, California 94720 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> Draft 16 </note>
 <date> Nov 94 </date>
 <note> - 1 - To appear IEEE MICRO Feb 1995 </note>
<title> Myrinet - A Gigabit-per-Second Local-Area Network </title>
<note> (Based on a keynote talk presented by Charles L. Seitz) </note>
<author> Nanette J. Boden, Danny Cohen, Robert E. Felderman,Alan E. Kulawik, Charles L. Seitz, Jakov N. Seizovic, and Wen-King Su </author>
<affiliation> Myricom, Inc. </affiliation>
<address> 325 N. Santa Anita Ave.Arcadia, CA 91006 </address>
<web> (http://www.myri.com) </web><abstract> Abstract. Myrinet is a new type of local-area network (LAN) based on thetechnology used for packet communication and switching within "massively-parallel processors" (MPPs). Think of Myrinet as an MPP message-passingnetwork that can span campus dimensions, rather than as a wide-areatelecommunications network that is operating in close quarters. Thetechnical steps toward making Myrinet a reality included the developmentof (1) robust, 25m communication channels with flow control, packetframing, and error control; (2) self-initializing, low-latency, cut-throughswitches; (3) host interfaces that can map the network, select routes, andtranslate from network addresses to routes, as well as handle packet traffic;and (4) streamlined host software that allows direct communicationbetween user processes and the network. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Network Subsystem Design:A Case for an Integrated Data Path </title>
<author> Peter DruschelMark B. AbbottMichael A. PagelsLarry L. Peterson  </author>
<affiliation> Department of Computer ScienceUniversity of Arizona </affiliation>
<address> Tucson, AZ 85721 </address>
<abstract> AbstractThis paper argues that the CPU/memory data path is a potential throughput bottleneck inworkstations connected to high-speed networks, and considers the implications for the designof the I/O subsystem. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Virtual Memory Architecture in SunOS </title>
<author> Robert A. GingellJoseph P. MoranWilliam A. Shannon </author>
<affiliation> Sun Microsystems, Inc. </affiliation>
<address> 2550 Garcia Ave.Mountain View, CA 94043 </address>
<abstract> ABSTRACTA new virtual memory architecture for the Sun implementation of the UNIXoperating system is described. Our goals included unifying and simplifying the conceptsthe system used to manage memory, as well as providing an implementation that fit wellwith the rest of the system. We discuss an architecture suitable for environments that(potentially) consist of systems of heterogeneous hardware and software architectures.The result is a page-based system in which the fundamental notion is that of mappingprocess addresses to files. </abstract>
<intro> 1. Introduction and Motivation </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Study of the Structure and Performanceof MMU Handling Software </title>
<author> Yousef A. KhalidiVikram P. JoshiDock Williams </author>
<pubnum> SMLI TR-94-28 </pubnum>
<date> June 1994 </date>
<abstract> Abstract:Modern operating systems provide a rich set of interfaces for mapping, sharing, and protecting memory. Differentmemory management unit (MMU) architectures provide different mechanisms for managing memory translations.Since the same OS usually runs on different MMU architectures, a software hardware address translation (hat)layer that abstracts the MMU architecture is normally implemented between MMU hardware and the virtual memory system of the OS. In this paper, we study the impact of the OS and the MMU on the structure and performanceof the hat layer. In particular, we concentrate on the role of the hat layer on the scalability of system performanceon symmetric multiprocessors with 2-12 CPUs. The results show that, unlike single-user applications, multi-userapplications require very careful multi-threading of the hat layer to achieve system performance that scales withthe number of CPUs. In addition, multi-threading the hat can result in better performance in lesser amounts ofphysical memory. </abstract>
<note> email addresses: </note>
<email> yousef.khalidi@eng.sun.comvikram.joshi@eng.sun.comdock.williams@eng.sun.com </email>
<address> M/S 29-012550 Garcia AvenueMountain View, CA 94043 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Survey of Collective Communication inWormhole-Routed Massively Parallel Computers </title>
<author> Philip K. McKinley, Yih-jia Tsai, and David F. Robinson </author>
<pubnum> Technical ReportMSU-CPS-94-35 </pubnum>
<date> June 1994 </date>
<note> Submitted for publication, June 1994. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Empirical Evaluation of Global Memory Supporton the CRAY-T3D and CRAY-T3E </title>
<author> Arvind Krishnamurthy, David E. Culler, and Katherine Yelick </author>
<affiliation> Computer Science DivisionUniversity of California, Berkeley </affiliation>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Feature Correspondence by Interleaving Shape and TextureComputations  </title>
<author> David Beymer </author>
<affiliation> Artificial Intelligence Laboratory, andCenter for Biological and Computational LearningMassachusetts Institute of Technology </affiliation>
<address> Cambridge, MA 02139, USA </address>
<email> email: beymer@ai.mit.edu </email>
<abstract> AbstractThe correspondence problem in computer vision is basically a matching task between two or more sets of features. In this paper, we introduce a vectorized imagerepresentation, which is a feature-based representationwhere correspondence has been established with respectto a reference image. The representation consists of twoimage measurements made at the feature points: shapeand texture. Feature geometry, or shape, is representedusing the (x; ) locations of features relative to the somestandard reference shape. Image grey levels, or texture,are represented by mapping image grey levels onto thestandard reference shape. Computing this representationis essentially a correspondence task, and in this paperwe explore an automatic technique for "vectorizing" faceimages. Our face vectorizer alternates back and forthbetween computation steps for shape and texture, and akey idea is to structure the two computations so that eachone uses the output of the other. In addition to describing the vectorizer, an application to the problem of facialfeature detection will be presented. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> RUNTIME SUPPORT FOR PORTABLE DISTRIBUTED DATA STRUCTURES </title>
 <author> Chih-Po Wen, Soumen Chakrabarti, Etienne Deprit, Arvind Krishnamurthy, Katherine Yelick </author>
 <affiliation> Computer Science Division, Department of EECS University of California, </affiliation>
 <address> Berkeley, California 94720 USA </address>
<abstract> ABSTRACTMultipol is a library of distributed data structures designed for irregular applications, including those with asynchronous communication patterns. In this paper,we describe the Multipol runtime layer, which provides an efficient and portable abstraction underlying the data structures. It contains a thread system to expresscomputations with varying degrees of parallelism and to support multiple threadsper processor for hiding communication latency. To simplify programming in a mul-tithreaded environment, Multipol threads are small, finite-length computations thatare executed atomically. Rather than enforcing a single scheduling policy on threads,users may write their own schedulers or choose one of the schedulers provided byMultipol. The system is designed for distributed memory architectures and performscommunication optimizations such as message aggregation to improve efficiency onmachines with high communication startup overhead. The runtime system currentlyruns on the Thinking Machines CM5, Intel Paragon, and IBM SP1, and is beingported to a network of workstations. Multipol applications include an event-driventiming simulator [1], an eigenvalue solver [2], and a program that solves the phylogenyproblem [3]. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<author> Joseph D. Darcy </author>
<pubnum> CS 270 Project Report, </pubnum>
<date> spring 1998 </date>
<title> Narrowing Interval Bounds </title>
<abstract> 1. AbstractInterval arithmetic is an automated attempt to give guaranteed upper and lower bounds of a numericalcomputation in the face of uncertainly in the input data and floating point roundoff during the calculation.While a simple interval equivalent of a rational function can be readily synthesized, the bounds from thisconstruction may be too pessimistically large to be useful. This paper surveys a variety of techniques forrefining the interval bounds. An appendix identifies issues with realizing floating point based intervalarithmetic on current IEEE 754 compliant processors. </abstract>
<intro> 2. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Modeling and Rendering Architecture from Photographs:A hybrid geometry- and image-based approach </title>
<pubnum> Technical Report UCB//CSD-96-893 </pubnum>
<date> January 19, 1996 </date>
<author> Paul E. Debevec Camillo J. Taylor Jitendra Malik </author>
<email> debevec@cs.berkeley.edu camillo@cs.berkeley.edu malik@cs.berkeley.edu </email>
<address> 545 Soda Hall 485 Soda Hall 725 Soda Hall </address>
<phone> (510) 642 9940 (510) 642 5029 (510) 642 7597 </phone><affiliation> Computer Science Division, University of California at Berkeley </affiliation>
<address> Berkeley, CA 94720-1776 </address>
<phone> (510) 642 5775 (fax) </phone><abstract> AbstractWe present an approach for creating realistic synthetic views of existing architecturalscenes from a sparse set of still photographs. Our approach, which combines both geometry-based and image-based modeling and rendering techniques, has two components. The firstcomponent is an easy-to-use photogrammetric modeling system which facilitates the recovery of a basic geometric model of the photographed scene. The modeling system is effectiveand robust because it exploits the constraints that are characteristic of architectural scenes.The second component is a model-based stereo algorithm, which recovers how the real scenedeviates from the basic model. By making use of the model, our stereo approach can robustlyrecover accurate depth from image pairs with large baselines. Consequently, our approachcan model large architectural environments with far fewer photographs than current image-based modeling approaches. As an intermediate result, we present view-dependent texturemapping, a method of better simulating geometric detail on basic models. Our approachcan recover models for use in either geometry-based or image-based rendering systems. Wepresent results that demonstrate our approach's abilty to create realistic renderings of architectural scenes from viewpoints far from the original photographs.Keywords: Image-based modeling, image-based rendering, interactive modeling systems,photogrammetry, reconstruction, view-dependent texture mapping, view interpolation, model-based stereo </abstract>
<note> See also: </note>
 <web> http://www.cs.berkeley.edu/~debevec/Research/ </web><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A New O(n2 ) Algorithm for the Symmetric TridiagonalEigenvalue/Eigenvector Problem </title>
<author> byInderjit Singh Dhillon </author>
<degree> B.Tech. (Indian Institute of Technology, Bombay) 1989A dissertation submitted in partial satisfaction of therequirements for the degree ofDoctor of PhilosophyinComputer Sciencein theGRADUATE DIVISIONof the </degree><affiliation> UNIVERSITY of CALIFORNIA, BERKELEY </affiliation>
<degree> Committee in charge:Professor James W. Demmel, ChairProfessor Beresford N. ParlettProfessor Phil Colella </degree><date> 1997 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Query Execution Techniques for Caching Expensive Methods </title>
<author> Joseph M. Hellerstein Jeffrey F. Naughton </author>
<affiliation> University of Wisconsin, Department of Computer Sciences </affiliation>
<address> 1210 W. Dayton St., Madison, WI 53706 </address>
<email> jmh@cs.berkeley.edu, naughton@cs.wisc.edu </email>
<abstract> Abstract. Object-Relational and Object-Oriented DBMSs allowusers to invoke time-consuming (expensive) methods in theirqueries. When queries containing these expensive methods are runon data with duplicate values, time is wasted redundantly computing methods on the same value. This problem has been studied inthe context of programming languages, where memoization is thestandard solution. In the database literature, sorting has been proposed to deal with this problem. We compare these approachesalongwith a third solution, a variant of unary hybrid hashing which we callHybrid Cache. We demonstrate that Hybrid Cache always dominates memoization, and significantly outperforms sorting in manyinstances. This provides new insights into the tradeoff between hashing and sorting for unary operations. Additionally, our Hybrid Cachealgorithm includes some new optimizations for unary hybrid hashing, which can be used for other applications such as grouping andduplicate elimination. We conclude with a discussion of techniquesfor caching multiple expensive methods in a single query, and raisesome new optimization problems in choosing caching techniques. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Using Skeletons for Nonholonomic Path Planning among Obstacles </title>
<author> Brian Mirtich John Canny  </author>
<affiliation> Computer Science DivisionUniversity of California </affiliation>
<address> Berkeley, CA 94720 </address>
<abstract> AbstractThis paper describes a practical path planner fornonholonomic robots in environments with obstacles.The planner is based on building a one-dimensional,maximal clearance skeleton through the configurationspace of the robot. However rather than using the Eu-clidean metric to determine clearance, a special metricwhich captures information about the nonholonomy ofthe robot is used. The robot navigates from start togoal states by loosely following the skeleton; the resulting paths taken by the robot are of low "complexity."We describe how much of the computation can be doneoff-line once and for all for a given robot, making foran efficient planner. The focus is on path planningfor mobile robots, particularly the planar two-axle car,but the underlying ideas are quite general and may beapplied to planners for other nonholonomic robots. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Dynamic Procedure Placement Through Cache Windowing </title>
<author> Carleton Miyamoto </author>
<pubnum> CS 252/265 </pubnum>
<date> Spring 98 </date>
<affiliation> University of California, Berkeley </affiliation>
<abstract> AbstractThe relative slowdown of DRAMs with respect toprocessor speeds and the widespread use of SMPmachines have bolstered the reliance on processor cachesto provide good performance. As a result, optimizingmachines and software for caches have recently receivedmore attention. In addition, with the popularity ofextensible computing, which includes the object orientedprogramming style, shared libraries, and Java basedcomputing, creating effective compilers has becomemore challenging, with an increased reliance on moredynamic techniques, such as profiling and runtime codegeneration. This paper proposes a dynamic optimizationmethod called cache windowing to reduce conflict missesin L1 instruction caches. Using a combination ofhardware and software support, cache windowingintegrates a RollCache (a direct-mapped cache enhancedto support dynamic cache configuration) and a softwareimplemented FIFO caching policy. Together, both allowa program to reposition procedures, dynamically andefficiently, to eliminate cache conflicts. Experimentsshow that this type of caching scheme can achieve missrates competitive to a 2-way set associative cache forvarious programs. Currently, a high software overheadexists to support a software caching policy, thoughdifferent compiler optimizations, such as inlining, mayhelp to reduce this. Such a system provides a more robustruntime architecture that, potentially, may adapt better toa wider variety of environments. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Belief Revision: A Critique </title>
<author> Nir Friedman </author>
<affiliation> Computer Science DepartmentStanford University </affiliation>
<address> Gates Building 1AStanford, CA 94305-9010 </address>
<email> nir@cs.stanford.edu </email>
<author> Joseph Y. Halpern </author>
<affiliation> IBM Research DivisionAlmaden Research Center, </affiliation>
 <address> Dept. K53-B2650 Harry RoadSan Jose, CA 95120-6099 </address>
<email> halpern@almaden.ibm.com </email>
<date> May 6, 1996 </date>
<abstract> AbstractThe problem of belief changehow an agent should revise her beliefs upon learning newinformationhas been an active area of research in both philosophy and artificial intelligence.Many approaches to belief change have been proposed in the literature. Our goal is not tointroduce yet another approach, but to examine carefully the rationale underlying the approachesalready taken in the literature, and to highlight what we view as methodological problems in theliterature. The main message is that to study belief change carefully, we must be quite explicitabout the ontology or scenario underlying the belief change process. This is something thathas been missing in previous work, with its focus on postulates. Our analysis shows that wemust pay particular attention to two issues which have often been taken for granted: The firstis how we model the agent's epistemic state. (Do we use a set of beliefs, or a richer structure,such as an ordering on worlds? And if we use a set of beliefs, in what language are thesebeliefs are expressed?) The second is the status of observations. (Are observations known tobe true, or just believed? In the latter case, how firm is the belief?) For example, we argue thateven postulates that have been called beyond controversy are unreasonable when the agent'sbeliefs include beliefs about her own epistemic state as well as the external world. Issues of thestatus of observations arise particularly when we consider iterated belief revision, and we mustconfront the possibility of revising by ' and then by :'. </abstract>
<keyword> Keyword: Belief revision </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> First-Order Conditional Logic Revisited </title>
<author> Nir Friedman </author>
<affiliation> Dept. of Computer ScienceStanford University </affiliation>
<address> Gates Building 1AStanford, CA 94305-9010 </address>
<email> nir@cs.stanford.edu </email>
<author> Joseph Y. Halpern </author>
<affiliation> IBM Almaden Research Center </affiliation>
<address> 650 Harry RoadSan Jose, CA 95120-6099 </address>
<email> halpern@almaden.ibm.com </email>
<author> Daphne Koller </author>
<affiliation> Dept. of Computer ScienceStanford University </affiliation>
<address> Gates Building 1AStanford, CA 94305-9010 </address>
<email> koller@cs.stanford.edu </email>
<abstract> AbstractConditional logics play an important role in recent attemptsto investigate default reasoning. This paper investigates first-order conditional logic. We show that, as for first-orderprobabilistic logic, it is important not to confound statistical conditionals over the domain (such as most birds fly),and subjective conditionals over possible worlds (such as Ibelieve that Tweety is unlikely to fly). We then addressthe issue of ascribing semantics to first-order conditionallogic. As in the propositional case, there are many possible semantics. To study the problem in a coherent way, weuse plausibility structures. These provide us with a generalframework in which many of the standard approaches can beembedded. We show that while these standard approachesare all the same at the propositional level, they are significantly different in the context of a first-order language. Weshow that plausibilities provide the most natural extension ofconditional logic to the first-order case: We provide a soundand complete axiomatization that contains only the KLMproperties and standard axioms of first-order modal logic.We show that most of the other approaches have additionalproperties, which result in an inappropriate treatment of aninfinitary version of the lottery paradox. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Fast Algorithm for Incremental Distance Calculation </title>
<author> Ming C. Lin and John F. Canny </author>
<affiliation> University of California, Berkeley </affiliation>
<address> Berkeley, CA 94720 </address>
<abstract> AbstractA simple and efficient algorithm for finding the closest points between two convex polyhedra is describedhere. Data from numerous experiments tested on abroad set of convex polyhedra on &amp;lt; 3 show that therunning time is roughly constant for finding closestpoints when nearest points are approximately knownand is linear in total number of vertices if no specialinitialization is done. This algorithm can be used forcollision detection, computation of the distance between two polyhedra in three-dimensional space, andother robotics problems. It forms the heart of themotion planning algorithm of [1]. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Eraser: A Dynamic Data Race Detector for Multi-Threaded Programs </title>
<author> Stefan Savage  </author>
<affiliation> Department of Computer Science and EngineeringUniversity of Washington,  Seattle </affiliation>
<author> Michael Burrows Greg Nelson Patrick Sobalvarro </author>
<affiliation> Digital Equipment CorporationSystems Research Center </affiliation>
<author> Thomas Anderson </author>
<affiliation> Computer Science DivisionUniversity of California, Berkeley </affiliation>
<abstract> AbstractMulti-threaded programming is difficult and error prone. Itis easy to make a mistake in synchronization that produces adata race, yet it can be extremely hard to locate this mistakeduring debugging. This paper describes a new tool, calledEraser, for dynamically detecting data races in lock-basedmulti-threaded programs. Eraser uses binary rewriting techniques to monitor every shared memory reference and verifythat consistent locking behavior is observed. We present several case studies, including undergraduate coursework and amulti-threaded Web search engine, that demonstrate the effectiveness of this approach. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> High-Performance Sorting on Networks of Workstations </title>
<author> Andrea C. Arpaci-Dusseau </author>
<affiliation> Computer Science DivisionUniversity of California, Berkeley </affiliation>
<email> dusseau@cs.berkeley.edu </email>
<author> Remzi H. Arpaci-Dusseau </author>
<affiliation> Computer Science DivisionUniversity of California, Berkeley </affiliation>
<email> remzi@cs.berkeley.edu </email>
<author> David E. Culler </author>
<affiliation> Computer Science DivisionUniversity of California, Berkeley </affiliation>
<email> culler@cs.berkeley.edu </email>
<author> Joseph M. Hellerstein </author>
<affiliation> Computer Science DivisionUniversity of California, Berkeley </affiliation>
<email> jmh@cs.berkeley.edu </email>
<author> David A. Patterson </author>
<affiliation> Computer Science DivisionUniversity of California, Berkeley </affiliation>
<email> patterson@cs.berkeley.edu </email>
<abstract> AbstractWe report the performance of NOW-Sort, a collection of sorting implementations on a Network of Workstations (NOW).We find that parallel sorting on a NOW is competitive to sorting on the large-scale SMPs that have traditionally held theperformance records. On a 64-node cluster, we sort 6.0 GBin just under one minute, while a 32-node cluster finishes theDatamation benchmark in 2.41 seconds.Our implementations can be applied to a variety of disk,memory, and processor configurations; we highlight salientissues for tuning each component of the system. We evaluate the use of commodity operating systems and hardware forparallel sorting. We find existing OS primitives for memorymanagement and file access adequate. Due to aggregate communication and disk bandwidth requirements, the bottleneckof our system is the workstation I/O bus. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An FFT algorithm on Vector Intelligent RAM </title>
<author> Kirby ZhangNathan Slingerland </author>
<pubnum> CS252: Advanced Computer Architecture </pubnum>
<affiliation> Department of Electrical Engineering and Computer ScienceUniversity of California, Berkeley </affiliation>
<date> May 18, 1998 </date>
<abstract> AbstractWe present an implementation of a Fast Fourier Transform on Vector Intelligent RAM architecture. The algorithm computes the DiscreteFourier Transform in O(N log N) time, is self-sorting (no bit-reversed copyphase is required), and has a minimum vector length ofpN=2, where N isthe number of data points in the transform. An N-element scratch spaceis required. The performance of this algorithm on VIRAM is analyzedagainst two variants of the Stockham [12] algorithm. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Interaction of Parallel and Sequential Workloads on aNetwork of Workstations </title>
<author> Remzi H. Arpaci, Andrea C. Dusseau, Amin M. Vahdat,Lok T. Liu, Thomas E. Anderson, and David A. Patterson </author>
<affiliation> Computer Science DivisionUniversity of California, Berkeley </affiliation>
<address> Berkeley, CA 94720 </address>
<abstract> AbstractThis paper examines the plausibility of using a network ofworkstations (NOW) for a mixture of parallel and sequentialjobs. Through simulations, our study examines issues that arisewhen combining these two workloads on a single platform. Starting from a dedicated NOW just for parallel programs, we incrementally relax uniprogramming restrictions until we have amulti-programmed, multi-user NOW for both interactive sequential users and parallel programs. We show that a number of issuesassociated with the distributed NOW environment (e.g., daemonactivity, coscheduling skew) can have a small but noticeable effect on parallel program performance. We also find that efficientmigration to idle workstations is necessary to maintain acceptable parallel application performance. Furthermore, we present amethodology for deriving an optimal delay time for recruiting idlemachines for use by parallel programs; this recruitment thresholdwas just 3 minutes for the research cluster we measured. Finally,we quantify the effects of the additional parallel load upon interactive users by keeping track of the potential number of userdelays in our simulations. When we limit the maximum numberof delays per user, we can still maintain acceptable parallel program performance. In summary, we find that for our workloads a2:1 rule applies: a NOW cluster of approximately 60 machines cansustain a 32-node parallel workload in addition to the sequentialload placed upon it by interactive users. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Software-only video production switcher for theInternet MBone </title>
<author> Tina H. Wong </author>
<affiliation> Computer Science DivisionUniversity of California, Berkeley </affiliation>
<email> twong@cs.berkeley.edu </email>
<abstract> ABSTRACTIn this paper, we describe the design and implementation of a prototypesoftware video production switcher, vps, that improves the quality of the content of MBone broadcasts. vps is modeled after the broadcast television industry's studio production switcher. It provides special effects processing toincorporate audience discussions, add titles and other information, and integrate stored videos into the presentation. vps is structured to work with otherMBone conferencing tools. The ultimate goal is to automate the production ofMBone broadcasts. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> "Go With the Winners" Algorithms </title>
<author> David Aldous  </author>
<affiliation> Department of StatisticsUniversity of California </affiliation>
<address> Berkeley CA 94720 </address>
<author> Umesh Vazirani  </author>
<affiliation> Department of Computer ScienceUniversity of California </affiliation>
<address> Berkeley CA 94720 </address>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Qualia Structure and theCompositional Interpretation of Compounds </title>
<author> Michael Johnston x and Federica Busa  </author>
<affiliation> Research Lab for Linguistics and Computation,Computer Science Department,Volen Center for Complex Systems,Brandeis University, </affiliation>
<address> Waltham, MA 02254 </address>
<email> johnston@cs.brandeis.edu federica@cs.brandeis.edu </email>
<abstract> AbstractThe analysis of nominal compound constructions has proven to be a recalcitrant problemfor linguistic semantics and poses serious challenges for natural language processing systems.We argue for a compositional treatment of compound constructions which limits the need forlisting of compounds in the lexicon. We argue that the development of a practical model ofcompound interpretation crucially depends on issues of lexicon design. The Generative Lexicon(Pustejovsky 1995) provides us with a model of the lexicon which couples sufficiently expressivelexical semantic representations with mechanisms which capture the relationship between thoserepresentations and their syntactic expression. In our approach, the qualia structures of thenouns in a compound provide relational structure enabling compositional interpretation of themodification of the head noun by the modifying noun. This brings compound interpretationunder the same rubric as other forms of composition in natural language, including argumentselection, adjectival modification, and type coercion (Pustejovsky (1991,1995), Bouillon 1995).We examine data from both English and Italian and develop analyses for both languages which usephrase structure schemata to account for the connections between lexical semantic representationand syntactic expression. In addition to applications in natural language understanding, machinetranslation, and generation, the model of compound interpretation developed here can be appliedto multi-lingual information extraction tasks. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Stochastic Interaction and Linear Logic </title>
<author> Patrick D. Lincoln John C. Mitchell Andre Scedrov x </author>
<abstract> AbstractWe present stochastic interactive semantics for propositional linearlogic without modalities. The framework is based on interactiveprotocols considered in computational complexity theory, in whicha prover with unlimited power interacts with a verifier that canonly toss fair coins or perform simple tasks when presented withthe given formula or with subsequent messages from the prover.The additive conjunction &amp; is described as random choice, whichreflects the intuitive idea that the verifier can perform only "random spot checks". This stochastic interactive semantic frameworkis shown to be sound and complete. Furthermore, the prover'swinning strategies are basically proofs of the given formula. Inthis framework the multiplicative and additive connectives of linear logic are described by means of probabilistic operators, giving anew basis for intuitive reasoning about linear logic and a potentialnew tool in automated deduction. </abstract>
<note> A revised version appears in : "Advances in Linear Logic", ed. by J.-Y. Girard etal., London Mathematical Society Lecture Notes Series, Volume 222, Cambridge UniversityPress, 1995, pp. 147-166. </note>
<email> lincoln@csl.sri.com </email>
 <affiliation> SRI International Computer Science Laboratory, </affiliation>
 <address> Menlo ParkCA 94025 USA. </address>
 <note> Work supported under NSF Grant CCR-9224858. </note>
<email> jcm@cs.stanford.edu </email>
 <web> http://theory.stanford.edu/people/jcm/home.html </web> <affiliation> Department of Computer Science, Stanford University, </affiliation>
 <address> Stanford, CA 94305. </address>
 <note> Supported in partby an NSF PYI Award, matching funds from Digital Equipment Corporation, the Pow-ell Foundation, and Xerox Corporation; and the Wallace F. and Lucille M. Davis FacultyScholarship. </note>
<email> andre@cis.upenn.edu </email>
 <web> http://www.cis.upenn.edu/~andre </web> <affiliation> Department of Mathematics, University of Pennsylvania, </affiliation>
 <address> Philadelphia, PA 19104-6395. </address>
 <note> Partially supported byNSF Grants CCR-91-02753 and CCR-94-00907 and by ONR Grant N00014-92-J-1916. Sce-drov is an American Mathematical Society Centennial Research Fellow. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> An Experimental Comparison ofThree Graph Drawing Algorithms  </title>
<note> (Extended Abstract) </note>
<author> Giuseppe Di Battista  </author>
<email> dibattista@iasi.rm.cnr.it </email>
<author> Roberto Tamassia  </author>
<email> rt@cs.brown.edu </email>
<affiliation> D. I. F. A.Univ. della Basilicata </affiliation>
<address> 85100 PotenzaItaly </address>
<author> Ashim Garg  </author>
<email> ag@cs.brown.edu </email>
<author> Emanuele Tassinari x </author>
<email> tassinar@dis.uniroma1.it </email>
<affiliation> Dept. of Computer ScienceBrown University </affiliation>
<address> Providence, RI 02912-1910USA </address>
<author> Giuseppe Liotta </author>
<email> liotta@dis.uniroma1.it </email>
<author> Francesco Vargiu </author>
<email> vargiu@dis.uniroma1.it </email>
<affiliation> Dip. Informatica e SistemisticaUniv. di Roma "La Sapienza" </affiliation>
<address> 00198 RomaItaly </address>
<abstract> AbstractIn this paper we present an extensive experimental study comparing three general-purpose graphdrawing algorithms. The three algorithms take asinput general graphs (with no restrictions whatsoever on the connectivity, planarity, etc.) and construct orthogonal grid drawings, which are widelyused in software and database visualization applications. The test data (available by anonymousftp) are 11,582 graphs, ranging from 10 to 100vertices, which have been generated from a coreset of 112 graphs used in "real-life" software engineering and database applications. The experiments provide a detailed quantitative evaluation ofthe performance of the three algorithms, and showthat they exhibit trade-offs between "aesthetic"properties (e.g., crossings, bends, edge length) andrunning time. The observed practical behavior ofthe algorithms is consistent with their theoreticalproperties.Research supported in part by the US National Science Foundation, by the US Army Research Office, by the US Office ofNaval Research and the Advanced Research Projects Agency, bythe NATO Scientific Affairs Division, by the "Progetto FinalizzatoSistemi Informatici e Calcolo Parallelo (Sottoprogetto 6, Infokit)"and Grant 94.23.CT07 of the Italian National Research Council(CNR), and by the ESPRIT II Basic Research Actions Program ofthe European Community (project ALgorithms and Complexity). </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Form(ers) Over Function(s): The KOLA Reference Manual </title>
<author> Mitch Cherniack </author>
<date> June 18, 1996 </date>
<abstract> 0.1 Still To Do* 6 more fold proofs, precondition proofs* Adjust primitives for Int, Str and Char to be synchronized with the Theta operators for these types* Add floats* Add section describing preconditions* Add section on semantic optimizations, nested query optimization* Fix awk script to generate Latex version of Larch scripts without typeface glitches </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> OBJECT-ORIENTED QUERIES: EQUIVALENCE AND OPTIMIZATION </title>
<author> Gail M. Shaw and Stanley B. Zdonik </author>
<affiliation> Department of Computer ScienceBrown University </affiliation>
<address> Providence, R.I. 02912 </address>
<abstract> We are interested in efficiently accessing data in an object-oriented database.We have developed a query algebra which fully supports object identity andabstract data types, and have identified a variety of algebraic query transformations. The equivalence of two queries is complicated by the presence ofobject identity. In this paper we define a hierarchy of notions of equivalencefor queries, and present examples of equivalent query transformations for eachlevel of the hierarchy. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in Proc. 11th Intl. Conf. on Data Engg., 1995 </note>
<title> The AQUA Approach to Querying Lists andTrees in Object-Oriented Databases  </title>
<author> Bharathi Subramanian Theodore W. Leung </author>
<affiliation> Brown University Brown University </affiliation>
<author> Scott L. Vandenberg Stanley B. Zdonik </author>
<affiliation> Siena College Brown University </affiliation>
<abstract> AbstractRelational database systems and most object-oriented database systems provide support for queries.Usually these queries represent retrievals over sets ormultisets. Many new applications for databases, suchas multimedia systems and digital libraries, need support for queries on complex bulk types such as listsand trees. In this paper we describe an object-orientedquery algebra for lists and trees. The operators in thealgebra preserve the ordering between the elements of alist or tree, even when the result list or tree contains anarbitrary set of nodes from the original tree. We alsopresent predicate languages for lists and trees whichallow order-sensitive queries because they use patternmatching to examine groups of list or tree nodes ratherthan individual nodes. The ability to decompose predicate patterns enables optimizations that make use ofindices. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Decomposition Techniques for Planning in Stochastic Domains </title>
<author> Thomas Dean Shieu-Hong Lin </author>
<affiliation> Department of Computer Science </affiliation>
<address> Box 1910, </address>
 <affiliation> Brown University </affiliation>
<address> Providence, RI 02906,  USA </address>
<email> Email: ftld,shlg@cs.brown.edu </email>
<abstract> AbstractThis paper is concerned with modelingplanning problems involving uncertainty asdiscrete-time, finite-state stochastic automata.Solving planning problems is reduced to computing policies for Markov decision processes.Classical methods for solving Markov decisionprocesses cannot cope with the size of thestate spaces for typical problems encounteredin practice. As an alternative, we investigatemethods that decompose global planning problems into a number of local problems, solve thelocal problems separately, and then combinethe local solutions to generate a global solution. We present algorithms that decomposeplanning problems into smaller problems givenan arbitrary partition of the state space. Thelocal problems are interpreted as Markov decision processes and solutions to the local problems are interpreted as policies restricted to thesubsets of the state space defined by the partition. One algorithm relies on constructing andsolving an abstract version of the original decision problem. A second algorithm iterativelyapproximates parameters of the local problemsto converge to an optimal solution. We showhow properties of a specified partition affect thetime and storage required for these algorithms. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Computational Intelligence, Volume 12, Number 3, 1996 </note>
<title> LOCALIZED TEMPORAL REASONING USING SUBGOALSAND ABSTRACT EVENTS </title>
<author> Shieu-Hong Lin, Thomas Dean 1 </author>
<affiliation> Department of Computer Science, Brown University, </affiliation>
 <address> Providence, RI 02912 </address>
<abstract> We are concerned with temporal reasoning problems where there is uncertainty about the orderin which events occur. The task of temporal reasoning is to derive an event sequence consistent witha given set of ordering constraints to achieve a goal. Previous research shows that the associateddecision problems are hard even for very restricted cases. In this paper, we investigate locality inevent ordering and causal dependencies. We present a localized temporal reasoning algorithm thatuses subgoals and abstract events to exploit locality. The computational efficiency of our algorithmfor a problem instance is quantified by the inherent locality in the instance. We theoreticallydemonstrate the substantial improvement in performance gained by exploiting locality. This workprovides a solid evidence of the usefulness of localized reasoning in exploiting locality. </abstract>
<keyword> Key words: Dynamical Systems, Temporal Reasoning, Planning, Locality, Localized Reasoning, Subgoals, Abstract Events </keyword>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Hierarchical Solution of Markov Decision Processes using Macro-actions </title>
<author> Milos Hauskrecht, Nicolas MeuleauLeslie Pack Kaelbling, Thomas Dean </author>
<affiliation> Computer Science Department, </affiliation>
 <address> Box 1910 </address>
<affiliation> Brown University, </affiliation>
 <address> Providence, RI 02912 </address>
<email> fmilos, nm, lpk, tldg@cs.brown.edu </email>
<author> Craig Boutilier </author>
<affiliation> Department of Computer ScienceUniversity of British Columbia </affiliation>
<address> Vancouver, BC V6T 1Z4, Canada </address>
<email> cebly@cs.ubc.ca </email>
<abstract> AbstractWe investigate the use of temporally abstractactions, or macro-actions, in the solution ofMarkov decision processes. Unlike current models that combine both primitive actions andmacro-actions and leave the state space unchanged, we propose a hierarchical model (usingan abstract MDP) that works with macro-actionsonly, and that significantly reduces the size of thestate space. This is achieved by treating macro-actions as local policies that act in certain regionsof state space, and by restricting states in the abstract MDP to those at the boundaries of regions.The abstract MDP approximates the original andcan be solved more efficiently. We discuss several ways in which macro-actions can be generated to ensure good solution quality. Finally,we consider ways in which macro-actions can bereused to solve multiple, related MDPs; and weshow that this can justify the computational overhead of macro-action generation. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> How good are genetic algorithms at findinglarge cliques: an experimental study  </title>
<author> Bob Carter </author>
<email> carter@cs.bu.edu </email>
<author> Kihong Park  </author>
<email> park@cs.bu.edu </email>
<pubnum> BU-CS-93-015 </pubnum>
n<date> October 10, 1993 </date>
<affiliation> Boston UniversityComputer Science Department </affiliation>
<address> Boston, MA 02215 </address>
<phone> Phone: 617 353-8919Fax: 617 353-6457 </phone><abstract> AbstractThis paper investigates the power of genetic algorithms at solving the MAX-CLIQUE problem. We measure the performance of a standard genetic algorithm on an elementary set ofproblem instances consisting of embedded cliques in random graphs. We indicate the needfor improvement, and introduce a new genetic algorithm, the multi-phase annealed GA, whichexhibits superior performance on the same problem set.As we scale up the problem size and test on "hard" benchmark instances, we notice adegraded performance in the algorithm caused by premature convergence to local minima. Toalleviate this problem, a sequence of modifications are implemented ranging from changes ininput representation to systematic local search. The most recent version, called union GA,incorporates the features of union cross-over, greedy replacement, and diversity enhancement.It shows a marked speed-up in the number of iterations required to find a given solution, as wellas some improvement in the clique size found.We discuss issues related to the SIMD implementation of the genetic algorithms on a Thinking Machines CM-5, which was necessitated by the intrinsically high time complexity (O(n 3 ))of the serial algorithm for computing one iteration.Our preliminary conclusions are: (1) a genetic algorithm needs to be heavily customized towork "well" for the clique problem; (2) a GA is computationally very expensive, and its use isonly recommended if it is known to find larger cliques than other algorithms; (3) although ourcustomization effort is bringing forth continued improvements, there is no clear evidence, at thistime, that a GA will have better success in circumventing local minima. </abstract>
<note> Part of this research was presented at the 2nd DIMACS Implementation Challenge on Combinatorial Optimization, DIMACS, October, 1993.Supported in part by NSF grant CCR-9204284 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> The Undecidability ofMitchell's Subtyping Relationship  </title>
<author> J. B. Wells </author>
<email> jbw@cs.bu.edu </email>
<affiliation> Dept. of Computer ScienceBoston University </affiliation>
<address> Boston, MA 02215, U.S.A. </address>
<date> December 10, 1995 </date>
<abstract> AbstractMitchell defined and axiomatized a subtyping relationship (also knownas containment, coercibility, or subsumption) over the types of System F(with "!" and "8"). This subtyping relationship is quite simple and doesnot involve bounded quantification. Tiuryn and Urzyczyn quite recentlyproved this subtyping relationship to be undecidable. This paper supplies a new undecidability proof for this subtyping relationship. First, anew syntax-directed axiomatization of the subtyping relationship is defined. Then, this axiomatization is used to prove a reduction from theundecidable problem of semi-unification to subtyping. The undecidability of subtyping implies the undecidability of type checking for System Fextended with Mitchell's subtyping, also known as "F plus eta". </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> In Proceedings of ICC'97: The IEEE International Conference onCommunications, Montreal, Canada, June 1997. </note>
<title> Implementation and Performance Evaluation of TCP BostonA Fragmentation-tolerant TCP Protocol for ATM Networks  </title>
<author> Azer Bestavros </author>
<email> best@cs.bu.edu </email>
<author> Gitae Kim </author>
<email> kgtjan@cs.bu.edu </email>
<affiliation> Computer Science DepartmentBoston University </affiliation>
<address> Boston, MA 02215 </address>
<abstract> ABSTRACT:In this paper, we overview the implementation of TCP Bostona novel fragmentation-tolerant transport protocol, especiallysuited for ATM's 53-byte cell-oriented switching architecture.TCP Boston integrates a standard TCP/IP protocol, such asReno or Vegas, with a powerful redundancy control mechanism based on AIDAan adaptive version of Rabin's IDA dispersal and reconstruction algorithms. Our results show thatTCP Boston improves TCP/IP's performance over ATMs forboth network-centric metrics (e.g., effective throughput) andapplication-centric metrics (e.g., response time). </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Transfer Equations in Global Illumination </title>
<author> James Arvo +L </author>
<affiliation> Program of Computer GraphicsCornell University </affiliation>
<abstract> AbstractThe purpose of these notes is to describe some of the physical and mathematical propertiesof the equations occurring in global illumination. We first examine the physical assumptionsthat make the particle model of light an appropriate paradigm for computer graphics andthen derive a balance equation for photons. In doing this we establish connections with thefield of radiative transfer and its more abstract counterpart, transport theory. The resultingbalance equation, known as the equation of transfer, accounts for large-scale interactionof light with participating media as well as complex reflecting surfaces. Under varioussimplifying assumptions the equation of transfer reduces to more conventional equationsencountered in global illumination. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Generating CAD-models of teeth </title>
<author> Peter Johannes Neugebauer </author>
<affiliation> Fraunhofer-Institute for Computer Graphics, </affiliation>
<address> Wilhelminenstrasse 7, 64283 Darmstadt, Germany, </address>
<email> email: neugeb@igd.fhg.de </email>
<abstract> In this paper, we present an approach for the reconstruction of teeth model. Therefore,a tooth model has to be scanned from several directions with a 3D-laser scanner. Severalviews are necessary because of shadows and occluded areas in the range images. Then,all acquired range views are combined to build a CAD-model of the tooth. The idea isthat every part of the surface should be visible in at least one view. The reconstructionprocess is divided into the steps registration, volume sculpturing and generation of anaccurate polygonal representation. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Sensing Polygon Poses by Inscription </title>
<author> Yan-Bin Jia Michael Erdmann </author>
<affiliation> The Robotics InstituteSchool of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213-3891 </address>
<abstract> AbstractIndustrial assembly involves sensing the pose (orientation and position) of a part. Efficient and reliablesensing strategies can be developed for an assemblytask if the shape of the part is known in advance. Inthis paper we investigate the problem of determiningthe pose of a convex n-gon from a set of m supportingcones, i.e., cones with both sides supporting the polygon. An algorithm with running time O(nm) whichalmost always reduces to O(n + m log n) is presentedto solve for all possible poses of the polygon. As a consequence, the polygon inscription problem of finding allpossible poses for a convex n-gon inscribed in anotherconvex m-gon, can be solved within the same asymptotic time bound. We prove that the number of possible poses cannot exceed 6n, given m 2 supportingcones with distinct vertices. Experiments demonstratethat two supporting cones are sufficient to determinethe real pose of the n-gon in most cases.Our results imply that sensing in practice can becarried out by obtaining viewing angles of a planarpart at multiple exterior sites in the plane. As a conclusion, we generalize this and other sensing methodsinto a scheme named sensing by inscription. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Journal of Artificial Intelligence Research 1 (1994) 159-208 Submitted 8/93; published 2/94 </note>
<title> Bias-Driven Revision of Logical Domain Theories </title>
<author> Moshe Koppel </author>
 <email> KOPPEL@BIMACS.CS.BIU.AC.IL </email>
<author> Ronen Feldman </author>
 <email> FELDMAN@BIMACS.CS.BIU.AC.IL </email>
<affiliation> Department of Mathematics and Computer Science, Bar-Ilan University, </affiliation>
<address> Ramat-Gan, Israel </address>
<author> Alberto Maria Segre </author>
 <email> SEGRE@CS.CORNELL.EDU </email>
<affiliation> Department of Computer Science, Cornell University, </affiliation>
<address> Ithaca, NY 14853, USA </address>
<abstract> AbstractThe theory revision problem is the problem of how best to go about revising a deficientdomain theory using information contained in examples that expose inaccuracies. In this paper wepresent our approach to the theory revision problem for propositional domain theories. Theapproach described here, called PTR, uses probabilities associated with domain theory elements tonumerically track the ``ow'' of proof through the theory. This allows us to measure the preciserole of a clause or literal in allowing or preventing a (desired or undesired) derivation for a givenexample. This information is used to efficiently locate and repair awed elements of the theory.PTR is proved to converge to a theory which correctly classifies all examples, and shownexperimentally to be fast and accurate even for deep theories. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> THE CORAL USER MANUALA Tutorial Introduction to CORAL  </title>
<author> Raghu Ramakrishnan Praveen Seshadri Divesh Srivastava </author>
<author> S. Sudarshan </author>
<affiliation> Computer Sciences Department,University of Wisconsin-Madison, </affiliation>
 <address> WI 53706, U.S.A. </address>
<note> The authors' e-mail addresses are fraghu,divesh,praveeng@cs.wisc.edu; sudarsha@research.att.com. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Middleware Service for Real-Time Push-PullCommunications </title>
<author> Kanaka Juvva and Raj Rajkumar </author>
<affiliation> Real-Time and Multimedia LaboratoryCarnegie Mellon University </affiliation>
<address> Pittsburgh PA 15213 </address>
<email> fkjuvva, raj+g@cs.cmu.edu </email>
<abstract> Abstract:Current and emerging real-time and multimedia applications like multi-party collaboration, internet telephony anddistributed command control systems require the exchange of information over distributed and heterogeneous nodes.Multiple data types including voice, video, sensor data, real-time intelligence data and text are being transportedwidely across today's information, control and surveillance networks. All such applications can benefit enormouslyfrom middleware, operating system and networking services that can support QoS guarantees, high availability,dynamic reconfigurability and scalability.In this paper, we propose a middleware layer called a "Real-Time Push-Pull Communications Service" to easily and quickly disseminate information across heterogeneous nodes with an underlying architecture to satisfy theabove-mentioned requirements. Push-Pull Communications is an extension of the real-time publisher/subscribermodel [4], and represents both "push" (data transfer initiated by a sender) and "pull" (data transfer initiated by areceiver) communications. Nodes with widely differing processing power and networking bandwidth can coordinateand co-exist by the provision of appropriate and automatic support for transformation on data and supports scaling.Different information sources and sinks can operate at different frequencies and also can choose another (intermedi-ate) node to act as their proxy and and deliver data at the desired frequency. This service has been implementedon RT-Mach, a resource-centric kernel using resource kernel primitives [7]. This paper presents an overview of thedesign, implementation and preliminary performance evaluation of the model. </abstract>
<keyword> Keywords: Push communications, Pull communications, Proxy, Scaling, Middleware service, QoS </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Quality-of-Service Routing forTraffic with PerformanceGuarantees </title>
<author> Qingming Ma and Peter Steenkiste </author>
<affiliation> Computer Science Department, Carnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213, USA, </address>
 <email> fqma, prsg@cs.cmu.edu </email>
<abstract> AbstractQuality-of-Service (QoS) routing tries to select a path that satisfies a set ofQoS constraints, while also achieving overall network resource efficiency. Wepresent initial results on QoS path selection for traffic requiring bandwidthand delay guarantees. For traffic with bandwidth guarantees, we found thatseveral routing algorithms that favor paths with fewer hops perform well. Fortraffic with delay guarantees, we show that for a broad class of WFQ-likescheduling algorithms, the problem of finding a path satisfying bandwidth,delay, delay-jitter, and/or buffer space constraints while at the same timederiving the bandwidth that has to be reserved to meet these constraints, issolvable by a modified version of the Bellman-Ford shortest-path algorithmin polynomial time. </abstract>
<keyword> KeywordsRouting, quality of service, integrated services networks </keyword>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Journal of Artificial Intelligence Research 3 (1995) 53-118 Submitted 3/95; published 7/95 </note>
<title> Building and Refining Abstract Planning Casesby Change of Representation Language </title>
<author> Ralph Bergmann </author>
 <email> bergmann@informatik.uni-kl.de </email>
<author> Wolfgang Wilke </author>
 <email> wilke@informatik.uni-kl.de </email>
<affiliation> Centre for Learning Systems and Applications (LSA)University of Kaiserslautern, </affiliation>
 <address> P.O.-Box 3049, D-67653 Kaiserslautern, Germany </address>
<abstract> AbstractAbstraction is one of the most promising approaches to improve the performance of problemsolvers. In several domains abstraction by dropping sentences of a domain description asused in most hierarchical planners has proven useful. In this paper we present exampleswhich illustrate significant drawbacks of abstraction by dropping sentences. To overcomethese drawbacks, we propose a more general view of abstraction involving the change ofrepresentation language. We have developed a new abstraction methodology and a relatedsound and complete learning algorithm that allows the complete change of representationlanguage of planning cases from concrete to abstract. However, to achieve a powerfulchange of the representation language, the abstract language itself as well as rules whichdescribe admissible ways of abstracting states must be provided in the domain model.This new abstraction approach is the core of Paris (Plan Abstraction and Refinementin an Integrated System), a system in which abstract planning cases are automaticallylearned from given concrete cases. An empirical study in the domain of process planningin mechanical engineering shows significant advantages of the proposed reasoning fromabstract cases over classical hierarchical planning. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Experience with Rover Navigation for Lunar-Like Terrains </title>
<author> Reid Simmons, Eric Krotkov, Lalitesh Katragadda, and Martial Hebert </author>
<affiliation> Robotics Institute, Carnegie Mellon University </affiliation>
<address> 5000 Forbes Avenue, Pittsburgh, PA 15213 </address>
<email> reids@cs.cmu.edu </email>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Final Version, 94-Mar-17,1of 9 </note>
<title> Automation Tools forNonDestructive Inspection of Aircraft:Promise of Technology Transfer from theCivilian to the Military Sector </title>
<author> Chris Seher 1 , Mel Siegel 2 , and William M. Kaufman 3 </author>
<affiliation> 1 Federal Aviation Administration, Technical Center, </affiliation>
 <address> Atlantic City NJ 08201 </address>
<affiliation> 2 Carnegie Mellon University, Robotics Institute, </affiliation>
 <address> Pittsburgh PA 15213 </address>
<affiliation> 3 Carnegie Mellon University, CMRI, </affiliation>
 <address> Pittsburgh PA 15213 </address>
<abstract> AbstractThe FAA Aging Aircraft Research Program issupporting the development of a robotic mobilenondestructive inspection (NDI) instrumentdeployment tool at Carnegie Mellon University(CMU) with the active participation of USAir. Theprogram has spawned several new relationshipsand entities: an alliance with an ARPA-fundedresearch program at CMU having the capability toadd 3D-stereoscopic enhanced visual inspectioncapability, a start-up company organized tocommercialize the combined technologies, andState of Pennsylvania funding to foster thiscommercialization. As a result of these activitiesand connections the civilian sector appears to beahead of the military sector in important aspects ofautomation for deployment of aircraft inspectionequipment. A partnership between the universityresearchers, the airline operator, the start-upcompany, and the state government is thusemerging as the likely agent for transfer of thecivilian-developed technology to the military sector. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Information Extraction from HTML:Application of a General Machine Learning Approach  </title>
<author> Dayne Freitag </author>
<affiliation> Department of Computer ScienceCarnegie Mellon University </affiliation>
<address> 5000 Forbes AvenuePittsburgh, PA 15213 </address>
<email> dayne@cs.cmu.edu </email>
<abstract> AbstractBecause the World Wide Web consists primarily oftext, information extraction is central to any effort thatwould use the Web as a resource for knowledge discovery. We show how information extraction can be castas a standard machine learning problem, and argue forthe suitability of relational learning in solving it. Theimplementation of a general-purpose relational learnerfor information extraction, SRV, is described. In contrast with earlier learning systems for information extraction, SRV makes no assumptions about documentstructure and the kinds of information available for usein learning extraction patterns. Instead, structural andother information is supplied as input in the form of anextensible token-oriented feature set. We demonstratethe effectiveness of this approach by adapting SRV foruse in learning extraction rules for a domain consistingof university course and research project pages sampledfrom the Web. Making SRV Web-ready only involvesadding several simple HTML-specific features to its basic feature set. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> The Candide System for Machine Translation </title>
<author> Adam L. Berger, Peter F. Brown , Stephen A. Della Pietra, Vincent J. Della Pietra,John R. Gillett, John D. Lafferty, Robert L. Mercer, Harry Printz, Lubos Ures </author>
<affiliation> IBM Thomas J. Watson Research Center </affiliation>
<address> P.O. Box 704Yorktown Heights, NY 10598 </address>
<abstract> ABSTRACTWe present an overview of Candide, a system for automatictranslation of French text to English text. Candide usesmethods of information theory and statistics to develop aprobability model of the translation process. This model,which is made to accord as closely as possible with a largebody of French and English sentence pairs, is then used togenerate English translations of previously unseen Frenchsentences. This paper provides a tutorial in these methods,discussions of the training and operation of the system, anda summary of test results. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Efficient Resource Management </title>
<note> This paper will appear in the proceedings of the 1996 International Workshop onExtensions of Logic Programming, Leipzig, Germany, March 28-30 1996. </note>
<title> for Linear Logic Proof Search </title>
<author> Iliano Cervesato 1 , Joshua S. Hodas 2 , and Frank Pfenning 1 </author>
<affiliation> 1 Department of Computer Science, Carnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213-3891, USA </address>
<email> e-mail: filianojfpg@cs.cmu.edu </email>
<affiliation> 2 Computer Science Department, Harvey Mudd College </affiliation>
<address> Claremont, CA 91711, USA </address>
<email> e-mail: hodas@cs.hmc.edu </email>
<abstract> Abstract. The design of linear logic programming languages and theorem provers opens a number of new implementation challenges notpresent in more traditional logic languages such as Horn clauses (Prolog)and hereditary Harrop formulas (Prolog). Among these, the problem ofefficiently managing the linear context when solving a goal is of crucialimportance for the use of these systems in non-trivial applications. Thispaper studies this problem in the case of Lolli [6] (though its results haveapplication to other systems). We first give a proof-theoretic presentation of the operational semantics of this language as a resolution calculus.We then present a series of resource management systems designed toeliminate the non-determinism in the distribution of linear formulas thatundermines the efficiency of a direct implementation of this system. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Simplified Account of Polymorphic References </title>
<author> Robert Harper </author>
<date> June, 1993 </date>
<pubnum> CMU-CS-93-169 </pubnum>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<abstract> AbstractA proof of the soundness of Tofte's imperative type discipline with respect to a structured operationalsemantics is given. The presentation is based on a semantic formalism that combines the benefits of theapproaches considered by Wright and Felleisen, and by Tofte, leading to a particularly simple proof ofsoundness of Tofte's type discipline. </abstract>
<note> This research was sponsored by the Defense Advanced Research Projects Agency, CSTO, under the title "The FoxProject: Advanced Development of Systems Software", ARPA Order No. 8313, issued by ESD/AVS under ContractNo. F19628-91-C-0168.The views and conclusions contained in this document are those of the author and should not be interpreted asrepresenting official policies, either expressed or implied, of the Defense Advanced Research Projects Agency or theU.S. Government. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<author> Shumeet Baluja </author>
<email> baluja@cs.cmu.edu </email>
<affiliation> Justsystem Pittsburgh Research Center &amp;Carnegie Mellon University </affiliation>
<author> Scott Davies </author>
<email> scottd@cs.cmu.edu </email>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<title> Fast Probabilistic Modeling for Combinatorial Optimization </title>
<abstract> AbstractProbabilistic models have recently been utilized for the optimization of large combinatorial search problems. However,complex probabilistic models that attempt to capture inter-parameter dependencies can have prohibitive computationalcosts. The algorithm presented in this paper, termedCOMIT, provides a method for using probabilistic models inconjunction with fast search techniques. We show howCOMIT can be used with two very different fast search algorithms: hillclimbing and Population-based incrementallearning (PBIL). The resulting algorithms maintain many ofthe benefits of probabilistic modeling, with far less computational expense. Extensive empirical results are provided;COMIT has been successfully applied to jobshop scheduling, traveling salesman, and knapsack problems. This paperalso presents a review of probabilistic modeling for combinatorial optimization. </abstract>
<intro> 1 Background </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> New Approximation Techniques for Some Ordering Problems </title>
<author> Satish Rao Andrea W. Richa  </author>
<abstract> AbstractWe describe logarithmic times optimal approximationalgorithms for the NP-hard graph optimization problems of minimum linear arrangement, minimum containing interval graph, and minimum storage-timeproduct. This improves on the best previous approximation bounds of Even, Naor, Rao, and Schieber forthese problems by an (log log n) factor.Even, Naor, Rao, and Schieber defined "spreadingmetrics" for each of the ordering problems above (andto other problems); for each of these problems, theyprovided a spreading metric of volume W , such that Wis a lower bound on the cost of a solution to the problem.They used this spreading metric to find a solution ofcost O(W log n log log n) (for simplicity, assume thatall tasks have unit processing time in the minimumstorage-time product problem). In this paper, we showhow to find a solution within a logarithmic factor timesW for these problems.We develop a recursion where at each level weidentify cost which, if incurred, yields subproblemswith reduced spreading metric volume. Specifically, wepresent a divide-and-conquer strategy where the cost ofa solution to a problem at a recursive level is C plus thecost of a solution to the subproblems at this level, andwhere the spreading metric volume on the subproblemsis less than the original volume by (C= log n). Thisensures that the resulting solution has cost O(log n)times the original spreading metric volume.We note that this is an existentially tight bound onthe relationship between the spreading metric volumeW and the true optimal values for these problems.For planar graphs, we combine a structural theoremof Klein, Plotkin, and Rao with our new recursion technique to show that the spreading metric cost volumesare within an O(log log n) factor of the cost of an optimal solution for the minimum linear arrangement, andthe minimum containing interval graph problems. </abstract>
<note> To appear in Proceedings of Ninth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), January 1998.Research supported by NEC Research Institute, 4 Independence Way, Princeton, NJ 08540; satish@research.nj.nec.com.Research supported in part by NSF NYI Award No. CCR-9457766, ARPA Contract F33615-93-1-1330, NEC Research Institute, and DIMACS. School of Computer Science, Carnegie MellonUniversity, Pittsburgh, PA 15213, aricha@cs.cmu.edu. </note>
<intro> 1 Introduction. </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Autonomous Robots, ??, 1-18 (??)c ?? Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. </note>
<title> Interleaving Planning and Robot Executionfor Asynchronous User Requests </title>
<author> KAREN ZITA HAIGH MANUELA M. VELOSO </author>
<email> khaigh@cs.cmu.edu mmv@cs.cmu.edu </email>
<web> http://www.cs.cmu.edu/~khaigh http://www.cs.cmu.edu/~mmv </web><affiliation> Computer Science Department, Carnegie Mellon University, </affiliation>
 <address> Pittsburgh PA 15213-3891 </address>
<abstract> Abstract.Rogue is an architecture built on a real robot which provides algorithms for the integration of high-level planning, low-level robotic execution, and learning. Rogue addresses successfully several of thechallenges of a dynamic office gopher environment. This article presents the techniques for the integrationof planning and execution.Rogue uses and extends a classical planning algorithm to create plans for multiple interacting goalsintroduced by asynchronous user requests. Rogue translates the planner's actions to robot executionactions and monitors real world execution. Rogue is currently implemented using the prodigy4.0planner and the Xavier robot. This article describes how plans are created for multiple asynchronous goals,and how task priority and compatibility information is used to achieve appropriate efficient execution. Wedescribe how Rogue communicates with the planner and the robot to interleave planning with executionso that the planner can replan for failed actions, identify the actual outcome of an action with multiplepossible outcomes, and take opportunities from changes in the environment.Rogue represents a successful integration of a classical artificial intelligence planner with a real mobilerobot. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Implementing Distributed Server Groups for theWorld Wide Web </title>
<author> Michael Garland, Sebastian Grassia, Robert Monroe, Siddhartha Puri </author>
<date> 25 January 1995 </date>
<pubnum> CMU-CS-95-114 </pubnum>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, Pennsylvania 15213-3890 </address>
<abstract> AbstractThe World Wide Web (WWW) has recently become a very popular facility for the dissemination ofinformation. As a result of this popularity, it is experiencing rapidly increasing traffic load. Singlemachine servers cannot keep pace with the ever greater load being placed upon them. To alleviate thisproblem, we have implemented a distributed Web server group. The server group can effectively balance request load amongst its members (within about 10% of optimal), and client response time is noworse than in the single server case. Client response time was not improved because the measured client traffic consumed all available network throughput. The distributed operation of the server groups iscompletely transparent to standard Web clients. </abstract>
<note> This research is sponsored in part by the Wright Laboratory, Aeronautical SystemsCenter, Air Force Materiel Command, USAF,and the Advanced Research Projects Agency (ARPA) under grant F33615-93-1-1330. The US Government is authorized to reproduce and distribute reprints for Government purposes, notwithstanding any copyright notation thereon. Support also came from theAir Force Materiel Command under contract number F19628-93-C-0171. Views and conclusions contained in this document arethose of the authors and should not be interpreted as representing the official policies, either expressed or implied, of Wright Laboratory or the United States Government. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Fast Soft Shadows </title>
<author> Michael Herf and Paul S. Heckbert  </author>
<abstract> AbstractPresented is a new algorithm to generate soft shadows. Itemploys graphics hardware, including texture mapping andaccumulation buffering, to produce shadows resulting fromarea light sources quickly. </abstract>
<affiliation>  Computer Science Dept., Carnegie Mellon University, </affiliation>
 <address>  Pittsburgh PA 15213-3891, USA. </address>
 <web> http://www.cs.cmu.edu/ph, </web> <email> herf+@cmu.edu,ph@cs.cmu.edu. </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Performance Measurements of the MultimediaTestbed on Real-Time Mach </title>
<author> Roger B. Dannenberg, David B. Anderson,Tom Neuendorffer, Dean Rubine </author>
<date> April 1994 </date>
<pubnum> CMU-CS-94-141 </pubnum>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213-3890 </address>
<abstract> AbstractMultimedia has generated widespread interest in real-time support within general purposeoperating systems. Multimedia also places new demands on operating systems for interprocesscommunication. The Multimedia Testbed is a set of applications that stress consistent low-latency response and efficient interprocess communication for large blocks of data. TheMultimedia Testbed was ported to Real-Time Mach in the hopes of providing predictable low-latency response and, consequently, good synchronization and low jitter as required formultimedia applications. Our work compares the performance of Real-Time Mach with that ofMach 3.0. Although the fixed-priority scheduling of Real-Time Mach is a substantialimprovement, user threads are still preempted by device drivers, and the overall real-timeperformance is not suitable for multimedia applications. We discuss areas where Real-TimeMach needs improvement. </abstract>
<note> This research was performed by the Carnegie Mellon Information Technology Center andsupported by the IBM Corporation. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Clustering Learning Tasks and the Selective Cross-TaskTransfer of Knowledge </title>
<author> Sebastian Thrun Joseph O'Sullivan </author>
<date> November 1995 </date>
<pubnum> CMU-CS-95-209 </pubnum>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<note> The first author is also affiliated with the Computer Science Department III of the University ofBonn, Germany, where part of this research was carried out.This research is sponsored in part by the National Science Foundation under award IRI-9313367,and by the Wright Laboratory, Aeronautical Systems Center, Air Force Materiel Command, USAF,and the Advanced Research Projects Agency (ARPA) under grant number F33615-93-1-1330. Theviews and conclusions contained in this document are those of the author and should not be interpretedas necessarily representing official policies or endorsements, either expressed or implied, of NSF,Wright Laboratory or the United States Government. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Moving target classification and tracking from real-time video </title>
<author> Alan J. Lipton Hironobu Fujiyoshi Raju S. Patil </author>
<affiliation> The Robotics Institute. Carnegie Mellon University </affiliation>
<address> 5000 Forbes Avenue, Pittsburgh, PA, 15213 </address>
<email> email: fajljhironobujrajug@cs.cmu.edu </email>
<web> URL: http://www.cs.cmu.edu/~ vsam </web><abstract> AbstractThis paper describes an end-to-end method for extracting moving targets from a real-time video stream,classifying them into predefined categories accordingto image-based properties, and then robustly trackingthem. Moving targets are detected using the pixelwisedifference between consecutive image frames. A classi-ficatoin metric is applied these targets with a temporalconsistency constraint to classify them into three categories: human, vehicle or background clutter. Onceclassified, targets are tracked by a combination of temporal differencing and template matching.The resulting system robustly identifies targets ofinterest, rejects background clutter, and continuallytracks over large distances and periods of time despiteocclusions, appearance changes and cessation of targetmotion. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Exploiting Weak Connectivity for Mobile File Access </title>
<author> Lily B. Mummert, Maria R. Ebling, M. Satyanarayanan </author>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<abstract> AbstractWeak connectivity, in the form of intermittent, low-bandwidth, or expensive networks is a fact of life in mobile computing.In this paper, we describe how the Coda File System has evolved to exploit such networks. The underlying theme of thisevolution has been the systematic introduction of adaptivity to eliminate hidden assumptions about strong connectivity.Many aspects of the system, including communication, cache validation, update propagation and cache miss handling havebeen modified. As a result, Coda is able to provide good performance even when network bandwidth varies over four ordersof magnitude from modem speeds to LAN speeds. </abstract>
<intro> 1. Introduction 2. Starting Point: Disconnected Operation </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> TIGHT ANALYSES OF TWO LOCAL LOAD BALANCING ALGORITHMS </title>
<author> BHASKAR GHOSH 1 F. T. LEIGHTON 2 BRUCE M. MAGGS 3;4S. MUTHUKRISHNAN 5 C. GREG PLAXTON 6;7 R. RAJARAMAN 6;7ANDR EA W. RICHA 3;4 ROBERT E. TARJAN 8 DAVID ZUCKERMAN 6;9 </author>
<abstract> Abstract.This paper presents an analysis of the following load balancing algorithm. At each step, each node in a network examines the numberof tokens at each of its neighbors and sends a token to each neighbor with at least 2d + 1 fewer tokens, where d is the maximum degreeof any node in the network. We show that within O(=ff) steps, the algorithm reduces the maximum difference in tokens between anytwo nodes to at most O((d 2 log n)=ff), where is the global imbalance in tokens (i.e., the maximum difference between the number oftokens at any node initially and the average number of tokens), n is the number of nodes in the network, and ff is the edge expansion ofthe network. The time bound is tight in the sense that for any graph with edge expansion ff, and for any value , there exists an initialdistribution of tokens with imbalance for which the time to reduce the imbalance to even =2 is at least (=ff). The bound on thefinal imbalance is tight in the sense that there exists a class of networks that can be locally balanced everywhere (i.e., the maximumdifference in tokens between any two neighbors is at most 2d), while the global imbalance remains ((d 2 log n)=ff). Furthermore, we showthat upon reaching a state with a global imbalance of O((d 2 log n)=ff), the time for this algorithm to locally balance the network can beas large as (n 1=2 ). We extend our analysis to a variant of this algorithm for dynamic and asynchronous networks. We also present tightbounds for a randomized algorithm in which each node sends at most one token in each step. </abstract>
<keyword> Keywords: load balancing, distributed network algorithms. </keyword>
<note> AMS subject classification: 68Q22 </note>
<intro> 1. Introduction. A natural way to balance the workload in a distributed system is to have each work station </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A PRINCIPLED REPRESENTATION OF ATTRIBUTIVE DESCRIPTIONSFOR GENERATING INTEGRATED TEXT AND INFORMATIONGRAPHICS PRESENTATIONS </title>
<author> Nancy Green*, Giuseppe Carenini**, and Johanna Moore** </author>
<affiliation> *Carnegie Mellon University, **University of Pittsburgh </affiliation>
<email> nancy.green@cs.cmu.edu, fjmoore,careninig@cs.pitt.edu </email>
<abstract> AbstractThis paper describes a media-independent, compositional, plan-based approach to representing attributive descriptions for use in integrated text and graphics generation. An attributivedescription's main function is to convey information directly contributing to the communicativegoals of a discourse, whereas a referential description's only function is to enable the audienceto identify a particular referent. This approach has been implemented as part of an architecturefor generating integrated text and information graphics. Uses of referential and attributive descriptions are represented as two distinct types of communicative acts in a media-independentplan. It is particularly important to distinguish the two types of acts, since they have differentconsequences for dialogue and text generation, and for graphic design. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> , , 1-8 () </note>
<note> c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. </note>
<title> A Note on Learning from Multiple-Instance Examples </title>
<author> AVRIM BLUM </author>
 <email> avrim+@cs.cmu.edu </email>
<author> ADAM KALAI </author>
 <email> akalai+@cs.cmu.edu </email>
<affiliation> School of Computer Science, Carnegie Mellon University, </affiliation>
 <address> Pittsburgh, PA 15213 </address>
<abstract> Abstract.We describe a simple reduction from the problem of PAC-learning from multiple-instance examples to that of PAC-learning with one-sided random classification noise. Thus, all concept classeslearnable with one-sided noise, which includes all concepts learnable in the usual 2-sided randomnoise model plus others such as the parity function, are learnable from multiple-instance examples. We also describe a more efficient (and somewhat technically more involved) reduction tothe Statistical-Query model that results in a polynomial-time algorithm for learning axis-parallelrectangles with sample complexity ~ O(d 2 r=* 2 ), saving roughly a factor of r over the results of Aueret al. (1997). </abstract>
<keyword> Keywords: Multiple-instance examples, classification noise, statistical queries </keyword>
<intro> 1. Introduction and Definitions </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Proceedings of the 4th International Symposium on Intelligent Robotic Systems SIRS'96, Lisbon, Portugal, July 22-26, 1996 </note>
<title> Memory-based Stochastic Optimization for Automated Tuningof Neural Network's High Level Parameters ? </title>
<author> Artur Dubrawski ?? </author>
<affiliation> The Robotics Institute, Carnegie Mellon University, </affiliation>
 <address> 5000 Forbes Avenue, Pittsburgh, PA 15213, USA </address>
<abstract> Abstract. In this paper we describe a new method for automated tuning of high level parameters of supervisedlearning systems. It uses memory-based learning principles and follows certain ideas of experimental design. Thedescribed method allows not only for an efficient search through a decision space, but also for a concurrent validationof the learning algorithm performance on a given data. Potential usefulness of the proposed approach is illustratedwith the Fuzzy-ARTMAP neural network application to learning a qualitative positioning of an indoor mobile robotequipped with sonar range sensors. Automatically selected neural network setpoints reach a comparable performanceto those achieved by human experts in relatively simple 2D cases. Migration of the proposed method to higher orderoptimization domains bears a big promise, but requires further research. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> SIGGRAPH 95, Los Angeles, August 6-11 COMPUTER GRAPHICS Proceedings, Annual Conference Series, 1995 </note>
<title> Interactive Physically-Based Manipulationof Discrete/Continuous Models </title>
<author> Mikako Harada </author>
<affiliation> Department of Architecture </affiliation>
<author> Andrew Witkin </author>
<affiliation> Department of Computer Science </affiliation>
<author> David Baraff </author>
<affiliation> Robotics InstituteCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<abstract> AbstractPhysically-based modeling has been used in the past to support a variety of interactive modeling tasks including free-form surface design, mechanism design, constrained drawing, and interactive camera control. In these systems, the user interacts with the modelby exerting virtual forces, to which the system responds subjectto the active constraints. In the past, this kind of interaction hasbeen applicable only to models that are governed by continuousparameters. In this paper we present an extension to mixed con-tinuous/discrete models, emphasizing constrained layout problemsthat arise in architecture and other domains. When the object beingdragged is blocked from further motion by geometric constraints, alocal discrete search is triggered, during which transformations suchas swapping of adjacent objects may be performed. The result of thesearch is a nearby state in which the target object has been movedin the indicated direction and in which all constraints are satisfied.The transition to this state is portrayed using simple but effective animated visual effects. Following the transition, continuous draggingis resumed. The resulting seamless transitions between discrete andcontinuous manipulation allow the user to easily explore the mixeddesign space just by dragging objects. We demonstrate the methodin application to architectural floor plan design, circuit board layout,art analysis, and page layout. </abstract>
<keyword> KeywordsInteractive techniques, physically-based modeling,grammars. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in the Proceedings of the 16th ACM Symposium on Operating System Principles </note>
<title> Agile Application-Aware Adaptation for Mobility </title>
<author> Brian D. Noble, M. Satyanarayanan, Dushyanth Narayanan, James Eric Tilton, Jason Flinn, Kevin R. Walker </author>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<abstract> AbstractIn this paper we show that application-aware adaptation, acollaborative partnership between the operating system andapplications, offers the most general and effective approachto mobile information access. We describe the design ofOdyssey, a prototype implementing this approach, and showhow it supports concurrent execution of diverse mobile applications. We identify agility as a key attribute of adaptive systems, and describe how to quantify and measure it.We present the results of our evaluation of Odyssey, indicating performance improvements up to a factor of 5 on abenchmark of three applications concurrently using remoteservices over a network with highly variable bandwidth. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Mixed-Initiative Management of Integrated Process-Planning andProduction-Scheduling Solutions </title>
<author> David W. Hildum, Norman M. Sadeh, Thomas J. Laliberty, Stephen F. Smith, John McA'Nulty and Dag Kjenstad  </author>
<affiliation> Intelligent Coordination and Logistics LaboratoryCenter for Integrated Manufacturing Decision SystemsThe Robotics InstituteCarnegie Mellon University </affiliation>
<address> Pittsburgh PA 15213-3890 </address>
<phone> 412.268.7598 fax: 412.268.5569 </phone><email> fHILDUM,SADEH,SFS,DAGg@ISL1.RI.CMU.EDU </email>
<affiliation> Software Engineering LaboratoryRaytheon Electronic SystemsRaytheon Company </affiliation>
<address> Tewksbury MA 01876-0901 </address>
<phone> 508.858.5756 fax: 508.858.5976 </phone><email> LALIBERTY THOMAS@CAEMAC.MSD.RAY.COMMCANULTY@CAESUN.MSD.RAY.COM </email>
<abstract> AbstractIncreased reliance on agile manufacturing techniques has created a demand for systems to solve integrated process-planningand production-scheduling problems in large-scale dynamic environments. To be effective, these systems should provide user-oriented interactive functionality for managing the various usertasks and objectives and reacting to unexpected events. This paper describes the mixed-initiative problem-solving features ofIP3S, an Integrated Process-Planning/Production-Schedulingshell for agile manufacturing. IP3S is a blackboard -based systemthat supports the concurrent development and dynamic revisionof integrated process-planning and production-scheduling solutions and the maintenance of multiple problem instances andsolutions, as well as other flexible user-oriented decision-makingcapabilities, allowing the user to control the scope of the problem and explore alternate tradeoffs (what-if scenarios) interactively. The system is scheduled for initial deploymentand evaluation in a large and highly dynamic machine shop atRaytheon's Andover manufacturing facility. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Proportional-Share Scheduling: Implementation andEvaluation in a Widely-Deployed Operating System </title>
<author> David Petrou and John Milford </author>
<email> dpetrou@cs.cmu.edu, jwm@csua.berkeley.edu </email>
<note> Draft 12/20/1997. Send feedback to the authors. </note>
<abstract> AbstractThis paper explores the feasibility of using lottery scheduling, a proportional-share resource management algorithm,to schedule processes under the FreeBSD operating system.Proportional-share scheduling enables flexible control overrelative process execution rates and processor load insulation among groups of processes. We show that a straight implementation of lottery scheduling performs worse than thestandard FreeBSD scheduler. This initial result promptedus to extend lottery scheduling. Except for one test werun, our resulting system performs within one percent ofthe FreeBSD scheduler. We describe our design, evaluateour implementation, and relate our experience in deployingour lottery scheduler on production machines. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Operant Conditioning in Skinnerbots </title>
<author> David S. Touretzky </author>
<affiliation> Computer Science Department &amp;Center for the Neural Basis of CognitionCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213-3891 </address>
<email> dst@cs.cmu.edu </email>
<author> Lisa M. Saksida </author>
<affiliation> Robotics Institute &amp;Center for the Neural Basis of CognitionCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213-3891 </address>
<email> saksida@ri.cmu.edu </email>
<note> To appear in Adaptive Behavior 5(3/4), 1997.Copyright c 1997 The MIT Press. </note>
<abstract> AbstractInstrumental (or operant) conditioning, a form of animal learning, is similar to reinforcement learning(Watkins, 1989) in that it allows an agent to adapt its actions to gain maximally from the environmentwhile only being rewarded for correct performance. But animals learn much more complicated behaviorsthrough instrumental conditioning than robots presently acquire through reinforcement learning. Wedescribe a new computational model of the conditioning process that attempts to capture some of theaspects that are missing from simple reinforcement learning: conditioned reinforcers, shifting reinforcement contingencies, explicit action sequencing, and state space refinement. We apply our model to a taskcommonly used to study working memory in rats and monkeys: the DMTS (Delayed Match to Sample)task. Animals learn this task in stages. In simulation, our model also acquires the task in stages, in asimilar manner. We have used the model to train an RWI B21 robot. </abstract>
<keyword> Keywords: operant conditioning, instrumental learning, shaping, chaining, learning robots </keyword>
<note> Running Head: Operant Conditioning in Skinnerbots </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<date> May 3, 1997 1 </date>
<title> Middleware Enabled Fault Management for Commercial Operating Systems </title>
<date> April 29, 1997 </date>
<note> for submission to: Software Reliability and Fault Tolerance Track of the Computer Science Division at the 15th Annual International Conference of the AOM/IAOMAuthor Information: </note>
<author> Charlotte A. Rekiere </author>
<affiliation> Carnegie Mellon University </affiliation>
<address> 5000 Forbes Ave.2201 Hamburgh HallPittsburgh, PA 15232 </address>
<phone> PH: (412) 621-9406 </phone><email> email: crekiere@cs.cmu.edu </email>
<author> Daniel P. Siewiorek </author>
<author> Professor CS/ECE </author>
<affiliation> Carnegie Mellon University </affiliation>
<address> 5000 Forbes Ave.1201 Hamburgh HallPittsburgh, PA 15232 </address>
<phone> PH: (412)268-2570 </phone><email> email: dps@cs.cmu.edu </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Improving Text Classification by Shrinkage in a Hierarchy of Classes </title>
<author> Andrew McCallum </author>
<email> mccallum@justresearch.com </email>
<author> Ronald Rosenfeld </author>
 <email> roni@cs.cmu.edu </email>
<author> Tom Mitchell </author>
 <email> mitchell+@cs.cmu.edu </email>
<author> Andrew Y. Ng </author>
 <email> ayn@ai.mit.edu </email>
<affiliation> Just Research </affiliation>
<address> 4616 Henry StreetPittsburgh, PA 15213 </address>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<affiliation> MIT AI Lab </affiliation>
<address> 545 Technology SquareCambridge, MA 02139 </address>
<abstract> AbstractWhen documents are organized in a largenumber of topic categories, the categoriesare often arranged in a hierarchy. The U.S.patent database and Yahoo are two examples.This paper shows that the accuracy of a naiveBayes text classifier can be significantly improved by taking advantage of a hierarchy ofclasses. We adopt an established statisticaltechnique called shrinkage that smoothes parameter estimates of a data-sparse child withits parent in order to obtain more robust parameter estimates. The approach is also employed in deleted interpolation, a techniquefor smoothing n-grams in language modelingfor speech recognition.Our method scales well to large data sets,with numerous categories in large hierarchies.Experimental results on three real-world datasets from UseNet, Yahoo, and corporate webpages show improved performance, with a reduction in error up to 29% over the traditional flat classifier. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Abstract Time Warping of Compound Events and Signals </title>
<author> Roger B. Dannenberg </author>
<affiliation> Carnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 USA </address>
<email> dannenberg@cs.cmu.edu </email>
<abstract> ABSTRACT: Functions of time are often used to represent continuous parameters and the passageof musical time (tempo). A new approach generalizes previous work in three ways. First, commontemporal operations of stretching and shifting are special cases of a new general time-warpingoperation. Second, these operations are ``abstract.'' Instead of operating directly on signals orevents, they operate on abstract behaviors that interpret the operations at an appropriate structurallevel. Third, time warping can be applied to both discrete events and continuous signals. </abstract>
<intro> 1. Introduction 2. Shift, Stretch, and Warp </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Remote Access to Interactive Media </title>
<author> Roger B. Dannenberg </author>
<affiliation> Carnegie Mellon University, School of Computer Science </affiliation>
<address> Pittsburgh, PA 15213 USA </address>
<email> Email: dannenberg@cs.cmu.edu </email>
<abstract> ABSTRACTDigital interactive media augments interactive computing with video, audio, computer graphics and text,allowing multimedia presentations to be individually and dynamically tailored to the user. Multimedia, andparticularly continuous media pose interesting problems for system designers, including those of latencyand synchronization. These problems are especially evident when multimedia data is remote and must beaccessed via networks. Latency and synchronization issues are discussed, and an integrated system,Tactus, is described. Tactus facilitates the implementation of interactive multimedia computer programs bymanaging latency and synchronization in the framework of an object-oriented graphical user interfacetoolkit. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> INFORMING LOADS: ENABLING SOFTWARE TOOBSERVE AND REACT TO MEMORY BEHAVIOR </title>
<author> Mark HorowitzMargaret MartonosiTodd C. MowryMichael D. Smith </author>
<pubnum> Technical Report No. CSL-TR-95-673 </pubnum>
n<note> (also numbered STAN-CS-95-673) </note>
<date> July 1995 </date>
<note> This research has been supported by ARPA contract DABT63-94-C-0054.In addition, Margaret Martonosi is supported in part by a National Science FoundationCareer Award (CCR-9502516). Todd C. Mowry is supported by a Research Grantfrom the Natural Sciences and Engineering Research Council of Canada. Michael D.Smith is supported by the National Science Foundation under a Young InvestigatorGrant No. CCR-9457779. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Informing Memory Operations: Providing MemoryPerformance Feedback in Modern Processors </title>
<author> Mark Horowitz Margaret Martonosi Todd C. Mowry Michael D. Smith </author>
<affiliation> Computer Systems Department of Department of Electrical Division ofLaboratory Electrical Engineering and Computer Engineering Applied SciencesStanford University Princeton University University of Toronto Harvard University </affiliation>
<email> horowitz@ee.stanford.edu martonosi@princeton.edu tcm@eecg.toronto.edu smith@eecs.harvard.edu </email>
<abstract> AbstractMemory latency is an important bottleneck in system performancethat cannot be adequately solved by hardware alone. Several promising software techniques have been shown to address this problemsuccessfully in specific situations. However, the generality of thesesoftware approaches has been limited because current architecturesdo not provide a fine-grained, low-overhead mechanism forobserving and reacting to memory behavior directly. To fill thisneed, we propose a new class of memory operations called informing memory operations, which essentially consist of a memoryoperation combined (either implicitly or explicitly) with a conditional branch-and-link operation that is taken only if the referencesuffers a cache miss. We describe two different implementations ofinforming memory operationsone based on a cache-outcomecondition code and another based on low-overhead trapsand findthat modern in-order-issue and out-of-order-issue superscalar processors already contain the bulk of the necessary hardware support.We describe how a number of software-based memory optimizations can exploit informing memory operations to enhance performance, and look at cache coherence with fine-grained accesscontrol as a case study. Our performance results demonstrate thatthe runtime overhead of invoking the informing mechanism on theAlpha 21164 and MIPS R10000 processors is generally smallenough to provide considerable exibility to hardware and software designers, and that the cache coherence application hasimproved performance compared to other current solutions. Webelieve that the inclusion of informing memory operations infuture processors may spur even more innovative performanceoptimizations. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Submitted to the Future Generation Computer Systems special issue on Data Mining. </note>
<title> Using Neural Networks for Data Mining </title>
<author> Mark W. Craven </author>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213-3891 </address>
<email> mark.craven@cs.cmu.edu </email>
<author> Jude W. Shavlik </author>
<affiliation> Computer Sciences DepartmentUniversity of Wisconsin-Madison </affiliation>
<address> Madison, WI 53706-1685 </address>
<email> shavlik@cs.wisc.edu </email>
<abstract> AbstractNeural networks have been successfully applied in a wide range of supervised and unsupervised learning applications. Neural-network methods are not commonly used for data-miningtasks, however, because they often produce incomprehensible models and require long trainingtimes. In this article, we describe neural-network learning algorithms that are able to producecomprehensible models, and that do not require excessive training times. Specifically, we discusstwo classes of approaches for data mining with neural networks. The first type of approach,often called rule extraction, involves extracting symbolic models from trained neural networks.The second approach is to directly learn simple, easy-to-understand networks. We argue that,given the current state of the art, neural-network methods deserve a place in the tool boxes ofdata-mining specialists. </abstract>
<keyword> Keywords: machine learning, neural networks, rule extraction, comprehensiblemodels, decision trees, perceptrons </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Simple Algorithm for Finding theMaximum Recoverable System State inOptimistic Rollback Recovery Methods </title>
<author> David B. JohnsonPeter J. KeleherWilly Zwaenepoel </author>
<pubnum> Rice COMP TR90-125 </pubnum>
<date> July 1990 </date>
<affiliation> Department of Computer ScienceRice University </affiliation>
<address> P.O. Box 1892Houston, Texas 77251-1892 </address>
<phone> (713) 527-4834 </phone><note> This research was supported in part by the National Science Foundation under grants CCR-8716914 andCDA-8619893, and by the Office of Naval Research under contract ONR N00014-88-K-0140. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Prototype Reading Coach that Listens </title>
<author> Jack Mostow, Steven F. Roth, Alexander G. Hauptmann, and Matthew Kane </author>
<affiliation> Project LISTEN, </affiliation>
 <address> 215 Cyert Hall, </address>
 <affiliation> Carnegie Mellon University Robotics Institute </affiliation>
<address> 4910 Forbes Avenue, Pittsburgh, PA 15213-3890 </address>
<email> mostow@cs.cmu.edu </email>
<note> COPYRIGHT NOTICEThis publication and its companion video and transcript (Mostow et al, 1994c) are copyrighted:J. Mostow, S. Roth, A. G. Hauptmann, and M. Kane. (August 1994). A Prototype Reading Coach that Listens. Proceedingsof the Twelfth National Conference on Artificial Intelligence (AAAI-94). Seattle, WA, American Association forArtificial Intelligence, Recipient of the AAAI-94 Outstanding Paper Award.J. Mostow, S. Roth, A. Hauptmann, M. Kane, A. Swift, L. Chase, and B. Weide. (August 1994). A Reading Coach thatListens (6-minute video). Video Track of the Twelfth National Conference on Artificial Intelligence (AAAI94). Seattle,WA, American Association for Artificial Intelligence.J. Mostow, S. Roth, A. Hauptmann, M. Kane, A. Swift, L. Chase, and B. Weide. (August 1994). A reading coach thatlistens: (edited) video transcript. Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI94).Seattle, WA.Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without feeprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and thefull citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers or to redistribute to lists, requiresprior specific permission and/or a fee.newpageThe following notice appears on page xiv of the proceedings:AAAI-94Outstanding Paper AwardA Prototype Reading Coach that ListensJack Mostow, Steven F. Roth, Alexander G. Hauptmann, and Matthew KaneThis year, AAAI's National Conference on Artifical Intelligence honors a paper that exemplifies high standards intechnical contribution and exposition. Papers were nominated for the Outstanding Paper Award by members of the programcommittee during the NCAI review process. These nominations were then reviewed once again by a smaller subset of theprogram committee to select the winning paper. Care was taken during the review process to ensure that our final decisionswere based on the opinions of impartial readers who are free from personal biases and conflicts of interest. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Towards a Principled Representationof Discourse Plans </title>
<author> R. Michael YoungJohanna D. MooreMartha E. Pollack </author>
<pubnum> ISP Technical Report 94-2 </pubnum>
<date> May 1994 </date>
<abstract> AbstractWe argue that discourse plans must capture the intended causal and decompositional relations between communicative actions. We present a planning algorithm, DPOCL, that builds plan structures that properly capture these relations, and showhow these structures are used to solve the problems that plagued previous discourse planners, and allow a system to participateeffectively and flexibly in an ongoing dialogue.A version of this paper appears in the Proceedings of the Sixteenth Annual Meetingof the Cognitive Science Society, Atlanta, GA, 1994. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Simulating Soft Shadowswith Graphics Hardware </title>
<author> Paul S. Heckbert and Michael Herf </author>
<date> January 15, 1997 </date>
<pubnum> CMU-CS-97-104 </pubnum>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<email> email: ph@cs.cmu.edu, herf+@cmu.edu </email>
<web> World Wide Web: http://www.cs.cmu.edu/~ph </web><note> This paper was written in April 1996. An abbreviated version appeared in [Michael Herf and Paul S. Heckbert, FastSoft Shadows, Visual Proceedings, SIGGRAPH 96, Aug. 1996, p. 145]. </note>
<abstract> AbstractThis paper describes an algorithm for simulating soft shadows at interactive rates using graphics hardware. On current graphicsworkstations, the technique can calculate the soft shadows cast by moving, complex objects onto multiple planar surfaces inabout a second. In a static, diffuse scene, these high quality shadows can then be displayed at 30 Hz, independent of the numberand size of the light sources.For a diffuse scene, the method precomputes a radiance texture that captures the shadows and other brightness variations oneach polygon. The texture for each polygon is computed by creating registered projections of the scene onto the polygon frommultiple sample points on each light source, and averaging the resulting hard shadow images to compute a soft shadow image.After this precomputation, soft shadows in a static scene can be displayed in real-time with simple texture mapping of theradiance textures. All pixel operations employed by the algorithm are supported in hardware by existing graphics workstations.The technique can be generalized for the simulation of shadows on specular surfaces. </abstract>
<note> This work was supported by NSF Young Investigator award CCR-9357763. The views and conclusions contained in this document are those of the authors andshould not be interpreted as representing the official policies, either expressed or implied, of NSF or the U.S. government. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> NIFDY: A Low Overhead, High Throughput Network Interface </title>
<author> Timothy Callahan and Seth Copen Goldstein </author>
<email> ftimothyc,sethgg@cs.berkeley.edu </email>
<affiliation> Computer Science DivisionUniversity of California-Berkeley </affiliation>
<abstract> AbstractIn this paper we present NIFDY, a network interface that uses admission control to reduce congestion and ensures that packets arereceived by a processor in the order in which they were sent, evenif the underlying network delivers the packets out of order. Thebasic idea behind NIFDY is that each processor is allowed to have atmost one outstanding packet to any other processor unless the destination processor has granted the sender the right to send multipleunacknowledged packets. Further, there is a low upper limit on thenumber of outstanding packets to all processors.We present results from simulations of a variety of networks(meshes, tori, butterflies, and fat trees) and traffic patterns to verify NIFDY's efficacy. Our simulations show that NIFDY increasesthroughput and decreases overhead. The utility of NIFDY increasesas a network's bisection bandwidth decreases. When combinedwith the increased payload allowed by in-order delivery NIFDY increases total bandwidth delivered for all networks. The resourcesneeded to implement NIFDY are small and constant with respect tonetwork size. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Implementing Bit-addressing with Specialization </title>
<author> Scott Draves  </author>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> 5000 Forbes Avenue, Pittsburgh, PA 15213, USA </address>
<abstract> AbstractGeneral media-processing programs are easily expressed with bit-addressing and variable-sized bit-fields. But the natural implementation of bit-addressing relies on dynamic shift offsets and repeatedloads, resulting in slow execution. If the code is specialized to thealignment of the data against word boundaries, the offsets becomestatic and many repeated loads can be removed. We show how introducing modular arithmetic into an automatic compiler generatorenables the transformation of a program that uses bit-addressinginto a synthesizer of fast specialized programs.In partial-evaluation jargon we say: modular arithmetic is supported by extending the binding time lattice used by the static analysis in a polyvariant compiler generator. The new binding timeCyclic functions like a partially static integer.A software cache combined with a fast, optimistic sharing analysis built into the compilers eliminates repeated loads and stores.The utility of the transformation is demonstrated with a collectionof examples and benchmark data. The examples include vectorarithmetic, audio synthesis, image processing, and a base-64 codec. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Exploiting Global Input/Output Access Pattern Classification </title>
<author> Tara M. Madhyastha Daniel A. Reed </author>
<email> ftara,reedg@cs.uiuc.edu </email>
<affiliation> Department of Computer ScienceUniversity of Illinois </affiliation>
<address> Urbana, Illinois 61801 </address>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> In: Proceedings of EURASIP Workshop, February 15-17, 1990, Portugal </note>
<title> INVERSION IN TIME </title>
<author> Sebastian Thrun Alexander Linden </author>
<affiliation> Gesellschaft fur Mathematik und Datenverarbeitung mbH </affiliation>
<address> D-5205 St. Augustin, West Germany </address>
<abstract> AbstractInversion of multilayer synchronous networks is a method which tries to answer questionslike "What kind of input will give a desired output?" or "Is it possible to get a desiredoutput (under special input/output constraints)?".We will describe two methods of inverting a connectionist network. Firstly, we extendinversion via backpropagation (Linden/Kindermann [4], Williams [11]) to recurrent (El-man [1], Jordan [3], Mozer [5], Williams/Zipser [10]), time-delayed (Waibel at al. [9])and discrete versions of continuous networks (Pineda [7], Pearlmutter [6]). The resultof inversion is an input vector. The corresponding output vector is equal to the targetvector except a small remainder. The knowledge of those attractors may help to understand the function and the generalization qualities of connectionist systems of thiskind.Secondly, we introduce a new inversion method for proving the non-existence of aninput combination under special constraints, e.g. in a subspace of the input space. Thismethod works by iterative exclusion of invalid activation values. It might be a helpfulway to judge the properties of a trained network.We conclude with simulation results of three different tasks: XOR, morse signal decodingand handwritten digit recognition. </abstract>
<keyword> Keywords: connectionist systems, backpropagation, inversion, recurrent neural networks, digit recognition </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> SUPRENUM: Perspectives and Performance </title>
<author> Oliver A. McBryan </author>
<affiliation> Dept. of Computer ScienceUniversity of Colorado </affiliation>
<address> Boulder, CO 80309. </address>
<email> Email: mcbryan@cs.colorado.edu </email>
<abstract> AbstractWe describe our impressions of the SUPRENUM project and of its primarysupercomputer result, the Suprenum-1 prototype. We comment on the significanceof the architecture, its role among contemporary systems and its relevance tocurrent systems. We similarly discuss the SUPRENUM software and its impact ondistributed systems. Finally we discuss the successes and failures observedthroughout this exciting project and relate these to the organizational decisions onwhich SUPRENUM was based.As an illustration of Suprenum-1 capabilities, we describe theimplementation of a fluid dynamical benchmark on the 256 node Suprenum-1parallel computer. The benchmark, the Shallow Water Equations, is frequently usedas a model for both oceanographic and atmospheric circulation. We describe thesteps involved in implementing the algorithm on the Suprenum-1 and we providedetails of performance obtained. For such regular grid-based algorithms the systemdelivers a very impressive fraction (25%) of its theoretical peak rate of 5 Gflops. </abstract>
<keyword> Keywords: SUPRENUM, MPP, MIMD, parallel, supercomputer, performance,atmospheric, shallow water, architecture, software, message passing. </keyword>
<note> * Research supported in part by NSF Grand Challenges Applications Group grant ASC-9217394 and byNASA HPCC Group Grant NAG5-2218.To appear in Parallel Computing, October 1994. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Metamorphosis Networks:An Alternative to Constructive Methods </title>
<author> Brian V. Bonnlander Michael C. Mozer </author>
<affiliation> Department of Computer Science &amp;Institute of Cognitive ScienceUniversity of Colorado </affiliation>
<address> Boulder, CO 80309-0430 </address>
<abstract> AbstractGiven a set of training examples, determining the appropriate number of free parameters is a challenging problem. Constructivelearning algorithms attempt to solve this problem automatically byadding hidden units, and therefore free parameters, during learning. We explore an alternative class of algorithms|called metamorphosis algorithms|in which the number of units is fixed, butthe number of free parameters gradually increases during learning.The architecture we investigate is composed of RBF units on a lattice, which imposes flexible constraints on the parameters of thenetwork. Virtues of this approach include variable subset selection, robust parameter selection, multiresolution processing, andinterpolation of sparse training data. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Sybil Database Integration and Evolution Environment: An Overview </title>
<author> Roger King, Michael Novak, Christian Och, Richard Osborne </author>
<affiliation> Department of Computer ScienceUniversity of Colorado </affiliation>
<address> Campus Box 430Boulder, CO 80309-0430 </address>
<email> roger@cs.colorado.edu, rick@cs.colorado.edu </email>
<author> Fernando Velez </author>
<affiliation> Unidata Inc. </affiliation>
<address> 1099 18th StreetSuite 2200Denver, CO 80202-1925 </address>
<abstract> AbstractSybil is a database integration and evolution environment for supporting large, heterogeneous applications.We are interested in using Sybil to support the data integration and evolution needs of applications that are using legacy databases and are looking to integrate withmore modern database systems. The Sybil approach isbased on loosely coupling databases or other persistenttools into lightweight alliances tailored for specific applications. Such alliances are built via four sorts of constructs: heterogeneous views, inter-database constraints,inter-database propagations, and integration supportedby domain specific information. </abstract>
<intro> Sybil Overview </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Schema Evolution in Object Databases: Measuringthe Performance of Immediate and Deferred Updates </title>
<author> Fabrizio Ferrandina Thorsten Meyer Roberto Zicari </author>
<affiliation> Johann Wolfgang Goethe-Universitat FrankfurtFachbereich Informatik (20)Datenbanken und Informationssysteme (DBIS) </affiliation>
<address> Robert-Mayer-Str. 11-15D-60325 Frankfurt am Main, Germany </address>
<email> fferrandi,meyer,zicarig@dbis.informatik.uni-frankfurt.de </email>
<web> http://www.dbis.informatik.uni-frankfurt.de </web><abstract> AbstractWhen the schema of an object database system is modified, the database needs to be changedin such a way that the schema and the database remain consistent with each other. This paperuses the OO1 benchmark [2], appropriately modified, to compare the two most used approaches fortransforming the database, namely the immediate and the deferred database transformation [4]. </abstract>
<intro> 1 Immediate vs. Lazy Database Updates </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Goal-Directed Classification using Linear MachineDecision Trees  </title>
<author> Bruce A. Draper Carla E. Brodley Paul E. Utgoff </author>
<affiliation> Department of Computer ScienceUniversity of Massachusetts </affiliation>
<address> Amherst, MA., USA. 01003 </address>
<email> bdraper@cs.umass.edu </email>
<date> September 17, 1993 </date>
<abstract> AbstractRecent work in feature-based classification has focused on non-parametric techniques that can classify instances even when the underlying feature distributions areunknown. The inference algorithms for training these techniques, however, are designedto maximize the accuracy of the classifier, with all errors weighted equally. In manyapplications, certain errors are far more costly than others, and the need arises fornon-parametric classification techniques that can be trained to optimize task-specificcost functions. This paper reviews the Linear Machine Decision Tree (LMDT) algorithm for inducing multivariate decision trees, and shows how LMDT can be altered toinduce decision trees that minimize arbitrary misclassification cost functions (MCFs).Demonstrations of pixel classification in outdoor scenes show how MCFs can optimizethe performance of embedded classifiers within the context of larger image understanding systems. </abstract>
<keyword> Keywords: Decision Trees, Non-Parametric Classification, Pattern Recognition, Object Recognition, Computer Vision, Machine Learning. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Cellular Encoding Applied to Neurocontrol </title>
<author> Darrell Whitley, Frederic Gruau and Larry Pyeatt </author>
<affiliation> Department of Computer ScienceColorado State University </affiliation>
<address> Fort Collins, Colorado 80523 USA </address>
<email> whitley,gruau,pyeatt@cs.colostate.edu +L </email>
<abstract> AbstractNeural networks are trained for balancing 1and 2 poles attached to a cart on a fixedtrack. For one variant of the single pole system, only pole angle and cart position variables are supplied as inputs; the networkmust learn to compute velocities. All of theproblems are solved using a fixed architectureand using a new version of cellular encoding that evolves an application specific architecture with real-valued weights. The learning times and generalization capabilities arecompared for neural networks developed using both methods. After a post processingsimplification, topologies produced by cellular encoding were very simple and could beanalyzed. Architectures with no hidden unitswere produced for the single pole and the twopole problem when velocity information issupplied as an input. Moreover, these linearsolutions display good generalization. For allthe control problems, cellular encoding canautomatically generate architectures whosecomplexity and structure reflect the featuresof the problem to solve. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Efficient Indexing for Object Recognition Using Large Networks </title>
<author> Mark R. Stevens Charles W. Anderson J. Ross Beveridge </author>
<affiliation> Department of Computer ScienceColorado State University </affiliation>
<address> Fort Collins, CO 80523 </address>
<email> fstevensm,anderson,rossg@cs.colostate.edu </email>
<abstract> AbstractTemplate matching is an effective means of locating vehicles in outdoor scenes, but it tends to bea computationally expensive. To reduce processing time, we use large neural networks to predict, orindex, a small subset of templates that are likely to match each window in an image. Results on actualLADAR range images show that limiting the templates to those selected by the neural networks reducesthe computation time by a factor of 5 without sacrificing the accuracy of the results. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Measured Performance of a Wireless LAN </title>
<author> Dan Duchamp and Neil F. Reynolds </author>
<affiliation> Computer Science DepartmentColumbia University </affiliation>
<address> 500 W. 120th St.New York, NY 10027 </address>
<email> fdjd,nfrg@cs.columbia.edu </email>
<abstract> AbstractWe have studied the performance of a high-speedcommercial spread-spectrum wireless LAN that uses theCSMA/CA multiple-access strategy. Employing synthetic workloads, we measured packet capture successmore so than signal propagation characteristics. Specifically, we measured throughput, packet loss rates, range,and patterns of errors within packets. We concludethat CSMA/CA is quite successful in allocating bandwidth under stress, but that packet capture rate degrades very quickly once the LAN's effective range isexceeded. Hence, network maintainers should plan thelayout of wireless networks at least as carefully as theyplan wired networks. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Internet Telephony: A (Partial) Research Agenda </title>
<author> Jonathan Rosenberg </author>
<affiliation> Bell Laboratories and Columbia U. </affiliation>
<address> Rm. 4C-526101 Crawfords Corner Rd.Holmdel, NJ 07733 </address>
<email> jdrosen@bell-labs.com </email>
<phone> TEL: +1 908 949-6418 </phone><date> October 17, 1997 </date>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Predictive Dynamic Load Balancing of Parallel Hash-Joins overHeterogeneous Processors in the Presence of Data Skew  </title>
<author> Hasanat M. Dewan Mauricio Hernandez Kui W. Mok Salvatore J. Stolfo </author>
<affiliation> Department of Computer Science, Columbia University, </affiliation>
<address> New York, NY 10027 </address>
<pubnum> CUCS-026-94 </pubnum>
<note> (This is an extended version of the paper that appeared in the Proceedings of the3rd International Conference on Parallel and Distributed Information Systems.) </note>
<abstract> AbstractIn this paper, we present new algorithms to balancethe computation of parallel hash joins over heterogeneous processors in the presence of data skew and external loads. Heterogeneity in our model consists ofdisparate computing elements, as well as general purpose computing ensembles that are subject to external loading (e.g., a LAN connected workstation cluster). Data skew manifests itself as significant non-uniformities in the distribution of attribute values ofunderlying relations that are involved in a join.We develop cost models and predictive dynamicload balancing protocols to detect imbalance duringthe computation of a single large join. New predictive bucket scheduling algorithms are presented thatsmooth out the load over the entire ensemble by reallocating buckets whenever imbalance is detected. Ouralgorithms can account for imbalance due to data skewas well as heterogeneity in the computing environment.Significant performance gains are reported for a widerange of test cases on a prototype implementation ofthe system. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Mining Audit Data to Build Intrusion Detection Models </title>
<author> Wenke Lee Salvatore J. StolfoKui W. Mok </author>
<affiliation> Computer Science DepartmentColumbia University </affiliation>
<address> 500 West 120th Street, New York, NY 10027 </address>
<email> fwenke,sal,mokg@cs.columbia.edu </email>
<abstract> AbstractIn this paper we discuss a data mining framework for constructing intrusion detection models.The key ideas are to mine system audit data for consistent and useful patterns of program anduser behavior, and use the set of relevant system features presented in the patterns to compute(inductively learned) classifiers that can recognize anomalies and known intrusions. Our past experiments showed that classifiers can be used to detect intrusions, provided that sufficient auditdata is available for training and the right set of system features are selected. We propose to usethe association rules and frequent episodes computed from audit data as the basis for guiding theaudit data gathering and feature selection processes. We modify these two basic algorithms to useaxis attribute(s) as a form of item constraints to compute only the relevant (useful) patterns, andan iterative level-wise approximate mining procedure to uncover the low frequency (but important)patterns. We report our experiments in using these algorithms on real-world audit data. </abstract>
<keyword> Keywords: Intrusion detection, audit data, classification, association rules, frequent episodes. </keyword>
<note> Contact Author: </note>
 <author> Wenke Lee, </author>
 <email> wenke@cs.columbia.edu, </email>
 <phone> (212) 939-7078. </phone><note> This research is supported in part by grants from DARPA (F30602-96-1-0311) and NSF (IRI-96-32225 and CDA-96-25374). </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Scalability of Hierarchical Meta-Learningon Partitioned Data  </title>
<author> Philip K. Chan </author>
<affiliation> Computer ScienceFlorida Institute of Technology </affiliation>
<address> Melbourne, FL 32901 </address>
<email> pkc@cs.fit.edu </email>
<phone> FAX: (407) 984-8461 </phone><author> Salvatore J. Stolfo </author>
<affiliation> Department of Computer ScienceColumbia University </affiliation>
<address> New York, NY 10027 </address>
<email> sal@cs.columbia.edu </email>
<phone> (212) 939-7080 </phone><date> May 8, 1997 </date>
<abstract> AbstractIn this paper we study the issue of how to scale machine learning algorithms, thattypically are designed to deal with main-memory based datasets, to efficiently learnmodels from large distributed databases. We have explored an approach called meta-learning that is related to the traditional approaches of data reduction commonlyemployed in distributed database query processing systems. We explore the scalabilityof learning arbiter and combiner trees from partitioned data. Arbiter and combinertrees integrate classifiers trained in parallel from small disjoint subsets. Previous workdemonstrated the efficacy of these meta-learning architectures in terms of accuracyof the computed meta-classifiers. Here we discuss the computational performanceof constructing arbiter and combiner trees in terms of speedup and scalability as afunction of database size and number of partitions. The performance of serial learningalgorithms is evaluated. We then analyze the performance of the algorithms used toconstruct combiner and arbiter trees in parallel. Our empirical results validate theseanalyses and indicate that the techniques can effectively scale up to large datasets withmillions of records using cheap commodity hardware. </abstract>
<keyword> Keywords: speedup, scalability, arbiter and combiner trees, meta-learning, parallel/distributedprocessing, inductive learning </keyword>
<note> This work was partially funded by grants from NSF (IRI-96-32225 &amp; CDA-96-25374), ARPA (F3060296-1-0311), and NYSSTF (423115-445). </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Learning Distributions from Random Walks </title>
<author> Funda Ergun S Ravi Kumar </author>
<affiliation> Department of Computer ScienceCornell University </affiliation>
<address> Ithaca, NY 14853. </address>
<author> Ronitt Rubinfeld </author>
<abstract> AbstractWe introduce a new model of distributions generated by random walks on graphs. This modelsuggests a variety of learning problems, using the definitions and models of distributionlearning defined in [6]. Our framework is general enough to model previously studied distribution learning problems, as well as to suggestnew applications. We describe special cases ofthe general problem, and investigate their relative difficulty. We present algorithms to solvethe learning problem under various conditions. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Compiling for distributed memory architectures </title>
<author> Anne Rogers and Keshav Pingali </author>
<date> June 10, 1991 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Embedded Machine Learning Systems forNatural Language Processing: A GeneralFramework </title>
<author> Claire Cardie </author>
<affiliation> Department of Computer Science, Cornell University, </affiliation>
 <address> Ithaca NY 14853, USA </address>
<note> In Wermter, S. and Riloff, E. and Scheler, Gabriele (eds.), Connectionist, Statistical andSymbolic Approaches to Learning for Natural Language Processing, Lecture Notes inArtificial Intelligence, 315-328, Springer, 1996. </note>
<abstract> Abstract. This paper presents Kenmore, a general framework for knowledge acquisition for natural language processing (NLP) systems. To easethe acquisition of knowledge in new domains, Kenmore exploits an online corpus using robust sentence analysis and embedded symbolic machine learning techniques while requiring only minimal human intervention. By treating all problems in ambiguity resolution as classificationtasks, the framework uniformly addresses a range of subproblems in sentence analysis, each of which traditionally had required a separate computational mechanism. In a series of experiments, we demonstrate thesuccessful use of Kenmore for learning solutions to several problems inlexical and structural ambiguity resolution. We argue that the learningand knowledge acquisition components should be embedded componentsof the NLP system in that (1) learning should take place within thelarger natural language understanding system as it processes text, and(2) the learning components should be evaluated in the context of practical language-processing tasks. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Comparing Mostly-Copying and Mark-Sweep Conservative Collection </title>
<author> Frederick Smith  </author>
<affiliation> Cornell University </affiliation>
<email> fms@cs.cornell.edu </email>
<author> Greg Morrisett </author>
<affiliation> Cornell University </affiliation>
<email> jgm@cs.cornell.edu </email>
<abstract> AbstractMany high-level language compilers generate C code andthen invoke a C compiler for code generation. To date, mostof these compilers link the resulting code against a conservative mark-sweep garbage collector in order to reclaim unusedmemory. We introduce a new collector, MCC, based on anextension of mostly-copying collection.We analyze the various design decisions made in MCCand provide a performance comparison to the most widelyused conservative mark-sweep collector (the Boehm-Demers-Weiser collector). Our results show that a good mostly-copying collector can outperform a mature highly-optimizedmark-sweep collector when physical memory is large relativeto the live data. A surprising result of our analysis is thatcache behavior can have a greater impact on overall performance than either collector time, or allocation code. </abstract>
<intro> 1 Overview </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On-Line Search in a Simple Polygon </title>
<author> Jon M. Kleinberg  </author>
<abstract> AbstractWe consider a number of search and exploration problems, from the perspective ofrobot navigation in a simple polygon. These problems are "on-line" in the sense thatthe robot does not have access to the map of the polygon; it must make decisions as itproceeds, based only on what it has seen so far. For the problem of exploring a simplerectilinear polygon (under the L 1 norm), Deng, Kameda, and Papadimitriou give a2-competitive deterministic algorithm; we present a randomized exploration algorithmwhich is 5=4-competitive. Using similar techniques, we are able to give an algorithmfor searching an arbitrary, unknown rectilinear polygon. No constant competitive ratiois attainable in this case, but our algorithm is within a constant factor of optimal inthe worst case; in a sense, it is a generalization of some of the strategies of Baeza-Yates, Culberson, and Rawlins to a much more general class of search spaces. Finally,we examine a type of polygon for which competitive search is possible | the class of"streets" considered by Klein, who gave a 1 + 32 -competitive algorithm for the searchproblem in this case. We present a simple algorithm with a competitive ratio of atmostqp8 (~ 2:61); in rectilinear streets it achieves the optimal competitive ratioof2. </abstract>
<note> This work was supported in part by the Sloan Fellowship and NSF PYI award of Eva Tardos. Authoris supported by an ONR Graduate FellowshipLaboratory for Computer Science, MIT, Cambridge MA 02139 USA. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> Submitted to the special Algorithmica issue of Algorithmic Foundations of Robotics </note>
<title> Visibility-Based Planning of Sensor Control Strategies </title>
<author> Amy J. Briggs Bruce R. Donald </author>
<affiliation> Department of Mathematics Department of Computer Scienceand Computer Science </affiliation>
 <address> Upson Hall </address>
<affiliation> Middlebury College Cornell University </affiliation>
<address> Middlebury, VT 05753, USA Ithaca, NY 14853, USA </address>
<email> briggs@middlebury.edu brd@cs.cornell.edu </email>
<keyword> Keywords: Visibility-based planning, error detection and recovery, sensor configuration, camera control, surveillance </keyword>
<abstract> AbstractWe consider the problem of planning sensor control strategies that enable asensor to be automatically configured for robot tasks. In this paper we presentrobust and efficient algorithms for computing the regions from which a sensorhas unobstructed or partially obstructed views of a target in a goal. We applythese algorithms to the Error Detection and Recovery problem of recognizingwhether a goal or failure region has been achieved. Based on these methods andstrategies for visually-cued camera control, we have built a robot surveillancesystem in which one mobile robot navigates to a viewing position from whichit has an unobstructed view of a goal region, and then uses visual recognitionto detect when a specific target has entered the region. </abstract>
<note> Support for this work was provided in part by the National Science Foundation under grantsNo. IRI-8802390, IRI-9000532, IRI-9201699, and by a Presidential Young Investigator award toBruce Donald, and in part by the Air Force Office of Sponsored Research, the Mathematical Sciences Institute, Intel Corporation, and AT&amp;T Bell laboratories. The first author was additionallysupported by an AT&amp;T Bell Laboratories Graduate Fellowship sponsored by the AT&amp;T Foundation. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Experimental Study of Minimum Cut Algorithms </title>
<author> Chandra S. Chekuri  </author>
<affiliation> Computer Science DepartmentStanford University </affiliation>
<address> Stanford, CA 94305 </address>
<email> chekuri@theory.stanford.edu </email>
<author> Andrew V. Goldberg </author>
<affiliation> NEC Research Institute </affiliation>
<address> Princeton, NJ 08540 </address>
<email> avg@research.nj.nec.com </email>
<author> David R. Karger  </author>
<affiliation> Laboratory for Computer ScienceMIT </affiliation>
<address> Cambridge, MA 02139 </address>
<email> karger@theory.lcs.mit.edu </email>
<author> Matthew S. Levine  </author>
<affiliation> Laboratory for Computer ScienceMIT </affiliation>
<address> Cambridge, MA 02139 </address>
<email> mslevine@theory.lcs.mit.edu </email>
<author> Cliff Stein x </author>
<affiliation> Department of Computer ScienceDartmouth College </affiliation>
<address> Hanover, NH, 03755 </address>
<email> cliff@cs.dartmouth.edu. </email>
<date> October 1996 </date>
<abstract> AbstractRecently, several new algorithms have been developed for the minimum cut problem.These algorithms are very different from the earlier ones and from each other and substantially improve worst-case time bounds for the problem. We conduct experimental evaluationthe relative performance of these algorithms. In the process, we develop heuristics and datastructures that substantially improve practical performance of the algorithms. We also develop problem families for testing minimum cut algorithms. Our work leads to a betterunderstanding of practical performance of the minimum cut algorithms and produces veryefficient codes for the problem. </abstract>
<note> Supported by NSF Award CCR-9357849, with matching funds from IBM, Mitsubishi, Schlumberger Foundation, Shell Foundation, and Xerox Corporation.Research partly supported by ARPA contract N00014-95-1-1246.Research partly supported by a grant from the World Wide Web Consortium. Some of this work was donewhile visiting the second author at NEC.x Research partly supported by NSF Award CCR-9308701, a Walter Burke Research Initiation Award and aDartmouth College Research Initiation Award. Some of this work was done while visiting the second author atNEC, and while visiting Stanford University. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> Dartmouth College Computer Science Technical ReportPCSTR96-294 </pubnum>
<note> (Revised September 1996) </note>
<title> Performing Out-of-Core FFTs on Parallel Disk Systems </title>
<author> Thomas H. Cormen David M. Nicol  </author>
<affiliation> Dartmouth CollegeDepartment of Computer Science </affiliation>
<abstract> AbstractThe Fast Fourier Transform (FFT) plays a key role in many areas of computational scienceand engineering. Although most one-dimensional FFT problems can be entirely solved entirely inmain memory, some important classes of applications require out-of-core techniques. For these,use of parallel I/O systems can improve performance considerably. This paper shows how toperform one-dimensional FFTs using a parallel disk system with independent disk accesses. Wepresent both analytical and experimental results for performing out-of-core FFTs in two ways:using traditional virtual memory with demand paging, and using a provably asymptoticallyoptimal algorithm for the Parallel Disk Model (PDM) of Vitter and Shriver. When run on aDEC 2100 server with a large memory and eight parallel disks, the optimal algorithm for thePDM runs up to 144.7 times faster than in-core methods under demand paging. Moreover, evenincluding I/O costs, the normalized times for the optimal PDM algorithm are competitive, orbetter than, those for in-core methods even when they run entirely in memory. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Agent Tcl: Alpha Release 1.1 </title>
<author> Robert S. Gray  </author>
<affiliation> Department of Computer ScienceDartmouth College </affiliation>
<address> Hanover, NH 03755 </address>
<email> E-mail: robert.s.gray@dartmouth.edu </email>
<date> December 1, 1995 </date>
<abstract> AbstractAgent Tcl is a transportable agent system. The agents are written in an extended version of theTool Command Lanuage (Tcl). Each agent can suspend its execution at an arbitrary point, transportto another machine and resume execution on the new machine. This migration is accomplished withthe agent jump command. agent jump captures the current state of the Tcl script and transfers thisstate to the destination machine. The state is restored on the new machine and the Tcl script continuesits execution from the command immediately after the agent jump. In addition to migration, agentscan send messages to each other and can establish direct connections. A direct connection is moreefficient than message passing for bulk data transfer. Finally, agents can use the Tk toolkit to creategraphical user interfaces on their current machine. Agent Tcl is implemented as two components. Thefirst component is an extended Tcl interpreter. The second component is a server which runs on eachmachine. The server accepts incoming agents, messages and connection requests and keeps track of theagents that are running on its machine. An alpha release of Agent Tcl is available for public use. Thisdocumentation describes how to obtain and compile the source code, how to run the server and how towrite transportable agents. </abstract>
<note> Supported by AFOSR contract F49620-93-1-0266 and ONR contract N00014-95-1-1204 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> DIMACS Series in Discrete Mathematicsand Theoretical Computer ScienceVolume 00, 19xx </note>
<title> Some applications of generalized FFTs </title>
<author> Daniel N. Rockmore </author>
<abstract> Abstract. Generalized FFTs are efficient algorithms for computing a Fouriertransform of a function defined on finite group, or a bandlimited function defined on a compact group. The development of such algorithms has been accompanied and motivated by a growing number of both potential and realizedapplications. This paper will attempt to survey some of these applications.Appendices include some more detailed examples. </abstract>
<intro> 1. A brief history </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Hyperconcentrator Switchfor Routing Bit-Serial Messages </title>
<author> Thomas H. Cormen Charles E. Leiserson  </author>
<affiliation> Laboratory for Computer ScienceMassachusetts Institute of Technology </affiliation>
<address> Cambridge, Massachusetts 02139 </address>
<note> Supported in part by the Defense Advanced Research Projects Agency under Contracts N00014-80-C-0622 and N00014-87-K-0825 and by a National Science FoundationFellowship.Supported in part by the Defense Advanced Research Projects Agency under ContractsN00014-80-C-0622 and N00014-87-K-0825 and by an NSF Presidential Young Investigator Award with matching funds provided by AT&amp;T Bell Laboratories, IBM Corporation,and Xerox Corporation. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Document Image Compression Via PatternMatching </title>
<degree> A ThesisSubmitted to the Facultyin partial fulfillment of the requirements for thedegree ofDoctor of Philosophyin </degree><affiliation> Computer Science </affiliation>
<author> byQin Zhang </author>
<affiliation> DARTMOUTH COLLEGE </affiliation>
<address> Hanover, New Hampshire </address>
<date> 9 September 1997 </date>
<degree> Examining Committee:(chairman) John DanskinHenry BairdDennis HealyGeoff DavisNeal YoungRoger D. SlobodaDean of Graduate Studies </degree><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Probabilistic Analysis for CombinatorialFunctions of Moving Points  </title>
<author> Li Zhang Harish Devarajan Julien Basch Piotr Indyk </author>
<affiliation> Computer Science DepartmentStanford University </affiliation>
<address> Stanford, CA94305 </address>
<email> flizhang,harish,jbasch,indykg@cs.stanford.edu </email>
<date> September 9, 1997 </date>
<abstract> AbstractGiven a set of n points, what is the description complexity of their convex hull? In our world, this questionis understood with an implicit "in the worst case", and the answer is n bd=2c where d is the dimension ofthe underlying space. This is not entirely satisfactory, as this description complexity can vary tremendouslydepending on the positions of the points. Another approach is to look at the expected description complexitywhen the points are drawn from a given distribution. This type of analysis, initiated by Renyi and Sulanke[RS63] and pursued by others gets its value from the fact that this expectation is in general much smallerthan in the worst case, and, more importantly, in that it often allows one to design algorithms that haveexpected running times against which worst case aware algorithms cannot compete. For instance, the convexhull of n points drawn independently uniformly at random from a d-dimensional hypercube has expectedcomplexity O(log d1 n), and can be computed in expected linear time.In parallel, in the past decade, a number of papers have considered a setting where points are allowedto move along low degree algebraic trajectories. Different questions have been asked in this context. Inparticular, Atallah [Ata85], studied the number of times the combinatorial description of the convex hullor closest pair can change, in the worst case ("dynamic computational geometry"). More recently, Basch,Guibas, and Hershberger [BGH97] have designed kinetic data structures to maintain these attributes in anonline setting, measuring the quality of a kinetic data structure by the ratio of the worst case number ofchanges to the configuration of interest, to the worst case number of changes to the data structure itself, forlow degree algebraic motions. However, an experimental study undertaken in [BGSZ97] to assess the qualityof these data structures in practice shows that the worst case analysis can hide vastly different results interms of expectation when the point positions and speeds are drawn at random from some distributions. Itis this study that motivated the present paper.In this communication, we report several results on the expected number of changes to various combinatorial structures for the case when points are drawn from the uniform distribution on the unit square. Theseresults can be generalized for any dimension d &amp;gt; 2. </abstract>
<note> This paper appeared in the proceedings of the 13th Symposium of Computational Geometry (1997) as a communicationSupported in part by National Science Foundation grant CCR-9623851 and by US Army MURI grant DAAH04-96-1-0007.Supported in part by the Okawa Foundation.x Supported in part by ARO MURI Grant DAAH04-96-1-0007 and by NSF Award CCR-9357849, with matching fundsfrom IBM, Mitsubishi, Schlumberger Foundation, Shell Foundation, and Xerox Corporation. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Geometric Matching under Noise: Combinatorial Bounds andAlgorithms  </title>
<author> Piotr Indyk Rajeev Motwani Suresh Venkatasubramanian </author>
<affiliation> Department of Computer ScienceStanford University </affiliation>
<address> Stanford, CA 94305 </address>
<email> findyk,rajeev,sureshg@cs.stanford.edu </email>
<abstract> AbstractThe geometric point set matching problem in 2 and 3 dimensions is a well-studied problem with application to areas such as computer vision and pattern recognition, computational chemistry and other fieldssuch as cartography and computer animation. The basic problems can be formulated as follows. Givensome choice of a space of transformations and a similarity measure d(P; Q) for two point sets P and Q inEuclidean space.Problem 1 (Pattern Matching (PM)) Given point sets P and Q, where jP j = k and jQj = n withk n, and an * &amp;gt; 0, find a transformation T for which d(T (P ); Q) * or return none if no such T exists.Problem 2 (Largest Common Point-set (LCP)) Given point sets P and Q, where jP j = m and jQj =n, K &amp;gt; 0 and * &amp;gt; 0, find a transformation T and a set P 0 P of size jP 0 j K such that jd(T (P 0 ); Q)j *or return none if no such T and P 0 exist.We restrict T to the space of rigid Euclidean translations and rotations. The similarity measures of interestto us are: the exact metric 1 d E (P; Q) (binary-valued, requiring each point in P to be mapped to a point inQ); the Hausdorff metric d H (P; Q) (maximum over all points in P of the distance to the nearest point inQ); and, the matching metric d M (bottleneck matching distance).A detailed study of this set of problems was initiated by Alt, Mehlhorn, Wagener, and Welzl [AMWW88].In this seminal work, they propose a suite of algorithms for the exact and matching metrics. More recent workled to improved bounds for pattern matching and LCP under the exact metric. The problem of estimatingthe minimum Hausdorff distance between two point sets in 2 and 3 dimensions has been studied extensively.Clearly, any real application of such algorithms has to deal with the presence of noise in data, requiringthe algorithms to perform matching within the limits of some reasonable noise model. In fact, our interestin these problems arose during an attempt to implement such algorithms for applications in computer visionand in computational biology and chemistry, particularly rational drug design [FKL + 97]. We discovered thatnoise present in real data rendered most known algorithms inoperative. In hindsight, this is not surprisingfor, as noted in the survey by Alt and Guibas [AG96], these algorithms are likely to be "difficult to implementand numerically unstable due to the necessary computation of intersections of complex algebraic surfaces."Worse still, they have unacceptably high running times: for example, even in R 2 , LCP under the matchingmetric requires O(n 8 ) time, although under additional restrictions on noise regions the running times can be </abstract>
<note> This research is supported in part by a grant from Pfizer Central Research.Supported by NSF Award CCR-9357849, with matching funds from IBM, Mitsubishi, Schlumberger Foundation, ShellFoundation, and Xerox Corporation.Supported by an Alfred P. Sloan Research Fellowship, an IBM Faculty Partnership Award, an ARO MURI Grant DAAH04-96-1-0007, and NSF Young Investigator Award CCR-9357849, with matching funds from IBM, Mitsubishi, Schlumberger Foundation, Shell Foundation, and Xerox Corporation. </note>
<note> 1 We use the term "metric" only for convenience; formally, none of the above measures satisfy all the properties of a metric. </note>
</NEW_HEADER>
<NEW_HEADER>
<title> Lexicographic Bit Allocation for MPEG Video </title>
<author> Dzung T. Hoang +L </author>
<affiliation> Sony Semiconductor of America </affiliation>
<address> 3300 Zanker Road, MS SJ3C3San Jose, CA 95134 </address>
<email> dth@ricochet.net </email>
<author> Elliot L. Linzer </author>
<affiliation> C-Cube Microsystems </affiliation>
<address> One Water Street, 2nd FloorWhite Plains, NY 10601 </address>
<email> elliot.linzer@c-cube.com </email>
<author> Jeffrey Scott Vitter </author>
<affiliation> Duke University </affiliation>
<address> Box 90129Durham, NC 27708-0129 </address>
<email> jsv@cs.duke.edu </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Scalable Mining for Classification Rulesin Relational Databases </title>
<author> Min Wang Bala Iyer Jeffrey Scott Vitter </author>
<affiliation> Dept. of Computer Science Database Technology Institute Dept. of Computer ScienceDuke University IBM Santa Teresa Lab Duke University </affiliation>
<address> Durham, NC 27708 San Jose, CA 95161 Durham, NC 27708 </address>
<abstract> AbstractClassification is a key function of many "businessintelligence" toolkits and a fundamental building blockin data mining. Immense data may be needed to traina classifier for good accuracy. The state-of-art classifiers [21, 25] need an in-memory data structure ofsize O(N ), where N is the size of the training data,to achieve efficiency. For large data sets, such a datastructure will not fit in the internal memory. The bestpreviously known classifier does a quadratic number ofI/Os for large N .In this paper, we propose a novel classification algorithm (classifier) called MIND (MINing inDatabases). MIND can be phrased in such a way thatits implementation is very easy using the extended relational calculus SQL, and this in turn allows the classifier to be built into a relational database system directly. MIND is truly scalable with respect to I/O efficiency, which is important since scalability is a keyrequirement for any data mining algorithm.We built a prototype of MIND in the relationaldatabase manager DB2 and benchmarked its performance. We describe the working prototype and reportthe measured performance with respect to the previousmethod of choice. MIND scales not only with the sizeof the datasets but also with the number of processorson an IBM SP2 computer system. Even on uniproces-sors, MIND scales well beyond the dataset sizes previously published for classifiers. We also give someinsights that may have an impact on the evolution ofthe extended relational calculus SQL. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Unified Analysis of Value-Function-BasedReinforcement-Learning Algorithms </title>
<author> Csaba Szepesvari </author>
<affiliation> Research Group on Artificial Intelligence"Jozsef Attila" University </affiliation>
<affiliation> Szeged 6720, Aradi vrt tere 1.Hungary </affiliation>
<email> szepes@sol.cc.u-szeged.hu </email>
<author> Michael L. Littman </author>
<affiliation> Department of Computer ScienceDuke University </affiliation>
<affiliation> Durham, NC 27708-0129 </affiliation>
<email> mlittman@cs.duke.edu </email>
<date> December 3, 1997 </date>
<abstract> AbstractReinforcement learning is the problem of generating optimal behavior in a sequential decision-making environment given the opportunity ofinteracting with it. Many algorithms for solving reinforcement-learningproblems work by computing improved estimates of the optimal valuefunction. We extend prior analyses of reinforcement-learning algorithmsand present a powerful new theorem that can provide a unified analysis ofvalue-function-based reinforcement-learning algorithms. The usefulnessof the theorem lies in how it allows the asynchronous convergence of acomplex reinforcement-learning algorithm to be proven by verifying thata simpler synchronous algorithm converges. We illustrate the applicationof the theorem by analyzing the convergence of Q-learning, model-basedreinforcement learning, Q-learning with multi-state updates, Q-learningfor Markov games, and risk-sensitive reinforcement learning. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 279 </pubnum>
<note> (Replaces TR-228) </note>
<note> Appears in the IEEE Transactions on Image Processing Special Issue: Image Sequence Compression,vol 3, no. 5, p. 625-638, September 1994. Revised: May, 1994 </note>
<title> Representing Moving Images with Layers </title>
<author> John Y. A. Wang AND Edward H. Adelson </author>
<abstract> AbstractWe describe a system for representing movingimages with sets of overlapping layers. Eachlayer contains an intensity map that defines theadditive values of each pixel, along with an alphamap that serves as a mask indicating the transparency. The layers are ordered in depth andthey occlude each other in accord with the rulesof compositing. Velocity maps define how thelayers are to be warped over time. The layeredrepresentation is more flexible than standard image transforms and can capture many importantproperties of natural image sequences. We describe some methods for decomposing image sequences into layers using motion analysis, and wediscuss how the representation may be used forimage coding and other applications. </abstract>
<keyword> Keywords| Image coding, motion analysis, imagesegmentation, image representation, robust estimation. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Extensible End-to-End Protocol and Framework </title>
<author> K. L. CalvertR. H. KravetsR. D. Krupczak </author>
<affiliation> College of ComputingGeorgia Institute of Technology </affiliation>
<address> Atlanta, Georgia, USA </address>
<email> fcalvert,robink,rdkg@cc.gatech.edu </email>
<abstract> AbstractWe describe a framework for composing end-to-end protocol functions. The framework comprises:a generic model of protocol processing; a metaheader protocol supporting per-packet configurationof protocol function and efficient demultiplexing of incoming data units; and an extensible set ofmodular protocol functions. This paper describes the pieces of the framework and motivates someof the design decisions. </abstract>
<intro> 1 Introduction and Motivations </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Protocol for Efficient Transfer of Data over Fiber/Cable Systems </title>
<author> Dolors Sala John O. Limb </author>
<affiliation> School of Electrical College of Computingand Computer EngineeringGeorgia Institute of Technology </affiliation>
<address> Atlanta, GA 30332-0280 </address>
<email> E-mail: (dolors,limb)@cc.gatech.edu </email>
<abstract> AbstractA revolution is occurring in the scope and rangeof information, communication and education servicesthat will be made available to schools, libraries, town-halls, clinics and, most importantly, residences. Theseservices will be provided initially, primarily over hybrid fiber-cable systems, either by telephone companiesor cable companies. The old cable plant is being upgraded and used in totally new ways.The topology and physical characteristics of the upstream channel present new challenges for efficientchannel access. We present a media access protocolthat efficiently transfers data on this channel. A primary goal in the design was to keep the portion of theprotocol resident in the station as simple as possible.Thus we use centralized control located in the cablehead-end and minimize intelligence in the station. Werefer to this protocol as Centralized Priority Reservation or CPR. A station wishing to transmit sends a request to the head-end using a contention channel. Thehead-end acknowledges the request and then schedulesthe request, informing the station by means of a grantmessage when to transmit.The protocol performs well under heavy load. Performance is affected little by the number of stations,the speed of the system and the physical length of thesystem. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> PARALLEL AND DISTRIBUTED SIMULATION </title>
<author> Richard M. Fujimoto </author>
<affiliation> College of ComputingGeorgia Institute of Technology </affiliation>
<address> Atlanta, Georgia 30332-0280, U.S.A. </address>
<abstract> ABSTRACTResearch and development efforts in the parallel anddistributed simulation field over the last 15 yearshas progressed, largely independently, in two separate camps: the largely academic high performanceParallel And Distributed (discrete event) Simulation (PADS) community, and the DoD-centered Distributed Interactive Simulation (DIS) community.This tutorial gives an overview and comparison ofwork in these two areas, emphasizing issues related todistributed execution where these fields have the mostoverlap. Differences in the fundamental assumptionsroutinely used within each community are contrasted,followed by overviews of work in each community. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Storage Systems for Movies-on-Demand Video Servers </title>
<author> Ann L. Chervenak </author>
<date> April 7, 1995 </date>
<abstract> 1 AbstractIn this paper, we evaluate storage system alternatives for movies-on-demand video servers. We begin bycharacterizing the movies-on-demand workload. Then we study disk farms in which one movie is stored perdisk. This is a simple scheme, but it wastes substantial disk bandwidth, since disks holding less popularmovies are under-utilized; also, good performance requires that movies be replicated to reflect the userrequest pattern. Next, we examine disk farms in which movies are striped across disks, and find thatstriped video servers offer close to full utilization of the disks by achieving better load balancing. Finally, weevaluate the use of storage hierarchies for video service that include a tertiary library along with a disk farm.Unfortunately, we show that the performance of neither magnetic tape libraries nor optical disk jukeboxesas part of a storage hierarchy is adequate to service the predicted distribution of movie accesses. We suggestchanges to tertiary libraries that would make them better-suited to these applications. </abstract>
<intro> 2 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Evaluating Blocking Probability in GeneralizedConnectors </title>
<author> Ellen Witte Zegura </author>
<abstract> Abstract| Generalized connectors provide the capability to connect a single input to one or more outputs. Such networks play an important role in supporting any application that involves the distribution of information from one source to many destinations or many sources to many destinations. We present the first analytic model for evaluating blocking probability in generalized connectors. The model allows flexibility in specifying traffic fanout characteristics and network routing algorithms. Equations are derived for computing blocking probability for the important class of series-parallel networks. We investigate the accuracy of the equations by comparing the blocking probability computed using the equations to results from simulation. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Reverse Engineering with a CASE Tool </title>
<author> Bret Johnson </author>
<note> Research advisors: Spencer Rugaber and Rich LeBlanc </note>
<date> October 6, 1994 </date>
<abstract> AbstractWe examine using a CASE tool, Interactive Development Environment's Software through Pictures (StP), to support reverse engineering. We generate structure charts in StP from the automated analysisof C source code. The advantages of this approach are that one can usethe CASE tool's support for drawing, linking, and modifying pictorialnotations for program design in order to make it easier to construct areverse engineering tool. Additionally, one can then use the design representations with the CASE tool to do reengineering for maintenance. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> Department of Computer ScienceSeries of Publications CReport C-1997-15 </pubnum>
<title> Discovery of frequent episodes in event sequences </title>
<author> Heikki Mannila, Hannu Toivonen, and A. Inkeri Verkamo </author>
<affiliation> University of HelsinkiFinland </affiliation>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Finding Interesting Rules from Large Sets of Discovered Association Rules </title>
<author> Mika Klemettinen Heikki Mannila Pirjo Ronkainen Hannu Toivonen A. Inkeri Verkamo </author>
<affiliation> Department of Computer ScienceUniversity of Helsinki </affiliation>
<address> P.O. Box 26, FIN-00014 University of Helsinki, Finland </address>
<email> mannila@cs.helsinki.fi </email>
<abstract> AbstractAssociation rules, introduced by Agrawal, Imielinski, andSwami, are rules of the form "for 90 % of the rows of therelation, if the row has value 1 in the columns in set W ,then it has 1 also in column B". Efficient methods exist fordiscovering association rules from large collections of data.The number of discovered rules can, however, be so largethat browsing the rule set and finding interesting rules fromit can be quite difficult for the user. We show how a simpleformalism of rule templates makes it possible to easily describe the structure of interesting rules. We also give examples of visualization of rules, and show how a visualizationtool interfaces with rule templates. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A structured document database system </title>
<author> Pekka Kilpelainen Greger Linden Heikki MannilaErja Nikunen </author>
<affiliation> University of Helsinki </affiliation>
<abstract> AbstractWe describe a database system for writing, editing, and querying structured documents. The structure of text is described using a context-freegrammar. The operations are implemented using a powerful query language. The system supports the use of user-defined multiple views of thedocuments: one view can contain all the structure explicitly, while anothercan contain only part of the document and have only part of the structure visible. This makes the system flexible for different editing tasks.The system is implemented in C using a relational database system. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Lempel-Ziv Index for q-Grams </title>
<author> Juha Karkkainen and Erkki Sutinen </author>
<affiliation> Department of Computer Science, </affiliation>
<address>  P.O. Box 26 (Teollisuuskatu 23), </address>
<address> FIN-00014 </address>
 <affiliation> University of Helsinki, </affiliation>
 <address> Finland </address>
<email> fJuha.Karkkainen,Erkki.Sutineng@cs.Helsinki.FI </email>
<abstract> Abstract. We present a new sublinear-size index structure for q-grams.A q-gram index of the text is used in many approximate pattern matchingalgorithms. All earlier q-gram indexes have at least linear size. The newmethod takes advantage of repetitions in the text found by Lempel-Zivparsing. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> ??, ??, 1-10 (??)c ?? Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. </note>
<title> Unifying Two-View and Three-View Geometry </title>
<author> SHAI AVIDAN, AMNON SHASHUA </author>
<email> favidan,shashuag@cs.huji.ac.il </email>
<affiliation> Institute of Computer Science, The Hebrew University, </affiliation>
 <address> Jerusalem 91904, Israel </address>
<note> Received ??. Revised ??. </note>
<abstract> Abstract. The core of multiple-view geometry is governed by the fundamental matrix and the trilineartensor. In this paper we unify both representations by first re-deriving the fundamental matrix as a rankdeficient tensor, and secondly by deriving a unified set of operators that are transparent to the number ofviews. As a result, we show that the basic building block of the geometry of multiple views is the trilineartensor of three views and that this tensor specializes to the fundamental matrix (in it's tensor form) inthe case of two views. The properties of the tensor (geometric interpretation, contraction properties,etc.) are independent of the number of views (two or three). As a byproduct, every two-view algorithmcan be considered as a degenerate three-view algorithm and three-view algorithms can work with eithertwo or three images, all using one standard set of tensor operations. To highlight the usefulness of thisparadigm we provide two practical applications. First we present a novel view synthesis algorithm thatstarts with the fundamental matrix (in its tensor form) and seamlessly move to the general trilineartensor, all using one set of tensor operations. The second application is a camera stabilization algorithm,originally introduced for three views, now working with two views without modification. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Using Queue Time Predictions for Processor Allocation </title>
<author> Allen B. Downey  </author>
<affiliation> University of California at BerkeleySan Diego Supercomputer Center </affiliation>
<abstract> AbstractWhen a moldable job is submitted to a space-sharingparallel computer, it must choose whether to begin execution on a small, available cluster or wait in queue formore processors to become available. To make this decision, it must predict how long it will have to wait forthe larger cluster. We propose statistical techniques forpredicting these queue times, and develop an allocationstrategy that uses these predictions. We present a workload model based on observed workloads at the San DiegoSupercomputer Center and the Cornell Theory Center,and use this model to drive simulations of various allocation strategies. We find that prediction-based allocationnot only improves the turnaround time of individual jobs;it also improves the utilization of the system as a whole. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Measure, Stochasticity, and the Density of Hard Languages </title>
<pubnum> TR 92-13 </pubnum>
<author> Jack H. Lutz and Elvira Mayordomo </author>
<date> May 1992 </date>
<affiliation> Iowa State University of Science and TechnologyDepartment of Computer Science </affiliation>
<address> 226 AtanasoffAmes, IA 50011 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> An Executable Semantics for a Formalized Data Flow Diagram Specification Language </title>
<pubnum> TR93-27 </pubnum>
<author> Tim Wahls, Albert L. Baker, and Gary T. Leavens </author>
<date> November 15, 1993 </date>
<affiliation> Iowa State University of Science and TechnologyDepartment of Computer Science </affiliation>
<address> 226 AtanasoffAmes, IA 50011 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Coordination and Control Structures and Processes:Possibilities for Connectionist Networks (CN) </title>
<author> Vasant Honavar &amp; Leonard Uhr </author>
<affiliation> Computer Sciences DepartmentUniversity of Wisconsin-Madison </affiliation>
<abstract> AbstractThe absence of powerful control structures and processes that synchronize, coordinate, switch between, choose among, regulate, direct, modulate interactions between, andcombine distinct yet interdependent modules of large connectionist networks (CN) isprobably one of the most important reasons why such networks have not yet succeeded athandling difficult tasks (e.g. complex object recognition and description, complexproblem-solving, planning).In this paper we examine how CN built from large numbers of relatively simpleneuron-like units can be given the ability to handle problems that in typical multi-computer networks and artificial intelligence programs along with all other types ofprograms are always handled using extremely elaborate and precisely worked out central control (coordination, synchronization, switching, etc.). We point out the severalmechanisms for central control of this un-brain-like sort that CN already have built intothem albeit in hidden, often overlooked, ways.We examine the kinds of control mechanisms found in computers, programs, fetaldevelopment, cellular function and the immune system, evolution, social organizations,and especially brains, that might be of use in CN. Particularly intriguing suggestions arefound in the pacemakers, oscillators, and other local sources of the brain's complex partial synchronies; the diffuse, global effects of slow electrical waves and neurohormones;the developmental program that guides fetal development; communication and coordination within and among living cells; the working of the immune system; the evolutionaryprocesses that operate on large populations of organisms; and the great variety of partially competing partially cooperating controls found in small groups, organizations, andlarger societies. All these systems are rich in control but typically control that emergesfrom complex interactions of many local and diffuse sources. We explore how severaldifferent kinds of plausible control mechanisms might be incorporated into CN, andassess their potential benefits with respect to their cost. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> 1 FEATURE SUBSET SELECTION USING AGENETIC ALGORITHM </title>
<author> Jihoon Yang and Vasant Honavar </author>
<affiliation> Artificial Intelligence Research GroupDepartment of Computer Science </affiliation>
<address> 226 Atanasoff Hall </address>
<affiliation> Iowa State University </affiliation>
<address> Ames, IA 50011U.S.A. </address>
<email> yangjhonavar-@cs.iastate.edu </email>
<abstract> Abstract: Practical pattern classification and knowledge discovery problems require selection of asubset of attributes or features (from a much larger set) to represent the patterns to be classified.This is due to the fact that the performance of the classifier (usually induced by some learningalgorithm) and the cost of classification are sensitive to the choice of the features used to constructthe classifier. Exhaustive evaluation of possible feature subsets is usually infeasible in practice becauseof the large amount of computational effort required. Genetic algorithms, which belong to a class ofrandomized heuristic search techniques, offer an attractive approach to find near-optimal solutionsto such optimization problems. This paper presents an approach to feature subset selection using agenetic algorithm. Some advantages of this approach include the ability to accommodate multiplecriteria such as accuracy and cost of classification into the feature selection process and to find featuresubsets that perform well for particular choices of the inductive learning algorithm used to constructthe pattern classifier. Our experiments with several benchmark real-world pattern classificationproblems demonstrate the feasibility of this approach to feature subset selection in the automateddesign of neural networks for pattern classification and knowledge discovery. </abstract>
<intro> 1.1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> EFFICIENT COMPILATION AND PROFILE-DRIVENDYNAMIC RECOMPILATION IN SCHEME </title>
<author> Robert G. Burger </author>
<degree> Submitted to the faculty of the University Graduate Schoolin partial fulfillment of the requirementsfor the degreeDoctor of Philosophyin the </degree> <affiliation> Department of Computer Science,Indiana University </affiliation>
<date> March 1997 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Compiler Construction Using Scheme </title>
<author> Erik Hilsdale J. Michael AshleyR. Kent Dybvig Daniel P. Friedman </author>
<affiliation> Indiana University Computer Science Department </affiliation>
<address> Lindley Hall 215Bloomington, Indiana 47405 </address>
<email> fehilsdal,jashley,dyb,dfried g@cs.indiana.edu </email>
<abstract> AbstractThis paper describes a course in compiler design that focuses on theScheme implementation of a Scheme compiler that generates native assembly code for a real architecture. The course is suitable for advancedundergraduate and beginning graduate students. It is intended both toprovide a general knowledge about compiler design and implementationand to serve as a springboard to more advanced courses. Although thispaper concentrates on the implementation of a compiler, an outline for anadvanced topics course that builds upon the compiler is also presented. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Using Goals and Experience to Guide Abduction </title>
<author> David B. Leake </author>
<email> leake@cs.indiana.edu </email>
<pubnum> Technical Report #359 </pubnum>
<affiliation> Department of Computer Science, Indiana University </affiliation>
<address> Lindley Hall 215, Bloomington, IN 47405 </address>
<abstract> AbstractStandard methods for abductive understanding are neutral to prior experience and current goals.Candidate explanations are built from scratch by backwards chaining, without considering howsimilar situations were previously explained, and selection of the candidate to accept is based on itslikelihood, without considering the information needs beyond routine understanding. Problems arisewhen applying these methods to everyday understanding: The vast range of possible explanationsmakes it difficult to control the cost of explanation construction and to assure that the explanationsgenerated will actually be useful.We argue that these problems can be overcome by using goals and experience to guide bothexplanation generation and evaluation. Our work is within the framework of case-based explanation, which builds explanations by retrieving and adapting prior explanations stored in memory.We substantiate our model by describing mechanisms that enable it to effectively generate goodexplanations. First, we demonstrate that there exists a theory of anomaly and explanation that canguide retrieval of relevant explanations. Second, we present a plausibility evaluation process thatefficiently detects conflicts and confirmations of an explanation's assumptions by prior patterns,making it possible to focus explanation adaptation when retrieved explanations are implausible.Third, we present methods for judging whether explanations provide the information needed to satisfy explainer goals beyond routine understanding. By reflecting experience and goals in the searchfor explanations, case-based explanation provides a practical mechanism for guiding search towardsexplanations that are both plausible and useful. </abstract>
<note> 1 The work described here was supported in part by the Defense Advanced Research Projects Agency, </note>
</NEW_HEADER>
<NEW_HEADER>
<title> Toward the Rigorous Use ofDiagrams in Reasoning aboutHardware </title>
<author> Steven D. Johnson </author>
 <email> sjohnson@indiana.edu </email>
 <affiliation> Department of Computer Science Indiana University </affiliation>
<author> Jon Barwise </author>
<email> barwise@indiana.edu </email>
<affiliation> Departments of Philosophy, Mathematics, and Computer ScienceIndiana University </affiliation>
<author> Gerard T. Allwein </author>
<affiliation> Visual Inference LaboratoryIndiana UniversityIndiana University Logic Group </affiliation>
<pubnum> Preprint No. IULG-93-23 </pubnum>
<date> May 1993 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, Morgan Kaufmann, San Francisco, 1997. </note>
<title> Learning to Integrate Multiple Knowledge Sourcesfor Case-Based Reasoning </title>
<author> David B. Leake, Andrew Kinley, and David Wilson </author>
<affiliation> Computer Science Department </affiliation>
<address> Lindley Hall 215, </address>
 <affiliation> Indiana University </affiliation>
<address> Bloomington, IN 47405, U.S.A. </address>
<email> fleake, akinley, davwilsg@cs.indiana.edu </email>
<abstract> AbstractThe case-based reasoning process depends onmultiple overlapping knowledge sources, eachof which provides an opportunity for learning. Exploiting these opportunities requiresnot only determining the learning mechanismsto use for each individual knowledge source,but also how the different learning mechanisms interact and their combined utility. Thispaper presents a case study examining therelative contributions and costs involved inlearning processes for three different knowledge sources|cases, case adaptation knowledge, and similarity information|in a case-based planner. It demonstrates the importanceof interactions between different learning processes and identifies a promising method for integrating multiple learning methods to improvecase-based reasoning. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Ray Tracing Method for Illumination Calculation inDiffuse-Specular Scenes </title>
<author> Peter Shirley </author>
<affiliation> Department of Computer ScienceUniversity of Illinois </affiliation>
<address> 1304 West Springfield AvenueUrbana, Illinois 61801USA </address>
<abstract> AbstractSeveral ways of improving the realism of the resultsof traditional ray tracing are presented. The essential physical quantities of spectral radiant power andspectral radiance and their use in lighting calculationsare discussed. Global illumination terms are derivedby employing illumination ray tracing for calculation ofquickly changing indirect lighting components, and ra-diosity ray tracing for slowly changing indirect lightingcomponents. Direct lighting is calculated during theviewing phase allowing the use of bump maps. Finally,a method is introduced that reduces the total numberof shadow rays to no more than the total number ofviewing rays for a given picture. </abstract>
<keyword> Keywords: Bump Mapping, Illumination, Radiosity,Radiance, Ray Tracing, Realism, Stratified Sampling,Texture Mapping. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> 3-D Stereo Using Photometric Ratios </title>
<author> Lawrence B. WolffElli Angelopoulou </author>
<affiliation> Computer Vision LaboratoryDepartment of Computer ScienceThe Johns Hopkins University </affiliation>
<address> Baltimore, MD 21218 </address>
<abstract> ABSTRACTWe present a novel robust methodology for corresponding a dense set of points on anobject surface from photometric values, for 3-D stereo computation of depth. The methodology utilizes multiple stereo pairs of images, each stereo pair taken of exactly the samescene but under different illumination. With just 2 stereo pairs of images taken respectively for 2 different illumination conditions, a stereo pair of ratio images can be produced; one for the ratio of left images, and one for the ratio of right images. Wedemonstrate how the photometric ratios composing these images can be used for accuratecorrespondence of object points. Object points having the same photometric ratio withrespect to 2 different illumination conditions comprise a well-defined equivalence class ofphysical constraints defined by local surface orientation relative to illumination conditions. We formally show that for diffuse reection the photometric ratio is invariant tovarying camera characteristics, surface albedo, and viewpoint and that therefore the samephotometric ratio in both images of a stereo pair implies the same equivalence class ofphysical constraints. Corresponding photometric ratios along epipolar lines in a stereo pairof images under different illumination conditions is therefore a robust correspondence ofequivalent physical constraints, and determination of depth from stereo can be performedwithout explicitly knowing what these physical constraints being corresponded actuallyare. This implies a very practical shape-from-stereo methodology applicable to perspective views and not requiring any knowledge whatsoever of illumination conditions. This isparticularly practical for determination of 3-D shape on smooth featureless surfaces whichhas previously been hard to perform using stereo. We demonstrate experimental 3-D shapedetermination from a dense set of points using our stereo technique on smooth objects ofknown ground truth shape that are accurate to well within 1% depth accuracy. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 17, NO. 6, JUNE 1995 599 </note>
<title> Best-Case Results for Nearest NeighborLearning </title>
<author> Steven Salzberg, Arthur Delcher, David Heath, and Simon Kasif </author>
<abstract> Abstract| In this paper we propose a theoretical modelfor analysis of classification methods, in which the teacherknows the classification algorithm and chooses examples inthe best way possible. We apply this model using the nearest-neighbor learning algorithm, and develop upper and lowerbounds on sample complexity for several different conceptclasses. For some concept classes, the sample complexityturns out to be exponential even using this best-case model,which implies that the concept class is inherently difficultfor the nearest-neighbor algorithm. We identify several geometric properties that make learning certain concepts relatively easy. Finally we discuss the relation of our workto helpful teacher models, its application to decision-treelearning algorithms, and some of its implications for current experimental work. </abstract>
<keyword> Keywords| machine learning, nearest-neighbor, geometricconcepts. </keyword>
<intro> I. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Deterministic Sortingin Nearly Logarithmic Timeon the Hypercubeand Related Computers </title>
<author> Robert Cypher </author>
<affiliation> IBM Almaden Research Center </affiliation>
<address> 650 Harry Rd.San Jose, CA 95120 </address>
<author> C. Greg Plaxton  </author>
<affiliation> MIT Laboratory for Computer Science </affiliation>
<address> 545 Technology SquareCambridge, MA 02139 </address>
<date> November 29, 1995 </date>
<abstract> AbstractThis paper presents a deterministic sorting algorithm, called Sharesort, that sorts nrecords on an n-processor hypercube, shu*e-exchange, or cube-connected cycles inO(log n (log log n) 2 ) time in the worst case. The algorithm requires only a constantamount of storage at each processor. The fastest previous deterministic algorithm forthis problem was Batcher's bitonic sort, which runs in O(log 2 n) time. </abstract>
<note> Supported by an NSERC postdoctoral fellowship, and DARPA contracts N00014-87-K-825 and N0001489-J-1988. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> Appears in Machine Learning: Proceedings of the Tenth International Conference,P. E. Utgoff (editor), Morgan Kaufmann, San Mateo, CA, 1993 </note>
<title> Learning Symbolic Rules Using Artificial Neural Networks </title>
<author> Mark W. Craven and Jude W. Shavlik </author>
<affiliation> Computer Sciences DepartmentUniversity of Wisconsin </affiliation>
<address> 1210 West Dayton St.Madison, WI 53706 </address>
<email> email: fcraven, shavlikg@cs.wisc.edu </email>
<abstract> AbstractA distinct advantage of symbolic learningalgorithms over artificial neural networks isthat typically the concept representationsthey form are more easily understood by humans. One approach to understanding therepresentations formed by neural networks isto extract symbolic rules from trained networks. In this paper we describe and investigate an approach for extracting rules fromnetworks that uses (1) the NofM extraction algorithm, and (2) the network trainingmethod of soft weight-sharing. Previously,the NofM algorithm had been successfullyapplied only to knowledge-based neural networks. Our experiments demonstrate thatour extracted rules generalize better thanrules learned using the C4.5 system. In addition to being accurate, our extracted rulesare also reasonably comprehensible. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Royal Tree Problem, a Benchmark for Single andMulti-population Genetic Programming </title>
<note> appears in "Advances in Genetic Programming II", MIT Press, Pete Angeline andKim Kinnear, editors </note>
<author> Bill Punch, Doug Zongker, and Erik Goodman </author>
<abstract> We report on work done to develop a benchmark problem for genetic programming, bothas a difficult problem to test GP abilities and as a platform for tuning GP parameters.This benchmark, the royal tree, is a function that accounts for tree shape as part of itsevaluation function, thus it controls for a parameter not often found in the GP literature.It also is a progressive function, allowing the user to set the difficulty of the problemattempted. We not only describe the function, but also report on results of using islandparallelism for solving GP problems. The results obtained are somewhat surprising, as itappears that a single large population outperforms a group of smaller populations underall the conditions tested. </abstract>
<intro> 15.1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Perspective on Word Sense Disambiguation Methodsand Their Evaluation </title>
<author> Philip Resnik </author>
<affiliation> Dept. of Linguistics/UMIACSUniversity of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<email> resnik@umiacs.umd.edu </email>
<author> David Yarowsky </author>
<affiliation> Dept. of Computer Science/CLSPJohns Hopkins University </affiliation>
<address> Baltimore, MD 21218 </address>
<email> yarowsky@cs.jhu.edu </email>
<abstract> AbstractIn this position paper, we make severalobservations about the state of the art inautomatic word sense disambiguation. Motivated by these observations, we offer several specific proposals to the community regarding improved evaluation criteria, common training and testing resources, and thedefinition of sense inventories. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Inductive Constraint Logicand the Mutagenesis Problem </title>
<author> Wim Van Laer Hendrik BlockeelLuc De Raedt </author>
<affiliation> Department of Computer Science, Katholieke Universiteit Leuven </affiliation>
<address> Celestijnenlaan 200A, B-3001 Heverlee, Belgium </address>
<email> Email:fWimV,Hendrik,LucDRg@cs.kuleuven.ac.be </email>
<abstract> AbstractA novel approach to learning first order logic formulae from positive and negative examples is incorporated in a system named ICL (Inductive ConstraintLogic). In ICL, examples are viewed as interpretations which are true or falsefor the target theory, whereas in present inductive logic programming systems,examples are true and false ground facts (or clauses). Furthermore, ICL uses aclausal representation, which corresponds to a conjunctive normal form whereeach conjunct forms a constraint on positive examples, whereas classical learningtechniques have concentrated on concept representations in disjunctive normalform.We present some experiments with this new system on the mutagenesis problem. These experiments illustrate some of the differences with other systems,and indicate that our approach should work at least as well as the more classicalapproaches. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Model-guided Segmentation of Corpus Callosum in MR Images </title>
<author> Arvid Lundervold 1 , Nicolae Duta 2 , Torfinn Taxt 1 &amp; Anil K. Jain 2 </author>
<affiliation> 1 Section for Medical Image Analysis and Informatics, Department of Physiology </affiliation>
<affiliation> University of Bergen, </affiliation>
 <address> Arstadveien 19, N-5009 Bergen, Norway </address>
<affiliation> 2 Department of Computer Science and Engineering, Michigan State University </affiliation>
<address> East Lansing, MI 48824-1226, USA </address>
<abstract> AbstractMagnetic resonance imaging (MRI) of the brain, followed by automated segmentation of the corpus callosum(CC) in midsagittal sections have important applicationsin both clinical neurology and neurocognitive researchsince the size and shape of the CC are shown to be correlated to sex, age, neurodegenerative diseases and various lateralized behavior in man. Moreover, whole head,multispectral 3D MRI recordings enable voxel-based tissue classification and estimation of total brain volumes,in addition to CC morphometric parameters. We proposea new algorithm that uses both multispectral MRI measurements (intensity values) and prior information aboutshape (CC template) to segment CC in midsagittal sliceswith very little user interaction. The algorithm has beentested on a sample of 10 subjects scanned with multispec-tral 3D MRI, collected for a study of dyslexia, with verygood agreement between the manually traced (true) CCoutline and the detected CC outline. We conclude thatthe proposed method for CC segmentation is promising forclinical use when multispectral MR images are recorded. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Statistical Characteristics and Multiplexing of MPEG Streams </title>
<author> Marwan Krunz , Ron Sass , and Herman Hughes  </author>
<affiliation> Department of Electrical EngineeringDepartment of Computer ScienceMichigan State University </affiliation>
<address> East Lansing, MI 48824 </address>
<abstract> AbstractThis paper presents a study of the statistical characteristics and multiplexing of Variable-Bit-Rate (VBR)MPEG-coded video streams. Our results are based on23 minutes of video obtained from the entertainmentmovie, The Wizard of Oz. The experimental setupwhich was used to capture, digitize, and compress thevideo stream is described. Although the study is conducted at the frame level (as opposed to the slice level),it is observed that the inter-frame correlation structure for the frame-size sequence involves complicatedforms of pseudo-periodicity that are mainly affectedby the compression pattern of the sequence. A simple model for an MPEG traffic source is developed inwhich frames are generated according to the compression pattern of the original captured video stream. Thenumber of cells per frame is fitted by a lognormal distribution. Simulations are used to study the performance of an ATM multiplexer for MPEG streams. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Aditi-Prolog language manual +L </title>
+<author> James HarlandDavid B. KempTim S. LeaskKotagiri RamamohanaraoJohn A. ShepherdZoltan SomogyiPeter J. StuckeyJayen Vaghani </author>
<abstract> AbstractAditi is a deductive database system under development at the Collaborative InformationTechnology Research Institute by researchers from the University of Melbourne. The mainlanguage in which users interact with Aditi is Aditi-Prolog. This document is a referencemanual for Aditi-Prolog. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Agent-Based Approachfor Robot Vision System </title>
<pubnum> Technical Report 95/34 </pubnum>
<author> Tak Keung CHENGLeslie KITCHENZhi-Qiang LIUJames COOPER </author>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Agents for Citation Findingon the World Wide Web </title>
<author> Yi Han, Seng Wai Loke, Leon Sterling </author>
<pubnum> Technical Report 96/40 </pubnum>
<affiliation> Department of Computer ScienceThe University of Melbourne </affiliation>
<address> Parkville, Victoria 3052Australia </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Termination Analysis for Mercury </title>
<author> Chris Speirs, Zoltan Somogyi and Harald Stndergaard </author>
<affiliation> Department of Computer ScienceThe University of Melbourne </affiliation>
<address> Parkville, Victoria 3052, Australia </address>
<abstract> AbstractSince the late eighties, much progress has been made in the theory of termination analysis forlogic programs. However, from a practical point of view, the significance of much of the workon termination is hard to judge, since experimental evaluations rarely get published. Here wedescribe and evaluate a termination analyzer for Mercury, a strongly typed and moded logic-functional programming language. Mercury's high degree of referential transparency and theguaranteed availability of reliable mode information simplify the termination analysis of Mer-cury compared with that of other logic programming languages. We describe our terminationanalyzer, which uses a variant of a method developed by Plumer. It deals with full Mercury,including modules, declarative input/output, the foreign language interface, and higher-orderfeatures. In spite of these obstacles, it produces high-quality termination information, comparable to the results recently obtained by Lindenstrauss and Sagiv. Most important, in starkcontrast with Lindenstrauss and Sagiv's experimental results, our analyzer has a negligibleimpact on the running time of the compiler of which it is part, even for large programs. Thismeans that the Mercury compiler can produce valuable termination information at no realcost to the programmer. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Mixed Semidefinite-Quadratic-Linear Programs </title>
<author> Jean-Pierre Haeberly Madhu V. Nayakkankuppam Michael L. Overton  </author>
<date> September 23, 1998 </date>
<abstract> AbstractWe consider mixed semidefinite-quadratic-linear programs. These arelinear optimization problems with three kinds of cone constraints, namely:the semidefinite cone, the quadratic cone and the nonnegative orthant. Weoutline a primal-dual path following method to solve these problems andhighlight the main features of SDPpack, a Matlab package which solvessuch programs. We give some examples where such mixed programs arise,and provide numerical results on benchmark problems. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Methods for Handling Faults and Asynchronyin Parallel Computation  </title>
<author> Z. M. Kedem  </author>
<intro> 1. Introduction and Motivation </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Toward the Automation of the Card-PlayingComponent of Bridge </title>
<author> Ming-Sheng Chang </author>
<affiliation> Department of Computer ScienceCourant Institute of Mathematical SciencesNew York University </affiliation>
<abstract> AbstractIn comparision with other games, particularly chess, the research in computer bridge isimmature, and the best bridge-playing programs are mediocre. We propose to study theautomation of the card-playing segment of bridge (omitting bidding), using a number ofdifferent techniques. In this paper we first give an introduction to the state of computerbridge. Next, we propose two possible architectures for solving double-dummy bridge(i.e., a simplified bridge game with perfect information): The first is based on thecombination of And-OR search and heuristic evaluation. The second forms a global planby merging subplans for each individual suit. Next, to deal with uncertain information inreal bridge, we present a new mechanism that combines the concepts of both minimaxsearch and possible worlds. Finally we give a brief description of further work towardautomating card-playing in real bridge. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Development of the C Language </title>
<author> Dennis M. Ritchie </author>
<affiliation> AT&amp;T Bell Laboratories </affiliation>
<address> Murray Hill, NJ 07974 USA </address>
<email> dmr@research.att.com </email>
<abstract> ABSTRACTThe C programming language was devised in the early 1970s as a systemimplementation language for the nascent Unix operating system. Derived fromthe typeless language BCPL, it evolved a type structure; created on a tinymachine as a tool to improve a meager programming environment, it has becomeone of the dominant languages of today. This paper studies its evolution. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Hierarchical Explanation-Based Reinforcement Learning </title>
<author> Prasad Tadepalli and Thomas G. Dietterich </author>
<affiliation> Computer Science DepartmentOregon State University </affiliation>
<address> Corvallis,Oregon 97331-3202 </address>
<email> ftadepalli,tgdg@research.cs.orst.edu </email>
<abstract> AbstractExplanation-Based Reinforcement Learning(EBRL) was introduced by Dietterich andFlann as a way of combining the ability ofReinforcement Learning (RL) to learn optimal plans with the generalization abilityof Explanation-Based Learning (EBL) (Di-etterich &amp; Flann, 1995). We extend thiswork to domains where the agent must order and achieve a sequence of subgoals inan optimal fashion. Hierarchical EBRL caneffectively learn optimal policies in some ofthese sequential task domains even when thesubgoals weakly interact with each other.We also show that when a planner that canachieve the individual subgoals is available,our method converges even faster. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> DISTRIBUTED CONTROL IN OPTICAL WDM NETWORKS </title>
<author> X. Yuan R. Gupta R. Melhem </author>
<affiliation> Department of Computer ScienceUniversity of Pittsburgh </affiliation>
<address> Pittsburgh, PA 15260 </address>
<abstract> ABSTRACTThis paper describes and evaluates distributedwavelength reservation protocols for all-optical WDMnetworks. These protocols are essential for applyingWDM techniques to large scale all-optical networks.The protocols ensure that the wavelengths on the linksalong a path are reserved before communication takesplace. A message is transmitted using the reservedwavelengths and remains in the optical domain utillit reaches the destination. Based upon the timing atwhich the reservation is performed, the protocols areclassified into two categories: forward reservation protocols and backward reservation protocols. Althoughforward reservation protocols are simpler, our performance study shows that backward reservation protocols provide better performance. </abstract>
<intro> INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Contingency Selection in Plan Generation </title>
<author> Nilufer Onder </author>
<affiliation> Department of Computer ScienceUniversity of Pittsburgh </affiliation>
<address> Pittsburgh, PA 15260 </address>
<note> nilufer@cs.pitt.edu </note>
<author> Martha E. Pollack </author>
<affiliation> Department of Computer Scienceand Intelligent Systems ProgramUniversity of Pittsburgh </affiliation>
<address> Pittsburgh, PA 15260 </address>
<note> pollack@cs.pitt.edu </note>
<abstract> AbstractA key question in conditional planning is: how many,and which of the possible execution failures should beplanned for? One cannot, in general, plan for all thepossible failures because the search space is too large.One cannot ignore all the possible failures, or one willfail to produce sufficiently flexible plans. In this paper,we describe an approach to conditional planning thatattempts to identify the contingencies that contributethe most to a plan's overall utility. Plan generationproceeds by handling the most important contingencies first, extending the plan to include actions thatwill be taken in case the contingency fails. We discussthe representational issues that must be addressed inorder to implement such an algorithm, and present anexample which illustrates our approach. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Working Sets, Cache Sizes, and Node Granularity Issuesfor Large-Scale Multiprocessors </title>
<author> Edward Rothberg Jaswinder Pal Singh and Anoop Gupta </author>
<affiliation> Intel Supercomputer Systems Division Computer Systems Laboratory </affiliation>
<address> 14924 N.W. Greenbrier Parkway </address>
 <affiliation> Stanford University </affiliation>
<address> Beaverton, OR 97006 Stanford, CA 94305 </address>
<abstract> AbstractThe distribution of resources among processors, memory andcaches is a crucial question faced by designers of large-scaleparallel machines. If a machine is to solve problems with acertain data set size, should it be built with a large number ofprocessors each with a small amount of memory, or a smallernumber of processors each with a large amount of memory?How much cache memory should be provided per processor forcost-effectiveness? And how do these decisions change as largerproblems are run on larger machines?In this paper, we explore the above questions based on thecharacteristics of five important classes of large-scale parallel scientific applications. We first show that all the applications have a hierarchy of well-defined per-processor workingsets, whose size, performance impact and scaling characteristicscan help determine how large different levels of a multiprocessor's cache hierarchy should be. Then, we use these working sets together with certain other important characteristics ofthe applications|such as communication to computation ratios,concurrency, and load balancing behavior|to reflect upon thebroader question of the granularity of processing nodes in high-performance multiprocessors.We find that very small caches whose sizes do not increasewith the problem or machine size are adequate for all but two ofthe application classes. Even in the two exceptions, the workingsets scale quite slowly with problem size, and the cache sizesneeded for problems that will be run in the foreseeable futureare small. We also find that relatively fine-grained machines,with large numbers of processors and quite small amounts ofmemory per processor, are appropriate for all the applications. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Modeling Communication in Parallel Algorithms:A Fruitful Interaction between Theory and Systems? </title>
<author> Jaswinder Pal Singh * , Edward Rothberg , and Anoop Gupta * </author>
<affiliation> * Computer Systems Laboratory Intel Supercomputer SystemsStanford University </affiliation>
 <address> 14924 NW Greenbrier Pkwy, CO6-09Stanford, CA 94305 Beaverton, OR 97006 </address>
<abstract> AbstractRecently, several theoretical models of parallel architectures have been proposed to replace the PRAM as the modelthat is presented to an algorithm designer. A primary focus ofthe new models is to include the cost of interprocessor communication, which is increasingly important in modern parallelarchitectures. We argue that modeling the communication costsin the architecture or system is only one part of the problem.The other, and usually much more difficult, part is modelingthe communication properties of the algorithm itself, whichprovides necessary inputs into the architectural model to determine overall complexity. In this context, we make three mainpoints in this paper: (i) It is incomplete to describe communication without regard to its relationship with replication. Wepropose a description of the communication-replication relationship in terms of the working set hierarchy of an algorithm.(ii) Both inherent communication and the communication-replication relationship can be very difficult to model in irregular, dynamic computations that are crucial in many real-worldapplications. We present some examples that demonstrate thisdifficulty. (iii) We believe that substantial leverage can beobtained in this effort from the computer systems community,which can provide a hierarchy of simulation and profilingtoolsfrom abstract to detailedtailored to the needs of thealgorithm designers. We propose an initial set of simulationtools, and we discuss possible future refinements to this set. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> Technical Report TR-514-96. </pubnum>
<title> Irregular Applications under Software Shared Memory </title>
<author> Liviu Iftode, Jaswinder Pal Singh and Kai Li </author>
<affiliation> Department of Computer SciencePrinceton University </affiliation>
<address> Princeton, NJ 08544 </address>
<email> liv,jps,li@cs.princeton.edu </email>
<abstract> AbstractShared Virtual Memory (SVM) provides an inexpensive way to support the popular shared addressspace programming model on networks of workstations or personal computers. Despite recent advancesin SVM systems, their performance for all but coarse-grained or regular applications is not well understood.Nor is there an understanding of whether and howfine-grained, irregular programs should be written differently for SVM, with its large granularities of communication and coherence, than for the more familiarhardware coherent at cache line granularity. In thispaper we try to understand the performance and programming issues for emerging, irregular applicationson SVM systems. We examine performance on bothan aggressive all-software system as well as one with alittle hardware support in the network interface. Wealso present approaches to improve the performanceof irregular applications at both the programming andthe system level. As a result of our experiences, weidentify a set of guidelines and techniques that pertainspecifically to programming SVM systems, beyond theguidelines commonly used for programming hardware-coherent systems as well. We also present a furtherrelaxation of the memory consistency model, calledscope consistency, which is particularly effective forsuch applications. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Network Services forMulti-User Virtual Environments </title>
<author> Thomas A. Funkhouser </author>
<affiliation> AT&amp;T Bell Laboratories </affiliation>
<address> Murray Hill, NJ </address>
<abstract> AbstractThis paper describes network services to supportlarge multi-user virtual environments. A client-server design is proposed in which multiple serverscoordinate execution, manage communication, offload processing, and provide persistent storage fortheir clients. Using this design, it is possible to support real-time features, such as collision detection,voice bridging, persistent updates, physical simulation, and autonomous agents, that would be difficult to implement for large virtual environmentswith a peer-to-peer design. The paper includes adescription of services being implemented in RING,a client-server system for interaction between manyusers in large virtual environments. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Database and Display Algorithms forInteractive Visualization of Architectural Models </title>
<author> byThomas Allen Funkhouser </author>
<degree> B.S. (Stanford University) 1983M.S. (University of California at Los Angeles) 1989A dissertation submitted in partial satisfaction of therequirements for the degree ofDoctor of Philosophyin </degree><affiliation> Computer Science </affiliation>
<degree> in theGRADUATE DIVISIONof the </degree><affiliation> UNIVERSITY of CALIFORNIA at BERKELEY </affiliation>
<degree> Committee in charge:Professor Carlo H. Sequin , ChairProfessor Lawrence RoweProfessor Jean Pierre Protzen </degree><date> 1993 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Simulating the Madness of Crowds:Price Bubbles in an Auction-Mediated Robot Market </title>
<author> Ken Steiglitz and Daniel Shapiro </author>
<affiliation> Dept. of Computer Science, Princeton University </affiliation>
<address> Princeton, NJ 08544 </address>
<date> May 5, 1997 </date>
<abstract> AbstractWe simulate a multiagent market with production, consumption, and exchangemediated by a sealed-bid double auction. Marked price bubbles and subsequentcrashes occur when value-based (fundamentals-driven) and trend-based traders areboth present, and the market equilibrium price is ramped up exogenously. Similarly,negative price bubbles and recoveries occur when the equilibrium price is rampeddown. Because the simulated market is auction-mediated, we can observe the operations of traders during these events, and study the interactions that produce andresolve bubbles. Some preliminary circuit-breaker experiments are described, in whichbubbles are interrupted during their formation. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> DIMACS Technical Report 98-10 </pubnum>
<date> February 1998 </date>
<title> Patience is a Virtue: The Effect of Delay onCompetitiveness for Admission Control </title>
<author> byMichael H. Goldwasser 1 </author>
<affiliation> Department of Computer SciencePrinceton University </affiliation>
<address> Princeton, NJ 08544 </address>
<email> wass@cs.princeton.edu </email>
<note> 1 Permanent MemberDIMACS is a partnership of Rutgers University, Princeton University, AT&amp;T Labs-Research,Bell Labs and Bellcore.DIMACS is an NSF Science and Technology Center, funded under contract STC-91-19999;and also receives support from the New Jersey Commission on Science and Technology. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> An Evolutionary Approach toCombinatorial Optimization Problems </title>
<author> Sami Khuri </author>
<affiliation> Department of Mathematics &amp; Computer ScienceSan Jose State University </affiliation>
<address> One Washington SquareSan Jose, CA 95192-0103, U.S.A. </address>
<email> khuri@sjsumcs.sjsu.edu </email>
<author> Thomas Back and Jorg Heitkotter </author>
<affiliation> Department of Computer ScienceUniversity of Dortmund Systems Analysis Research Group, LSXI </affiliation>
<address> D-44221 Dortmund, Germany </address>
<email> fbaeck,jokeg@ls11.informatik.uni-dortmund.de </email>
<note> Copyright c 1993 ACM Press. All rights reserved.To appear in the proceedings of CSC'94Phoenix Arizona, March 8-10, 1994. </note>
<abstract> Abstract: The paper reports on the application of geneticalgorithms, probabilistic search algorithms based on themodel of organic evolution, to NP-complete combinatorialoptimization problems. In particular, the subset sum, maximum cut, and minimum tardy task problems are considered.Except for the fitness function, no problem-specific changesof the genetic algorithm are required in order to achieve results of high quality even for the problem instances of size100 used in the paper. For constrained problems, such as thesubset sum and the minimum tardy task, the constraints aretaken into account by incorporating a graded penalty terminto the fitness function. Even for large instances of thesehighly multimodal optimization problems, an iterated application of the genetic algorithm is observed to find the globaloptimum within a number of runs. As the genetic algorithmsamples only a tiny fraction of the search space, these resultsare quite encouraging. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> InvestigatingGenetic Algorithmsfor Scheduling </title>
<author> Hsiao-Lan Fang </author>
<degree> MSc Dissertation </degree><affiliation> Department of Artificial IntelligenceUniversity of Edinburgh </affiliation>
<date> 1992 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Navigation in Three Dimensional Spaces </title>
<pubnum> CS-590Z </pubnum>
<author> Carlos Gonzalez Ochoa Aleman </author>
<date> May 23, 1994 </date>
<abstract> AbstractCurrent graphic hardware have helped to develop scientific visualization tools,but this progress has not level with the magnitude of data genereted in some areas needing to be visualized. Techniques to navigate data have been developed,including new hardware and algorithms to improve the rendering speed and quality.This paper will describe the issues of navigation, current display and interactiontechnology, and algorithms. At the end a set of problems yet to be solved will bediscussed </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Color-based Technique for Measuring Visible Loss for Usein Image Data Communication 1 </title>
<author> Melliyal Annamalai, Aurobindo Sundaram and Bharat Bhargava </author>
<affiliation> Department of Computer SciencesPurdue University </affiliation>
<address> W. Lafayette, IN 47906, USA </address>
<email> fmelli,auro,bbg@cs.purdue.edu </email>
<abstract> AbstractThe concept of the global information infrastructure and specifically that of the WorldWide Web (WWW) has led to users accessing data of different media including imagesand video data over a wide area network. These data objects have sizes the order ofmegabytes and communication time is very large. The data size can be reduced withoutlosing information by applying loss-inducing techniques and this will lead to reduction incommunication time. Several loss-inducing techniques have been developed and each imageis treated differently by each technique. In some cases an acceptable quality of the imageis obtained and in some cases it is not. In this paper we develop a color-based techniqueto quantify the data loss when a loss-inducing technique is applied to an image. This willresult in estimating whether the resulting image is indistinguishable from the original withrespect to the human eye. We illustrate its use to classify images according to the loss theycan tolerate. This avoids redundant communication of a high quality image when a lowerquality image can satisfy the application resulting in the conservation and better usageof network resources. We present the technique, the communication time saved, and anexperimental evaluation to prove the validity of the technique. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> AFEC: An Adaptive Forward Error-CorrectionProtocol and Its Analysis </title>
<author> Kihong Park </author>
<affiliation> Department of Computer SciencesPurdue University </affiliation>
<address> West Lafayette, IN 47907 </address>
<email> park@cs.purdue.edu </email>
<pubnum> CSD-TR 97-038 </pubnum>
<abstract> AbstractThis paper presents an adaptive protocol for packet-level forward error-correction in dynamic networks. The objective is to facilitate best-effort real-time applications whose timingconstraints rule out the use of retransmission-based ARQ schemes. The degree of redundancyis adjusted as a function of network state, decreasing when the network is well-behaved andincreasing when it is not. The control problem is nontrivial due to the fact that increased redundancy, beyond a certain level, backfires resulting in self-induced congestion which impedesthe timely recovery of information at the receiver.In the first part of the paper, we present a comprehensive analysis of the control problemassociated with dynamic forward error-correction, concentrating on a particular protocol calledAdaptive Forward Error-Correction (AFEC). We show that instabilities can arise from twodistinct sources|desired operating point location and network delay|and we give solutions tohandle them. The first causal factor is intimately tied to optimality, making its achievementpotentially perilous in the context of QoS-greedy applications.The second part of the paper presents simulation results that confirm the qualitative dynamics predicted by the analysis. We quantitatively estimate the redundancy-recovery rate functionwhich relates redundancy to the quality of service rendered at the receiver. We show under whatconditions the curve's shape is unimodal and to what degree. We compare the performance ofAFEC against a static FEC protocol in which the redundancy factor is fixed. We show thatAFEC exhibits superior performance when the network is subject to structural changes thatpersist for nonnegligible durations. Under short-range dependent traffic conditions, AFEC isable to closely match the performance of optimum static FEC but not exceed it. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> PYTHIA: A Knowledge Based Systemfor Intelligent Scientific Computing </title>
<author> Sanjiva Weerawarana, Elias N. Houstis, John R. Rice, Anupam Joshi </author>
<affiliation> Purdue University </affiliation>
<author> andCatherine E. Houstis </author>
<affiliation> University of Crete </affiliation>
<keyword> Categories and Subject Descriptors: I.2.1 [Artificial Intelligence]: Applications and ExpertSystems; G.1.8 [Numerical Analysis]: Partial Differential EquationsGeneral Terms: Knowledge Based SystemsAdditional Key Words and Phrases: Computational Intelligence, Knowledge Based Systems, Partial Differential Equations, Performance Evaluation, Problem Solving Environments </keyword>
<abstract> 1. ABSTRACTDomain specific Problem Solving Environments (PSEs) are the key new ingredients that will aid in the widespread use of Computational Science &amp; Engineering(CS&amp;E) systems. Each PSE consists of a well defined library that supports thenumerical and symbolic solution of certain mathematical model(s) characterizing aspecific discipline, together with an easy to use software environment. This environment should ideally interact with the user in a language "natural" to the associateddiscipline, and provide a high level abstraction of the underlying, computationallycomplex, model. However, it appears that almost all extant PSEs assume thatthe user is familiar with the specific functionality/applicability of the PSE. Theirprimary design objective is to support some form of high level programming withpredefined state-of-the-art algorithmic infrastructure. As the functionality of thesesystems increases, the user is expected to make complex decisions in the parametric space of the algorithmic infrastructure supported by the PSE. In this paperwe describe a knowledge based system, PYTHIA, to automate this decision making process and aid in providing a high level abstraction to the user. Specifically,PYTHIA addresses the problem of (parameter, algorithm) pair selection within ascientific computing domain assuming some minimum user specified computationalobjectives and some characteristics of the given problem. PYTHIA's frameworkand methodology is general and applicable to any class of scientific problems and </abstract>
<note> Work supported in part by AFOSR award 91-F49620, NSF awards CCR 86-19817, CCR 92-02536,and ASC 9404859. </note>
<note> Authors' addresses: </note>
 <author> S. Weerawarana, E.N. Houstis, J.R. Rice and A. Joshi: </author>
 <affiliation> Department of Computer Sciences, Purdue University, </affiliation>
 <address> West Lafayette, IN 47907, USA; </address>
 <author> C.E. Houstis: </author>
 <affiliation> Department ofComputer Science, University of Crete, </affiliation>
 <address> Heraklion, Greece. </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> On the Collapse of the q-Gram Filtration </title>
<author> E. SUTINEN </author>
<affiliation> University of Helsinki, </affiliation>
 <address> Finland </address>
<author> W. SZPANKOWSKI </author>
<affiliation> Purdue University, </affiliation>
 <address> U.S.A. </address>
<abstract> AbstractIn the approximate pattern matching problem, the text area to be searchedfor an occurrence of a pattern can be pruned by applying a filtration condition. A q-gram based filtration condition defines potential text areas in termsof pattern q-grams, i.e., strings of length q. A text area will be checked byan accurate method only if the set of the q-grams in the text area satisfies acertain condition. One hopes that the filtration limits the number of checksto a minimum, thus making the algorithm quite efficient. However, computer experiments show that the filtration method works fine for cases whenthe allowed error level k is relatively small compared to the pattern length,but loses its efficiency quite sharply with an increasing k. This is a phasetransition phenomenon that is quite often observed in nature. In this paper,we present a theoretical explanation for this phenomenon which will excuseus to introduce advanced mathematical analysis based on certain languages,correlation polynomials, generating functions and complex analysis. It is ourview that nothing can be more exciting and rewarding than finding a theoretical justification for an abrupt manifestation of nature. </abstract>
<keyword> Keywords: Algorithm Analysis, Approximate Pattern Matching. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Authorship Analysis: Identifying TheAuthor of a Program 1 </title>
<author> Ivan Krsul </author>
<affiliation> The COAST ProjectDepartment of Computer SciencesPurdue University </affiliation>
<address> West Lafayette, IN 47907-1398 </address>
<email> krsul@cs.purdue.edu </email>
<date> May 3, 1994 </date>
<pubnum> Technical Report CSD-TR-94-030 </pubnum>
<note> 1 This paper was originally written as a Master's thesis at Purdue University. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Efficient Disk Allocation for Fast Similarity Searching </title>
<author> Sunil Prabhakar Divyakant Agrawal Amr El Abbadi </author>
<affiliation> Department of Computer ScienceUniversity of California </affiliation>
<address> Santa BarbaraCA 93106, U.S.A. </address>
<email> fsunilp,agrawal,amrg@cs.ucsb.edu </email>
<abstract> AbstractAs databases increasingly integrate non-textual informationit is becoming necessary to support efficient similarity searching in addition to range searching. Recently, declusteringtechniques have been proposed for improving the performance of similarity searches through parallel I/O. In thispaper, we propose a new scheme which provides good declus-tering for similarity searching. In particular, it does globaldeclustering as opposed to local declustering, exploits theavailability of extra disks and does not limit the partitioning of the data space. Our technique is based upon theCyclic declustering schemes which were developed for rangeand partial match queries. We establish, in general, thatCyclic declustering techniques outperform previously proposed techniques. </abstract>
<note> Appeared in Proc. 10th ACM Symposium on Parallel Algorithms and Architectures (SPAA '98), Puerto Vallarta, Mexico </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Coarse-Grained ParallelQR-Factorization Algorithm forSparse Least Squares Problems </title>
<author> Tz. Ostromsky P. C. Hansen Z. Zlatev  </author>
<abstract> AbstractA sparse QR-factorization algorithm SPARQR for coarse-grained parallelcomputations is described. The coefficient matrix, which is assumed to begeneral sparse, is reordered in an attempt to bring as many zero elements inthe lower left corner as possible. The reordered matrix is then partitioned intoblock rows, and Givens plane rotations are applied in each block-row. These areindependent tasks and can be done in parallel. Row and column permutationsare carried out within the diagonal blocks in an attempt to preserve better thesparsity of the matrix.The algorithm can be used for solving least squares problems either directlyor combined with an iterative method (preconditioned conjugate gradients areused). Small non-zero elements can optionally be dropped in the latter case.This leads to a better preservation of the sparsity and, therefore, to a fasterfactorization. The price which has to be paid is some loss of accuracy. Theiterative method is used to regain the accuracy lost during the factorization.Numerical results from several experiments with matrices from the well-known Harwell-Boeing collection as well as with some larger sparse matrices arepresented in this work. An SGI Power Challenge computer with 16 processorshas been used in the experiments. </abstract>
<keyword> Keywords: coarse-grained parallelism, least squares problem, QR-factorization,general sparse matrix, drop-tolerance, reordering, partitioning, block algorithm. </keyword>
<affiliation> Purdue University, Department of Computer Science, </affiliation>
<address> West Lafayette, IN 47907, USA </address>
<email> e-mail: tto@cs.purdue.edu </email>
<affiliation> Institute of Mathematical Modelling, Technical University of Denmark, </affiliation>
<address> Bldg. 305, DK-2800 Lyngby, Denmark </address>
<email> e-mail: pch@imm.dtu.dk </email>
<affiliation> National Environmental Research Institute, </affiliation>
 <address> Frederiksborgvej 399, DK-4000 Roskilde, Denmark </address>
<email> e-mail: luzz@sun2.dmu.dk </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Efficient Finite-State Approximation of ContextFree Grammars </title>
<author> C.M. Rood </author>
<affiliation> Computer LaboratoryUniversity of Cambridge </affiliation>
<email> cmr1001@cl.cam.ac.uk </email>
<abstract> Abstract. This paper introduces a novel method for constructing finite-state machines recognising context free (CF)grammars. The method utilizes the idea of a path througha finite-state machine (FSM). Certain paths form the basisfor an unfolding process which is applied to the LR(0) characteristic finite-state machine (CFSM) corresponding to thegrammar. The next section discusses the approximation algorithm, including this unfolding process, in more detail, andsection 3 introduces the concept of an unfolding criterion.Section 4 proves the soundness of the approximation method,and its exactness to arbitrary, fixed recursive depths. Section5 presents initial computational figures resulting from an implementation of the method. A variation of the method thatis more computationally feasible is discussed. The final section compares the method with existing research on finite-state approximation of CF grammars, and presents preliminary conclusions regarding the method. </abstract>
<intro> 1 THE APPROXIMATION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Evaluating the Performance of Software Distributed Shared Memoryas a Target for Parallelizing Compilers </title>
<author> Alan L. Cox , Sandhya Dwarkadas , Honghui Lu and Willy Zwaenepoel  </author>
<affiliation> Rice University </affiliation>
<address> Houston, TX 77005-1892 </address>
<email> falc, hhl, willyg@cs.rice.edu </email>
<affiliation> University of Rochester </affiliation>
<address> Rochester, NY14627-0226 </address>
<email> sandhya@cs.rochester.edu </email>
<abstract> AbstractIn this paper, we evaluate the use of software distributedshared memory (DSM) on a message passing machine asthe target for a parallelizing compiler. We compare this approach to compiler-generated message passing, hand-codedsoftware DSM, and hand-coded message passing. For thiscomparison, we use six applications: four that are regularand two that are irregular.Our results are gathered on an 8-node IBM SP/2 using the TreadMarks software DSM system. We use the APRshared-memory (SPF) compiler to generate the shared memory programs, and the APR XHPF compiler to generate message passing programs. The hand-coded message passingprograms run with the IBM PVMe optimized message passing library. On the regular programs, both the compiler-generated and the hand-coded message passing outperformthe SPF/TreadMarks combination: the compiler-generatedmessage passing by 5.5% to 40%, and the hand-codedmessage passing by 7.5% to 49%. On the irregular programs, the SPF/TreadMarks combination outperforms thecompiler-generated message passing by 38% and 89%, andonly slightly underperforms the hand-coded message passing, differing by 4.4% and 16%. We also identify the factorsthat account for the performance differences, estimate theirrelative importance, and describe methods to improve theperformance. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Carlsberg: A Distributed Execution EnvironmentProviding Coherent Shared Memory andIntegrated Message Passing </title>
<note> A Position/Work-in-Progress Paper presented atNordic Workshop on Programming Environment Research, NWPER'94,Lund, Sweden, June, 1994 </note>
<author> Povl T. Koch Robert J. Fowler </author>
<affiliation> Department of Computer Science, University of Copenhagen (DIKU) </affiliation>
<address> Universitetsparken 1, 2100 Copenhagen, Denmark </address>
<phone> Tel: +45 35 32 14 18 Fax: +45 35 32 14 01 </phone> <email> E-mail: koch,fowler@diku.dk </email>
<abstract> AbstractThe Carlsberg prototype is a distributed operating system designed to provide efficient support for distributed-parallel applications on a cluster of high-performance workstations. A unique feature of Carlsberg is the integration ofcoherent shared memory, multithreading, and message passing in one system.In this paper we discuss the motivation for the Carlsberg system and we presentaspects of its design. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> 8th SIAM Conference on Parallel Processing for Scientific Computing, Minneapolis, MN, March 1997. </note>
<title> On the Accuracy of Anderson's Fast N-body Algorithm </title>
<author> Yu Charlie Hu S. Lennart Johnsson  </author>
<abstract> AbstractWe present an empirical study of the accuracy-cost tradeoffs of Anderson's method.The various parameters that control the degree of approximation of the computationalelements and the separateness of interacting computational elements govern both thearithmetic complexity and the accuracy of the method. Our experiment shows that fora given error requirement, using a near-field containing only nearest neighbor boxesand a hierarchy depth that minimizes the number of arithmetic operations minimizesthe total number of arithmetic operations. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Reprinted from International Journal in Computer Simulation, Vol. 1, pp. 31-58 (1991) </note>
<title> The Efficient Simulation of Parallel Computer Systems </title>
<author> R. G. Covington </author>
<affiliation> Jet Propulsion Laboratory, </affiliation>
 <address> 125-2334800 Oak Grove DrivePasadena, CA 91109 </address>
<author> S. Dwarkadas, J. R. Jump, and J. B. Sinclair </author>
<affiliation> Department of Electrical and Computer EngineeringRice University </affiliation>
<address> Houston, Texas 77251 </address>
<author> S. Madala +L </author>
<affiliation> Coherent Systems, Inc. </affiliation>
<address> 1000 Bay Area Blvd., Suite 206Houston, TX 77058 </address>
<abstract> Abstract: An ongoing research project involves the design and evaluation of a software systemfor simulating parallel computers. A major goal in the development of this system was to avoid thehigh overhead associated with the conventional instruction-level simulation of sequentialcomputers, but to retain the accuracy of that technique derived from its use of the execution of realprograms. The resulting system is program-driven, but the overhead is significantly reduced byprofiling the program to get timing estimates for its basic blocks, which are then used at run time togenerate process execution times dynamically while avoiding a detailed emulation of eachinstruction's execution. A number of experiments dealing with message-passing computersystems have been performed in order to determine the level of accuracy that can be expected fromits performance predictions and to measure its overhead. </abstract>
<keyword> Index Terms - Architecture models, efficiency, parallel computers, parallel programs,performance, simulation, testbed, validation. </keyword>
<note> This research was supported by Texas Instruments Grant No. TI720845RJ, NSF/ONR Grant No. N00014-87-K0324, SDSU/SDIO Contract No. N66001-85-D-0203, NASA Grant No. NAG 0-208, and a Shell DoctoralFellowship. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> RICE UNIVERSITY </affiliation>
<title> Synchronization, Coherence, and Consistency forHigh Performance Shared-MemoryMultiprocessing </title>
<author> bySandhya Dwarkadas </author>
<degree> A Thesis Submittedin Partial Fulfillment of theRequirements for the DegreeDoctor of PhilosophyApproved, Thesis Committee:J Robert Jump, Co-ChairmanProfessorElectrical and Computer EngineeringJames B. Sinclair, Co-ChairmanAssociate ProfessorElectrical and Computer EngineeringJohn K. BennettAssistant ProfessorElectrical and Computer EngineeringKen KennedyProfessorComputer ScienceHouston, Texas </degree><date> September, 1992 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Theoretical Foundations of Association Rules </title>
<author> Mohammed J. Zaki and Mitsunori Ogihara  </author>
<affiliation> Computer Science Department, University of Rochester, </affiliation>
 <address> Rochester NY 14627 </address>
<email> fzaki,ogiharag@cs.rochester.edu </email>
<abstract> AbstractIn this paper we describe a formal framework for the problem of mining association rules. The theoretical foundation is based on the field of formal concept analysis. A concept is composed of closed subsets of attributes (itemsets)and objects (transactions). We show that all frequent itemsets are uniquely determined by the frequent concepts. Wefurther show how this lattice-theoretic framework can be used to find a small rule generating set, from which one caninfer all other association rules. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On GDM's: Geometrically Deformed Models for the Extraction of ClosedShapes from Volume Data </title>
<author> ByJames Vradenburg Miller </author>
<degree> A Thesis Submitted to the GraduateFaculty of </degree> <affiliation> Rensselaer Polytechnic Institute </affiliation>
<degree> in Partial Fulfillment of theRequirements for the Degree ofMaster of ScienceApproved:Dr. Michael J. WoznyThesis Adviser </degree><affiliation> Rensselaer Polytechnic Institute </affiliation>
<address> Troy, New York </address>
<date> December 1990 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Modeling and the Adaptive Solution ofCVD Fiber-Coating Processes </title>
<author> S. Adjerid, J. E. Flaherty, J. B. Hudson, and M. S. Shephard </author>
<affiliation> Scientific Computation Research CenterRensselaer Polytechnic Institute </affiliation>
<address> Troy, New York 12180, USA </address>
<abstract> AbstractWe develop a mathematical model for the coating of ceramic fibers by chemical vapordeposition (CVD) in cylindrical hot- or cold-walled reactors. The model couples theNavier-Stokes equations for the mixture of a carrier gas and precursor species, an energyequation for the gaseous mixture, a convection-diffusion system for the reacting precursorspecies, a fiber coating model, and a fiber heat conduction equation. The system is heatedby a combination of conduction, convection, and radiation.The partial differential system resulting from this model is solved by adaptive finite element software using automatic mesh refinement and coarsening on a quadtree-structuredmesh. The results of parameter studies indicate the effectiveness of using adaptive solution techniques with CVD applications and also suggest some guidance for improvingthe process. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Automated Design Optimization for the P2 and P8Hypersonic Inlets </title>
<author> Vijay Shukla , Andrew Gelsey , Mark Schwabacher Donald Smith , Doyle D. Knight </author>
<affiliation> Rutgers, the State University of New Jersey </affiliation>
<address> New Brunswick, NJ 08903 </address>
<date> February 20, 1997 </date>
<note> To appear in Journal of Aircraft, Vol 34, No. 2, March-April 1997Copyright c by Vijay Shukla, Andrew Gelsey, Mark Schwabacher, Donald Smith and Doyle D. Knight. </note>
<abstract> AbstractAn automated design methodology incorporating industry-standard Navier-Stokescodes and a gradient-based optimizer has been developed. This system is used to redesign the well-known NASA P2 and P8 hypersonic inlets. First, the Navier-Stokessimulations of the original P2 and P8 inlet designs are validated using numerical convergence studies and comparison with wind-tunnel experimental data for the originalinlets published by NASA in the early 1970s. Second, the P2 and P8 inlets are redesigned with the objective of canceling the cowl shock (and, in the case of the P8inlet, the additional cowl-generated compression) at the centerbody by appropriatecontouring of the centerbody boundary. The original inlets were intended to achievethese same objectives, but detailed experimental measurements indicated that a substantial reflected shock system was present. The choice of the objective function, whichis used to drive the optimization, has a significant impact on the final design. Severaldifferent formulations for the objective function have been employed, and improvements of 60% to 90% in the objective function have been achieved. This automateddesign system represents one of the first successful combinations of numerical optimization methods with Reynolds-averaged Navier-Stokes fluid dynamics simulation for highspeed inlets, and demonstrates a new area in which High Performance Computing mayhave considerable impact on problems of military and industrial significance. </abstract>
<affiliation> Postdoctoral Research Associate, Dept. of Mechanical and Aerospace Engineering. AIAA Member.Assistant Professor, Computer Science Dept. AIAA Member.Graduate Student, Computer Science Dept.Assistant Professor, Computer Science Dept.Professor, Dept. of Mechanical and Aerospace Engineering. AIAA Associate Fellow. </affiliation>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> To be presented at the AAAI/ICML 1998 Workshop on Predicting the Future: AI Approaches to Time-Series Analysis 1 </note>
<title> Predicting Sequences of User Actions </title>
<author> Brian D. Davison and Haym Hirsh </author>
<affiliation> Department of Computer ScienceRutgers, The State University of New Jersey </affiliation>
<address> New Brunswick, NJ 08903 USA </address>
<email> fdavison,hirshg@cs.rutgers.edu </email>
<abstract> AbstractPeople display regularities in almost everything they do. Thispaper proposes characteristics of an idealized algorithm that,when applied to sequences of user actions, would allow a userinterface to adapt over time to an individual's pattern of use.We describe a simple predictive method with these characteristics and show its predictive accuracy on a large dataset ofUNIX commands to be at least as good as others that havebeen considered, while using fewer computational and memory resources. </abstract>
<intro> Motivation </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Towards a Cost-Effective Parallel Data Mining Approach </title>
<author> Zoltan Jarai, Aashu Virmani, Liviu Iftode </author>
<affiliation> Department of Computer ScienceRutgers University </affiliation>
<address> Piscataway, NJ 08854 </address>
<email> fjarai,avirmanig@paul.rutgers.edu, iftode@cs.rutgers.edu </email>
<abstract> AbstractMassive rule induction has recently emerged as one of thepowerful data mining techniques. The problem is known tobe exponential in the size of the attributes, and given its everincreasing use, can greatly benefit from parallelization.In this paper, we study cost-effective approaches to paral-lelize rule generation algorithms. In particular, we considerthe propositional rule generation algorithm of the DiscoveryBoard system, and present our design and implementation ofa parallel algorithm for the same task. We then present someearly performance results of our parallelization scheme onhardware and software distributed shared memory multiprocessors. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Intelligent Model Selection for Hillclimbing Search inComputer-Aided Design </title>
<author> Thomas Ellman John Keane Mark Schwabacher </author>
<affiliation> Department of Computer Science, Hill Center for Mathematical SciencesRutgers University, </affiliation>
 <address> New Brunswick, NJ 08903 </address>
<email> fellman,keane,schwabacg@cs.rutgers.edu </email>
<abstract> AbstractModels of physical systems can differ according tocomputational cost, accuracy and precision, amongother things. Depending on the problem solvingtask at hand, different models will be appropriate. Several investigators have recently developedmethods of automatically selecting among multiple models of physical systems. Our research isnovel in that we are developing model selectiontechniques specifically suited to computer-aided design. Our approach is based on the idea that artifact performance models for computer-aided designshould be chosen in light of the design decisionsthey are required to support. We have developeda technique called "Gradient Magnitude Model Selection" (GMMS), which embodies this principle.GMMS operates in the context of a hillclimbingsearch process. It selects the simplest model thatmeets the needs of the hillclimbing algorithm inwhich it operates. We are using the domain of sailing yacht design as a testbed for this research. Wehave implemented GMMS and used it in hillclimb-ing search to decide between a computationally expensive potential-flow program and an algebraicapproximation to analyze the performance of sailing yachts. Experimental tests show that GMMSmakes the design process faster than it would be ifthe most expensive model were used for all designevaluations. GMMS achieves this performance improvement with little or no sacrifice in the qualityof the resulting design. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Why Should Architectural Principles beEnforced? </title>
<author> Naftaly H. Minsky  </author>
<email> minsky@cs.rutgers.edu </email>
<affiliation> Department of Computer ScienceRutgers University </affiliation>
<address> New Brunswick, NJ, 08903 USA </address>
<date> August 12, 1998 </date>
<abstract> AbstractThere is an emerging consensus that an explicit architectural modelwould be invaluable for large evolving software systems, providing themwith a framework within which such a system can be reasoned about andmaintained. But the great promise of architectural models has not beenfulfilled so far, due to a gap between the model and the system it purportsto describe. It is our contention that this gap is best bridged if the modelis not just stated, but is enforced.This gives rise to a concept enforced architectural model |or, a law |which is explored in this paper. We argue that this model has two major beneficial consequences: First, by bridging the above mentioned gapbetween an architectural model and the actual system, an enforced architectural model provides a truly reliable framework within which a systemcan be reasoned about and maintained. Second, our model provides software developers with a carefully circumscribed flexibility in molding thelaw of a project, during its evolutionary lifetime|while maintaining certain architectural principles as invariant of evolution. </abstract>
<keyword> Keywords: architectural model, law-governed software, evolution, invariants of evolution, firewalls, protection. </keyword>
<note> Work supported in part by NSF grants No. CCR-9308773 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Imposing The Law of Demeter and Its Variations </title>
<author> Partha pratim Pal  </author>
<email> partha@cs.rutgers.edu </email>
<author> Naftaly H. Minsky  </author>
<email> minsky@cs.rutgers.edu </email>
<affiliation> Department of Computer ScienceRutgers University </affiliation>
<address> New Brunswick, NJ 08903 </address>
<date> February 28, 1996 </date>
<abstract> AbstractThe Law of Demeter [4] is accepted as a useful design principle thatpromotes tightly encapsulated classes and reduced coupling. Principleslike this are routinely adopted in real-life projects, however neither theprogramming languages nor the existing environments provide enoughsupport for effective realization of these principles. It is our thesisthat broad structural principles should be formally specified, strictlyenforced, and relaxed whenever relaxation is in order. In this paperwe show how this can be done under our darwin-E environment using,the Law of Demeter as an illustration. </abstract>
<keyword> keywords: Law of Demeter, Law-Governed Architecture, SoftwareEngineering Principles, Enforcement. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Learning Novel Domains Through Curiosity and Conjecture </title>
<author> Paul D. Scott &amp; Shaul Markovitch </author>
<affiliation> Center for Machine Intelligence </affiliation>
<address> 2001,Commonwealth Blvd.,Ann Arbor, Michigan 48105 </address>
<abstract> AbstractThis paper describes DIDO, a system we havedeveloped to carry out exploratory learning ofunfamiliar domains without assistance from anexternal teacher. The program incorporates novelapproaches to experience generation and representationgeneration. The experience generator uses a heuristicbased on Shannon's uncertainty function to findinformative examples. The representation generatormakes conjectures on the basis of small amounts ofevidence and retracts them if they prove to be wrongor useless. A number of experiments are describedwhich demonstrate that the system can distribute itslearning resources to steadily acquire a goodrepresentation of the whole of a domain, and that thesystem can readily acquire both disjunctive andconjunctive concepts even in the presence of noise. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Distributed parallel shooting for BVODEs </title>
<author> K.L. Chow and W.H. Enright </author>
<affiliation> Department of Computer Science, University of Toronto </affiliation>
<email> E-mail : chow@cs.toronto.edu and enright@cs.toronto.edu </email>
<abstract> AbstractMany important scientific problems can be formulated as systems of ordinary differential equations with two-point boundary value constraints (BVODE). Multiple shootingis one of the most widely used numerical techniques for solving BVODE problems.In this work, we present a new distributed parallel numerical algorithm for BVODEswhich is based on multiple shooting. We investigate the numerical stability of thisnew distributed algorithm and identify difficulties that can arise. We propose a newparallel iterative refinement scheme to cope with some specific numerical difficultiesidentified in our investigation. Computational experience is presented to demonstratethe potential effectiveness of our approach. </abstract>
<keyword> Keywords: Distributed parallel algorithm, boundary value problems, multiple shooting </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Practical PAC Learning </title>
<author> Dale Schuurmans </author>
<affiliation> Department of Computer ScienceUniversity of Toronto </affiliation>
<address> Toronto, Ontario M5S 1A4, Canada </address>
<email> dale@cs.toronto.edu </email>
<author> Russell Greiner </author>
<affiliation> Siemens Corporate Research </affiliation>
<address> Princeton, NJ 08540, USA </address>
<email> greiner@scr.siemens.com </email>
<note> Appears inProceedings of the Fourteenth International Conference on Artificial Intelligence (IJCAI-95),Montreal, August 1995. </note>
<abstract> AbstractWe present new strategies for "probably approximately correct" (pac) learning that usefewer training examples than previous approaches. The idea is to observe training examples one-at-a-time and decide "on-line" when toreturn a hypothesis, rather than collect a largefixed-size training sample. This yields sequential learning procedures that pac-learn by observing a small random number of examples.We provide theoretical bounds on the expectedtraining sample size of our procedure | but establish its efficiency primarily by a series of experiments which show sequential learning actually uses many times fewer training examples inpractice. These results demonstrate that pac-learning can be far more efficiently achieved inpractice than previously thought. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Continuous sigmoidal belief networkstrained using slice sampling </title>
<author> Brendan J. Frey </author>
<affiliation> Department of Computer Science, University of Toronto </affiliation>
<address> 6 King's College Road, Toronto, Canada M5S 1A4 </address>
<abstract> AbstractReal-valued random hidden variables can be useful for modellinglatent structure that explains correlations among observed variables. I propose a simple unit that adds zero-mean Gaussian noiseto its input before passing it through a sigmoidal squashing function. Such units can produce a variety of useful behaviors, rangingfrom deterministic to binary stochastic to continuous stochastic. Ishow how "slice sampling" (Neal 1996) can be used for inferenceand learning in top-down networks of these units and demonstratelearning on two simple problems. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Learning Useful Horn Approximations </title>
<author> Russell Greiner  </author>
<address> 755 College Road East </address>
<affiliation> Siemens Corporate Research </affiliation>
<address> Princeton, NJ 08540 </address>
<email> greiner@learning.siemens.com </email>
<author> Dale Schuurmans </author>
<affiliation> Department of Computer ScienceUniversity of Toronto </affiliation>
<address> Toronto, Ontario M5S 1A4 </address>
<email> dale@cs.toronto.edu </email>
<abstract> AbstractWhile the task of answering queries from anarbitrary propositional theory is intractable ingeneral, it can typically be performed efficientlyif the theory is Horn. This suggests that itmay be more efficient to answer queries using a "Horn approximation"; i.e., a horn theory that is semantically similar to the originaltheory. The utility of any such approximationdepends on how often it produces answers tothe queries that the system actually encounters;we therefore seek an approximation whose expected "coverage" is maximal. Unfortunately,there are several obstacles to achieving this goalin practice: (i) The optimal approximation depends on the query distribution, which is typically not known a priori; (ii) identifying the optimal approximation is intractable, even giventhe query distribution; and (iii) the optimal approximation might be too large to guaranteetractable inference. This paper presents an approach that overcomes (or side-steps) each ofthese obstacles. We define a learning process,AdComp, that uses observed queries to estimate the query distribution "online", and thenuses these estimates to hill-climb, efficiently,in the space of size-bounded Horn approximations, until reaching one that is, with provablyhigh probability, effectively at a local optimum. </abstract>
<note> Appears in theProceedings of the Third International Conference on Knowledge Representation and Reasoning,25-29 October 1992, Cambridge, MA. </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Powers of Trees </title>
<author> Paul E. Kearney and Derek G. Corneil </author>
<affiliation> Department of Computer Science, University of Toronto, </affiliation>
<address> Toronto ON, CANADA M5S 1A4 </address>
<email> kearney@cs.toronto.edudgc@cs.toronto.edu </email>
<abstract> Abstract. We present the first polynomial algorithm for recognizing tree powers. A graph Gis a tree power if there is a tree T and a positive integer k such that T k ~ = G where x and areadjacent in T k if and only if d T (x; ) k. We also show that a natural extension of tree powerrecognition is NP-complete, namely, given a graph G and a positive integer r, determine ifthere is a tree power within r edges of G. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Coding Segments Inside and Outside the Chromosome </title>
<author> Thomas Haynes </author>
<affiliation> Department of Computer ScienceWichita State University </affiliation>
<address> Wichita, KS 67260 </address>
<email> E-mail: haynes@cs.twsu.edu </email>
<phone> Phone: (316) 978-3925 </phone><abstract> AbstractCoding segments are those sub-segments of the chromosome which contribute either positively ornegatively to the fitness evaluation of the chromosome. We extract coding segments from chromosomesand we investigate the sharing of coding segments both inside and outside of the chromosome. Wefind duplication of coding segments inside the chromosomes provides a back-up mechanism for thesearch heuristics. We further find local search in a collective memory of coding segments outside of thechromosome, collective adaptation, enables the search heuristic to represent partial solutions which arelarger than realistic chromosomes lengths and to express the solution outside of the chromosome. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Learning to Select Useful Landmarks </title>
<author> Russell Greiner </author>
<affiliation> Siemens Corporate Research </affiliation>
<address> Princeton, NJ 08540 </address>
<email> greiner@learning.siemens.com </email>
<author> Ramana Isukapalli </author>
<affiliation> Department of Computer ScienceRutgers University </affiliation>
<email> ramana@cs.rutgers.edu </email>
<note> Appears in theProceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94),Seattle, Washington, July 1994. </note>
<abstract> AbstractTo navigate effectively, an autonomous agent must beable to quickly and accurately determine its currentlocation. Given an initial estimate of its position (perhaps based on dead-reckoning) and an image taken ofa known environment, our agent first attempts to locate a set of landmarks (real-world objects at knownlocations), then uses their angular separation to obtain an improved estimate of its current position. Unfortunately, some landmarks may not be visible, orworse, may be confused with other landmarks, resulting in both time wasted in searching for invisible landmarks, and in further errors in the agent's estimate ofits position. To address these problems, we propose amethod that uses previous experiences to learn a selection function that, given the set of landmarks thatmight be visible, returns the subset which can reliablybe found correctly, and so provide an accurate registration of the agent's position. We use statistical techniques to prove that the learned selection function is,with high probability, effectively at a local optimal inthe space of such functions. This report also presentsempirical evidence, using real-world data, that demonstrate the effectiveness of our approach. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Support for Implementation of EvolutionaryConcurrent Systems in ConcurrentProgramming Languages </title>
<author> Raju Pandey 1 and J. C. Browne 2 </author>
<affiliation> 1 Computer Science Department, University of California, </affiliation>
 <address> Davis, CA 95616  </address>
 <affiliation> 2 Department of Computer Sciences, The University of Texas, </affiliation>
 <address> Austin, TX 78712 </address>
<abstract> Abstract. In many concurrent programming languages, concurrent programs are difficult to extend and modify: small changes in a concurrentprogram may require re-implementations of a large number of its components. In this paper a novel concurrent program composition mechanismis presented in which implementations of computations and synchronizations are completely separated. Separation of implementations facilitatesextensions and modifications of programs by allowing one to change implementations of both computations and synchronizations. The paperalso describes a concurrent programming model and a programming language that support the proposed approach. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A VARIABLE TIME STEP METHOD FOR AN AGE-DEPENDENTPOPULATION MODEL WITH NONLINEAR DIFFUSION </title>
<author> BRUCE P. AYATI  </author>
<abstract> Abstract. We propose a method for solving a model of age-dependent population diusionwith random dispersal. This method, unlike previous methods, allows for variable time steps andindependent age and time discretizations. We use a moving age discretization that transforms theproblem to a system of parabolic equations. The system is then solved by backward dierences intime and a Galerkin approximation in space; the equations that need to be solved at each step treateach age group separately. A priori L 2 error estimates are obtained by an energy analysis. Theseestimates are superconvergent in the age variable. We present a postprocessing technique whichcapitalizes on the superconvergence. </abstract>
<keyword> Key words. population dynamics, age-dependence, nonlinear diusion, variable time steps,superconvergence, postprocessing. AMS subject classitcations. 35Q80, 65M06, 65M15, 65M60, 92D25. </keyword>
<intro> 1. Introduction. In this paper, we consider a numerical method for solving an </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> ISSN 1360-1725 </note>
<title> The Test Matrix Toolbox for Matlab (Version 3.0) </title>
<author> N. J. Higham </author>
<pubnum> Numerical Analysis Report No. 276 </pubnum>
<date> September 1995 </date>
<note> Manchester Centre for Computational MathematicsNumerical Analysis ReportsDEPARTMENTS OF MATHEMATICSReports available from: </note>
<affiliation> Department of MathematicsUniversity of Manchester </affiliation>
<address> Manchester M13 9PLEngland </address>
<note> And over the World-Wide Web from URLs </note>
<web> http://www.ma.man.ac.uk/MCCM/MCCM.htmlftp://ftp.ma.man.ac.uk/pub/narep </web><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> User-Defined Aggregatesfor Logical Data Languages </title>
<author> Haixun Wang and Carlo Zaniolo </author>
<affiliation> Computer Science DepartmentUniversity of California at Los Angeles </affiliation>
<address> Los Angeles, CA 90095 </address>
<email> hxwang@cs.ucla.edu zaniolo@cs.ucla.edu </email>
<abstract> Abstract. A new wave of data-intensive and knowledge-based applications|such as datamining and decision support|require the introduction of complex application-specific aggregate functions. In this paper, we propose extensions for deductive database systems tosupport these new applications. We develop constructs, formal semantics, and implementation techniques for user-defined aggregates, and describe their realization in an extendedLDL++ system recently built at UCLA. With these extensions, the system can support online aggregation, roll-ups for data cubing, temporal aggregates for time-series, iceberg queries,and other recently proposed operators used in decision support and data mining procedures.We then discuss the application of this technology to other DBMSs, and in particular to theSQL3 specifications that support the notion of user-defined aggregates. We show that SQL3suffers from limitations that severely restrict its use in new applications; thus we proposesimple extensions similar to those used for LDL++ to overcome such limitations. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Greedy Algorithms inGreedy with Choice and Negation  </title>
<author> Sergio Greco Carlo Zaniolo </author>
<affiliation> Dip: Elettr: Informatica Sist: Computer Science Dept:Universita della Calabria Univ: of California at Los Angeles </affiliation>
<address> 87030 Rende; Italy LosAngeles; CA 90024 </address>
<email> greco@si:deis:unical:it zaniolo@cs:ucla:edu </email>
<abstract> AbstractIn the design of algorithms, the greedy paradigm provides a powerful tool for solvingefficiently classical computational problems, within the framework of procedural languages. However, expressing these algorithms within the declarative framework of logic-based languages has proved to be a difficult research challenge. In this paper, we extend the framework of Datalog-like languages to obtain simple declarative formulationsfor such problems, and propose effective implementation techniques to ensure computational complexities comparable to those of procedural formulations. These advances areachieved through the use of the choice construct, that has semantics reducible to that ofprograms with negation under stable model semantics. Then we extend the fixpoint-basedsemantics of choice programs with preference annotations to guide search strategies andsimple logic-based formulations of classical greedy algorithms. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Semantics-based Failure Recovery in Distributed Systemswith Optimistic Message Logging  </title>
<author> Hong Va Leong Divyakant Agrawal  </author>
<affiliation> Department of Computer ScienceUniversity of California </affiliation>
<address> Santa Barbara, CA 93106 </address>
<abstract> AbstractRecovery from failures is important in distributed computing. A common technique to supportrecovery is asynchronous checkpointing, coupled with optimistic message logging. These schemes havelow overheads during failure-free operations and can provide an acceptable degree of fault-tolerance.Central to these protocols is the determination of a maximal consistent global state, which is recoverable.Message semantics is not exploited in most existing recovery protocols to determine the recoverable state.We propose to identify messages that are not influential in the computation through message semantics.These messages can be logically removed from the computation without changing its meaning or result.In this paper, we illustrate with examples how the removal of these messages improves the theoreticalmaximal consistent global state. Taking semantics into account, recovery protocols are then developedto realize the idea. The semantics in object-oriented databases is adapted to special processes acting asservers for further improvements. This technique can also be applied to ensure a more timely commitmentfor output in a distributed computation. </abstract>
<keyword> Keywords: message semantics, commutativity, recovery, optimistic message logging, asynchronouscheckpointing </keyword>
<note> An abridged version of this paper appears in the Proceedings of the 14th International Conference on Distributed ComputingSystems as Using Message Semantics to Reduce Rollback in Optimistic Message Logging Recovery Schemes.This research is supported in part by the NSF under grant number IRI-9117094. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Run-time Compilation for Parallel Sparse Matrix Computations </title>
<author> Cong Fu and Tao Yang </author>
<affiliation> Department of Computer ScienceUniversity of California, </affiliation>
<address> Santa Barbara, CA 93106. </address>
<web> http://www.cs.ucsb.edu/f~cfu,~tyangg </web><abstract> AbstractRun-time compilation techniques have been shown effectivefor automating the parallelization of loops with unstructuredindirect data accessing patterns. However, it is still an openproblem to efficiently parallelize sparse matrix factorizationscommonly used in iterative numerical problems. The difficulty is that a factorization process contains irregularly-interleaved communication and computation with varyinggranularities and it is hard to obtain scalable performanceon distributed memory machines. In this paper, we presentan inspector/executor approach for parallelizing such applications by embodying automatic graph scheduling techniques to optimize interleaved communication and computation. We describe a run-time system called RAPID thatprovides a set of library functions for specifying irregulardata objects and tasks that access these objects. The systemextracts a task dependence graph from data access patterns,and executes tasks efficiently on a distributed memory machine. We discuss a set of optimization strategies used inthis system and demonstrate the application of this systemin parallelizing sparse Cholesky and LU factorizations. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> TRCS 97-02 </pubnum>
<title> A New Framework for Image Invariants using Basis Expansion  </title>
<author> Yuan-Fang Wang </author>
<affiliation> Department of Computer ScienceUniversity of California </affiliation>
<address> Santa Barbara, CA 93106 </address>
<email> E-mail: yfwang@cs.ucsb.edu </email>
<web> Web: http://www.cs.ucsb.edu/ yfwang </web><abstract> AbstractWe propose a general framework for computing invariant features from images. The proposedapproach is based on a simple concept of basis expansion. It is widely applicable to many popularbasis representations, such as wavelets [4, 5, 24, 25], short-time Fourier analysis [15, 30], andsplines [2, 6, 33]. Exploiting formulations that use both global and local information aboutshape and color, the new approach is neither strictly global nor local. It has the advantage oftolerating a certain degree of occlusion (unlike global analysis) and does not require estimatinghigh-order derivatives in computing invariants (unlike local analysis), whence is more robust.Furthermore, it enables a quasi-localized, hierarchical shape analysis which is not possible withother known invariant techniques. Unlike most current research on image invariants whichconcentrates on either geometry or illumination invariants, the proposed framework is verygeneral and produces invariants which are insensitive to rigid motion, general affine transform,changes of parameterization and scene illumination, and perspective transform. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A SUIF Java Compiler </title>
<author> Holger M. Kienle </author>
<email> kienle@cs.uscb.edu </email>
<pubnum> Technical Report TRCS98-18 </pubnum>
<date> August, 1998 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Jade: A High-Level, Machine-Independent Language for ParallelProgramming </title>
<author> Martin C. Rinard, Daniel J. Scales and Monica S. Lam </author>
<affiliation> Computer Systems LaboratoryStanford University, </affiliation>
 <address> CA 94305 </address>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> EXPLOITING COMMUTING OPERATIONS IN PARALLELIZINGSERIAL PROGRAMS </title>
<author> PEDRO DINIZ AND MARTIN RINARD </author>
<affiliation> DEPARTMENT OF COMPUTER SCIENCEUNIVERSITY OF CALIFORNIA, SANTA BARBARA </affiliation>
<address> SANTA BARBARA, CA 93106 </address>
<abstract> Abstract. Two operations commute if the result of their execution is independent of the order in which they execute. Commuting operations can be executedconcurrently provided they execute atomically on the objects they access. Staticallyrecognizing commuting operations is of great interest because they increase the amountof concurrency a compiler can exploit. In this document we introduce commutativityanalysis anew technique for automatically parallelizing serial programs. We thenconduct a feasibility study of existing scientific applications as to the existence andexploitability of commuting operations. We study the commuting operations presentin one such application the Barnes-Hut hierarchical N-body algorithm. We thenparallelize this application using knowledge of commuting operations and present performance results of the parallel code for a shared-memory multiprocessor. </abstract>
<intro> 1. Introduction. </intro> 
</NEW_HEADER>
<NEW_HEADER>
<title> A Concurrency Mechanism For Sequential Eiffel </title>
<author> Murat Karaorman John Bruno </author>
<affiliation> Department of Computer ScienceUniversity of California </affiliation>
<address> Santa Barbara, CA 93106 </address>
<email> Email: murat@cs.ucsb.edu, bruno@cs.ucsb.edu </email>
<abstract> AbstractThis paper describes a set of classes designed tofacilitate concurrent programming using the sequential object-oriented language EIFFEL. The design andimplementation presented here is the application of amore general Concurrency Model we have built to introduce concurrency to sequential OOPLs. The modelviews concurrency as a well-defined, inheritable property of objects specified in the class CONCURRENCY,and provides a methodology using inheritance to writeconcurrent object-orient applications. Key ideas involved in the methodology are: active objects, extensibility of protocols, synchronization programming,data-driven synchronization with asynchronous message passing.The novel feature of our work is in its describingconcurrency in the context of sequential programmingand using a object-oriented design methodology to describe and implement it.We illustrate the usefulness and expressiveness ofthe concurrency mechanism by presenting examplesand analyzing them. The ability to express powerfulsynchronization constraints as reusable software components emerges as a strong point of our implementation. </abstract>
<note> This research has been supported by the Lawrence Liver-more National Labs; grant no: ISCR/LLNL 89-22,90-22 </note>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Scintilla: Cluster Computing with SCI </title>
<author> Max Ibel, Klaus E. Schauser, Chris J. Scheiman, and Michael Schmitt </author>
<affiliation> Department of Computer ScienceUniversity of California, Santa Barbara </affiliation>
<address> Santa Barbara, CA 93106 </address>
<email> fibel,schauser,chriss,schmittmg@cs.ucsb.edu </email>
<web> http://www.cs.ucsb.edu/research/scintilla </web><abstract> AbstractThe Scintilla project at UCSB studies SCI-based clustercomputing. The Scalable Coherent Interface (SCI) is arecent communication standard for cluster interconnects.We focus on non-coherent SCI, using our cluster setupof SBus-based and PCI-based workstations connected viaDolphin SCI adapters. Our motivation for choosing SCI asnetwork fabric is the very low latency and high bandwidth.We study how to map a variety of programming models efficiently onto the SCI hardware, focusing on messagepassing and global address space support, implementingActive Messages and Split-C. We present implementationtrade-offs, present performance measurements and compare the PCI and SBus adapters.We found that the user-level load/store programming interface of SCI is very convenient to use, achieves low latencies, and is fully virtualized, simultaneously supportingmultiple parallel programs and communication channels.On the other hand, neither of the programming modelsstudied maps directly to SCI. Issues such as notification,atomic operations, and virtual address space limitationsrepresent major implementation challenges, which we address with a combination of compiler and run-time support. Overall, we found the SCI network a good substratefor high-performance cluster computing. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Run-time Techniques for Exploiting Irregular TaskParallelism on Distributed Memory Architectures  </title>
<author> Cong Fu and Tao Yang </author>
<affiliation> Department of Computer ScienceUniversity of California </affiliation>
<address> Santa Barbara, CA 93106 </address>
<email> fcfu,tyangg@cs.ucsb.edu </email>
<abstract> AbstractAutomatic scheduling for directed acyclic graphs (DAG) and its applications for coarse-grained irregular problems such as large n-body simulation have been studied in the literature.However solving irregular problems with mixed granularities such as sparse matrix factorizationis challenging since it requires efficient run-time support to execute a DAG schedule. In thispaper, we investigate run-time optimization techniques for executing general asynchronousDAG schedules on distributed memory machines. Our solution tightly integrates the run-timescheme with a fast communication mechanism to eliminate unnecessary overhead in messagebuffering and copying. We discuss a consistency model incorporating the above optimizations,and taking advantage of task dependence properties to ensure the correctness of execution.We demonstrate the applications of this scheme in sparse factorizations and triangular solverfor which actual speedups are hard to obtain. Our experiments on Meiko CS-2 show that theautomatically scheduled code has achieved scalable performance for these problems and therun-time overhead is small compared to the total execution time. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> UNIVERSITY of CALIFORNIASanta Barbara </affiliation>
<title> Design and Implementation of a System to Support Integration ofAutonomous Database Systems </title>
<degree> A thesis submitted in partial satisfaction of therequirements for the degree ofMaster of ScienceinComputer Science </degree><author> byTze Kwan Lau </author>
<degree> Committee in charge:Professor Jianwen Su, ChairProfessor Oscar IbarraProfessor Amr El Abbadi </degree><date> December 1998 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> The Institution of order-sorted equational logic </title>
<author> Grigore Ro~su </author>
<affiliation> University of Bucharest, Faculty of Mathematics,Department of Computer Science </affiliation>
<address> Str. Academiei 14, R70109, ROMANIA </address>
<abstract> AbstractThe paper provides an organisation of order-sorted equational logic asan Institution. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Appears in Journal of the ACM, Vol. 39, No. 1, January 1992, pp. 214-233. Prelimanary versionin Proceedings of the 20th Annual Symposium on Theory of Computing, ACM, 1988. </note>
<title> How to Sign Given Any Trapdoor Permutation </title>
<author> Mihir Bellare Silvio Micali  </author>
<date> January 1992 </date>
<abstract> AbstractWe present a digital signature scheme which is based on the existence of any trapdoorpermutation. Our scheme is secure in the strongest possible natural sense: namely, it is secureagainst existential forgery under adaptive chosen message attack. </abstract>
<affiliation> Department of Computer Science &amp; Engineering, </affiliation>
 <address> Mail Code 0114, </address>
 <affiliation> University of California at San Diego, </affiliation>
 <address> 9500Gilman Drive, La Jolla, CA 92093. </address>
 <email> E-mail: mihir@cs.ucsd.edu. </email>
 <note> Work done while author was at MIT, supported inpart by NSF grant CCR-87-19689. </note>
<affiliation> MIT Laboratory for Computer Science, </affiliation>
 <address> 545 Technology Square, Cambridge, MA 02139. </address>
 <note> Supported in part byNSF grant DCR-84-13577 and ARO grant DAALO3-86-K-0171. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> The Relative Complexity of NP Search Problems </title>
<author> Paul Beame  </author>
<affiliation> Computer Science and EngineeringUniversity of Washington </affiliation>
<email> beame@cs.washington.edu </email>
<author> Stephen Cook  </author>
<affiliation> Computer Science Dept.University of Toronto </affiliation>
<email> sacook@cs.toronto.edu </email>
<author> Jeff Edmonds  </author>
<affiliation> I.C.S.I. </affiliation>
<address> Berkeley, CA 94704-1198 </address>
<email> edmonds@icsi.berkeley.edu </email>
<author> Russell Impagliazzo x </author>
<affiliation> Computer Science and EngineeringUC, San Diego </affiliation>
<address> 9500 Gilman DriveLa Jolla, CA 92093-0114 </address>
<email> russell@cs.ucsd.edu </email>
<author> Toniann Pitassi - </author>
<affiliation> Mathematics and Computer ScienceUniversity of Pittsburgh </affiliation>
<email> toni@cs.pitt.edu </email>
<abstract> AbstractPapadimitriou introduced several classes of NP search problems based on combinatorial principles which guarantee theexistence of solutions to the problems. Many interestingsearch problems not known to be solvable in polynomialtime are contained in these classes, and a number of themare complete problems. We consider the question of the relative complexity of these search problem classes. We proveseveral separations which show that in a generic relativizedworld, the search classes are distinct and there is a standardsearch problem in each of them that is not computation-ally equivalent to any decision problem. (Naturally, absolute separations would imply that P 6= NP.) Our separationproofs have interesting combinatorial content and go to theheart of the combinatorial principles on which the classes arebased. We derive one result via new lower bounds on thedegrees of polynomials asserted to exist by Hilbert's Null-stellensatz over finite fields. </abstract>
<note> Research supported by NSF grants CCR-8858799 and CCR-9303017Research supported by an NSERC operating grant and the Information Technology Research CentreSupported by an NSF postdoctoral fellowship and by a CanadianNSERC postdoctoral fellowshipx Research Supported by NSF YI Award CCR-92-570979, SloanResearch Fellowship BR-3311, grant #93025 of the joint US-Czechoslovak Science and Technology Program, and USA-Israel BSFGrant 92-00043Research supported by an NSF postdoctoral fellowship and byNSF Grant CCR-9457782 </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> TR - UCSD - CS96-484 </pubnum>
<title> Mapping Parallel Applications toDistributed Heterogeneous Systems </title>
<author> Silvia M. Figueira 1 and Francine Berman 2 </author>
<affiliation> Department of Computer Science and EngineeringUniversity of California, San Diego </affiliation>
<email> -silvia,berman-@cs.ucsd.edu </email>
<abstract> AbstractFast networks have made it possible to coordinate distributed heterogeneous CPU,memory and storage resources to provide a powerful platform for executing high-performance applications. However, the performance of parallel applications on suchsystems is highly dependent on the mapping of application tasks to machines. In thispaper, we propose a mapping strategy for applications formed by multiple tasks targetedto heterogeneous platforms. We first define a mapping model, the match-tree, whichreects the data movement and conversion costs of distributed algorithms and allows foralternative implementations of individual tasks on different machines. We then define thefind-mapping and split-partition algorithms, based on the match-tree model, todetermine the best allocation of tasks to resources in heterogeneous systems. Weillustrate the use of these algorithms with a sample distributed application. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Almost All Regular Graphs areHamiltonian </title>
<author> R. W. Robinson </author>
<affiliation> Computer Science DepartmentUniversity of Georgia </affiliation>
<address> Athens, GA 30602, U.S.A. </address>
<author> N. C. Wormald  </author>
<affiliation> Department of MathematicsUniversity of Melbourne </affiliation>
<address> Parkville, VIC 3052, Australia </address>
<abstract> AbstractIn a previous paper the authors showed that almost all labelledcubic graphs are hamiltonian. In the present paper, this result isused to show that almost all r-regular graphs are hamiltonian for anyfixed r 3, by an analysis of the distribution of 1-factors in randomregular graphs. Moreover, almost all such graphs are r-edge-colourableif they have an even number of vertices. Similarly, almost all r-regularbipartite graphs are hamiltonian and r-edge-colourable for fixed r 3. </abstract>
<note> Research supported by the Australian Research Council </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Learning to Schedule Straight-Line Code </title>
<author> J. Eliot B. Moss </author>
<affiliation> Dept. of Comp. Sci.Univ. of Mass. </affiliation>
<address> Amherst, MA 01003 </address>
<author> Paul E. Utgoff </author>
<affiliation> Dept. of Comp. Sci.Univ. of Mass. </affiliation>
<address> Amherst, MA 01003 </address>
<author> John Cavazos </author>
<affiliation> Dept. of Comp. Sci.Univ. of Mass. </affiliation>
<address> Amherst, MA 01003 </address>
<author> Doina Precup </author>
<affiliation> Dept. of Comp. Sci.Univ. of Mass. </affiliation>
<address> Amherst, MA 01003 </address>
<author> Darko Stefanovi c </author>
<affiliation> Dept. of Comp. Sci.Univ. of Mass. </affiliation>
<address> Amherst, MA 01003 </address>
<author> Carla Brodley </author>
<affiliation> Sch. of Elec. and Comp. Eng.Purdue University </affiliation>
<address> W. Lafayette, IN 47907 </address>
<author> David Scheeff </author>
<affiliation> Sch. of Elec. and Comp. Eng.Purdue University </affiliation>
<address> W. Lafayette, IN 47907 </address>
<abstract> AbstractExecution speed of programs on modern computer architectures is sensitive, by a factor of two or more, to the order in which instructionsare presented to the processor. To realize potential execution efficiency,it is now customary for an optimizing compiler to employ a heuristicalgorithm for instruction scheduling. These algorithms are painstakinglyhand-crafted, which is expenseive and time-consuming. We show howto cast the instruction scheduling problem as a learning task, so that oneobtains the heuristic scheduling algorithm automatically. Our focus is thenarrower problem of scheduling straight-line code, also known as a basicblock of instructions. Our empirical results show that just a few featuresare adequate for quite good performance at this task for a real modernprocessor, and that any of several supervised learning methods performnearly optimally with respect to the features used. </abstract>
<keyword> Category: Applications (compiler optimization) </keyword>
<note> Original: This work has not been submitted elsewhere.Presentation: We prefer oral presentation.Contact author: Eliot Moss </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Multi-time Models for Temporally AbstractPlanning </title>
<author> Doina Precup, Richard S. Sutton </author>
<affiliation> University of Massachusetts </affiliation>
<address> Amherst, MA 01003 </address>
<email> fdprecupjrichg@cs.umass.edu </email>
<abstract> AbstractPlanning and learning at multiple levels of temporal abstraction is a keyproblem for artificial intelligence. In this paper we summarize an approach to this problem based on the mathematical framework of Markovdecision processes and reinforcement learning. Current model-based reinforcement learning is based on one-step models that cannot representcommon-sense higher-level actions, such as going to lunch, grasping anobject, or flying to Denver. This paper generalizes prior work on temporally abstract models [Sutton, 1995] and extends it from the predictionsetting to include actions, control, and planning. We introduce a moregeneral form of temporally abstract model, the multi-time model, and establish its suitability for planning and learning by virtue of its relationshipto the Bellman equations. This paper summarizes the theoretical framework of multi-time models and illustrates their potential advantages in agridworld planning task. </abstract>
<intro> The need for hierarchical </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Intra-Option Learning about Temporally Abstract Actions </title>
<author> Richard S. Sutton </author>
<affiliation> Department of Computer ScienceUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003-4610 </address>
<email> rich@cs.umass.edu </email>
<author> Doina Precup </author>
<affiliation> Department of Computer ScienceUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003-4610 </address>
<email> dprecup@cs.umass.edu </email>
<author> Satinder Singh </author>
<affiliation> Department of Computer ScienceUniversity of Colorado </affiliation>
<address> Boulder, CO 80309-0430 </address>
<email> baveja@cs.colorado.edu </email>
<abstract> AbstractSeveral researchers have proposed modelingtemporally abstract actions in reinforcementlearning by the combination of a policy and a termination condition, which we refer to as an option. Value functions over options and models ofoptions can be learned using methods designedfor semi-Markov decision processes (SMDPs).However, all these methods require an option tobe executed to termination. In this paper we explore methods that learn about an option fromsmall fragments of experience consistent withthat option, even if the option itself is not executed. We call these methods intra-option learning methods because they learn from experiencewithin an option. Intra-option methods are sometimes much more efficient than SMDP methods because they can use off-policy temporal-difference mechanisms to learn simultaneouslyabout all the options consistent with an experience, not just the few that were actually executed. In this paper we present intra-option learning methods for learning value functions over options and for learning multi-time models of theconsequences of options. We present computational examples in which these new methodslearn much faster than SMDP methods and learneffectively when SMDP methods cannot learn atall. We also sketch a convergence proof for intraoption value learning. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Method Providing Identity Privacy to Mobile Users duringAuthentication </title>
<author> Didier Samfat, Refik Molva </author>
<affiliation> Institut Eurecom </affiliation>
<address> 2229 Route des Cr^etesBP 193 - Sophia Antipolis FRANCE </address>
<email> fsamfat, molvag@eurecom.fr </email>
<abstract> AbstractThe increasing development of mobile networksraises new security requirements and concerns. In addition to the basic need of authentication, confidentiality and key distribution services, a new problem involving privacy is the unauthorized tracking of users'migration. In other words, accessing any informationrelated to the mobile user's location data without hisconsent, is a serious violation of his privacy. Moreover, if no care is taken, the disclosure of the mobileuser real identity may appear during the authentication process. The basic solution to this problem is theuse of aliases which insure non-traceability by hidingthe user's real identity and also his relationship withdomain authorities. In this paper we provide a classification of the different degrees of non-traceability andpresent a new efficient method for the computation ofaliases. This technique can be used during authentication of mobile users and thus avoids the drawbacks ofexisting solutions such as GSM and CDPD. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Composite Model Checking with Type SpecificSymbolic Encodings  </title>
<author> Tevfik Bultan Richard Gerber </author>
<affiliation> Department of Computer ScienceUniversity of Maryland, </affiliation>
 <address> College Park, MD 20742, USA </address>
<abstract> AbstractWe present a new symbolic model checking technique, which analyzes temporal properties in multi-typed transition systems. Specifically, the method uses multiple type-specific data encodings to representsystem states, and it carries out fixpoint computations via the corresponding type-specific symbolicoperations. In essence, different symbolic encodings are unified into one composite model checker. Anytype-specific language can be included in this framework provided that the language is closed underBoolean connectives, propositions can be checked for satisfiability, and relational images can be computed.Our technique relies on conjunctive partitioning of transition relations of atomic events based on variabletypes involved, which allows independent computation of one-step pre- and post-conditions for eachvariable type.In this paper we demonstrate the effectiveness of our method on a nontrivial data-transfer protocol,which contains a mixture of integer and Boolean-valued variables. The protocol operates over an unreliable channel that can lose, duplicate or reorder messages. Moreover, the protocol's send and receivewindow sizes are not specified in advance; rather, they are represented as symbolic constants. The resulting system was automatically verified using our composite model checking approach, in concert witha conservative approximation technique. </abstract>
<note> This research is supported in part by ONR grant N00014-94-10228 and NSF CCR-9619808. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Mobile-End Transport Protocol:An Alternative to TCP/IP Over Wireless Links  </title>
<author> Kuang-Yeh Wang </author>
<affiliation> Department of Computer ScienceUniversity of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<email> kwang@cs.umd.edu </email>
<author> Satish K. Tripathi </author>
<affiliation> Bourns College of EngineeringUniversity of California </affiliation>
<address> Riverside, CA 92521-0425 </address>
<email> tripathi@engr.ucr.edu </email>
<abstract> AbstractUnlike wired links, wireless network bandwidth is highly limitedand the channel usually suffers from frequent and bursty loss dueto its vulnerability to various kinds of interference. At the sametime, the traditional TCP with its congestion control is well knownfor its poor performance over wireless links. This paper proposesa new protocol that (1) replaces TCP/IP over the wireless link bya simpler protocol with smaller headers, if the link is the last hopalong a data path, (2) shifts functions needed to communicate withan Internet host using TCP/IP from the mobile host to the basestation, so that the distinct wireless link is hidden from the outside Internet, and (3) exploits link-layer acknowledgments and re-transmissions to quickly recover losses over the wireless link. Oursimulation results show a substantial performance improvementachieved by the new protocol. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Ratio Rules:A New Paradigm for Fast, Quantifiable Data Mining </title>
<author> Flip Korn, Alexandros Labrinidis, Yannis Kotidis </author>
<affiliation> Department of Computer ScienceUniversity of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<email> fflip,labrinid,kotidisg@cs.umd.edu </email>
<author> Christos Faloutsos  </author>
<affiliation> Computer Science DepartmentCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<email> christos@cs.cmu.edu </email>
<abstract> AbstractAssociation Rule Mining algorithms operateon a data matrix (e.g., customers fi products)to derive association rules [2, 23]. We propose a new paradigm, namely, Ratio Rules,which are quantifiable in that we can measurethe "goodness" of a set of discovered rules.We propose to use the "guessing error" as ameasure of the "goodness", that is, the root-mean-square error of the reconstructed valuesof the cells of the given matrix, when we pretend that they are unknown. Another contribution is a novel method to guess missing/hidden values from the Ratio Rules thatour method derives. For example, if somebody bought $10 of milk and $3 of bread, ourrules can "guess" the amount spent on, say,butter. Thus, we can perform a variety of important tasks such as forecasting, answering"what-if" scenarios, detecting outliers, and visualizing the data. Moreover, we show how tocompute Ratio Rules in a single pass over thedataset with small memory requirements (afew small matrices), in contrast to traditionalassociation rule mining methods that requiremultiple passes and/or large memory. Experiments </abstract>
<note> Work performed while at the University of Maryland. Thisresearch was partially funded by the Institute for Systems Research (ISR), and by the National Science Foundation underGrants No. EEC-94-02384, IRI-9205273 and IRI-9625428.Permission to copy without fee all or part of this material isgranted provided that the copies are not made or distributed fordirect commercial advantage, the VLDB copyright notice andthe title of the publication and its date appear, and notice isgiven that copying is by permission of the Very Large Data BaseEndowment. To copy otherwise, or to republish, requires a feeand/or special permission from the Endowment.Proceedings of the 24th VLDB ConferenceNew York, USA, 1998 </note>
<abstract> on several real datasets (e.g., basketball and baseball statistics, biological data)demonstrate that the proposed method consistently achieves a "guessing error" of up to5 times less than the straightforward competitor. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in Proc. AAAI'97 </note>
<title> Dynamic Abstraction Planning </title>
<author> Robert P. Goldman, David J. Musliner, Kurt D. Krebsbach, Mark S. Boddy </author>
<affiliation> Automated Reasoning GroupHoneywell Technology Center </affiliation>
<address> 3660 Technology DriveMinneapolis, MN 55418 </address>
<email> fgoldman,musliner,krebsbac,boddyg@htc.honeywell.com </email>
<abstract> AbstractThis paper describes Dynamic Abstraction Planning(DAP), an abstraction planning technique that improves the efficiency of state-enumeration planners forreal-time embedded systems such as CIRCA. Abstraction is used to remove detail from the state representation, reducing both the size of the state space thatmust be explored to produce a plan and the size of theresulting plan. The intuition behind this approach issimple: in some situations, certain world features areimportant, while in other situations those same features are not important.By automatically selecting the appropriate level of abstraction at each step during the planning process,DAP can significantly reduce the size of the searchspace. Furthermore, the planning process can supplyinitial plans that preserve safety but might, on furtherrefinement, do a better job of goal achievement. DAPcan also terminate with an executable abstract plan,which may be much smaller than the correspondingplan expanded to precisely-defined states. Preliminaryresults show dramatic improvements in planning speedand scalability. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Appears in Working Notes of the NASA Workshop on Planning and Scheduling for SpaceOxnard, CA, October 1997 </note>
<title> CIRCA and the Cassini Saturn Orbit Insertion:Solving a Prepositioning Problem </title>
<author> David J. Musliner and Robert P. Goldman </author>
<affiliation> Automated Reasoning GroupHoneywell Technology Center </affiliation>
<address> 3660 Technology DriveMinneapolis, MN 55418 </address>
<email> fmusliner,goldmang@htc.honeywell.com </email>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Quantum Computing | A treatise </title>
<author> Prabhat Kumar </author>
<date> October 24, 1996 </date>
<abstract> AbstractQuantum computing has witnessed a surge of activity recently owingto some very exciting discoveries on both the theoretical and practicalfronts. In this overview, we sketch an account of the developments inthis scientifically intriguing field, starting in the early 80's when the firstquestions about the computability of quantum processes were raised,and which led to the formal definitions of a Quantum Computer and aQuantum Complexity Theory. Peter Shor's recent remarkable discovery of quantum algorithms to solve the problems of integer factoringand discrete log computing, which are believed to be extremely hard tosolve efficiently on classical computers, is a compelling demonstrationof the suspected superiority of quantum computing over the classicalmodel that is in use today. We discuss one of his algorithms and theimplications it has for classical cryptography. We discuss some of thelatest work in this field which has brought us yet closer to achieving aphysical realization of a quantum computer. Whenever it happens, if ithappens, it would be yet another revolution in the field of computing,and maybe the biggest one to date. </abstract>
<intro> 1 Birth of Quantum Computing </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Within the Letter of the Law: open-textured planning </title>
<author> Kathryn E. Sanders  </author>
<affiliation> Department of Computer ScienceUniversity of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<email> sanders@cs.umd.edu </email>
<abstract> AbstractMost case-based reasoning systems have used asingle "best" or "most similar" case as the basisfor a solution. For many problems, however,there is no single exact solution. Rather, thereis a range of acceptable answers. We use casesnot only as a basis for a solution, but also toindicate the boundaries within which a solutioncan be found. We solve problems by choosingsome point within those boundaries.In this paper, I discuss this use of cases withillustrations from chiron, a system I have implemented in the domain of personal incometax planning. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Comparison of Content-Based Image/Video RetrievalSystems </title>
<author> Fatma Ozcan </author>
<date> December 15, 1997 </date>
<abstract> AbstractRecently, content-based retrieval of images and video has become a hot research area. The reason for thisis the need for effective and efficient techniques, that meet user requirements, to access large volumes of digitalimages and video data. In [GR 95], previous approaches to content-based retrieval is said to have taken twodirections. In the first approach, image contents are modeled as a set of attributes extracted manually andmanaged within the framework of conventional database-management systems. The second approach dependson an integrated feature-extraction/object-recognition subsystem to overcome the limitations of attribute-based retrieval. However, it has been also stated that [GR 95] recent content-based image retrieval systemsrecognized the need for synergy between these two approaches.There has been numerous efforts to build content-based image retrieval systems. These include, Chabot[OS 95], SCORE [ATY 95, ATY 96], CONIVAS [AD 96], Photobook [PPS 93], CANDID [KCH 95], JACOB[ALDV 96, LA 96], VisualSEEk [SC 96] and QBIC [FSN+ 95]. In the first place, these systems differ in theirquerying capabilities. Images could be retrieved through the use of color, texture, sketch, shape, volume,spatial constraints, browsing, motion, text and domain concepts. Current approaches to content-based imageretrieval also differ in terms of image features extracted, their level of abstraction and the degree of domainindependence. In this paper, a comparative survey on these systems is conducted to figure out design tradeoffsand different approaches to content-based image retrieval. Furthermore, a taxonomy of content-based retrievalsystems, as well as a generic architecture, is provided. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Efficiently Supporting Ad Hoc Queries in Large Datasets of TimeSequences </title>
<author> Flip Korn  </author>
<affiliation> Dept. of Computer ScienceUniversity of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<email> flip@cs.umd.edu </email>
<author> H. V. Jagadish </author>
<affiliation> AT&amp;T Laboratories </affiliation>
<address> Florham Park, NJ 07932 </address>
<email> jag@research.att.com </email>
<author> Christos Faloutsos  </author>
<affiliation> Dept. of Computer Science andInst. for Systems ResearchUniversity of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<email> christos@cs.umd.edu </email>
<abstract> AbstractAd hoc querying is difficult on very large datasets, since itis usually not possible to have the entire dataset on disk.While compression can be used to decrease the size of thedataset, compressed data is notoriously difficult to indexor access.In this paper we consider a very large dataset comprising multiple distinct time sequences. Each point in thesequence is a numerical value. We show how to compresssuch a dataset into a format that supports ad hoc querying, provided that a small error can be tolerated when thedata is uncompressed. Experiments on large, real worlddatasets (AT&amp;T customer calling patterns) show that theproposed method achieves an average of less than 5% errorin any data value after compressing to a mere 2.5% of theoriginal space (i.e., a 40:1 compression ratio), with thesenumbers not very sensitive to dataset size. Experimentson aggregate queries achieved a 0.5% reconstruction errorwith a space requirement under 2%. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> How to Be a GoodGraduate StudentAdvisor </title>
<author> Marie desJardins </author>
<email> marie@erg.sri.com </email>
<date> March 1994 </date>
<abstract> AbstractThis paper attempts to raise some issues thatare important for graduate students to be successful and to get as much out of the processas possible, and for advisors who wish to helptheir students be successful. The intent is notto provide prescriptive advice no formulas forfinishing a thesis or twelve-step programs for becoming a better advisor are given but to raiseawareness on both sides of the advisor-studentrelationship as to what the expectations are andshould be for this relationship, what a graduatestudent should expect to accomplish, commonproblems, and where to go if the advisor is notforthcoming. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear, Computer Aided Design, 1995 or 1996 </note>
<title> GENERATING REDESIGN SUGGESTIONS TO REDUCE SETUP COST:A STEP TOWARDS AUTOMATED REDESIGN </title>
<author> Diganta Das </author>
<affiliation> Mechanical Engr. Dept. andInstitute for Systems Research,University of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<email> diganta@cs.umd.edu </email>
<author> Satyandra K. Gupta </author>
<affiliation> The Robotics InstituteCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<email> skgupta@isl1.ri.cmu.edu </email>
<author> Dana S. Nau </author>
<affiliation> Dept. of Computer Science andInstitute for Systems Research,University of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<email> nau@cs.umd.edu </email>
<abstract> AbstractAll mechanical designs pass through a series of formal and informal redesign steps, involving the analysis of functionality, manufacturability, cost and other life-cycle factors. Thespeed and efficacy of these steps has a major influence on the lead time of the product fromconceptualization to launching. In this paper we propose a methodology for automaticallygenerating redesign suggestions for reducing setup costs for machined parts.Given an interpretation of the design as a collection of machinable features, our approachis to generate alternate machining features by making geometric changes to the originalfeatures, and add them to the feature set of the original part to create an extended featureset. The designer may provide restrictions on the design indicating the type and extent ofmodifications allowed on certain faces and volumes, in which case all redesign suggestionsgenerated by our approach honor those restrictions.By taking combinations of features from the extended feature set generated above, we cangenerate modified versions of the original design that still satisfy the designer's intent. Byconsidering precedence constraints and approach directions for the machining operations aswell as simple fixturability constraints, we can estimate the setup time that will be requiredfor each design. Any modified design whose setup time is less than that of the originaldesign can be presented to the designer as a possible way to modify the original design. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Transport and Display Mechanisms For MultimediaConferencing Across Packet-Switched Networks * </title>
<author> K. Jeffay, D.L. Stone, F.D. Smith </author>
<affiliation> University of North Carolina at Chapel HillDepartment of Computer Science </affiliation>
<address> Chapel Hill, NC 27599-3175 USA </address>
<email> -jeffay,stone,smithfd-@cs.unc.edu </email>
<date> September, 1993 </date>
<abstract> Abstract: A transport protocol that supports real-time communication ofaudio/video frames across campus-area packet switched networks is presented.It is a best effort protocol that attempts to ameliorate the effect of jitter, loadvariation, and packet loss, to provide low latency, synchronized audio and videocommunications. This goal is realized through four transport and displaymechanisms, and a real-time implementation of these mechanisms thatintegrates operating system services ( e.g., scheduling and resource allocation,and device management) with network communication services ( e.g., transportprotocols), and with application code ( e.g., display routines). The fourmechanisms are: a facility for varying the synchronization between audio andvideo to achieve continuous audio in the face of jitter, a network congestionmonitoring mechanism that is used to control audio/video latency, a queueingmechanism at the sender that is used to maximize frame throughput withoutunnecessarily increasing latency, and a forward error correction mechanism fortransmitting audio frames multiple times to ameliorate the effects of packet lossin the network. The effectiveness of these techniques is demonstrated bymeasuring the performance of the protocol when transmitting audio and videoacross congested networks. </abstract>
<note> Published in: Computer Networks and ISDN Systems,Vol. 26, No. 10, (July 1994) pp. 1281-1304.* This work supported in parts by grants from the National Science Foundation (numbers CCR-9110938 and ICI9015443), and by the Digital Equipment Corporation and the IBM Corporation. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in 1996 ACM SIGMETRICS (Extended Version: UMass TR 95-98, Nov. 1995) </note>
<title> Supporting Stored Video: Reducing Rate Variability and End-to-End ResourceRequirements through Optimal Smoothing  </title>
<author> James D. Salehi, Zhi-Li Zhang, James F. Kurose, and Don Towsley </author>
<affiliation> Department of Computer Science, University of Massachusetts, </affiliation>
 <address> Amherst MA 01003, USA </address>
<abstract> AbstractVBR compressed video is known to exhibit significant, multiple-time-scale bit rate variability. In this paper, we consider the transmission of stored video from a server to a client across a high speednetwork, and explore how the client buffer space can be used mosteffectively toward reducing the variability of the transmitted bitrate.We present two basic results. First, we present an optimalsmoothing algorithm for achieving the greatest possible reductionin rate variability when transmitting stored video to a client withgiven buffer size. We provide a formal proof of optimality, anddemonstrate the performance of the algorithm on a set of longMPEG-1 encoded video traces. Second, we evaluate the impactof optimal smoothing on the network resources needed for videotransport, under two network service models: Deterministic Guar-anteed service [1, 11] and Renegotiated CBR (RCBR) service [9, 8].Under both models, we find the impact of optimal smoothing to bedramatic. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Alleviating Priority Inversion and Non-determinismin Real-time CORBA ORB Core Architectures </title>
<author> Douglas C. Schmidt, Sumedh Mungee, and Aniruddha Gokhale </author>
<email> fschmidt,sumedh,gokhaleg@cs.wustl.edu </email>
<affiliation> Department of Computer Science, Washington University </affiliation>
<address> St. Louis, MO 63130, USA  </address>
<note> This paper has been submitted to the 4 th IEEE Real-timeTechnology and Applications Symposium (RTAS), Denver,Colorado, June 3-5, 1998. </note>
<abstract> AbstractThere is increasing demand to extend CORBA to supportapplications with stringent real-time requirements. However, conventional CORBA Object Request Brokers (ORBs)exhibit substantial priority inversion and non-determinism,which makes them unsuitable for applications with deterministic real-time requirements. This paper focuses on softwarearchitectures that help to alleviate priority inversion and non-determinism in real-time CORBA ORBs. It also illustrates empirically why conventional ORBs do not yet support real-timequality of service. </abstract>
<keyword> Keywords: Real-time CORBA Object Request Broker, QoS-enabled OO Middleware, Performance Measurements </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Reducing False Sharing on Shared Memory Multiprocessorsthrough Compile Time Data Transformations </title>
<author> Tor E. Jeremiassen </author>
<affiliation> AT&amp;T Bell Laboratories  </affiliation>
<address> 600 Mountain Ave.Murray Hill, New Jersey 07974 </address>
<email> tor@research.att.com </email>
<author> Susan J. Eggers </author>
<affiliation> Department of Computer Science and EngineeringUniversity of Washington </affiliation>
<address> Seattle, Washington 98195 </address>
<email> eggers@cs.washington.edu </email>
<abstract> AbstractWe have developed compiler algorithms that analyze explicitly parallel programs and restructure their shared data toreduce the number of false sharing misses. The algorithmsanalyze per-process shared data accesses, pinpoint the datastructures that are susceptible to false sharing and choosean appropriate transformation to reduce it. The transformations either group data that is accessed by the same processor or separate individual data items that are shared.This paper evaluates that technique. We show throughsimulation that our analysis successfully identifies the datastructures that are responsible for most false sharing misses,and then transforms them without unduly decreasing spatiallocality. The reduction in false sharing positively impactsboth execution time and program scalability when executedon a KSR2. Both factors combine to increase the maximumachievable speedup for all programs, more than doublingit for several. Despite being able to only approximate actual inter-processor memory accesses, the compiler-directedtransformations always outperform programmer efforts toeliminate false sharing. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in Proceedings of the Twenty Third ACM SIGPLAN-SIGACTSymposium on Principles of Programming Languages, St. PetersburgBeach, Florida, January 21-24, 1996. c fl1996 ACM (see notice below). </note>
<title> Is it a Tree, a DAG, or a Cyclic Graph?A Shape Analysis for Heap-Directed Pointers in C </title>
<author> Rakesh Ghiya and Laurie J. Hendren </author>
<affiliation> School of Computer Science, McGill University </affiliation>
<address> Montreal, Quebec, CANADA H3A 2A7 </address>
<email> fghiya,hendreng@cs.mcgill.ca </email>
<abstract> AbstractThis paper reports on the design and implementation of a practical shape analysis for C. The purpose of the analysis is to aid in the disambiguation ofheap-allocated data structures by estimating the shape(Tree, DAG, or Cyclic Graph) of the data structure accessible from each heap-directed pointer. This shapeinformation can be used to improve dependence testing and in parallelization, and to guide the choice ofmore complex heap analyses.The method has been implemented as a context-sensitive interprocedural analysis in the McCAT compiler. Experimental results and observations are givenfor 16 benchmark programs. These results show thatthe analysis gives accurate and useful results for animportant group of applications. </abstract>
<intro> 1 Introduction and Related </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Compiler Support for Maintaining CacheCoherence Using Data Prefetching ? </title>
<note> (Extended Abstract) </note>
<author> Hock-Beng Lim 1 , Lynn Choi 2 and Pen-Chung Yew 3 </author>
<affiliation> 1 Center for Supercomputing R &amp; D, Univ. of Illinois, </affiliation>
 <address> Urbana, IL 61801 </address>
<affiliation> 2 Microprocessor Group, Intel Corporation, </affiliation>
 <address> Santa Clara, CA 95095 </address>
<affiliation> 3 Dept. of Computer Science, Univ. of Minnesota, </affiliation>
 <address> Minneapolis, MN 55455 </address>
<intro> 1 Introduction and Motivation </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> INTEGRATING FINE-GRAINED MESSAGE PASSING IN CACHE COHERENTSHARED MEMORY MULTIPROCESSORS (*) </title>
<author> David K. Poulsen </author>
<affiliation> Kuck and Associates, Inc. </affiliation>
<address> 1906 Fox DriveChampaign, IL 61821 </address>
<phone> 217-356-2288 </phone><email> poulsen@kai.com </email>
<author> andPen-Chung Yew </author>
<affiliation> Department of Computer ScienceUniversity of Minnesota </affiliation>
<address> 4-192 EE/CS Building200 Union Street SEMinneapolis, MN 55455 </address>
<email> yew@cs.umn.edu </email>
<note> (*) This work was supported in part by the National Science Foundation under grant nos. NSF MIP 93-07910 andNSF MIP 89-20891, the Department of Energy under grant no. DOE DE FG02-85ER25001, the National SecurityAgency, and an IBM Resident Study Fellowship.This work was performed while the authors were with the Center for Supercomputing Research and Development,University of Illinois at Urbana-Champaign, Urbana, IL 61801. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Constraint-Based Animations </title>
<author> Allan Heydon Greg Nelson </author>
<affiliation> Digital Systems Research Center </affiliation>
<address> 130 Lytton Ave., Palo Alto, CA 94301 </address>
<email> fheydon,gnelsong@pa.dec.com </email>
<note> Copyright c fl1995, Digital Equipment Corporation. All right reserved. </note>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Dynamic Resource Management for ContinuousMedia Traffic over ATM Networks </title>
<author> Rose P. Tsang 1 , Paisal KeattithananantTaisheng Chang 3 , Jenwei Hsieh 3 , David H.C. Du 2 </author>
<affiliation> Distributed Multimedia Center 3Computer Science DepartmentUniversity of Minnesota </affiliation>
<address> Minneapolis, MN 55455 </address>
<abstract> AbstractReal-time continuous media traffic, such as digital video and audio, is expectedto comprise a large percentage of the network load on future high speed packetswitch networks such as ATM. A major feature which distinguishes high speednetworks from traditional slower speed networks is the large amount of data thenetwork must manage. For efficient network usage, traffic control mechanisms areessential. Currently, most mechanisms for traffic control (such as flow control)have centered on the support of Available Bit Rate (ABR), i.e., non real-time,traffic. With regard to ATM, for ABR traffic, two major types of schemes whichhave been proposed are rate-control and credit-control schemes. Neither of theseschemes are directly applicable to Real-time Variable Bit Rate (VBR) traffic suchas continuous media traffic. Traffic control for continuous media traffic is an inherently difficult problem due to the time-sensitive nature of the traffic and itsunpredictable burstiness. In this study, we present a scheme which controls traffic by dynamically allocating/de-allocating resources among competing VCs basedupon their real-time requirements. This scheme incorporates a form of rate-control,real-time burst-level scheduling and link-link flow control. We show analytically potential performance improvements of our rate-control scheme and present a schemefor buffer dimensioning. We also present simulation results of our schemes and discuss the tradeoffs inherent in maintaining high network utilization and statisticallyguaranteeing many users' Quality of Service. </abstract>
<keyword> Keywords: Asynchronous Transfer Mode (ATM), dynamic traffic control, resource management, rate control, Real-time Variable Bit Rate traffic, continuous media traffic. </keyword>
<note> 1 This work is supported in part by U S WEST Communications. </note>
</NEW_HEADER>
<NEW_HEADER>
<note> A short version of this paper appears in Supercomputing 1996 The serial algorithms described in this paper are implemented by the`METIS: Unstructured Graph Partitioning and Sparse Matrix Ordering System'.METIS is available on WWW at URL: </note>
 <web> http://www.cs.umn.edu/karypis/metis/metis.html </web><title> Parallel Multilevel k -way Partitioning Scheme forIrregular Graphs </title>
<author> George Karypis and Vipin Kumar </author>
<affiliation> University of Minnesota, Department of Computer Science </affiliation>
<address> Minneapolis, MN 55455, </address>
 <pubnum> Technical Report: 96-036 </pubnum>
<email> fkarypis, kumarg@cs.umn.edu </email>
<note> Last updated on October 24, 1996 at 9:02am </note>
<abstract> AbstractIn this paper we present a parallel formulation of a multilevel k-way graph partitioning algorithm. The multilevelk-way partitioning algorithm reduces the size of the graph by collapsing vertices and edges (coarsening phase), findsa k-way partitioning of the smaller graph, and then it constructs a k-way partitioning for the original graph by projecting and refining the partition to successively finer graphs (uncoarsening phase). A key innovative feature of ourparallel formulation is that it utilizes graph coloring to effectively parallelize both the coarsening and the refinementduring the uncoarsening phase. Our algorithm is able to achieve a high degree of concurrency, while maintaining thehigh quality partitions produced by the serial algorithm. We test our scheme on a large number of graphs from finiteelement methods, and transportation domains. For graphs with a million vertices, our parallel formulation produceshigh quality 128-way partitions on 128 processors in a little over two seconds, on Cray T3D. Thus our parallel algorithm makes it feasible to perform frequent dynamic graph partition in adaptive computations without compromisingquality. </abstract>
<keyword> Keywords: Parallel Graph Partitioning, Multilevel Partitioning Methods, Spectral Partitioning Methods,Kernighan-Lin Heuristic, Parallel Sparse Matrix Algorithms. </keyword>
<note> This work was supported by NSF CCR-9423082 and by Army Research Office contract DA/DAAH04-95-1-0538, and by Army High Performance Computing Research Center under the auspices of the Department of the Army, Army Research Laboratory cooperative agreementnumber DAAH04-95-2-0003/contract number DAAH04-95-C-0008, the content of which does not necessarily reflect the position or the policy of the government, and no official endorsement should be inferred. Access to computing facilities was provided by AHPCRC, MinnesotaSupercomputer Institute, Cray Research Inc, and by the Pittsburgh Supercomputing Center. Related papers are available via WWW at URL:http://www.cs.umn.edu/karypis </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Optimizing Multi-Join Queries in Parallel Relational Databases </title>
<author> Jaideep SrivastavaGary Elsesser </author>
<affiliation> Computer Science DepartmentUniversity of Minnesota </affiliation>
<address> Minneapolis, MN 55455 </address>
<abstract> AbstractQuery optimization for parallel machines needs toconsider machine architecture, processor and memoryresources available, and different types of parallelism,making the search space much larger than the sequential case. In this paper our aim is to determine a planthat makes the execution of an individual query veryfast, making minimizing parallel execution time theright objective. This creates the following circular dependence: a plan tree is needed for effective resourceassignment, which is needed to estimate the parallelexecution time, and this is needed for the cost-basedsearch for a good plan tree. In this paper we proposea new search heuristic that breaks the cycle by constructing the plan tree layer by layer in a bottom-upmanner. To select nodes at the next level, the lowerand upper bounds on the execution time for plans consistent with the decisions made so far are estimatedand are used to guide the search. A query plan representation for intra- and inter-operator parallelism,pipelining, and processor and memory assignment isproposed. Also proposed is a new approach to estimating the parallel execution time of a plan that considerssum and max of operators working sequentially andin parallel, respectively. The results obtained from aprototype optimizer are presented. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> CS/TR-92-80 </pubnum>
<title> The COOL architecture and abstractions for object-orienteddistributed operating systems </title>
<author> Rodger Lea, Christian Jacquemot </author>
<note> approved by:distribution: COOL </note>
<abstract> abstract: Building distributed operating systems benefits from the micro-kernel approach by allowing better support for modularization. However, we believethat we need to take this support a step further. A more modular, or objectoriented approach is needed if we wish to cross the barrier of complexity thatis holding back distributed operating system development. The Chorus Object Oriented Layer (COOL) is a layer built above the Chorus micro-kerneldesigned to extend the micro-kernel abstractions with support for object oriented systems. COOL v2, the second iteration of this layer provides genericsupport for clusters of objects, in a distributed virtual memory model. It isbuilt as a layered system where the lowest layer support only clusters and theupper layers support objects. </abstract>
<note> c Chorus systemes, 1992c Chorus systemes, 1992 September 21, 1992 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Using PVS to Analyze Hierarchical State-Based Requirements forCompleteness and Consistency  </title>
<author> Mats P.E. Heimdahl </author>
<affiliation> University of Minnesota, Institute of TechnologyDepartment of Computer Science, </affiliation>
 <address> 4-192 EE/CS Bldg.Minneapolis, MN 55455 </address>
<email> heimdahl@cs.umn.edu </email>
<author> Barbara J. Czerny </author>
<affiliation> Department of Computer Science, </affiliation>
 <address> A-714 Wells Hall </address>
<affiliation> Michigan State University </affiliation>
<address> East Lansing, MI 48824 </address>
<email> czerny@cps.msu.edu </email>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> AN ALGORITHM FOR GENERATING EXECUTABLEASSERTIONS FOR FAULT TOLERANCE  </title>
<author> Martina Schollmeyer, Hanan Lutfiyya and Bruce McMillin </author>
<pubnum> CSC-92-01 </pubnum>
<date> March 21, 1992 </date>
<affiliation> Department of Computer ScienceUniversity of Missouri at Rolla </affiliation>
<address> Rolla, Missouri 65401 </address>
<note> This work was supported in part by the National Science Foundation under Grant Numbers MIP-8909749 and CDA-8820714, and in part by the AMOCO Faculty DevelopmentProgram. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> To be presented at the 17th IEEE Real-Time Systems Symposium, December 1996. </note>
<title> A Framework for Implementing Objects and Scheduling Tasks in Lock-FreeReal-Time Systems  </title>
<author> James H. Anderson and Srikanth Ramamurthy </author>
<affiliation> Department of Computer Science, University of North Carolina at Chapel Hill </affiliation>
<abstract> AbstractWe present an integrated framework for developing real-time systems in which lock-free algorithms are employed toimplement shared objects. There are two key objectives ofour work. The first is to enable functionality for object sharing in lock-free real-time systems that is comparable to thatin lock-based systems. Our main contribution toward thisobjective is an efficient approach for implementing multi-object lock-free operations and transactions. A second keyobjective of our work is to improve upon previously proposedscheduling conditions for tasks that share lock-free objects.When developing such conditions, the key issue is to boundthe cost of operation interferences. We present a generalapproach for doing this, based on linear programming. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Universal Constructions for Large Objects </title>
<author> James H. Anderson and Mark Moir </author>
<affiliation> Dept. of Computer Science, University of North Carolina at Chapel Hill </affiliation>
<abstract> AbstractWe present lock-free and wait-free universal constructions for implementing largeshared objects. Most previous universal constructions require processes to copy theentire object state, which is impractical for large objects. Previous attempts toaddress this problem require programmers to explicitly fragment large objects intosmaller, more manageable pieces, paying particular attention to how such pieces arecopied. In contrast, our constructions are designed to largely shield programmersfrom this fragmentation. Furthermore, for many objects, our constructions resultin lower copying overhead than previous ones.Fragmentation is achieved in our constructions through the use of load-linked,store-conditional, and validate operations on a "large" multi-word shared variable.Before presenting our constructions, we show that these operations can be efficientlyimplemented from similar one-word primitives. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> View-Dependent Simplification Of Arbitrary Polygonal Environments </title>
<author> David Luebke, Carl Erikson </author>
<affiliation> Department of Computer ScienceUniversity of North Carolina at Chapel Hill </affiliation>
<abstract> 1. ABSTRACTHierarchical dynamic simplification (HDS) is a new approach tothe problem of simplifying arbitrary polygonal environments.HDS operates dynamically, retessellating the scene continuouslyas the users viewing position shifts, and adaptively, processingthe entire database without first decomposing the environmentinto individual objects. The resulting system allows real-timedisplay of very complex polygonal CAD models consisting ofthousands of parts and hundreds of thousands of polygons. HDSsupports various preprocessing algorithms and various runtimecriteria, providing a general framework for dynamic view-dependent simplification.Briefly, HDS works by clustering vertices together in ahierarchical fashion. The simplification process continuouslyqueries this hierarchy to generate a scene containing only thosepolygons that are important from the current viewpoint. Whenthe volume of space associated with a vertex cluster occupies lessthan a userspecified amount of the screen, all vertices withinthat cluster are collapsed together and degenerate polygonsfiltered out. HDS maintains an active list of visible polygons forrendering. Since frame-to-frame movements typically involvesmall changes in viewpoint, and therefore modify the active listby only a few polygons, the method takes advantage of temporalcoherence for greater speed.CR Categories: I.3.5 [Computer Graphics]: Computational Geometry andObject Modeling - surfaces and object representations.Additional Keywords: polygonal simplification, level of detail, viewdependent rendering. </abstract>
<intro> 2. INTRODUCTION </intro> 
</NEW_HEADER>
<NEW_HEADER>
<title> Modeling and Parameter Estimation of the Human Index Finger </title>
<author> Robert N. Rohling and John M. Hollerbach </author>
<affiliation> Biorobotics Laboratory, McGill University </affiliation>
<address> 3775 University St., Montreal, Quebec H3A 2B4 </address>
<abstract> AbstractPrecise teleoperation of dextrous robotic hands byhand masters requires an accurate human hand model.A kinematic model of a human index finger is developed as an example for human hand modeling. Theparameters of the model are determined by open-loopkinematic calibration. Singular value decomposition isused as a tool for analyzing the kinematic model andthe identification process. Accurate and reliable results are obtained only when the numerical conditionis minimized through parameter scaling, model reduction and pose set selection. The identified kinematicparameters show the kinematic model and calibrationprocedure have an accuracy on the order of a few millimeters. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Dossier Driven Persistent Objects Facility </title>
<author> Robert Mecklenburg, Charles Clark, Gary Lindstrom and Benny Yih </author>
<affiliation> University of Utah Center for Software ScienceDepartment of Computer Science </affiliation>
<address> Salt Lake City, UT 84112 </address>
<email> E-mail: fmecklen,clark,gary,yihg@cs.utah.edu </email>
<abstract> AbstractWe describe the design and implementation of a persistent object storage facilitybased on a dossier driven approach. Objects are characterized by dossiers which describe both their language defined and "extra-linguistic" properties. These dossiers aregenerated by a C++ preprocessor in concert with an augmented, but completely C++compatible, class description language. The design places very few burdens on the application programmer and can be used without altering the data member layout of application objects or inheriting from special classes. The storage format is kept simple to allowthe use of a variety of data storage backends. In addition, these dossiers can be used toimplement (or augment) a run-time typing facility compatible with the proposed ANSIC++ standard. Finally, by providing a generic object to byte stream conversion the persistent object facility can also be used in conjunction with an interprocess communicationfacility to provide object-level communication between processes. 1 </abstract>
<intro> 1 Motivation </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Next Frontier: Interactive and Closed Loop PerformanceSteering  </title>
<author> Daniel A. Reed Christopher L. ElfordTara M. Madhyastha Evgenia SmirniStephen E. Lamm </author>
<email> freed,elford,tara,esmirni,slammg@cs.uiuc.edu </email>
<affiliation> Department of Computer ScienceUniversity of Illinois </affiliation>
<address> Urbana, Illinois 61801 </address>
<abstract> AbstractSoftware for a growing number of problem domainshas complex, time varying behavior and unpredictableresource demands (e.g., WWW servers and parallel input/output systems). While current performance analysis tools provide insights into application dynamicsand the causes of poor performance, with a posteriori analysis one cannot adapt to temporally varyingapplication resource demands and system responses.We believe that the solution to this performance optimization conundrum is integration of dynamic performance instrumentation and on-the-fly performancedata reduction with real-time adaptive control mechanisms that select and configure resource managementalgorithms automatically, based on observed application behavior, or interactively, through high-modalityvirtual environments. We motivate this belief by firstdescribing our experiences with performance analysis tools, input/output characterization, and WWWserver analysis, and then sketching the design of interactive and closed loop adaptive control systems. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Compilation of Constraint Systems toProcedural Parallel Programs </title>
<author> Ajita John and J. C. Browne </author>
<affiliation> Dept. of Computer SciencesUniversity of Texas, </affiliation>
<address>  Austin, TX 78712 </address>
<email> fajohn,browneg@cs.utexas.edu </email>
<abstract> Abstract. This paper describes the first results from research 1 on thecompilation of constraint systems into task level parallel programs in aprocedural language. This is the only research, of which we are aware,which attempts to generate efficient parallel programs for numericalcomputations from constraint systems. Computations are expressed asconstraint systems. A dependence graph is derived from the constraintsystem and a set of input variables. The dependence graph, which exploits the parallelism in the constraints, is mapped to the target language CODE, which represents parallel computation structures as generalized dependence graphs. Finally, parallel C programs are generated.The granularity of the derived dependence graphs depends upon thecomplexity of the operations represented in the type system of the constraint specification language. To extract parallel programs of appropriate granularity, the following features have been included: (i) modularity, (ii) operations over structured types as primitives, (iii) definitionof sequential C functions. A prototype of the compiler has been implemented. The execution environment or software architecture is specifiedseparately from the constraint system. The domain of matrix computations has been targeted for applications. Some examples have beenprogrammed. Initial results are very encouraging. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Optimal Wire-Sizing Formula Under the Elmore Delay Model </title>
<author> Chung-Ping Chen, Yao-Ping Chen, and D. F. Wong </author>
<affiliation> Department of Computer Sciences, University of Texas, </affiliation>
 <address> Austin, Texas 78712 </address>
<abstract> AbstractIn this paper, we consider non-uniform wire-sizing. Given awire segment of length L, let f(x) be the width of the wireat position x, 0 x L. We show that the optimal wire-sizing function that minimizes the Elmore delay through thewire is f(x) = ae bx , where a &amp;gt; 0 and b &amp;gt; 0 are constantsthat can be computed in O(1) time. In the case where lowerbound (L &amp;gt; 0) and upper bound (U &amp;gt; 0) on the wire widthsare given, we show that the optimal wire-sizing function f(x)is a truncated version of ae bx that can also be determined inO(1) time. Our wire-sizing formula can be iteratively appliedto optimally size the wire segments in a routing tree. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> In Proceedings of the Eighth International Workshopon Qualitative Physics about Physical Systems (QR-94)Nara, Japan, 1994.  </note>
<title> Model Decomposition and Simulation </title>
<author> Daniel J. Clancy and Benjamin Kuipers </author>
<affiliation> Department of Computer SciencesUniversity of Texas at Austin </affiliation>
<address> Austin, Texas 78712 </address>
<email> clancy@cs.utexas.edu and kuipers@cs.utexas.edu </email>
<abstract> AbstractQualitative reasoning uses incomplete knowledge to compute a description of the possible behaviors for dynamicsystems. For complex systems containing a large numberof variables and constraints, the simulation frequently isintractable or results in a large, incomprehensible behavioral description. Abstraction and aggregation techniques are required during the simulation to eliminateirrelevant details and highlight the important characteristics of the behavior. The total temporal ordering ofunrelated events provided by a traditional state-basedqualitative representation is one such irrelevant distinction. Model decomposition and simulation addresses thisproblem.Model decomposition uses a causal analysis of the modelto partition the variables into tightly connected components. The components are simulated separately inthe order dictated by the causal analysis beginning withcausally upstream components. Information from thesimulation of causally upstream components is used toconstrain the behavior of downstream components. If afeedback loop exists between components or a set of components are acausally related, then a concurrent simulation is performed for these components. A truth maintenance system is used to record and retract assumptionsmade during this concurrent simulation.Model decomposition provides a general architecturewhich separates the method of simulation from the modeldecomposition algorithm. This architecture can be usedto introduce alternative abstraction techniques to eliminate other irrelevant distinctions. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Programming the Web:An Application-oriented Language for Hypermedia Services </title>
<author> David A. Ladd J. Christopher Ramming </author>
<email> ladd@research.att.com jcr@research.att.com </email>
<affiliation> AT&amp;T Bell Laboratories </affiliation>
<date> October 9, 1995 </date>
<abstract> AbstractMAWL is an application language for programming interactive services in the context of the WorldwideWeb. The language is small, because no construct was introduced without compelling justification; as withyacc [8], general-purpose computation is done in a host language. MAWL offers conveniences such as controlabstraction, persistent state management, synchronization, and shared memory. In addition, the MAWLcompiler performs static checking designed to prevent common Web programming errors. In this paper wediscuss the design and engineering of MAWL.We describe the problems MAWL is intended to solve, and then discuss our design choices in the contextof our general language design philosophy, We also include an appendix of commentary on several shortMAWL programs. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Stability and Chaos in an Inertial TwoNeuron System </title>
<author> Diek W. Wheeler 1 and W. C. Schieve </author>
<affiliation> Ilya Prigogine Center for Studies in Statistical Mechanics andComplex SystemsandPhysics Department, The University of Texas, </affiliation>
<address> Austin, TX 78712 </address>
<abstract> Abstract.Inertia is added to a continuous-time, Hopfield [1] effective-neuron system.We explore the effects on the stability of the fixed points of the system. A twoneuron system with one or two inertial terms added is shown to exhibit chaos.The chaos is confirmed by Lyapunov exponents, power spectra, and phase spaceplots. </abstract>
<intro> INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> ON UNAPPROXIMABLE VERSIONS OF NP-COMPLETEPROBLEMS  </title>
<author> DAVID ZUCKERMAN  </author>
<abstract> Abstract.We prove that all of Karp's 21 original NP -complete problems have a version that's hard toapproximate. These versions are obtained from the original problems by adding essentially the same,simple constraint. We further show that these problems are absurdly hard to approximate. In fact, nopolynomial-time algorithm can even approximate log (k) of the magnitude of these problems to withinany constant factor, where log (k) denotes the logarithm iterated k times, unless N P is recognized byslightly superpolynomial randomized machines. We use the same technique to improve the constant* such that MAX CLIQUE is hard to approximate to within a factor of n * . Finally, we show that itis even harder to approximate two counting problems: counting the number of satisfying assignmentsto a monotone 2-SAT formula and computing the permanent of -1,0,1 matrices. </abstract>
<keyword> Key words. NP-complete, unapproximable, randomized reduction, clique, counting problems,permanent, 2SAT </keyword>
<note> AMS subject classifications. 68Q15, 68Q25, 68Q99 </note>
<intro> 1. Introduction. </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Recursive Functions of SymbolicExpressions and Their Computation byMachine, Part I </title>
<author> John McCarthy, </author>
 <affiliation> Massachusetts Institute of Technology, </affiliation>
 <address> Cambridge, Mass.  </address>
<date> April 1960 </date>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Frangipani: A Scalable Distributed File System </title>
<author> Chandramohan A. ThekkathTimothy MannEdward K. Lee </author>
<affiliation> Systems Research CenterDigital Equipment Corporation </affiliation>
<address> 130 Lytton Ave, Palo Alto, CA 94301 </address>
<abstract> AbstractThe ideal distributed file system would provide all its users with coherent, shared access to the same set of files,yet would be arbitrarilyscalable to provide more storage space and higher performance toa growing user community. It would be highly available in spite ofcomponent failures. It would require minimal human administration, and administration would not become more complex as morecomponents were added.Frangipani is a new file system that approximates this ideal, yetwas relatively easy to build because of its two-layer structure. Thelower layer is Petal (described in an earlier paper), a distributedstorage service that provides incrementally scalable, highly available, automatically managed virtual disks. In the upper layer,multiple machines run the same Frangipani file system code on topof a shared Petal virtual disk, using a distributed lock service toensure coherence.Frangipani is meant to run in a cluster of machines that are undera common administration and can communicate securely. Thus themachines trust one another and the shared virtual disk approach ispractical. Of course, a Frangipani file system can be exported tountrusted machines using ordinary network file access protocols.We have implemented Frangipani on a collection of Alphasrunning DIGITAL Unix 4.0. Initial measurements indicate thatFrangipani has excellent single-server performance and scales wellas servers are added. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Cost of Recovery in Message Logging Protocols </title>
<author> Sriram Rao, Lorenzo Alvisi, and Harrick M. Vin </author>
<affiliation> Department of Computer SciencesThe University of Texas at Austin </affiliation>
<address> Taylor Hall 2.124, Austin, Texas 78712-1188, USA </address>
<email> E-mail: fsriram,lorenzo,ving@cs.utexas.edu, </email>
 <phone> Telephone: (512) 471-9792, Fax: (512) 471-8885 </phone><web> URL: http://www.cs.utexas.edu/users/fsriram,lorenzo,ving </web><abstract> AbstractMessage logging is a popular technique for building low-overhead protocols that tolerateprocess crash failures. Past research in message logging has focused on studying the relativeoverhead imposed by pessimistic, optimistic, and causal protocols during failure-free executions. In this paper, we give the first experimental evaluation of the performance of theseprotocols during recovery. We discover that, if a single failure is to be tolerated, pessimisticand causal protocols perform best, because they avoid rollbacks of correct processes. Formultiple failures, however, the dominant factor in determining performance becomes wherethe recovery information is logged (i.e. at the sender, at the receiver, or replicated at asubset of the processes in the system) rather than when this information is logged (i.e. iflogging is synchronous or asynchronous). From our results, we distil a few lessons that canguide the design of message-logging protocols that combine low-overhead during failure-freeexecutions with fast recovery. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Constructing Scripts from Components:Working Note 6 </title>
<author> Peter Clark and Bruce Porter </author>
<affiliation> Dept. CS, UT Austin </affiliation>
<email> fpclark,porterg@cs.utexas.edu </email>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Design Goals for ACL2 </title>
<author> Matt Kaufmann and J Strother Moore </author>
<pubnum> Technical Report 101 </pubnum>
<date> August, 1994 </date>
<affiliation> Computational Logic, Inc. </affiliation>
<address> 1717 West Sixth Street, Suite 290Austin, Texas 78703-4776 </address>
<phone> TEL: +1 512 322 9951 </phone><email> EMAIL: kaufmann@cli.com and moore@cli.com </email>
<note> This work was supported in part at Computational Logic, Inc., by the DefenseAdvanced Research Projects Agency, ARPA Order 7406. The views and conclusions contained in this document are those of the author(s) and should notbe interpreted as representing the official policies, either expressed or implied,of Computational Logic, Inc., the Defense Advanced Research Projects Agencyor the U.S. Government. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Broadcasting on Meshes with Worm-Hole Routing </title>
<author> Michael Barnett </author>
<affiliation> Department of Computer ScienceUniversity of Idaho </affiliation>
<address> Moscow, Idaho 83844-1010 </address>
<email> mbarnett@cs.uidaho.edu </email>
<author> David G. Payne </author>
<affiliation> Supercomputer Systems DivisionIntel Corporation </affiliation>
<address> 15201 N.W. Greenbrier PkwyBeaverton, Oregon 97006 </address>
<email> payne@ssd.intel.com </email>
<author> Robert A. van de Geijn </author>
<affiliation> Department of Computer SciencesThe University of Texas at Austin </affiliation>
<address> Austin, Texas 78712-1188 </address>
<email> rvdg@cs.utexas.edu </email>
<author> Jerrell Watts </author>
<affiliation> Scalable Concurrent Programming LaboratoryCalifornia Institute of Technology </affiliation>
<address> Pasadena, California 91125 </address>
<email> jwatts@scp.caltech.edu </email>
<note> Original Version: November 2, 1993Revised Version: September 21, 1994 </note>
<abstract> AbstractWe address the problem of broadcasting on mesh architectures with arbitrary (non-power-two) dimensions. It is assumed that such mesh architectures employ cut-through or worm-hole routing. Theprimary focus is on avoiding network conflicts in the various proposed algorithms. We give algorithmsfor performing a conflict-free minimum-spanning tree broadcast, a pipelined algorithm that is similar toHo and Johnsson's EDST algorithm for hypercubes, and a novel scatter-collect approach that is a naturalchoice for communication libraries due to its simplicity. Results obtained on the Intel Paragon systemare included. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Towards Usable and LeanParallel Linear Algebra Libraries  </title>
<author> Almadena Chtchelkanova Carter EdwardsJohn Gunnels Greg MorrowJames Overfelt Robert van de Geijn  </author>
<affiliation> Department of Computer SciencesandTexas Institute for Computational and Applied MathematicsThe University of Texas at Austin </affiliation>
<address> Austin, Texas 78712 </address>
<date> May 1, 1996 </date>
<abstract> AbstractIn this paper, we introduce a new parallel library effort, as part of the PLAPACKproject, that attempts to address discrepencies between the needs of applications andparallel libraries. A number of contributions are made, including a new approachto matrix distribution, new insights into layering parallel linear algebra libraries, andthe application of "object based" programming techniques which have recently becomepopular for (parallel) scientific libraries. We present an overview of a prototype library,the SL Library, which incorporates these ideas. Preliminary performance data showsthis more application-centric approach to libraries does not necessarily adversely impactperformance, compared to more traditional approaches. </abstract>
<note> This project is sponsored in part by the Office of Naval Research under Contract N00014-95-1-0401,the NASA High Performance Computing and Communications Program's Earth and Space Sciences Projectunder NRA Grant NAG5-2497, the PRISM project under ARPA grant P-95006.Corresponding and presenting author. </note>
 <affiliation> Dept. of Computer Sciences, The University of Texas at Austin, </affiliation>
<address> Austin, TX 78712, </address>
 (<phone> 512) 471-9720 (Office), (512) 471-8885 (Fax), </phone> <email> rvdg@cs.utexas.edu. </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Anatomy of a Parallel Out-of-Core Dense Linear Solver </title>
<author> Kenneth Klimkowski </author>
<affiliation> Texas Institute for Computationaland Applied MathematicsThe University of Texas at Austin </affiliation>
<address> Austin, Texas 78712 </address>
<email> ken@ticam.utexas.edu </email>
<author> Robert A. van de Geijn </author>
<affiliation> Department of Computer SciencesThe University of Texas at Austin </affiliation>
<address> Austin, Texas 78712 </address>
<email> rvdg@cs.utexas.edu </email>
<abstract> Abstract In this paper, we describe the designand implementation of the Platform IndependentParallel Solver (PIPSolver) package for the out-of-core (OOC) solution of complex dense linear systems. Our approach is unique in that it allows essentially all of RAM to be filled with the currentportion of the matrix (slab) to be updated and factored, thereby greatly improving the computation toI/O ratio over previous approaches. Experiencesand performance are reported for the Cray T3Dsystem. </abstract>
<intro> INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Automated Proof Support forReasoning about Distributed MobilePrograms </title>
<degree> A thesissubmitted in partial fulfilmentof the requirements forthe degreeofBachelor of TechnologyinComputer Science and Engineering </degree><author> byB KarthikeyanT R Vishwanath </author>
<degree> under the guidance ofDr Sanjiva Prasad </degree><affiliation> Department of Computer Science &amp; EngineeringIndian Institute of Technology, Delhi </affiliation>
<date> May 1997 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> NetSolve: A Network Serverfor Solving Computational Science Problems </title>
<author> Henri Casanova </author>
<affiliation> University of TennesseeUTK, Dept. of Computer Science </affiliation>
 <address> 104, Ayres Hall. KNOXVILLE, TN 37996-1301. </address>
<email> casanova@cs.utk.edu </email>
<web> http://www.cs.utk.edu/~casanova </web><author> Jack Dongarra </author>
<affiliation> University of Tennessee,  Oak Ridge National LaboratoryUTK, Dept. of Computer Science </affiliation>
 <address> 104, Ayres Hall. KNOXVILLE, TN 37996-1301. </address>
<email> dongarra@cs.utk.edu </email>
<web> http://www.netlib.org/utk/people/JackDongarra.html </web><date> November 12, 1996 </date>
<abstract> AbstractThis paper presents a new system, called NetSolve, that allows users to access computational resources, such as hardware and software, distributed across the network. The development of NetSolvewas motivated by the need for an easy-to-use, efficient mechanism for using computational resources remotely. Ease of use is obtained as a result of different interfaces, some of which require no programmingeffort from the user. Good performance is ensured by a load-balancing policy that enables NetSolve touse the computational resources available as efficiently as possible. NetSolve offers the ability to lookfor computational resources on a network, choose the best one available, solve a problem (with retry forfault-tolerance), and return the answer to the user. </abstract>
<keyword> KeywordsNetworking, Heterogeneity, Load Balancing,Client-Server, Fault Tolerance, Numerical Computing, Virtual Library. </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> What robots can do:Robot programs and effective achievability </title>
<author> Fangzhen Lin </author>
<affiliation> Department of Computer ScienceThe Hong Kong University of Science and Technology </affiliation>
<address> Clear Water Bay, Hong Kong </address>
<email> flin@cs.ust.hk </email>
<author> Hector Levesque </author>
<affiliation> Department of Computer ScienceUniversity of Toronto </affiliation>
<address> Toronto, Canada M5S 3H5 </address>
<email> hector@ai.toronto.edu </email>
<date> May 15, 1997 </date>
<abstract> AbstractIn this paper, we propose a definition of goal achievability: given a basic action theory describing an initial state of the world and some primitive actions available to arobot, including some actions which return binary sensing information, what goals canbe achieved by the robot? The main technical result of the paper is a proof that a simplerobot programming language is universal, in that any effectively achievable goal can beachieved by getting the robot to execute one of the robot programs. The significance ofthis result is at least two fold. First, it is in many ways similar to the equivalence theorem between Turing machines and recursive functions, but applied to robots whoseactions are specified by an action theory. Secondly, it provides formal justifications forusing the simple robot programming language as a foundation for our work on robotics. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> An Ordering on Subgoals for Planning </title>
<author> Fangzhen Lin </author>
<affiliation> epartment of Computer ScienceThe Hong Kong University of Science and Technology </affiliation>
<address> Clear Water Bay, Kowloon, Hong Kong </address>
<email> @cs.ust.hk </email>
<abstract> AbstractSubgoal ordering is a type of control information that has received much attentionin AI planning community. In this paper we formulate precisely a subgoal orderingin the situation calculus. We show how information about this subgoal ordering canbe deduced from the background action theory. We also show for both linear andnonlinear planners how knowledge about this ordering can be used in a provablycorrect way to avoid unnecessary backtracking. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> How to Progress a Database (and Why)I. Logical Foundations </title>
<author> Fangzhen Lin and Ray Reiter  </author>
<affiliation> Department of Computer ScienceUniversity of Toronto </affiliation>
<address> Toronto, Canada M5S 1A4 </address>
<email> email: @ai.toronto.edu reiter@ai.toronto.edu </email>
<abstract> AbstractOne way to think about STRIPS is as a mapping from databases to databases, in the following sense: Suppose we want to know whatthe world would be like if an action, represented by the STRIPS operator ff, were donein some world, represented by the STRIPSdatabase D 0 . To find out, simply performthe operator ff on D 0 (by applying ff's elementary add and delete revision operators toD 0 ). We describe this process as progressingthe database D 0 in response to the action ff.In this paper, we consider the general problem of progressing an initial database in response to a given sequence of actions. Weappeal to the situation calculus and an axiomatization of actions which addresses theframe problem (Reiter [13], Lin and Reiter[8]). This setting is considerably more general than STRIPS. Our results concerningprogression are mixed. The (surprising) badnews is that, in general, to characterize a progressed database we must appeal to secondorder logic. The good news is that there aremany useful special cases for which we cancompute the progressed database in first order logic; not only that, we can do so efficiently. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Specifying Instructions' Semantics Using CSDL(Preliminary Report) </title>
<author> Norman Ramsey and Jack W. Davidson </author>
<affiliation> Department of Computer ScienceUniversity of Virginia </affiliation>
<address> Charlottesville, VA 22903 </address>
<date> June 10, 1998 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Approaching the 5/4-Approximationfor Rectilinear Steiner Trees  </title>
<author> Piotr Berman Ulrich Fomeier Marek KarpinskiMichael Kaufmann Alexander Zelikovsky </author>
<date> September 29, 1995 </date>
<abstract> AbstractThe rectilinear Steiner tree problem requires a shortest tree spanning a given vertex subsetin the plane with rectilinear distance. It was proved that the output length of Zelikovsky's [25]and Berman/Ramaiyer [3] heuristics is at most 1.375 and 9772 1:347 of the optimal length,respectively. It was claimed that these bounds are not tight. Here we improve these bounds to1.3125 and 6148 1:271, respectively, and give efficient algorithms to find approximations of suchquality. We also prove that for Zelikovsky's heuristic this bound cannot be less than 1.3. </abstract>
<keyword> Keywords: Algorithms, approximations, Steiner tree </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Distributed Protocol for Channel-BasedCommunication with Choice </title>
<author> Frederick Knabe </author>
<affiliation> European Computer-Industry Research Centre GmbH </affiliation>
<address> Munich, Germany </address>
<email> knabe@ecrc.de </email>
<abstract> AbstractRecent attempts at incorporating concurrency into functional languages haveidentified synchronous communication via shared channels as a promising primitive. An additional useful feature found in many proposals is a nondeterministicchoice operator. Similar in nature to the CSP alternative command, this operatorallows different possible actions to be guarded by sends or receives. Choice isdifficult to implement in a distributed environment because it requires offeringmany potential communications but closing only one. In this paper we presentthe first distributed, deadlock-free algorithm for choice. </abstract>
<keyword> Keywords: Distributed protocols, channels, synchronous communication,choice operator, CSP alternative command. </keyword>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Reprinted from 1995 Usenix Technical Conference * January 16-20, 1995 * New Orleans, LA </note>
<title> The New Jersey Machine-Code Toolkit </title>
<author> Norman Ramsey </author>
<affiliation> Bell Communications Research </affiliation>
<author> Mary F. Fernandez </author>
<affiliation> Department of Computer Science, Princeton University </affiliation>
<abstract> AbstractThe New Jersey Machine-Code Toolkit helps programmers write applications that process machine code.Applications that use the toolkit are written at anassembly-language level of abstraction, but they recognize and emit binary. Guided by a short instruction-set specification, the toolkit generates all the bit-manipulating code.The toolkit's specification language uses four concepts: fields and tokens describe parts of instructions,patterns describe binary encodings of instructions orgroups of instructions, and constructors map betweenthe assembly-language and binary levels. These concepts are suitable for describing both CISC and RISCmachines; we have written specifications for the MIPSR3000, SPARC, and Intel 486 instruction sets.We have used the toolkit to help write two applications: a debugger and a linker. The toolkit generatesefficient code; for example, the linker emits binary upto 15% faster than it emits assembly language, makingit 1.7-2 times faster to produce an a.out directly thanby using the assembler. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Non-Tree Routing </title>
<author> Bernard A. McCoy and Gabriel Robins </author>
<affiliation> Department of Computer Science, University of Virginia, </affiliation>
 <address> Charlottesville, VA 22903-2442 </address>
<note> Appeared in: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,Vol. 14, No. 6, June 1995, pp. 780-784. </note>
<abstract> AbstractAn implicit premise of existing routing methods is that the routing topology must correspond to atree (i.e., it does not contain cycles). In this paper we investigate the consequences of abandoning thisbasic axiom, and instead we allow routing topologies that correspond to arbitrary graphs (i.e., wherecycles are allowed). We show that non-tree routing can significantly improve signal propagation delay,reduce signal skew, and afford increased reliability with respect to open faults that may be caused bymanufacturing defects and electro-migration. Simulations on uniformly-distributed nets indicate thatdepending on net size and technology parameters, our non-tree routing construction reduces maximumsourse-sink SPICE delay by an average of up to 62%, and reduces signal skew by an average of up to63%, as compared with Steiner routing. Moreover, up to 77% of the total wirelength in non-trees cantolerate an open fault without disconnecting the circuit. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Scheduling and Page Migration for Multiprocessor Compute Servers </title>
<author> Rohit Chandra, Scott Devine, Ben Verghese,Anoop Gupta, and Mendel Rosenblum </author>
<affiliation> Computer Systems LaboratoryStanford University, </affiliation>
 <address> Stanford CA 94305 </address>
<abstract> AbstractSeveral cache-coherent shared-memory multiprocessors have beendeveloped that are scalable and offer a very tight coupling betweenthe processing resources. They are therefore quite attractive foruse as compute servers for multiprogramming and parallel application workloads. Process scheduling and memory management,however, remain challenging due to the distributed main memory found on such machines. This paper examines the effects ofOS scheduling and page migration policies on the performanceof such compute servers. Our experiments are done on the Stan-ford DASH, a distributed-memory cache-coherent multiprocessor.We show that for our multiprogramming workloads consisting ofsequential jobs, the traditional Unix scheduling policy does verypoorly. In contrast, a policy incorporating cluster and cache affinity along with a simple page-migration algorithm offers up to twofold performance improvement. For our workloads consisting ofmultiple parallel applications, we compare space-sharing policiesthat divide the processors among the applications to time-slicingpolicies such as standard Unix or gang scheduling. We showthat space-sharing policies can achieve better processor utilizationdue to the operating point effect, but time-slicing policies benefitstrongly from user-level data distribution. Our initial experiencewith automatic page migration suggests that policies based onlyon TLB miss information can be quite effective, and useful foraddressing the data distribution problems of space-sharing sched-ulers. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Using Runtime Measured Workload Characteristics inParallel Processor Scheduling </title>
<author> Thu D. Nguyen, Raj Vaswani, and John Zahorjan </author>
<affiliation> Department of Computer Science and Engineering, </affiliation>
 <address> Box 352350 </address>
<affiliation> University of Washington </affiliation>
<address> Seattle, WA 98195-2350 USA </address>
<pubnum> Technical Report UW-CSE-95-10-01 </pubnum>
<date> October 15, 1995 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Semantic Query Optimization in Datalog Programs </title>
<note> (Extended Abstract) </note>
<author> Alon Y. Levy </author>
<affiliation> AT&amp;T Bell Laboratories </affiliation>
<email> levy@research.att.com </email>
<author> Yehoshua Sagiv  </author>
<affiliation> Hebrew University, Jerusalem </affiliation>
<email> sagiv@cs.huji.ac.il </email>
<abstract> AbstractSemantic query optimization refers to the process of usingintegrity constraints (ic's) in order to optimize the evaluationof queries. The process is well understood in the caseof unions of select-project-join queries (i.e., nonrecursivedatalog). For arbitrary datalog programs, however, theissue has largely remained an unsolved problem. Thispaper studies this problem and shows when semantic queryoptimization can be completely done in recursive rulesprovided that order constraints and negated EDB subgoalsappear only in the recursive rules, but not in the ic's.If either order constraints or negated EDB subgoals areintroduced in ic's, then the problem of semantic queryoptimization becomes undecidable. Since semantic queryoptimization is closely related to the containment problemof a datalog program in a union of conjunctive queries, ourresults also imply new decidability and undecidability resultsfor that problem when order constraints and negated EDBsubgoals are used. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> PCp3 : A C Front End forPreprocessor Analysis and Transformation </title>
<author> Greg J. Badros  </author>
<email> gjb@cs.washington.edu </email>
<date> 16 October 1997 </date>
<abstract> AbstractThough the C preprocessor provides necessary language features, it does so in an unstructured way. The lexical nature of cpp creates numerous problems for software engineersand their tools, all stemming from the chasm between the engineer's view of the source codeand the compiler's view. The simplest way to reduce this problem is to minimize use of thepreprocessor. In light of the data collected in a prior empirical analysis, this paper describesa tool to aid the software engineer in analyses targeted at replacing preprocessor constructswith language features. Existing tools for analyzing C source in the context of the preprocessor are unsuitable for such transformations. This work introduces a new approach: tightlyintegrating the preprocessor with a C language parser, permitting the code to be analyzed atboth the preprocessor and syntactic levels simultaneously. The front-end framework, calledPCp 3 , combines a preprocessor, a parser, and arbitrary Perl subroutine "hooks" invoked uponvarious preprocessor and parser events. PCp 3 's strengths and weaknesses are discussed in thecontext of several program understanding and transformation tools, including a conservativeanalysis to support replacing cpp's #define directives with C++ language features. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Automatic Dynamic Compilation Support forEvent Dispatching in Extensible Systems </title>
<author> Craig Chambers, Susan J. Eggers,Joel Auslander, Matthai Philipose, Markus Mock, Przemyslaw Pardyak </author>
<affiliation> Department of Computer Science and EngineeringUniversity of Washington </affiliation>
<address> Box 352350, Seattle, WA 98195-2350 </address>
<phone> (206) 685-2094; fax: (206) 543-2969 </phone><email> -chambers, eggers,ausland,matthai,mock,pardy-@cs.washington.edu </email>
<abstract> AbstractThis paper describes extensions to an automatic dynamic compilation framework to supportoptimized event dispatching in the SPIN extensible operating system. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Effective Cache Prefetching on Bus-Based Multiprocessors </title>
<author> Dean M. Tullsen and Susan J. Eggers </author>
<affiliation> University of Washington </affiliation>
<abstract> AbstractCompiler-directed cache prefetching has the potential to hide much of the high memory latency seen bycurrent and future high-performance processors. However, prefetching is not without costs, particularly on amultiprocessor. Prefetching can negatively affect bus utilization, overall cache miss rates, memory latencies anddata sharing.We simulate the effects of a compiler-directed prefetching algorithm, running on a range of bus-based multiprocessors. We show that, despite a high memory latency, this architecture does not necessarily support prefetchingwell, in some cases actually causing performance degradations. We pinpoint several problems with prefetching ona shared memory architecture (additional conflict misses, no reduction in the data sharing traffic and associatedlatencies, a multiprocessor's greater sensitivity to memory utilization and the sensitivity of the cache hit rate toprefetch distance) and measure their effect on performance. We then solve those problems through architecturaltechniques and heuristics for prefetching that could be easily incorporated into a compiler: 1) victim caching,which eliminates most of the cache conflict misses caused by prefetching in a direct-mapped cache, 2) specialprefetch algorithms for shared data, which significantly improve the ability of our basic prefetching algorithmto prefetch invalidation misses, and 3) compiler-based shared data restructuring, which eliminates many of theinvalidation misses the basic prefetching algorithm doesn't predict. The combined effect of these improvementsis to make prefetching effective over a much wider range of memory architectures. </abstract>
<keyword> keywords: cache prefetching, bus-based multiprocessor, cache misses, prefetching strategies, parallel programs, false sharing, memory latency </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Journal of Artificial Intelligence Research 6 (1997) 35-85 Submitted 7/96; published 1/97 </note>
<title> SCREEN: Learning a Flat Syntactic and Semantic SpokenLanguage Analysis Using Artificial Neural Networks </title>
<author> Stefan Wermter </author>
 <email> wermter@informatik.uni-hamburg.de </email>
<author> Volker Weber </author>
 <email> weber@informatik.uni-hamburg.de </email>
<affiliation> Department of Computer ScienceUniversity of Hamburg </affiliation>
<address> 22527 Hamburg, Germany </address>
<abstract> AbstractPrevious approaches of analyzing spontaneously spoken language often have been basedon encoding syntactic and semantic knowledge manually and symbolically. While therehas been some progress using statistical or connectionist language models, many currentspoken-language systems still use a relatively brittle, hand-coded symbolic grammar orsymbolic semantic component.In contrast, we describe a so-called screening approach for learning robust processingof spontaneously spoken language. A screening approach is a flat analysis which uses shallow sequences of category representations for analyzing an utterance at various syntactic,semantic and dialog levels. Rather than using a deeply structured symbolic analysis, weuse a flat connectionist analysis. This screening approach aims at supporting speech andlanguage processing by using (1) data-driven learning and (2) robustness of connectionistnetworks. In order to test this approach, we have developed the screen system which isbased on this new robust, learned and flat analysis.In this paper, we focus on a detailed description of screen's architecture, the flatsyntactic and semantic analysis, the interaction with a speech recognizer, and a detailedevaluation analysis of the robustness under the influence of noisy or incomplete input.The main result of this paper is that flat representations allow more robust processing ofspontaneous spoken language than deeply structured representations. In particular, weshow how the fault-tolerance and learning capability of connectionist networks can supporta flat analysis for providing more robust spoken-language processing within an overallhybrid symbolic/connectionist framework. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Journal of Artificial Intelligence Research 8 (1998) 165-222 Submitted 8/97; published 6/98 </note>
<title> Model-Based Diagnosis using Structured SystemDescriptions </title>
<author> Adnan Darwiche </author>
 <email> darwiche@aub.edu.lb </email>
<affiliation> Department of MathematicsAmerican University of Beirut </affiliation>
<address> PO Box 11-236Beirut, Lebanon </address>
<abstract> AbstractThis paper presents a comprehensive approach for model-based diagnosis which includes proposals for characterizing and computing preferred diagnoses, assuming that thesystem description is augmented with a system structure (a directed graph explicating theinterconnections between system components). Specifically, we first introduce the notion ofa consequence, which is a syntactically unconstrained propositional sentence that characterizes all consistency-based diagnoses and show that standard characterizations of diagnoses,such as minimal conflicts, correspond to syntactic variations on a consequence. Second,we propose a new syntactic variation on the consequence known as negation normal form(NNF) and discuss its merits compared to standard variations. Third, we introduce a basicalgorithm for computing consequences in NNF given a structured system description. Weshow that if the system structure does not contain cycles, then there is always a linear-sizeconsequence in NNF which can be computed in linear time. For arbitrary system structures, we show a precise connection between the complexity of computing consequencesand the topology of the underlying system structure. Finally, we present an algorithmthat enumerates the preferred diagnoses characterized by a consequence. The algorithm isshown to take linear time in the size of the consequence if the preference criterion satisfiessome general conditions. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Software Deviation Analysis: A "Safeware" Technique </title>
<author> Jon Damon Reese and Nancy G. Leveson </author>
<affiliation> Dept. of C.S.E. Safeware Engineering Corp.University of Washington </affiliation>
 <address> 7200 Lower Ridge, Unit BBox 352350 Everett, WA 98203, U.S.A.Seattle, WA 98195, U.S.A. </address>
<email> fjdreese,levesong@cs.washington.edufjdreese,levesong@safeware-eng.com </email>
<abstract> AbstractStandard safety analysis techniques are often ineffective when computers and digital devices are integrated into plant control. The Safeware methodology and itsset of supporting safety analysis techniques (and prototype tools) includes modelingand hazard analysis of complex systems where the components may be a mixture ofhumans, hardware, and software. This paper describes one of the Safeware hazardanalysis techniques, Software Deviation Analysis, that incorporates the beneficial features of HAZOP (such as guidewords, deviations, exploratory analysis, and a systemsengineering approach) into an automated procedure that is capable of handling thecomplexity and logical nature of computer software. </abstract>
<note> This work was partly funded by NASA/Langley Grant NAG-1-1495, NSF Grant CCR-9396181, and theCalifornia PATH Program of the University of California, in cooperation with the California Departmentof Transportation and the U.S. Department of Transportation. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Partition Based Spatial-Merge Join </title>
<author> Jignesh M. Patel David J. DeWitt </author>
<affiliation> Computer Sciences Department,University of Wisconsin, Madison </affiliation>
<email> fjignesh, dewittg@cs.wisc.edu </email>
<abstract> AbstractThis paper describes PBSM (Partition Based Spatial-Merge), a new algorithm for performing spatial join operation. This algorithm is especially effective when neither of the inputs to the join have an index on the joiningattribute. Such a situation could arise if both inputs to the join are intermediate results in a complex query, or ina parallel environment where the inputs must be dynamically redistributed. The PBSM algorithm partitions theinputs into manageable chunks, and joins them using a computational geometry based plane-sweeping technique. This paper also presents a performance study comparing the the traditional indexed nested loops joinalgorithm, a spatial join algorithm based on joining spatial indices, and the PBSM algorithm. These comparisonsare based on complete implementations of these algorithms in Paradise, a database system for handling GIS applications. Using real data sets, the performance study examines the behavior of these spatial join algorithms in avariety of situations, including the cases when both, one, or none of the inputs to the join have an suitable index.The study also examines the effect of clustering the join inputs on the performance of these join algorithms. Theperformance comparisons demonstrates the feasibility, and applicability of the PBSM join algorithm. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Demand Interprocedural Dataflow Analysis </title>
<author> Susan Horwitz, Thomas Reps, and Mooly Sagiv  </author>
<affiliation> University of Wisconsin </affiliation>
<abstract> AbstractAn exhaustive dataflow-analysis algorithm associates with each point in a program a set of dataflow factsthat are guaranteed to hold whenever that point is reached during program execution. By contrast, ademand dataflow-analysis algorithm determines whether a single given dataflow fact holds at a single givenpoint.This paper presents a new demand algorithm for interprocedural dataflow analysis. The algorithm hasfour important properties:g It provides precise (meet-over-all-interprocedurally-valid-paths) solutions to a large class of problems.g It has a polynomial worst-case cost for both a single demand and a sequence of all possible demands.g The worst-case total cost of the sequence of all possible demands is no worse than the worst-case costof a single run of the current best exhaustive algorithm.g Experimental results show that in many situations (e.g., when only a small number of demands aremade, or when most demands are answered yes) the demand algorithm is superior to the current bestexhaustive algorithm. </abstract>
<keyword> CR Categories and Subject Descriptors: D.2.2 [Software Engineering]: Tools and Techniques; D.3.4[Programming Languages]: Processors compilers, optimization; E.1 [Data Structures] graphs; F.2.2[Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems computations on discrete structures; G.2.2 [Discrete Mathematics]: Graph Theory graph algorithmsGeneral Terms: Algorithms, Experimentation, TheoryAdditional Key Words and Phrases: demand dataflow analysis, distributive dataflow framework, graphreachability, interprocedural dataflow analysis, interprocedurally realizable path, interprocedurally validpath, meet-over-all-valid-paths solution </keyword>
<note> On leave from IBM Scientific Center, Haifa, Israel.This work was supported in part by a David and Lucile Packard Fellowship for Science and Engineering, by the National ScienceFoundation under grants CCR-8958530 and CCR-9100424, by the Defense Advanced Research Projects Agency under ARPA OrderNo. 8856 (monitored by the Office of Naval Research under contract N00014-92-J-1937), by the Air Force Office of ScientificResearch under grant AFOSR-91-0308, and by a grant from Xerox Corporate Research.Part of this work was done while the authors were visiting the University of Copenhagen.A preliminary version of this paper appeared in SIGSOFT 95: Proceedings of the Third ACM SIGSOFT Symposium on Foundationsof Software Engineering (Washington DC, October 10-13, 1995) [15]Authors' address: </note>
 <affiliation> Computer Sciences Department; Univ. of Wisconsin; </affiliation>
 <address> 1210 West Dayton Street; Madison, WI 53706; USA. </address>
<email> Electronic mail: -horwitz, reps, sagiv-@cs.wisc.edu. </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Maximal-Munch Tokenization in Linear Time </title>
<author> THOMAS REPS </author>
<affiliation> University of Wisconsin </affiliation>
<abstract> The lexical-analysis (or scanning) phase of a compiler attempts to partition the input stream into a sequence of tokens.The convention in most languages is that the input is scanned left to right, and each token identified is a maximalmunch of the remaining inputthe longest prefix of the remaining input that is a token of the language. Most textbooks on compiling have extensive discussions of lexical analysis in terms of finite-state automata and regular expressions: Token classes are defined by a set of regular expressions R i , 1 i k, and the lexical analyzer is based on someform of finite-state automaton for recognizing the language L (R 1 + R 2 + . . . + R k ). However, the treatment is unsatisfactory in one respect: The theory of finite-state automata assumes that the end of the input stringi.e., the right-hand-side boundary of the candidate for recognitionis known a priori, whereas a scanner must identify the next tokenwithout knowing a definite bound on the extent of the token.Although most of the standard compiler textbooks discuss this issue, the solution they sketch out is one thatforcertain sets of token definitionscan cause the scanner to exhibit quadratic behavior in the worst case. This property isnot only dissatisfying, it blemishes an otherwise elegant treatment of lexical analysis.In this paper, we rectify this defect: We show that, given a deterministic finite-state automaton that recognizes thetokens of a language, maximal-munch tokenization can always be performed in time linear in the size of the input. </abstract>
<keyword> CR Categories and Subject Descriptors: D.3.1 [Programming Languages]: Formal Definitions and Theory syntax;D.3.4 [Programming Languages]: Processors compilers; F.1.1 [Computation by Abstract Devices]: Models ofComputation automata; F.2.2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms andProblems pattern matching; I.2.8 [Artificial Intelligence]: Problem Solving, Control Methods, and Search backtracking, dynamic programming; I.5.4 [Pattern Recognition]: Applications text processingGeneral Terms: Algorithms, TheoryAdditional Key Words and Phrases: memoization, tabulation, tokenization </keyword>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> DEVise: Integrated Querying andVisual Exploration of Large Datasets </title>
<author> M. Livny, R. Ramakrishnan, K. Beyer, G. Chen, D. Donjerkovic,S. Lawande, J. Myllymaki and K. Wenger </author>
<affiliation> Department of Computer Sciences, University of Wisconsin-Madison </affiliation>
<email> fmiron,raghu,beyer,guangshu,donjerko,ssl,jussi,wengerg@cs.wisc.edu </email>
<abstract> AbstractDEVise is a data exploration system that allows users to easily develop, browse, and share visual presentations of largetabular datasets (possibly containing or referencing multimedia objects) from several sources. The DEVise frameworkis being implemented in a tool that has been already successfully applied to a variety of real applications by a numberof user groups.Our emphasis is on developing an intuitive yet powerful set of querying and visualization primitives that can beeasily combined to develop a rich set of visual presentationsthat integrate data from a wide range of application domains. While DEVise is a powerful visualization tool, itsgreatest strengths are the ability to interactively explore avisual presentation of the data at any level of detail (including retrieving individual data records), and the ability toseamlessly query and combine data from a variety of localand remote sources. In this paper, we present the DEViseframework, describe the current tool, and report on our experience in applying it to several real applications. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Cost-Aware WWW Proxy Caching Algorithms </title>
<author> Pei Cao Sandy Irani </author>
<affiliation> Department of Computer Science, Information and Computer Science Department,University of Wisconsin-Madison. University of California-Irvine. </affiliation>
<email> cao@cs.wisc.edu irani@ics.uci.edu </email>
<abstract> AbstractWeb caches can not only reduce network traffic anddownloading latency, but can also affect the distribution of web traffic over the network through cost-aware caching. This paper introduces GreedyDual-Size, which incorporates locality with cost and sizeconcerns in a simple and non-parameterized fashionfor high performance. Trace-driven simulations showthat with the appropriate cost definition, GreedyDual-Size outperforms existing web cache replacement algorithms in many aspects, including hit ratios, latency reduction and network cost reduction. In addition, GreedyDual-Size can potentially improve theperformance of main-memory caching of Web documents. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> LATENT VARIABLES, MEASUREMENT ERROR ANDMETHODS FOR ANALYZING LONGITUDINALORDINAL DATA </title>
<author> Mari Palta, Chin-Yu Lin, </author>
 <affiliation> University of Wisconsin-Madison </affiliation>
<author> Mari Palta, </author>
 <address> 504 N Walnut Street, Madison, WI 53705 </address>
<keyword> Key Words: Latent variable, Longitudinal ordinal data, Structural equation model </keyword>
<abstract> AbstractWe examine the effects of latent variables, betweenindividual variability and measurement error in theoutcome on commonly used methods for the analysis of longitudinal ordinal data, such as marginaland cluster-specific models. The impact of such variability becomes very clear when viewed in the context of structural equation modeling (e.g. Muthen1979, 1983, 1984, 1988). The structural equationformulation also provides insight into the assumptions and differences in interpretation of regressioncoefficients of these various methods of analysis. Weexplore the potential for using structural equationsto model random effects and to adjust for measurement error, and in the process compare resultsfrom marginal modeling using a SAS GEE routine(Karim and Zeger, 1988), Qu's GAUSS program(Qu, 1992) for generalized mixed models using GEE,the MIXOR package for cluster-specific mixed effects models (Hedeker and Gibbons, 1994), and LIS-COMP (Muthen, 1988) for structural equation models. These approaches are illustrated in a longitudinal data set of sleep disorders. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<author> Aart J.C. Bik </author>
<title> High Performance Computing Division </title>
<affiliation> Department of Computer ScienceLeiden University </affiliation>
<address> P.O. Box 9512, 2300 RA LeidenThe Netherlands </address>
<email> ajcbik@cs.leidenuniv.nl </email>
<phone> Tel. +31 71 5277037 </phone><note> Submission to PLDI'96 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Practical Comparison of call string and functional Approach inData Flow Analysis  </title>
<author> Martin Alt Florian Martin </author>
<affiliation> Universitat des Saarlandes, </affiliation>
 <address> P.O. Box 151150, 66041 Saarbrucken, </address>
<email> faltjfloriang@cs.uni-sb.de </email>
<date> October 20, 1995 </date>
<abstract> AbstractThe techniques which are used to implement interprocedural data flow analyzers can be generallydivided into two parts: the call string and the functional approach [18]. Both differ in their time and spacecomplexity as well as in the preciseness due to properties of the abstract domains and transfer functions.We have developed a data flow analyzer generator PAG [2] which is able to produce interproceduralanalyzers for both techniques. We specified two variants of constant propagation working in an ANSI-Ccompiler; a copy constant propagation that uses distributive transfer function and can be solved precisely,even interprocedurally [13], and a full constant propagator which includes an interpreter for expressionsof the language. We present the practical relevant results applying both analyzers to a rather fair set ofreal-world programs and compare the space/time consumption of the analyzers versus their preciseness. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Kerberos: An Authentication Service for Open Network Systems </title>
<author> Jennifer G. Steiner </author>
<affiliation> Project AthenaMassachusetts Institute of Technology </affiliation>
<address> Cambridge, MA 02139 </address>
<email> steiner@ATHENA.MIT.EDU </email>
<author> Clifford Neuman </author>
<affiliation> Department of Computer Science, </affiliation>
 <address> FR-35 </address>
<affiliation> University of Washington </affiliation>
<address> Seattle, WA 98195 </address>
<email> bcn@CS.WASHINGTON.EDU </email>
<author> Jeffrey I. Schiller </author>
<affiliation> Project AthenaMassachusetts Institute of Technology </affiliation>
<address> Cambridge, MA 02139 </address>
<email> jis@ATHENA.MIT.EDU </email>
<abstract> ABSTRACTIn an open network computing environment, a workstation cannot be trusted toidentify its users correctly to network services. Kerberos provides an alternativeapproach whereby a trusted third-party authentication service is used to verify users'identities. This paper gives an overview of the Kerberos authentication model as implemented for MIT's Project Athena. It describes the protocols used by clients, servers, andKerberos to achieve authentication. It also describes the management and replication ofthe database required. The views of Kerberos as seen by the user, programmer, andadministrator are described. Finally, the role of Kerberos in the larger Athena picture isgiven, along with a list of applications that presently use Kerberos for user authentication. We describe the addition of Kerberos authentication to the Sun Network File System as a case study for integrating Kerberos with an existing application. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> DEVise: Integrated Querying andVisual Exploration of Large Datasets </title>
<author> M. Livny, R. Ramakrishnan, K. Beyer, G. Chen, D. Donjerkovic,S. Lawande, J. Myllymaki and K. Wenger </author>
<affiliation> Department of Computer Sciences, University of Wisconsin-Madison </affiliation>
<email> fmiron,raghu,beyer,guangshu,donjerko,ssl,jussi,wengerg@cs.wisc.edu </email>
<abstract> AbstractDEVise is a data exploration system that allows users to easily develop, browse, and share visual presentations of largetabular datasets (possibly containing or referencing multimedia objects) from several sources. The DEVise frameworkis being implemented in a tool that has been already successfully applied to a variety of real applications by a numberof user groups.Our emphasis is on developing an intuitive yet powerful set of querying and visualization primitives that can beeasily combined to develop a rich set of visual presentationsthat integrate data from a wide range of application domains. While DEVise is a powerful visualization tool, itsgreatest strengths are the ability to interactively explore avisual presentation of the data at any level of detail (includ-ing retrieving individual data records), and the ability toseamlessly query and combine data from a variety of localand remote sources. In this paper, we present the DEViseframework, describe the current tool, and report on our experience in applying it to several real applications. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Approximate Analysis of Parallel Processor Allocation Policies </title>
<author> Rajesh K. Mansharamani and Mary K. Vernon </author>
<email> (mansha@cs.wisc.edu) (vernon@cs.wisc.edu) </email>
<affiliation> Computer Sciences DepartmentUniversity of Wisconsin </affiliation>
<address> 1210 West Dayton StreetMadison, WI 53706. </address>
<date> November 29, 1993 </date>
<abstract> AbstractThe complexity of parallel applications and parallel processor scheduling policies makes both exact analysis and simulation difficult, if not intractable, for large systems. In this paper we propose a new approachto performance modeling of multiprogrammed processor scheduling policies, that of interpolation approximations. We first define a workload model that contains parameters for the essential properties of parallelapplications with respect to scheduling discipline performance, yet lends itself to mathematical analysis. Keyfeatures of the workload model include general distribution of total job processing time, general distributionof available job parallelism, and a simple characterization of parallelism overheads. We then show that onecan find specific values of the system parameters for which the parallel system under a given schedulingpolicy reduces to a queueing system with a known (closed-form) solution. Finally, interpolation betweenthe points with known solutions is used to arrive at mean response time estimates that hold over the entiresystem parameter space. The interpolation approximations readily yield insight into policy behavior and areeasy to evaluate for systems with hundreds of processors.We illustrate the approach by developing and validating models of three scheduling policies, under theassumptions of linear job execution rates and independence between job parallelism and processing time.We discuss several insights and results obtained from the analysis of the three policies under the assumedworkloads. One result clarifies and generalizes observations in two previous simulation studies of how policyperformance varies with the coefficient of variation in job processing requirement. Another result of theinterpolation models yields new insight into how policy performance varies with job parallelism. We alsocomment on the generalizations of these insights for workloads with less restrictive assumptions. </abstract>
<note> This research was partially supported by the National Science Foundation under grants CCR-9024144 and CDA-9024618. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> High-Order Accurate Schemes for Incompressible Viscous Flow </title>
<author> John C. Strikwerday </author>
<affiliation> Computer Sciences DepartmentUniversity of Wisconsin-Madison </affiliation>
<abstract> AbstractWe present new finite difference schemes for the incompressible Navier-Stokes equations. The schemes are based on two spatial differencing methods, one is fourth-orderaccurate and the other is sixth-order accurate. The temporal differencing is based onbackward differencing formulas. The schemes use non-staggered grids and satisfy regularity estimates, guaranteeing smoothness of the solutions. The schemes are computationallyefficient. Computational results demonstrating the accuracy are presented. </abstract>
<keyword> Keywords: incompressible Navier-Stokes, finite difference schemes, GMRES. </keyword>
<note> AMS(MOS) classifications: 65M05, 65N05, 76D05 </note>
<intro> 1. Introduction. </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Use of Application Characteristics and Limited Preemption forRun-To-Completion Parallel Processor Scheduling Policies * </title>
<author> Su-Hui Chiang , Rajesh K. Mansharamani , and Mary K. Vernon  </author>
<affiliation> Computer Sciences DepartmentUniversity of Wisconsin-Madison </affiliation>
<address> Madison, WI 53706. </address>
<email> email: -suhui, vernon-@cs.wisc.edu </email>
<affiliation> TRDDC </affiliation>
<address> 1 Mangaldas RoadPune 411 050, India. </address>
<email> email: mansha@research.trddc.ernet.in </email>
<abstract> AbstractThe performance potential of run-to-completion (RTC) parallelprocessor scheduling policies is investigated by examiningwhether (1) application execution rate characteristics such as average parallelism (avg) and processor working set (pws) and/or (2)limited preemption can be used to improve the performance ofthese policies. We address the first question by comparing policies(previous as well as new) that differ only in whether or not theyuse execution rate characteristics and by examining a wider rangeof the workload parameter space than previous studies. We addressthe second question by comparing a simple two-level queueingpolicy with RTC scheduling in the second level queue againstRTC policies that don't allow any preemption and against dynamicequiallocation (EQ).Using simulation to estimate mean response times we find that forpromising RTC policies such as adaptive static partitioning (ASP)and shortest demand first (SDF), a maximum allocation constraintthat is for all practical purposes independent of avg and pws provides greater and more consistent improvement in policy performance than using avg or pws. Also, under the assumption that jobdemand information is unavailable to the scheduler we show thatthe ASP-max policy outperforms all previous high performanceRTC policies for workloads with coefficient of variation in processing requirement greater than one. Furthermore, a two-levelqueue that allows at most one preemption per job outperformsASP-max but is not competitive with EQ. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> RD-OPT: An Efficient Algorithm For Optimizing DCTQuantization Tables  </title>
<author> Viresh Ratnakar </author>
<affiliation> University of Wisconsin-MadisonComputer Sciences Department </affiliation>
<address> Madison, WI 53706 </address>
<phone> Phone: (608) 262-6627 </phone><email> Email: ratnakar@cs.wisc.edu </email>
<author> Miron Livny </author>
<affiliation> University of Wisconsin-MadisonComputer Sciences Department </affiliation>
<address> Madison, WI 53706 </address>
<phone> Phone: (608) 262-0856 </phone><email> Email: miron@cs.wisc.edu </email>
<abstract> AbstractThe Discrete Cosine Transform (DCT) is widely used in lossy image and video compression schemessuch as JPEG and MPEG. In this paper we describe RD-OPT, an efficient algorithm for constructingDCT quantization tables with optimal rate-distortion tradeoffs for a given image. The algorithm usesDCT coefficient distribution statistics in a novel way and uses a dynamic programming strategy toproduce optimal quantization tables over a wide range of rates and distortions. It can be used tocompress images at any desired signal-to-noise ratio or compressed size. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Program Generalization for Software Reuse:From C to C++  </title>
<author> Michael Siff </author>
<email> siff@cs.wisc.edu </email>
<author> Thomas Reps </author>
<email> reps@cs.wisc.edu </email>
<affiliation> University of Wisconsin-Madison </affiliation>
<address> 1210 West Dayton StreetMadison, WI 53706 </address>
<abstract> AbstractWe consider the problem of software generalization: Given a program component C, createa parameterized program component C 0 such that C 0 is usable in a wider variety of syntacticcontexts than C. Furthermore, C 0 should be a semantically meaningful generalization of C;namely, there must exist an instantiation of C 0 that is equivalent in functionality to C.In this paper, we present an algorithm that generalizes C functions via type inference. Theoriginal functions operate on specific data types; the result of generalization is a collection ofC++ function templates that operate on parameterized types. This version of the generalizationproblem is useful in the context of converting existing C programs to C++. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Interconvertibility of Set Constraints andContext-Free Language Reachability </title>
<author> David Melski Thomas Reps </author>
<date> November 18, 1996 </date>
<abstract> AbstractWe show the interconvertibility of context-free-language reachability problems and a classof set-constraint problems: given a context-free-language reachability problem, we show how toconstruct a set-constraint problem whose answer gives a solution to the reachability problem;given a set-constraint problem, we show how to construct a context-free-language reachabilityproblem whose answer gives a solution to the set-constraint problem. The interconvertibilityof these two formalisms offers an conceptual advantage akin to the advantage gained from theinterconvertibility of finite-state automata and regular expressions in language theory, namely,a problem can be formulated in whichever formalism is most natural. It also offers some insight into the "O(n 3 ) bottleneck" for different types of program-analysis problems, and allowsresults previously obtained for context-free-language reachability problems to be applied to setconstraint problems. </abstract>
<author> David Melski Thomas Reps </author>
<affiliation> Computer Sciences Department Computer Sciences DepartmentUniversity of Wisconsin University of Wisconsin </affiliation>
<address> 1210 W. Dayton St. 1210 W. Dayton St.Madison, WI 53706 Madison, WI 53706 </address>
<phone> 608/262-0016 608/262-2091 </phone><email> melski@cs.wisc.edu </email>
 <phone> 608/262-9777 (fax) </phone><email> reps@cs.wisc.edu </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> MULTI-COORDINATION METHODS FORPARALLEL SOLUTION OFBLOCK-ANGULAR PROGRAMS </title>
<author> ByGolbon Zakeri </author>
<degree> A thesis submitted in partial fulfillment of therequirements for the degree ofDoctor of Philosophy(Computer Sciences and Mathematics)at the </degree><affiliation> UNIVERSITY OF WISCONSIN - MADISON </affiliation>
<date> 1995 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> , , 1-19 ()c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. </note>
<title> A Comparison of Large Scale MixedComplementarity Problem Solvers * </title>
<author> STEPHEN C. BILLUPS </author>
 <email> sbillups@carbon.cudenver.edu </email>
<affiliation> Mathematics Department, University of Colorado, </affiliation>
 <address> Denver, Colorado 80217 </address>
<author> STEVEN P. DIRKSE </author>
 <email> steve@gams.com </email>
<affiliation> GAMS Development Corporation, </affiliation>
 <address> Washington, DC 20007 </address>
<author> MICHAEL C. FERRIS </author>
 <email> ferris@cs.wisc.edu </email>
<affiliation> Computer Sciences Department, University of Wisconsin, </affiliation>
 <address> Madison, Wisconsin 53706 </address>
<date> Received Oct 1, 1995; Revised March 22, 1996 </date>
<note> Editor: </note>
<abstract> Abstract. This paper provides a means for comparing various computer codes for solving largescale mixed complementarity problems. We discuss inadequacies in how solvers are currentlycompared, and present a testing environment that addresses these inadequacies. This testingenvironment consists of a library of test problems, along with GAMS and MATLAB interfaces thatallow these problems to be easily accessed. The environment is intended for use as a tool by otherresearchers to better understand both their algorithms and their implementations, and to directresearch toward problem classes that are currently the most challenging. As an initial benchmark,eight different algorithm implementations for large scale mixed complementarity problems arebriefly described and tested with default parameter settings using the new testing environment. </abstract>
<keyword> Keywords: complementarity problems, variational inequalities, computation, algorithms </keyword>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> SYNCHRONOUS AND ASYNCHRONOUS MULTI-COORDINATIONMETHODS FOR THE SOLUTION OF BLOCK-ANGULARPROGRAMS </title>
<author> R.R. MEYER AND G. ZAKERI  </author>
<abstract> Abstract. Several types of multi-coordination methods for block-angular programs are considered. We present a computational comparison of synchronous multi-coordination methods. The mostefficient of these approaches is shown to involve an intermediate number of blocks in the coordinationphase. We also develop a new stabilization algorithm and present asynchronous multi-coordinationschemes, which are particularly useful when the number of blocks exceeds the number of availableprocessors or when the block sizes vary significantly. </abstract>
<intro> 1. Introduction. In this paper we present multi-coordinator synchronous and </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> PRECONDITIONING FOR REGULAR ELLIPTIC SYSTEMS </title>
<author> Hsing-Hsia Chen </author>
<affiliation> Department of MathematicsChung-Yuan Christian University </affiliation>
<address> Chung-Li, 320, Taiwan </address>
<author> andJohn C. Strikwerday </author>
<affiliation> Department of Computer SciencesUniversity of Wisconsin - Madison </affiliation>
<address> Madison, WI </address>
<abstract> Abstract. In this paper we examine preconditioning operators for regular ellipticsystems of partial differential operators. We obtain general conditions under which thepreconditioned systems are bounded. We also provide some useful guidelines for choosingleft and right preconditioning operators for regular elliptic systems. The condition numbersof the discrete operators arising from these preconditioned operators are shown to bebounded independent of grid spacing. Several examples of the two-dimensional regularelliptic systems are discussed, including scalar elliptic operators and the Stokes operatorwith several different boundary conditions. Several preconditioners for these regular ellipticsystems are presented and used in numerical experiments illustrating the theoretical results. </abstract>
<keyword> Key word. preconditioning, elliptic systems, numerical methods </keyword>
<note> AMS subject classifications. 65N06, 65N22 </note>
<intro> 1. Introduction. </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Evaluation of Object Management SystemArchitectures for Software Engineering Applications </title>
<author> Jayavel Shanmugasundaram, Barbara Staudt Lerner, Lori Clarke </author>
<affiliation> Department of Computer ScienceUniversity of Massachusetts </affiliation>
<address> Amherst, MA 01003 USA </address>
<phone> +1 413 545 3787 </phone><email> fshan, lerner, clarkeg@cs.umass.edu </email>
<abstract> ABSTRACTSoftware engineering applications require sophisticatedobject management system support for creating andmanipulating software objects. One of the key issues forobject management systems is distribution. Addressing this issue in the context of software engineering applications is particularly challenging because they havewidely varying object access profiles. Two fundamentalapproaches to dealing with distribution are the objectserver architecture, where objects are shipped to theapplication program, and the operation server architecture, where operation requests are shipped to where theobjects reside. We compare these architectures experimentally to determine the conditions under which eachperforms better. </abstract>
<keyword> KEYWORDSDistributed object management, experimental evaluation </keyword>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Moufang Quasigroups </title>
<author> Kenneth Kunen 1 </author>
<affiliation> University of Wisconsin, </affiliation>
 <address> Madison, WI 53706, U.S.A. </address>
<email> kunen@cs.wisc.edu </email>
<date> September 5, 1995 </date>
<abstract> ABSTRACTEach of the Moufang identities in a quasigroup implies that thequasigroup is a loop. </abstract>
<intro> x1. Introduction. </intro> 
</NEW_HEADER>
<NEW_HEADER>
<title> Fast and Accurate Flow-Insensitive Points-To Analysis </title>
<author> Marc Shapiro and Susan Horwitz </author>
<affiliation> Computer Sciences Department, University of Wisconsin-Madison </affiliation>
<address> 1210 West Dayton Street, Madison, WI 53706 USA </address>
<email> Electronic mail: fmds, horwitzg@cs.wisc.edu </email>
<abstract> AbstractIn order to analyze a program that involves pointers, itis necessary to have (safe) information about what eachpointer points to. There are many different approachesto computing points-to information. This paper addresses techniques for flow- and context-insensitive in-terprocedural analysis of stack-based storage.The paper makes two contributions to work in thisarea:* The first contribution is a set of experiments thatexplore the trade-offs between techniques previously defined by Lars Andersen and Bjarne Steens-gaard. The former has a cubic worst-case runningtime, while the latter is essentially linear. However, the former may be much more precise thanthe latter. We have found that in practice, Ander-sen's algorithm is consistently more precise thanSteensgaard's. For small programs, there is verylittle difference in the times required by the twoapproaches; however, for larger programs, Ander-sen's algorithm can be much slower than Steensgaard's.* The second contribution is the definition of twonew algorithms. The first algorithm can be "tuned"so that its worst-case time and space requirements,as well as its accuracy range from those of Steens-gaard to those of Andersen. We have experimentedwith several versions of this algorithm; one versionprovided a significant increase in accuracy overSteensgaard's algorithm, while keeping the running time within a factor of two.The second algorithm uses the first as a subroutine. Its worst-case time and space requirementsare a factor of log N (where N is the number ofvariables in the program) worse than those ofSteensgaard's algorithm. In practice, it appears to </abstract>
<note> This work was supported in part by the National Science Foundation under grant CCR-8958530, and by the Defense Advanced Research Projects Agency under ARPA Order No. 8856 (monitored bythe Office of Naval Research under contract N00014-92-J-1937). </note>
<abstract> run about ten times slower than Steensgaard's algorithm; however it is significantly more accuratethan Steensgaard's algorithm, and significantlyfaster than Andersen's algorithm on largeprograms. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> C**:A Large-Grain, Object-Oriented, Data-ParallelProgramming Language </title>
<author> James R. Larus, Brad Richards, and Guhan Viswanathan 1 </author>
<affiliation> Computer Sciences DepartmentUniversity of Wisconsin-Madison </affiliation>
<address> 1210 West Dayton StreetMadison, WI 53706 USA </address>
<pubnum> UW Technical Report #1126 </pubnum>
<date> November 24, 1992 </date>
<note> 1 This work was supported by the National Science Foundation under grants CCR-9101035 and CDA9024618. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Storage Estimation for Multidimensional Aggregates inthe Presence of Hierarchies  </title>
<author> Amit Shukla Prasad M. DeshpandeJeffrey F. Naughton Karthikeyan Ramasamy </author>
<email> famit,pmd,naughton,karthikg@cs.wisc.edu </email>
<affiliation> Computer Sciences DepartmentUniversity of Wisconsin - Madison </affiliation>
<abstract> AbstractTo speed up multidimensional data analysis,database systems frequently precompute aggregates on some subsets of dimensions andtheir corresponding hierarchies. This improvesquery response time. However, the decision ofwhat and how much to precompute is a difficult one. It is further complicated by the factthat precomputation in the presence of hierarchies can result in an unintuitively large increase in the amount of storage required by thedatabase. Hence, it is interesting and usefulto estimate the storage blowup that will result from a proposed set of precomputationswithout actually computing them. We proposethree strategies for this problem: one based onsampling, one based on mathematical approximation, and one based on probabilistic counting. We investigate the accuracy of these algorithms in estimating the blowup for differentdata distributions and database schemas. Thealgorithm based upon probabilistic counting isparticularly attractive, since it estimates thestorage blowup to within provable error boundswhile performing only a single scan of the data. </abstract>
<note> Work supported by an IBM CAS Fellowship, NSF grant IRI-9157357, and a grant from IBM under the University PartnershipProgram.Permission to copy without fee all or part of this material isgranted provided that the copies are not made or distributed fordirect commercial advantage, the VLDB copyright notice andthe title of the publication and its date appear, and notice isgiven that copying is by permission of the Very Large Data BaseEndowment. To copy otherwise, or to republish, requires a feeand/or special permission from the Endowment.Proceedings of the 22nd VLDB ConferenceMumbai (Bombay), India, 1996 </note>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Towards Effective and Efficient Free Space Management </title>
<author> Mark L. McAuliffe </author>
<affiliation> University of Wisconsin|Madison </affiliation>
<email> mcauliff@cs.wisc.edu </email>
<author> Michael J. Carey </author>
<affiliation> IBM Almaden Research Center </affiliation>
<email> carey@almaden.ibm.com </email>
<author> Marvin H. Solomon </author>
<affiliation> University of Wisconsin|Madison </affiliation>
<email> solomon@cs.wisc.edu </email>
<abstract> AbstractAn important problem faced by many database managementsystems is the "online object placement problem"|theproblem of choosing a disk page to hold a newly allocatedobject. In the absence of clustering criteria, the goal isto maximize storage utilization. For main-memory basedsystems, simple heuristics exist that provide reasonablespace utilization in the worst case and excellent utilizationin typical cases. However, the storage management problemfor databases includes significant additional challenges, suchas minimizing I/O traffic, coping with crash recovery, andgracefully integrating space management with locking andlogging.We survey several object placement algorithms, includingtechniques that can be found in commercial and researchdatabase systems. We then present a new object placementalgorithm that we have designed for use in Shore, anobject-oriented database system under development at theUniversity of Wisconsin|Madison. Finally, we presentresults from a series of experiments involving actual Shoreimplementations of some of these algorithms. Our resultsshow that while current object placement algorithms haveserious performance deficiencies, including excessive CPUor main memory overhead, I/O traffic, or poor diskutilization, our new algorithm consistently demonstratesexcellent performance in all of these areas. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Asking Questions to Minimize Errors </title>
<author> Nader H. Bshouty </author>
<affiliation> Department of Computer ScienceThe University of Calgary </affiliation>
<address> 2500 University Drive N.W.Calgary, Alberta, Canada T2N 1N4 </address>
<email> bshouty@cpsc.ucalgary.ca </email>
<author> Sally A. Goldman </author>
<affiliation> Department of Computer ScienceWashington University </affiliation>
<address> St. Louis, MO 63130 </address>
<email> sg@cs.wustl.edu </email>
<author> Thomas R. Hancock </author>
<affiliation> Siemens Corporate Research, Inc. </affiliation>
<address> 755 College Road EastPrinceton, NJ 08540 </address>
<email> hancock@learning.siemens.com </email>
<author> Sleiman Matar </author>
<affiliation> Department of Computer ScienceThe University of Calgary </affiliation>
<address> 2500 University Drive N.W.Calgary, Alberta, Canada T2N 1N4 </address>
<email> sleiman@cpsc.ucalgary.ca </email>
<date> September 1993 </date>
<pubnum> WUCS-93-23 </pubnum>
<abstract> AbstractA number of efficient learning algorithms achieve exact identification of an unknown functionfrom some class using membership and equivalence queries. Using a standard transformationsuch algorithms can easily be converted to on-line learning algorithms that use membershipqueries. Under such a transformation the number of equivalence queries made by the queryalgorithm directly corresponds to the number of mistakes made by the on-line algorithm. Inthis paper we consider several of the natural classes known to be learnable in this setting, andinvestigate the minimum number of equivalence queries with accompanying counterexamples(or equivalently the minimum number of mistakes in the on-line model) that can be made by alearning algorithm that makes a polynomial number of membership queries and uses polynomialcomputation time. We are able both to reduce the number of equivalence queries used by theprevious algorithms and often to prove matching lower bounds. As an example, consider theclass of DNF formulas over n variables with at most k = O(log n) terms. Previously, thealgorithm of Blum and Rudich [BR92] provided the best known upper bound of 2 O(k) log n forthe minimum number of equivalence queries needed for exact identification. We greatly improveon this upper bound showing that exactly k counterexamples are needed if the learner knows k apriori and exactly k +1 counterexamples are needed if the learner does not know k a priori. Thisexactly matches known lower bounds [BC92]. For many of our results we obtain a completecharacterization of the tradeoff between the number of membership and equivalence queriesneeded for exact identification. The classes we consider here are monotone DNF formulas, Hornsentences, O(log n)-term DNF formulas, read-k sat-j DNF formulas, read-once formulas overvarious bases, and deterministic finite automata. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Learning One-Dimensional Geometric PatternsUnder One-Sided Random MisclassificationNoise </title>
<author> Paul W. Goldberg  </author>
<address> Department 1423 </address>
<affiliation> Sandia National Laboratories, </affiliation>
 <address> MS 1110P.O. Box 5800Albuquerque, NM 87185-1110 </address>
<email> pwgoldb@cs.sandia.gov </email>
<author> Sally A. Goldman  </author>
<affiliation> Dept. of Computer ScienceWashington University </affiliation>
<address> St. Louis, MO 63130 </address>
<email> sg@cs.wustl.edu </email>
<pubnum> WUCS-94-01 </pubnum>
<date> May 12, 1994 </date>
<note> This research was performed while visiting Washington University. Currently supported by theU.S. Department of Energy under contract DE-AC04-76AL85000.Supported in part by NSF Grant CCR-9110108 and an NSF NYI Grant CCR-9357707. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Optimal Solution of Off-line and On-line Generalized Caching </title>
<author> Saied Hosseini-Khayat and Jerome R. Cox, Jr. </author>
<affiliation> Washington University in St. Louis </affiliation>
<abstract> Abstract. Network traffic can be reduced significantly if caching is utilized effectively. As an effortin this direction we study the replacement problemthat arises in caching of multimedia objects. The sizeof objects and the cost of cache misses are assumednon-uniform. The non-uniformity of size is inherent in multimedia objects, and the non-uniformity ofcost is due to the non-uniformity of size and the factthat the objects are scattered throughout the network.Although a special case of this problem, i.e. the caseof uniform size and cost, has been extensively studied, the general case needs a great deal of study. Wepresent a dynamic programming method of optimallysolving the off-line and on-line versions of this problem, and discuss the complexity of this method. </abstract>
<keyword> Key words: Generalized caching, network traffic,network caching, file caching, optimal replacement,replacement algorithm. </keyword>
<intro> I. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Advantages of a Leveled CommitmentContracting Protocol </title>
<author> Tuomas W. Sandholm and Victor R. Lesser </author>
<affiliation> Computer Science DepartmentUniversity of Massachusetts at Amherst </affiliation>
<pubnum> CMPSCI Technical Report 95-72 </pubnum>
<date> September 7, 1995 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Techniques for Developing and MeasuringHigh-Performance Web Servers over ATM Networks </title>
<author> James C. Hu , Sumedh Mungee, Douglas C. Schmidt </author>
<email> fjxh,sumedh,schmidtg@cs.wustl.edu </email>
<phone> TEL: (314) 935-4215 FAX: (314) 935-7302 </phone><address> Campus Box 1045/Bryan 509 </address>
<affiliation> Washington University </affiliation>
<address> One Brookings DriveSt. Louis, MO 63130, USA  </address>
<note> This paper has been submitted to the INFOCOM '98 conference. </note>
<abstract> AbstractHigh-performance Web servers are essential to meet the growing demands of the Internet and large-scale intranets. Satisfying these demands requires a thorough understanding of keyfactors affecting Web server performance. This paper presentsempirical analysis illustrating how dynamic and static adaptivity can enhance Web server performance. Two researchcontributions support this conclusion.First, the paper presents results from a comprehensive empirical study of Web servers (such as Apache, Netscape Enterprise, PHTTPD, Zeus, and JAWS) over high-speed ATM networks. This study illustrates their relative performance andprecisely pinpoints the server design choices that cause performance bottlenecks. We found that once network and diskI/O overheads are reduced to negligible constant factors, themain determinants of Web server performance are its protocol processing path and concurrency strategy. Moreover, nosingle strategy performs optimally for all load conditions andtraffic types.Second, we describe the design techniques and optimizations used to develop JAWS, our high-performance, adaptiveWeb server. JAWS is an object-oriented Web server that wasexplicitly designed to alleviate the performance bottleneckswe identified in existing Web servers. It consistently outperforms all other Web servers over ATM networks. The performance optimizations used in JAWS include adaptive pre-spawned threading, fixed headers, cached date processing,and file caching. In addition, JAWS uses a novel software architecture that substantially improves its portability and flexThis work was funded in part by NSF grant NCR-9628218, Object Technologies International, Eastman Kodak, and Siemens MED.ibility, relative to other Web servers. Our empirical resultsillustrate that highly efficient communication software is notantithetical to highly flexible software. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Measuring the Performance of CommunicationMiddleware on High-Speed Networks </title>
<author> Aniruddha Gokhale and Douglas C. Schmidt </author>
<email> gokhale@cs.wustl.edu and schmidt@cs.wustl.edu </email>
<affiliation> Department of Computer Science, Washington University </affiliation>
<address> St. Louis, MO 63130, USA </address>
<note> An earlier version of this paper appeared in the Proceedingsof the SIGCOMM Conference, 1996, Stanford University,August, 1996. </note>
<abstract> AbstractConventional implementations of communication middle-ware (such as CORBA and traditional RPC toolkits) incurconsiderable overhead when used for performance-sensitiveapplications over high-speed networks. As gigabit networksbecome pervasive, inefficient middleware will force programmers to use lower-level mechanisms to achieve the necessarytransfer rates. This is a serious problem for mission/life-critical applications (such as satellite surveillance and medical imaging).This paper compares the performance of several widelyused communication middleware mechanisms on a high-speed ATM network. The middleware ranged from lower-level mechanisms (such as socket-based C interfaces andC++ wrappers for sockets) to higher-level mechanisms (suchas RPC, hand-optimized RPC and two implementations ofCORBA - Orbix 2.0.1 and ORBeline 2.0). These measurements reveal that the lower-level C and C++ implementations outperform the CORBA implementations significantly(the best CORBA throughput for remote transfer was roughly75 to 80 percent of the best C/C++ throughput for sending scalar data types and only around 33 percent for sending structs containing binary fields), and the hand-optimizedRPC code performs slightly better than the CORBA implementations. Our goal in precisely pinpointing the sources ofoverhead for communication middleware is to develop scalable and flexible CORBA implementations that can delivergigabit data rates to applications. </abstract>
<keyword> Keywords: Communication middleware, distributed object computing, CORBA, high-speed networks. </keyword>
<intro> 1 Introduction and Motivation </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> MINIMIZING MEMORY CACHE USAGE FOR MULTIGRIDALGORITHMS IN TWO DIMENSIONS  </title>
<author> CRAIG C. DOUGLAS  </author>
<abstract> Abstract. Computers today rely heavily on good utilization of their cache memory subsystems.Compilers are optimized for business applications, not scientific computing ones, however. Automatictiling of basic numerical algorithms is simply not provided by any compiler. Thus, absolutely terriblecache performance is normal for scientific computing applications.Multigrid algorithms combine several numerical algorithms into a more complicated algorithm.In this paper, an algorithm is derived that allows for data to pass through cache exactly once permultigrid level during a V cycle before the level changes. This is optimal cache usage for largeproblems that do not fit entirely in cache.The new algorithm would appear to be quite complicated to implement, leading to spaghetticoding. Actually, an efficient implementation of the algorithm requires a rigid, highly structuredcoding style. A coding example is given that is suitable for almost all common discretization methods.Numerical experiments are provided that show that the new algorithm is up to an integer factorfaster than the traditional implementation method for common multigrid parameter choices. </abstract>
<keyword> Key words. multigrid, cache, threads, sparse matrix, iterative methods, domain decomposition,compiler optimization. </keyword>
<note> AMS subject classifications. 65N15, 65N10 </note>
<intro> 1. Introduction. Multigrid methods are widely known as the fastest methods </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> THE DOMAIN REDUCTION METHOD: HIGH WAY REDUCTIONIN THREE DIMENSIONS AND CONVERGENCE WITH INEXACTSOLVERS  </title>
<author> CRAIG C. DOUGLAS AND JAN MANDEL  </author>
<abstract> Abstract. We study a method for parallel solution of elliptic partial differential equations whichdecomposes the problem into a number of independent subproblems on subspaces of the underlyingsolution space. Using symmetries of the domain, we obtain up to 64 such subproblems for a 3dimensional cube and the method reduces to a direct solver. In the general case, or when thesubproblems are solved only approximately, the method becomes an iterative method or can be usedas a preconditioner. Bounds on the resulting convergence factors and condition numbers are given. </abstract>
<intro> 1. Introduction. In this paper, we approximate the solution to the elliptic </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> GEMMW: A PORTABLE LEVEL 3 BLAS WINOGRAD VARIANT OFSTRASSEN'S MATRIX-MATRIX MULTIPLY ALGORITHM  </title>
<author> CRAIG C. DOUGLAS , MICHAEL HEROUX , GORDON SLISHMAN x AND ROGER M.SMITH - </author>
<abstract> Abstract. Matrix-matrix multiplication is normally computed using one of the BLAS or areinvention of part of the BLAS. Unfortunately, the BLAS were designed with small matrices inmind. When huge, well conditioned matrices are multiplied together, the BLAS perform like theblahs, even on vector machines. For matrices where the coefficients are well conditioned, Winograd'svariant of Strassen's algorithm offers some relief, but is rarely available in a quality form on mostcomputers. We reconsider this method and offer a highly portable solution based on the Level 3BLAS interface. </abstract>
<keyword> Key Words. Level 3 BLAS, matrix multiplication, Winograd's variant of Strassen's algorithm,multilevel algorithmsAMS(MOS) subject classification. Numerical Analysis: Numerical Linear Algebra </keyword>
<intro> 1. Preliminaries. Matrix-matrix multiplication is a very basic computer oper </intro>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> Yale UniversityDepartment of Computer Science </affiliation>
<title> Dynamic Fault Diagnosis </title>
<author> William Hurwood </author>
<pubnum> YALEU/DCS/TR-1056 </pubnum>
<date> December 1994 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Constructing Logic Programs withHigher-Order Predicates 1 </title>
<author> Jtrgen Fischer Nilsson </author>
<affiliation> Department of Computer ScienceTechnical University of Denmark </affiliation>
<author> Andreas Hamfelt </author>
<affiliation> Computing Science DepartmentUppsala University </affiliation>
<abstract> Abstract: This paper proposes a logic programming approach based on theapplication of a system of higher-order predicates put at disposal within ordinary logic programming languages such as prolog. These higher-orderpredicates parallel the higher-order functionals or combinators which form anestablished part of contemporary functional programming methodology.The suggested toolbox of higher-order predicates for composing logic programsis derived from one universal higher-order predicate. They take the form ofrecursion operators (in particular for expressing recursion along lists) intendedto cover all commonly occurring recursion schemes in logic programming practice. Their theoretical sufficiency is proved and their practical adequacy isargued through examples.The recursion operators, denoting higher-order relations rather than functions, are brought about straightforwardly through a well-known metalogicprogramming technique, rendering superfluous the need for special higher-order unification mechanisms. </abstract>
<keyword> Keywords: Relational higher-order and metalogic programming. Logic program recursion schemes. Declarative logic programming methodology. </keyword>
<note> Perche nessuna cosa si puo amare ne odiare,se prima no si a cognitio di quella.- Leonardo da Vinci, Notebooks </note>
<intro> 1 Introduction: Background and Ob jectives </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Facilitating Worst-Case Execution Times Analysis for Optimized Code </title>
<author> Jakob Engblom 1 Andreas Ermedahl 1 Peter Altenbernd 2 </author>
<email> 1 fjakob,ebbeg@docs.uu.se, </email>
 <affiliation> Department of Computer Systems (DoCS),Uppsala University, </affiliation>
 <address> P.O. Box 325, S-751 05 Uppsala, Sweden, </address>
 <phone> Fax: +46-(0)18-550225 </phone><email> 2 peter@c-lab.de, </email>
 <affiliation> C-LAB, </affiliation>
 <address> D-33094 Paderborn, Germany  </address>
<abstract> AbstractIn this paper we present co-transformation, a novel approach to the mapping of execution information from thesource code of a program to the object code for the purpose of worst-case execution time (WCET) analysis. Ourapproach is designed to handle the problems introduced byoptimizing compilers, i.e. that the structure of the objectcode is very different from the structure of the source code.The co-transformer allows us to keep track of how different compiler transformations, including optimizations, influence the execution time of a program. This allows us tostatically calculate the execution time of a program at theobject code level, using information about the program execution obtained at the source code level. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Experience with MPI: 'Convertingpvmmake to mpimake under LAM'and 'MPI and Parallel GeneticProgramming' </title>
<author> Judith Ellen Devaney </author>
<affiliation> NIST </affiliation>
<email> jdevaney@nist.gov </email>
<date> June 1995 </date>
<abstract> AbstractThis looks at the issues which arose in porting the pvmmake utilityfrom PVM to MPI. Pvmmake is a PVM application which allowsa user to send files, execute commands, and receive results from asingle machine on any machine in the virtual machine. Its actions arecontrolled by the contents of a configuration file. Its most commonuse is to enable management of the development of a parallel programin a heterogeneous environment. A utility with the same features,mpimake, was coded up to run under LAM.Genetic programming is an algorithm which evolves an algorithmin the form of a program to solve your input problem. The implementation under MPI requires the transfer of dynamic data structuressuch as lists and trees. This paper discusses the match between therequirements of this algorithm and the datatype feature in MPI. Anew library, MPI DataStruct is being developed which can transferdynamic data structures, created with pointers, without interventionby the user. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> An Object-Oriented Approach to Interoperation ofHeterogeneous Information Sources </title>
<author> Ling Liu 1 and Calton Pu 2 </author>
<affiliation> 1 University of Alberta, </affiliation>
 <address> Edmonton, Alberta T6G 2H1 Canada </address>
<email> email: lingliu@cs.ualberta.ca </email>
<affiliation> 2 Oregon Graduate Institute, </affiliation>
 <address> Portland, Oregon 97291-1000 USA </address>
<email> email: calton@cse.ogi.edu </email>
<abstract> Abstract. In the modern Internet environment, various types ofdata sources have become accessible, including multimedia data and webpages. Some of the fundamental assumptions in traditional databases,such as the existence of a global schema and data consistency maintainedby a Data Base Administrator, are no longer true in many of the newdata sources. We outline the DIOM [LP95b] object-oriented approachto build interoperable heterogeneous information systems despite theabsence of global schema and the presence of data inconsistency. We describe the metadata catalog management component of DIOM, a key service in the support for interoperation among heterogeneous informationsources. To support a flexible and customizable conection between information consumers and information producers, DIOM metadata catalogdevelopment utilizes the adaptive specification mechanisms, provided inDIOM interface description language, for explicit description of information consumers' domain query requirements and for object-orientedabstractions of information producers' information sources. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Microkernel Operating System Architecture and Mach </title>
<author> David L. Black David B. Golub Daniel P. Julin Richard F. RashidRichard P. Draves Randall W. Dean Alessandro Forin Joseph BarreraHideyuki Tokuda Gerald Malan David Bohman  </author>
<note> DRAFT of </note>
 <date> June 16, 1991 </date>
<abstract> AbstractModular architectures based on a microkernel are suitable bases for the design and implementationof operating systems. Prototype systems employing microkernel architectures are achieving the levels offunctionality and performance expected and required of commercial products. Researchers at CarnegieMellon University, the Open Software Foundation, and other sites are investigating implementations of anumber of operating systems (e.g., Unix 1 , MS-DOS 2 ) that use the Mach microkernel. This paper describesthe Mach microkernel, its use to support implementations of other operating systems, and the status of theseefforts. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Defining and Measuring Conflictsin Optimistic Replication  </title>
<author> John Heidemann Ashvin Goel Gerald Popek </author>
<affiliation> University of California, Los Angeles </affiliation>
<pubnum> Technical report UCLA-CSD-950033 </pubnum>
<abstract> AbstractOptimistic replication is often viewed as essential forlarge scale systems and for supporting mobile computing. In optimistic replication, updates can be made concurrently to different file replicas, resulting in multipleversions of the file. To recover from these conflictingupdates, after-the fact conflict resolution actions arerequired to recombine multiple versions into one. Thispaper defines these concepts and discusses approachesto measure them in optimistically replicated systems.Measurement of the number of conflicting updatesand conflict resolution is important to judge the practicality of optimistic replication. An environmentwhere conflicting updates are frequent will not be attractive since users cannot assume they have up-to-datedata. Although many conflicts can be automaticallyresolved, some conflicts require user intervention; suchconflicts cannot be too common. This paper shows anapproach to measure the number of conflicting updates.From this measurement we derive the actual amount ofwork done by the user or system to resolve conflictsand the minimum amount of work required to resolveconflicts. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Weak and Strong Beta Normalisationsin Typed -Calculi </title>
<author> Hongwei Xi </author>
<affiliation> Department of Mathematical SciencesCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213, USA </address>
<abstract> Abstract. We present a technique to study relations between weak andstrong fi-normalisations in various typed -calculi. We first introduce atranslation which translates a -term into a I-term, and show that a-term is strongly fi-normalisable if and only if its translation is weaklyfi-normalisable. We then prove that the translation preserves typabilityof -terms in various typed -calculi. This enables us to establish theequivalence between weak and strong fi-normalisations in these typed-calculi. This translation can deal with Curry typing as well as Churchtyping, strengthening some recent closely related results. This may bringsome insights into answering whether weak and strong fi-normalisationsin all pure type systems are equivalent. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> This research is partially supported by DARPA grant N00014-94-1-0845, DARPA contract F19628--95-C-0193, NSF grant CCR-9224375, and grants from Hewlett-Packard, Intel and Tektronix. </note>
<title> Predictable File Access Latency for Multimedia </title>
<author> D. Revel, C. Cowan, D. McNamee, C. Pu, and J. Walpole </author>
<affiliation> Department of Computer Science and EngineeringOregon Graduate Institute of Science &amp; Technology </affiliation>
<address> 20000 N.W. Walker Rd., P.O. Box 91000Portland, OR 97291-1000 </address>
<phone> (503) 690-1121 </phone><email> revel,crispin,dylan,calton,walpole-@cse.ogi.edu </email>
<abstract> AbstractMultimedia applications are sensitive to I/O latency and jitter when accessing data in secondary storage. Transparent adaptive prefetching (TAP) uses software feedback to provide multimedia applications with file system quality of service (QoS) guarantees. We are investigating how QoS requirements can be communicated and how they can be met by adaptive resource management. A preliminary test of adaptive prefetching is presented. </abstract>
<keyword> KeywordsQoS, adaptive, multimedia, prefetching </keyword>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Realistic Parsing:Practical Solutions of Difficult Problems </title>
<author> SYLVAIN DELISLE a &amp; STAN SZPAKOWICZ b </author>
<affiliation> a Dpartement de mathmatiques et dinformatiqueUniversit du Qubec Trois-Rivires </affiliation>
<address> Trois-Rivires, Qubec, Canada G9A 5H7 </address>
<email> email: Sylvain_Delisle@uqtr.uquebec.ca, </email>
 <phone> phone +1 819 376 5125; fax +1 819 376 5185 </phone><affiliation> b Department of Computer ScienceUniversity of Ottawa </affiliation>
<address> Ottawa, Ontario, Canada K1N 6N5 </address>
<email> email: szpak@csi.uottawa.ca, </email>
 <phone> phone +1 613 562 5800 ext. 6687; fax +1 613 562 5187 </phone><abstract> AbstractThis paper describes work on the linguisticanalysis of texts within a project devoted toknowledge acquisition from text. We focuson syntactic processing and present somekey elements of the projects parser thatallow it to deal successfully with technicaltexts. The parser is fully implemented andtested on a variety of real texts;improvements and enhancements are inprogress. Because our knowledge acquisitionmethod assumes no a priori model of thedomain of the source text, the parser reliesas much as possible on lexical and syntacticclues. That is why it strives for fullsyntactic analysis rather than some form oftext skimming. We present a practicalapproach to four acknowledged difficultproblems which to date have no generallyacceptable answers: phrase attachment; timeconstraints for problematic input (how toavoid long and unproductive computation);parsing conjoined structures (how topreserve broad coverage without losingcontrol of the parsing process); and thetreatment of fragmentary input or fragmentsthat are a byproduct of a fallback parsingstrategy. We review recent related work andconclude by listing several future workitems. </abstract>
<keyword> Key WordsText processing, knowledge acquisition fromtext, broad-coverage parsing, parsing conjoinedstructures. </keyword>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Verifying a Self-Stabilizing Mutual Exclusion Algorithm </title>
<note> To Appear in the Proceedings of PROCOMET'98 </note>
<author> Shaz Qadeer </author>
<affiliation> Department of EECSUniversity of California at Berkeley </affiliation>
<address> Berkeley CA 94720 </address>
<phone> Phone: (510)642-1490 </phone><email> shaz@eecs.berkeley.edu </email>
<author> Natarajan Shankar </author>
<affiliation> Computer Science LaboratorySRI International </affiliation>
<address> Menlo Park CA 94025 </address>
<phone> Phone: (415)859-5272 </phone><email> shankar@csl.sri.com </email>
<abstract> AbstractWe present a detailed description of a machine-assisted verification of an algorithmfor self-stabilizing mutual exclusion that is due to Dijkstra [Dij74]. This verification wasconstructed using PVS. We compare the mechanical verification to the informal proofsketch on which it is based. This comparison yields several observations regarding thechallenges of formalizing and mechanically verifying distributed algorithms in general. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Handling Infeasible Specifications of Cryptographic Protocols </title>
<author> Li Gong </author>
<affiliation> ORA Corporation Cornell University </affiliation>
<address> 301A Dates Drive </address>
  <affiliation> Dept. of Computer Science </affiliation>
<address>  Ithaca, NY 14850 Ithaca, NY 14853  </address>
<abstract> AbstractIn the verification of cryptographic protocols along theapproach of the logic for authentication by Burrows,Abadi, and Needham, it is possible to write a specification which does not faithfully represent the real worldsituation. Such a specification, though impossible orunreasonable to implement, can go undetected and beverified to be correct. It can also lead to logical statements that do not preserve causality, which in turn canhave undesirable consequences. Such a specification,called an infeasible specification here, can be subtle andhard to locate. This note shows how the logic of cryptographic protocols by Gong, Needham, and Yahalomcan be enhanced with a notion of eligibility to preservecausality of beliefs and detect infeasible specifications.It is conceivable that this technique can be adopted inother similar logics. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Integrating Security in a Group Oriented Distributed System </title>
<author> Michael Reiter Kenneth Birman Li Gong </author>
<affiliation> Dept. of Computer Science Dept. of Computer Science ORA CorporationCornell University Cornell University </affiliation>
 <address> 675 Massachusetts Ave.Ithaca, NY 14853 Ithaca, NY 14853 Cambridge, MA 02139 </address>
<email> reiter@cs.cornell.edu ken@cs.cornell.edu li@cambridge.oracorp.com </email>
<abstract> AbstractA distributed security architecture is proposed forincorporation into group oriented distributed systems,and in particular, into the Isis distributed programming toolkit. The primary goal of the architecture isto make common group oriented abstractions robustin hostile settings, in order to facilitate the construction of high performance distributed applications thatcan tolerate both component failures and malicious attacks. These abstractions include process groups andcausal group multicast. Moreover, a delegation andaccess control scheme is proposed for use in grouporiented systems. The focus of the paper is the security architecture; particular cryptosystems and keyexchange protocols are not emphasized. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Abstract Datatypes in PVS </title>
<author> S. Owre N. Shankar </author>
<affiliation> Computer Science LaboratorySRI International </affiliation>
<address> Menlo Park CA 94025 </address>
<phone> Phone: (415)859-5272 </phone><email> fowre, shankarg@csl.sri.com </email>
<web> URL: http://www.csl.sri.com/sri-csl-fm.html </web><note> 1 The development of PVS was funded by internal research funding from SRI International. Support for the preparation of this document came from the National Aeronautics and Space Administration Langley Research Center under Contract NAS1-18969. This report is a revised and updated </note>
</NEW_HEADER>
<NEW_HEADER>
<title> Toward a MAC policy framework </title>
<author> Xiaolei Qian Teresa F. Lunt </author>
<affiliation> SRI International ARPA/ITO </affiliation>
<address> 333 Ravenswood Avenue 3701 North Fairfax DriveMenlo Park, CA 94025 Arlington, VA 22203 </address>
<email> qian@csl.sri.com tlunt@arpa.mil </email>
<abstract> AbstractWe propose a formal policy framework of MAC policies in multilevel relational databases.We identify the important components of such policies and their desirable properties. Theframework provides a basis for systematically specifying such policies and characterizingtheir potential mismatches. Based on the framework, we compare and unify the MACpolicies and policy components that are proposed in the literature or imposed in existingsystems. Our framework could be used to capture and resolve MAC policy mismatches inthe trusted interoperation of heterogeneous multilevel relational databases. </abstract>
<keyword> KeywordsHeterogeneity, interoperation, mandatory access control, multilevel security, relationaldatabase, security policy </keyword>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, 7(5), OCTOBER 1995 1 </note>
<title> Enriching the Expressive Power of Security Labels </title>
<author> Li Gong and Xiaolei Qian </author>
<abstract> Abstract| Common security models such as Bell-LaPadulafocus on the control of access to sensitive data but leavesome important systems issues unspecified, such as the implementation of read-only objects, garbage collection, andobject upgrade and downgrade paths. Consequently, different implementations of the same security model may haveconflicting operational and security semantics. We proposethe use of more expressive security labels for specifying thesesystem issues within the security model, so that the semantics of a system design are precisely understood and areindependent of implementation details. </abstract>
<keyword> Keywords| Data security, garbage collection, multilevelsecurity, object label, read-only object. </keyword>
<intro> I. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Using Linguistic Phenomena to Motivate a Set of RhetoricalRelations </title>
<author> Alistair Knott </author>
<affiliation> Department of Artificial Intelligence, University of Edinburgh </affiliation>
<address> 80 South Bridge, Edinburgh EH1 1HN, Scotland </address>
<email> Email: A.Knott@ed.ac.uk </email>
<author> Robert Dale </author>
<affiliation> Human Communication Research Centre, University of Edinburgh </affiliation>
<address> 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland </address>
<email> Email: R.Dale@ed.ac.uk </email>
<date> May 5, 1993 </date>
<note> Running head: Motivating Rhetorical Relations </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Indexing PROLOG Procedures into DAGsby Heuristic Classification </title>
<author> Michael Sintek </author>
<affiliation> DFKI </affiliation>
<address> Postfach 208067608 KaiserslauternGermany </address>
<date> May 5, 1994 </date>
<abstract> AbstractThis paper first gives an overview of standard PROLOG indexing andthen shows, in a step-by-step manner, how it can be improved by slightlyextending the WAM indexing instruction set to allow indexing on multiplearguments. Heuristics are described that overcome the difficulty of computing the indexing WAM code. In order to become independent from aconcrete WAM instruction set, an abstract graphical representation basedon DAGs (called DAXes) is introduced.The paper includes a COMMON LISP listing of the main heuristicsimplemented; the algorithms were developed for RELFUN, a relational-plus-functional language, but can easily be used in arbitrary PROLOGimplementations. </abstract>
<note> The ideas described in this paper were first presented at the Workshop"Sprachen fur KI-Anwendungen, Konzepte - Methoden Implementierun-gen" 1992 in Bad Honnef [SS92]. This paper is part of a collaborative worktogether with Werner Stein [Ste92]. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Relational-Functional Integrationfor Declarative Programming </title>
<author> Harold Boley </author>
<affiliation> DFKI </affiliation>
<address> Box 2080, 67608 Kaiserslautern, Germany </address>
<email> boley@informatik.uni-kl.de </email>
<abstract> Abstract. A relational-functional kernel language is introduced thatintegrates essential declarative constructs: logic variables and non-determinism from the relational paradigm with nested and higher-order operations from the functional paradigm. Operator definitions use`valued clauses', subsuming relational Horn clauses and functional(conditional or unconditional) directed equations. Their semantics complements the atoms in relational Herbrand models by `molecules', whichpair functions, applied to argument terms, with returned-value terms.All abstract notions are illustrated by concrete declarative programs. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Layer Reassignment for Antenna EffectMinimization in 3-Layer Channel Routing  </title>
<author> Zhan Chen and Israel Koren </author>
<affiliation> Department of Electrical and Computer EngineeringUniversity of Massachusetts, </affiliation>
 <address> Amherst, MA 01003 </address>
<abstract> AbstractAs semiconductor technology enters the deep submicron era, reliability hasbecome a major challenge in the design and manufacturing of next generationVLSI circuits. In this paper we focus on one reliability issue the antennaeffect in the context of 3-layer channel routing. We first present an antenna effect model in 3-layer channel routing and, based on this, an antenna effect costfunction is proposed. A layer reassignment approach is adopted to minimize thiscost function and we show that the layer reassignment problem can be formulated as a network bipartitioning problem. Experimental results show that theantenna effect can be reduced considerably by applying the proposed technique.Compared with previous work, one advantage of our approach is that no extrachannel area is required for antenna effect minimization. We show that layerreassignment technique can be used in yield-related critical area minimizationin 3-layer channel routing as well. The trade-off between these two objectives isalso presented. </abstract>
<intro> 1: Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Crosstalk Minimization in Three-LayerHVH Channel Routing  </title>
<author> Zhan Chen and Israel Koren </author>
<affiliation> Department of Electrical and Computer EngineeringUniversity of Massachusetts, </affiliation>
 <address> Amherst, MA 01003, USA </address>
<abstract> AbstractCrosstalk has become a major issue in VLSI design due to the high frequency, longinterconnecting lines and small spacing between interconnects in today's integrated circuits.In this paper, we study the problem of crosstalk minimization in 3-layer HVH channelrouting. A heuristic algorithm that combines layer reassignment and track reassignmentis presented. This algorithm can iteratively modify the layout so that the crosstalk in thechannel is minimized. Experimental results show that the proposed approach can reduce thecrosstalk by an average of 16.4% on a set of benchmark examples. </abstract>
<intro> 1: Introduction </intro> 
</NEW_HEADER>
<NEW_HEADER>
<title> Optimal Routing Control: Game Theoretic Approach </title>
<author> Richard J. La, and Venkat Anantharam </author>
<affiliation> Department of Electrical Engineering and Computer ScienceUniversity of California at Berkeley </affiliation>
<email> hyongla@eecs.berkeley.edu, ananth@eecs.berkeley.edu </email>
<abstract> AbstractCommunication networks shared by selfish users areconsidered and modeled as noncooperative repeatedgames. Each user is interested only in optimizing itsown performance by controlling the routing of its load.We investigate the existence of a NEP that achievesthe system-wide optimal cost. The existence of a NEPthat not only achieves the system-wide optimal cost butalso yields a cost for each user no greater than its stagegame NEP cost is shown for two-node multiple link networks. It is shown that more general networks whereall users have the same source-destination pair havea NEP that achieves the minimum total system costunder a mild technical condition. It is shown generalnetworks with users having multiple source-destinationpairs don't necessarily have such an NEP. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Common Randomness Capacity of aPair of Independent Discrete MemorylessChannels  </title>
<author> S. Venkatesan V. Anantharam zx </author>
<date> 13 August 1995 </date>
<abstract> AbstractWe study the following problem: two agents Alice and Bob are connected to each other by independent discrete memoryless channels. Theywish to generate common randomness by communicating interactively overthe two channels. Assuming that Alice and Bob are allowed access toindependent external random sources at rates (in bits per step of communication) of H A and H B , respectively, we show that they can generate common randomness at a rate of max f min [H A + H(W jQ); I(P ; V )] +min [H B + H(V jP ); I(Q; W )] g bits per step. Here, V is the channel fromAlice to Bob, and W is the channel from Bob to Alice. The maximumis over all probability distributions P and Q on the input alphabets of Vand W respectively. We also prove a strong converse which establishes theabove rate as the highest attainable in this situation. </abstract>
<keyword> Keywords: Common randomness capacity, generating randomness fromnoise, interactive communication. </keyword>
<note> Research supported by NSF IRI 9005849, IRI 9310670, NCR 9422513, and the AT&amp;TFoundation. </note>
<affiliation> Cornell University and U.C. Berkeley.Univ. of California, Berkeley. </affiliation>
<note> x Address all correspondence to the second author: </note>
 <address> 570 Cory Hall, Dept. of EECS, U.C.Berkeley, Berkeley, CA 94720. </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> TIME-FREQUENCY SIGNAL MODELS FOR MUSIC ANALYSIS,TRANSFORMATION, AND SYNTHESIS </title>
<author> Michael Goodwin Martin Vetterli </author>
<affiliation> Department of Electrical Engineering and Computer Science &amp; Center for New Music and Audio TechnologiesUniversity of California at Berkeley </affiliation>
<abstract> ABSTRACTIn signal analysis-synthesis, the analysis derives a set of parameters that the synthesis uses to reconstruct the originalsignal. In musical applications, this reconstruction shouldbe perceptually accurate, and the parameterization shouldallow for such desirable signal modifications as time-scaling,pitch-shifting, and cross-synthesis; the analysis parametersshould correspond to a signal model that is flexible enoughto allow these transformations. Sinusoidal modeling meetsthis flexibility requirement, but has difficulty representingsome salient features of musical signals such as attack transients and noiselike processes. In this paper, sinusoidalmodeling is reviewed and some variations are proposed toaccount for its shortcomings; also, wavelet-based representations of musical signals are considered. </abstract>
<intro> 1. SIGNAL MODELING FOR MUSIC </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Reactive Modules </title>
<author> Rajeev Alur Thomas A. Henzinger  </author>
<abstract> Abstract. We present a formal model for concurrent systems. The model representssynchronous and asynchronous components in a uniform framework that supports compositional (assume-guarantee) and hierarchical (stepwise-refinement) design and verification. While synchronous models are based on a notion of atomic computation step,and asynchronous models remove that notion by introducing stuttering, our model isbased on a flexible notion of what constitutes a computation step: by applying an abstraction operator to a system, arbitrarily many consecutive steps can be collapsed intoa single step. The abstraction operator, which may turn an asynchronous system into asynchronous one, allows us to describe systems at various levels of temporal detail. Fordescribing systems at various levels of spatial detail, we use a hiding operator that mayturn a synchronous system into an asynchronous one. We illustrate the model with diverse examples from synchronous circuits, asynchronous shared-memory programs, andsynchronous message-passing protocols. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Capacity, Mutual Information, and Codingfor Finite-State Markov Channels </title>
<author> Andrea J. Goldsmith, Member, IEEE and Pravin P. Varaiya, Fellow, IEEE  </author>
<abstract> AbstractThe Finite-State Markov Channel (FSMC) is a discrete-time varying channel whose variation is determined by a finite-state Markov process. These channels have memory due to theMarkov channel variation. We obtain the FSMC capacity as a function of the conditional channelstate probability. We also show that for i.i.d. channel inputs, this conditional probability convergesweakly, and the channel's mutual information is then a closed-form continuous function of the inputdistribution.We next consider coding for FSMCs. In general, the complexity of maximum-likelihooddecoding grows exponentially with the channel memory length. Therefore, in practice, interleavingand memoryless channel codes are used. This technique results in some performance loss relativeto the inherent capacity of channels with memory. We propose a maximum-likelihood decision-feedback decoder with complexity that is independent of the channel memory. We calculate thecapacity and cutoff rate of our technique, and show that it preserves the capacity of certain FSMCs.We also compare the performance of the decision-feedback decoder with that of interleaving andmemoryless channel coding on a fading channel with 4PSK modulation. </abstract>
<keyword> Index Terms: Finite-State Markov Channels, Capacity, Mutual Information, Decision-FeedbackMaximum-Likelihood Decoding. </keyword>
<note> Work supported in part by an IBM graduate fellowship, and in part by the PATH program, Institute of Transportation Studies, University of California, Berkeley.A. Goldsmith is with the Department of Electrical Engineering, California Institute of Technology, Pasadena, CA91125.P. Varaiya is with the Department of Electrical Engineering and Computer Science, University of California,Berkeley, CA 94720. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> What's Decidable about Hybrid Automata? </title>
<author> Thomas A. Henzinger 2 Peter W. Kopke 2 Anuj Puri 3 Pravin Varaiya 3 </author>
<abstract> Abstract. Hybrid automata model systems with bothdigital and analog components, such as embedded control programs. Many verification tasks for such programscan be expressed as reachability problems for hybrid automata. By improving on previous decidability and undecidability results, we identify the precise boundary between decidability and undecidability of the reachabilityproblem for hybrid automata.On the positive side, we give an (optimal) PSPACEreachability algorithm for the case of initialized rectangular automata, where all analog variables follow trajectories within piecewise-linear envelopes and are reinitializedwhenever the envelope changes. Our algorithm is basedon a translation of an initialized rectangular automatoninto a timed automaton that defines the same timed language. The translation has practical significance for verification, because it guarantees the termination of symbolicprocedures for the reachability analysis of initialized rectangular automata.On the negative side, we show that several slight generalizations of initialized rectangular automata lead to anundecidable reachability problem. In particular, we provethat the reachability problem is undecidable for timed automata with a single stopwatch. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Analysis of Geographical Push-Caching +L </title>
<author> James Gwertzman, </author>
 <affiliation> Microsoft Corporation </affiliation>
<author> Margo Seltzer, </author>
 <affiliation> Harvard University </affiliation>
<abstract> AbstractMost caching schemes in wide-area, distributed systems are client-initiated. Decisions of when andwhere to cache information are made without the benefit of the server's global knowledge of the usagepatterns. In this paper, we present a new caching strategy: geographical push-caching. Using the server'sglobal knowledge and a derived network topology, we distribute data to cooperating servers. The WorldWide Web is an example of a wide-area system that will benefit from distance-sensitive caching, and wepresent an architecture that allows a Web server to autonomously replicate HTML pages. We use a trace-driven simulation to evaluate several competing caching strategies. Our results show that geographicalpush-caching reduces bandwidth consumption and sever load by the same amount as web proxy caching,but with a savings in global cache space of almost two orders of magnitude. More importantly, serversthat wish to reduce Internet bandwidth consumption and their load can do so without waiting for webproxies to be implemented world-wide. Furthermore, geographical push-caching helps distribute serverload for all web servers, not just the most popular as is the case with proxy caching. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in the 10th International Parallel Processing Symposium, April 1996. 1 </note>
<title> Modeling the Communication Performance of the IBM SP2 </title>
<author> Gheith A. Abandah Edward S. Davidson </author>
<affiliation> Advanced Computer Architecture Laboratory, Department of EECSUniversity of Michigan </affiliation>
<address> 1301 Beal Avenue, Ann Arbor, MI 48109-2122 </address>
<email> gabandah,davidson@eecs.umich.edu </email>
<abstract> AbstractThe objective of this paper is to develop models thatcharacterize the communication performance of a message-passing multicomputer by taking the IBM SP2 as a casestudy. The paper evaluates and models the three aspectsof the communication performance: scheduling overhead,message-passing time, and synchronization overhead. Performance models are developed for the basic communication patterns, enabling the estimation of the communicationtimes of a message-passing application. Such estimates facilitate activities such as application tuning, selection of thebest available implementation technique, and performancecomparisons among different multicomputers. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Efficient Formulation for Optimal Modulo Schedulers </title>
<author> Alexandre E. Eichenberger Edward S. Davidson </author>
<affiliation> ECE Department EECS DepartmentNorth Carolina State University University of Michigan </affiliation>
<address> Raleigh, NC 27695-7911 Ann Arbor, MI 48109-2122 </address>
<email> alexe@eos.ncsu.edu davidson@eecs.umich.edu </email>
<abstract> AbstractModulo scheduling algorithms based on optimalsolvers have been proposed to investigate and tune theperformance of modulo scheduling heuristics. Whilerecent advances have broadened the scope for whichthe optimal approach is applicable, this approachincreasingly suffers from large execution times. In thispaper, we propose a more efficient formulation of themodulo scheduling space that significantly decreasesthe execution time of solvers based on integer linearprograms. For example, the total execution time isreduced by a factor of 8.6 when 782 loops from thePerfect Club, SPEC, and Livermore Fortran Kernelsare scheduled for minimum register requirements usingthe more efficient formulation instead of the traditionalformulation. Experimental evidence further indicatesthat significantly larger loops can be scheduled underrealistic machine constraints. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Chromaticity Space for Specularity, IlluminationColor- and Illumination Pose-Invariant 3-D ObjectRecognition </title>
<author> Daniel Berwick and Sang Wook Lee </author>
<email> (dberwick@umich.edu and swlee@umich.edu) </email>
<affiliation> Dept. of Electrical Enginnering and Computer ScienceUniversity of Michigan </affiliation>
<address> Ann Arbor, MI 48104 </address>
<abstract> AbstractMost of the recent color recognition/indexing approaches concentrate on establishing invariance to illumination color to improve the utility of color recognition. However, other effects caused by illumination pose and specularity on three-dimensionalobject surfaces have not received notable attention. We present a chromaticity recognition method that discounts the effects of illumination pose, illumination color andspecularity. It utilizes a chromaticity space based on log-ratio of sensor responses forillumination pose and color invariance. A model-based specularity detection/rejectionalgorithm can be used to improve the chromaticity recognition and illumination estimation for objects including specular reflections. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Scalable Key Distribution Hierarchy </title>
<author> Patrick McDaniel Sugih Jamin </author>
<affiliation> Electrical Engineering and Computer Science DepartmentUniversity of Michigan </affiliation>
<address> Ann Arbor, MI 48109-2122 </address>
<email> fpdmcdan,jaming@eecs.umich.edu </email>
<date> April 13, 1998 </date>
<abstract> AbstractAs the use of the Internet for electronic commerce, audioand video conferencing, and other applications with sensitive content grows, the need for secure services becomescritical. Central to the success of these services is the support for secure public key distribution. Although there areseveral existing services available for this purpose, theyare not very scalable, either because they depend on a centralized server or rely on ad hoc trust relationships.In this paper, we present and examine a flexible approach to certificate distribution scalable to arbitrarilylarge networks. We propose a two level hierarchy wherecertificates can be independently authenticated by one ormore peer authorities, called keyservers. Certificates forend-user and host entities are managed within local domains, called enterprises. By administering certificatesclose to the source, we reduce the load on the key serversand the effects of network topology changes. We describethe design of our system and present a preliminary performance analysis based on traces of present-day DNS requests. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To Appear in AI Magazine,Summer/Fall 1994. </note>
<title> An Introduction to Least CommitmentPlanning </title>
<author> Daniel S. Weld 1 </author>
<affiliation> Department of Computer Science and EngineeringUniversity of Washington </affiliation>
<address> Seattle, WA 98195 </address>
<email> weld@cs.washington.edu </email>
<abstract> AbstractRecent developments have clarified the process of generating partially ordered, partially specified sequences of actions whose executionwill achive an agent's goal. This paper summarizes a progression ofleast commitment planners, starting with one that handles the simple strips representation, and ending with one that manages actionswith disjunctive precondition, conditional effects and universal quantification over dynamic universes. Along the way we explain howChapman's formulation of the Modal Truth Criterion is misleadingand why his NP-completeness result for reasoning about plans withconditional effects does not apply to our planner. </abstract>
<note> 1 I thank Franz Amador, Tony Barrett, Darren Cronquist, Denise Draper, Ernie Davis, </note>
</NEW_HEADER>
<NEW_HEADER>
<title> A Novel Framework for Decentralized Supervisory Control with Communication </title>
<author> George Barrett </author>
<email> grbarret@eecs.umich.edu </email>
<author> Stephane Lafortune </author>
<email> stephane@eecs.umich.edu </email>
<affiliation> Department of Electrical Engineering and Computer ScienceThe University of Michigan </affiliation>
<address> 1301 Beal AvenueAnn Arbor, MI 48109-2122 </address>
<abstract> ABSTRACTThe decentralized control problem that we address inthis paper is that of several communicating supervisorycontrollers, each with different information, working inconcert to exactly achieve a given legal sublanguage ofthe uncontrolled system's language model. We presenta novel information structure formalism for dealing withthis class of problems. Preliminary results are presentedwhich elucidate a fundamental concept in decentralizedcontrol problems: the importance of controllers anticipating future possible communications. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> MDARTS: A Multiprocessor Database Architecture for Real-TimeSystems </title>
<affiliation> Real-Time Computing LaboratoryComputer Science and Engineering DivisionDepartment of Electrical Engineering and Computer ScienceThe University of Michigan </affiliation>
<address> Ann Arbor, Michigan 48109-2122 </address>
<phone> (313) 763-0391 </phone><abstract> ABSTRACTSome of the advanced real-time systems being proposed, such as the Next Generation Workstation/MachineController (NGC) for automated factories, require a built-in database to support concurrent data access and providewell-defined interfaces between software modules. However, conventional database systems do not provide the performance levels or response time guarantees needed by real-time applications. To address the need for high-performancereal-time database systems, we propose to design, implement, and evaluate an object-oriented software system calledMultiprocessor Database Architecture for Real-Time Systems (MDARTS). An important feature of MDARTS is thatit supports explicit specification of real-time requirements and semantic constraints at an object-granularity level.The database examines these specifications at runtime during application initialization and dynamically adjustsits data management strategy accordingly to provide hard real-time guarantees. For maximum performance onshared-memory multiprocessors, MDARTS supports concurrent, direct, shared-memory data access. Prior real-timedatabase systems do not support per-object dynamic configuration during initialization, and they either work only onuniprocessors or use relatively slow inter-process communication for all transactions. The unique design of MDARTSwill support a transaction execution time two to three orders of magnitude faster than current real-time databasesystems for multiprocessors. For data access with less stringent timing constraints, MDARTS also supports remotetransactions across networks and provides interfaces to external database systems. Once we have implemented thebasic MDARTS architecture, we will demonstrate its capabilities by using it to develop distributed, open architecturecontrollers for actual manufacturing machine tools. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Internet Routing Instability </title>
<author> Craig Labovitz, G. Robert Malan, and Farnam Jahanian </author>
<affiliation> University of MichiganDepartment of Electrical Engineering and Computer Science </affiliation>
<address> 1301 Beal Ave.Ann Arbor, Michigan 48109-2122 </address>
<email> flabovit, rmalan, farnamg@eecs.umich.edu </email>
<abstract> AbstractThis paper examines the network inter-domain routing information exchanged between backbone service providers atthe major U.S. public Internet exchange points. Internetrouting instability, or the rapid fluctuation of network reach-ability information, is an important problem currently facing the Internet engineering community. High levels of network instability can lead to packet loss, increased networklatency and time to convergence. At the extreme, high levels of routing instability have lead to the loss of internalconnectivity in wide-area, national networks. In this paper,we describe several unexpected trends in routing instability,and examine a number of anomalies and pathologies observed in the exchange of inter-domain routing information.The analysis in this paper is based on data collected fromBGP routing messages generated by border routers at fiveof the Internet core's public exchange points during a ninemonth period. We show that the volume of these routing updates is several orders of magnitude more than expected andthat the majority of this routing information is redundant,or pathological. Furthermore, our analysis reveals severalunexpected trends and ill-behaved systematic properties inInternet routing. We finally posit a number of explanationsfor these anomalies and evaluate their potential impact onthe Internet infrastructure. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Spheres of Control:An Approach to Advanced Recovery </title>
<author> C. Wallace N. Soparkar </author>
<affiliation> Electrical Engineering &amp; Computer ScienceThe University of Michigan </affiliation>
<address> Ann Arbor, MI 48109-2122USA </address>
<email> fwallace,soparkarg@eecs.umich.edu </email>
<abstract> AbstractRecovery from failures and erroneous executions is a crucial but complicated issue for concurrently accessed data systems. Increasingly sophisticated techniques are being developed to improve performanceand functionality of recovery protocols. To better understand and analyze recovery schemes, we reexamine the concept of spheres of control [Dav78], using it as a unifying framework for specifying diverserecovery models simply and precisely. We constrain sphere-of-control formulations appropriately to capture transaction-oriented recovery in both centralized and distributed environments and with differenttypes of schedules, as well as semantics-based recovery and compensation. In addition, we discuss howthe operational semantics methodology of evolving algebras [Gur95] can model spheres of control formallyand refine them to lower levels of abstraction. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Distributed Pipeline Scheduling: End-to-End Analysis ofHeterogeneous, Multi-Resource Real-Time Systems </title>
<author> Saurav Chatterjee and Jay Strosnider </author>
<affiliation> Department of Electrical &amp; Computer EngineeringCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<note> This research was supported in part by a grant from the Officeof Naval Research, in part by a grant from the Naval Researchand Development Laboratory, and in part by a grant fromSiemens Corporate Research.In 15th IEEE International Conference on Distributed Computing Systems, May 1995. </note>
<abstract> AbstractThis paper presents an hierarchical end-to-endanalysis technique that decomposes the very complexheterogeneous multi-resource scheduling problem intoa set of single resource scheduling problems with welldefined interactions. We define heterogeneity both inresource types, e.g., CPU, and in scheduling policies,e.g., rate-monotonic scheduling. This analysistechnique is one phase of our systems integrationframework for designing large-scale, heterogeneous,distributed real-time systems whose timing propertiescan be strictly controlled and analyzed. This approach,denoted the Distributed Pipelining Framework,exploits the natural pipelining execution pattern foundin a large number of continuous (periodic) applicationsexecuting over heterogenous resources. A teleconference application is used in this paper to show theutility of the approach. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Modelling rational inquiry in non-ideal agents </title>
<author> Antonio Moreno </author>
<affiliation> Escola Tecnica Superior d'EnginyeriaDepartament d'Enginyeria InformaticaUniversitat Rovira i Virgili (URV) </affiliation>
<address> Carretera de Salou, s/n. 43006-Tarragona </address>
<email> amoreno@etse.urv.es </email>
<abstract> AbstractThe construction of rational agents is one of the goals that has been pursued inArtificial Intelligence (AI). In most of the architectures that have been proposed forthis kind of agents, its behaviour is guided by its set of beliefs. In our work, rationalagents are those systems that are permanently engaged in the process of rationalinquiry; thus, their beliefs keep evolving in time, as a consequence of their internalinference procedures and their interaction with the environment. Both AI researchersand philosophers are interested in having a formal model of this process, and this isthe main topic in our work.Beliefs have been formally modelled in the last decades using doxastic logics. Thepossible worlds model and its associated Kripke semantics provide an intuitive semantics for these logics, but they seem to commit us to model agents that are logicallyomniscient and perfect reasoners. We avoid these problems by replacing possibleworlds by conceivable situations, which are all the situations that the modelled agentis capable of considering.In this document we show how this notion of conceivable situations may be usedto model the process of rational inquiry in which a non-ideal rational agent is engaged. We define a wide class of agents, called rational inquirers, which are a generalabstraction of any kind of non-ideal agent. We show how the beliefs of these kind ofagents evolve in time as a consequence of a multi-dimensional belief analysis, and weuse the framework of conceivable situations in order to model this evolution. </abstract>
<keyword> Keywords: rational inquiry, doxastic logics, logical omniscience, perfect reasoning, possibleworlds, Kripke semantics, dynamic multi-dimensional belief analysis </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Some Geographical Applications ofGenetic Programming on the Cray T3DSupercomputer </title>
<author> I. Turton, S. Openshaw and G. Diplock </author>
<affiliation> School of Geography, University of Leeds, </affiliation>
 <address> Leeds, UK </address>
<email> email: ian@geog.leeds.ac.uk, stan@geog.leeds.ac.uk, gary@geog.leeds.ac.uk </email>
<date> April 15, 1996 </date>
<abstract> AbstractThe paper describes some geographical applications of a parallel GP codewhich is run on a Cray T3D 512 processor supercomputer to create newtypes of well performing mathematical models. A series of results are described which allude to the potential power of the method for which thereare many practical applications in spatial data rich environments wherethere are no suitable existing models and no soundly based theoreticalframework on which to base them. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Simulation of Simplicity:A Technique to Cope with Degenerate Casesin Geometric Algorithms 1 </title>
<author> Herbert Edelsbrunner 2 and Ernst Peter Mucke 2 </author>
<abstract> AbstractThis paper describes a general-purpose programming technique, called the Simulation ofSimplicity, which can be used to cope with degenerate input data for geometric algorithms.It relieves the programmer from the task to provide a consistent treatment for every singlespecial case that can occur. The programs that use the technique tend to be considerablysmaller and more robust than those that do not use it. We believe that this technique willbecome a standard tool in writing geometric software. </abstract>
<keyword> Keywords: Computational geometry, degenerate data, implementation, programmingtool, perturbation, determinants, symbolic computation. </keyword>
<note> ACM Transactions on Graphics, 9(1):66-104, 1990.1 Research of both authors was supported by Amoco Foundation Faculty Development Grant CS 1-6-44862. It </note>
</NEW_HEADER>
<NEW_HEADER>
<note> , , 1-30 ()c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. </note>
<title> On the Optimality of the Simple BayesianClassifier under Zero-One Loss </title>
<author> PEDRO DOMINGOS </author>
 <email> pedrod@ics.uci.edu </email>
<author> MICHAEL PAZZANI </author>
 <email> pazzani@ics.uci.edu </email>
<affiliation> Department of Information and Computer Science, University of California, </affiliation>
 <address> Irvine, CA 92697 </address>
<note> Editor: Gregory Provan </note>
<abstract> Abstract. The simple Bayesian classifier is known to be optimal when attributes are independentgiven the class, but the question of whether other sufficient conditions for its optimality exist hasso far not been explored. Empirical results showing that it performs surprisingly well in manydomains containing clear attribute dependences suggest that the answer to this question may bepositive. This article shows that, although the Bayesian classifier's probability estimates are onlyoptimal under quadratic loss if the independence assumption holds, the classifier itself can beoptimal under zero-one loss (misclassification rate) even when this assumption is violated by awide margin. The region of quadratic-loss optimality of the Bayesian classifier is in fact a second-order infinitesimal fraction of the region of zero-one optimality. This implies that the Bayesianclassifier has a much greater range of applicability than previously thought. For example, in thisarticle it is shown to be optimal for learning conjunctions and disjunctions, even though theyviolate the independence assumption. Further, studies in artificial domains show that it will oftenoutperform more powerful classifiers for common training set sizes and numbers of attributes, evenif its bias is a priori much less appropriate to the domain. This article's results also imply thatdetecting attribute dependence is not necessarily the best way to extend the Bayesian classifier,and this is also verified empirically. </abstract>
<keyword> Keywords: Simple Bayesian classifier, naive Bayesian classifier, zero-one loss, optimal classification, induction with attribute dependences </keyword>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> STATISTICAL LANGUAGE MODELING FOR SPEECH DISFLUENCIES </title>
<author> Andreas Stolcke Elizabeth Shriberg </author>
<affiliation> Speech Technology and Research LaboratorySRI International, </affiliation>
 <address> Menlo Park, CA 94025 </address>
<email> stolcke@speech.sri.comees@speech.sri.com </email>
<abstract> ABSTRACTSpeech disfluencies (such as filled pauses, repetitions, restarts) areamong the characteristics distinguishing spontaneous speech fromplanned or read speech. We introduce a language model that predicts disfluencies probabilistically and uses an edited, fluent contextto predict following words. The model is based on a generalizationof the standard N-gram language model. It uses dynamic programming to compute the probability of a word sequence, taking intoaccount possible hidden disfluency events. We analyze the model's performance for various disfluency types on the Switchboardcorpus. We find that the model reduces word perplexity in theneighborhood of disfluency events; however, overall differencesare small and have no significant impact on recognition accuracy.We also note that for modeling of the most frequent type of dis-fluency, filled pauses, a segmentation of utterances into linguistic(rather than acoustic) units is required. Our analysis illustrates agenerally useful technique for language model evaluation based onlocal perplexity comparisons. </abstract>
<intro> 1. MOTIVATION AND OVERVIEW </intro>
</NEW_HEADER>
<NEW_HEADER>
<affiliation> INTERNATIONAL COMPUTER SCIENCE INSTITUTE </affiliation>
<address> I 1947 Center St. * Suite 600 * Berkeley, California 94704-1198 * </address>
 <phone> (510) 643-9153 * FAX (510) 643-7684 </phone><title> Some MPEG Decoding Functionson SpertAn Example for AssemblyProgrammers </title>
<author> Arno Formella </author>
<pubnum> TR-94-027 </pubnum>
<date> October 1994 </date>
<abstract> AbstractWe describe our method how to implement C-program sequences in torrent (T0)assembler code while there is no efficient automatic tool. We use re-structuring ofthe source code, vectorization, dataflow graphs, a simple scheduling strategy and astraight forward register allocation algorithm. We define some lower and an upperbound for the expected run time. For two functions, namely the color transformationand reverse DCT, we achieve almost 54, respectively 16 times the performance of aSparc 2 workstation. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Getting a Grip: A Computational Model of theAcquisition of Verb Semantics for Hand Actions </title>
<author> David Bailey </author>
<affiliation> Computer Science Division, Univ. of California at Berkeleyand International Computer Science Institute </affiliation>
<address> 1947 Center St. Suite 600, Berkeley CA 94704 </address>
<email> dbailey@icsi.berkeley.edu </email>
<abstract> AbstractWe present a computational model of how verbs might be learned withinthe limited domain of hand actions. We hypothesize that such verbs refer tothe activities of underlying motor schemas, and leverage this constraint tobuild a system with strong enough biases that it can learn from a reasonablysmall number of examples, while still having adequate flexibility to learn thehand-action verbs of any language. The completed system should demonstrate its knowledge both by labelling its own behavior and by carrying outverbal commands in a simulated world. </abstract>
<intro> 1 Overview </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Storage of Two and Three Dimensional Raster Type Data forOptimized Retrieval of One, Two or Three Dimensional Features </title>
<author> Kjell Bratbergsengen </author>
<affiliation> Department of Computer Systems and Information ScienceNorwegian University of Science and Technology, </affiliation>
 <address> Trondheim, Norway </address>
<email> email: kjellb@idi.ntnu.no </email>
<abstract> AbstractWe are analyzing storage structures for two and three dimensional raster type data which are usedfor feature retrieval. The features are one, two or three dimensional objects with regular outlineslike a rectangle or a prism. The features could be parts of a map or image, an area of specialinterest for searching after oil, a sequence of ultra sound images, and so on. The storage mediumis magnetic disk. The data are stored in chunks or blocks representing a regular part of the sourceobject. We analyze the shape and the size to minimize the cost of retrieval. The optimization isbased on minimum time to do retrieval. We have five combinations: Lines and areas from areas andvolumes, and volumes from volumes. The optimal block sizes for random retrieval varies, with case,feature size and disk characteristics. One general observation is that longer disk tracks gives largerblocks. For line retrieval the optimal block size is only depending on disk track length. For othercases it is also depending on the feature size. For partly sequential retrieval the block size is not theactual block size used during retrieval, but the smallest addressing unit, and the optimal addressingunit could be rather small.The analysis reveals that using too small blocks could be very costly. The time could easilydouble or triple if small blocks are used. In many cases the optimal block size is several tracks. </abstract>
<keyword> Keywords: storage and retrieval, matrix, optimization </keyword>
<intro> 1 Problem Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Video Server on an ATM Connected Cluster of Workstations </title>
<author> Olav Sandsta, Stein Langrgen, and Roger Midtstraum </author>
<affiliation> Department of Computer and Information ScienceNorwegian University of Science and Technology </affiliation>
<address> N-7034 Trondheim, Norway </address>
<email> folavsa, steinl, rogerg@idi.ntnu.no </email>
<abstract> AbstractVideo servers are important for applications which makeuse of digital video. The video servers should provide betterfunctionality than most of today's video servers offer, - e.g.,support of flexible and instant user interactions, delivery ofmultiple video formats and support of virtual video documents. In this paper we discuss the requirements that videoservers should fulfill and we describe the design and implementation of the Elvira video server. The Elvira video serveris built on a cluster of standard UNIX workstations interconnected by an ATM switch. The capacity of the Elvira serveris evaluated and we show the effects of different strategiesfor allocation of video data across nodes and disks. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Write Optimized Object-Oriented Database Systems </title>
<author> Kjetil Nrvag and Kjell Bratbergsengen </author>
<affiliation> Department of Computer and Information ScienceNorwegian University of Science and Technology </affiliation>
<address> 7034 Trondheim, Norway </address>
<email> fnoervaag, kjellbg@idi.ntnu.no </email>
<abstract> AbstractIn a database system, read operations are much morecommon than write operations, and consequently, databasesystems have been read optimized. As the size of main memory increases, more of the database read requests will be satisfied from the buffer system, and the amount of disk writeoperations relative to disk read operations will increase.This calls for a focus on write optimized database systems.In this paper, we present solutions to this problem. We describe in detail the data structures and algorithms neededto realize a write optimized object-oriented database systemin the context of Vagabond, an OODB currently being implemented at our department. In Vagabond, focus has beento provide support for applications which have earlier usedfile systems because of the limited data bandwidth in currentdatabase systems, typical examples are super computing applications and geographical information systems </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On the Computational Requirements ofVirtual Reality Systems 1 </title>
<author> Frank Devai </author>
<affiliation> School of Computing &amp; Mathematics, University of Ulster </affiliation>
<abstract> AbstractThe computational requirements of high-quality, real-time rendering exceeds the limits ofgenerally available computing power. However illumination effects, except shadows, areless noticeable on moving pictures. Shadows can be produced with the same techniquesused for visibility computations, therefore the basic requirements of real-time renderingare transformations, pre-selection of the part of the scene to be displayed and visibilitycomputations. Transformations scale well, ie, their time requirement grows linearly withthe input size. Pre-selection, if implemented by the traditional way of polygon clipping,has a growing rate of N log N in the worst case, where N is the total number of edges inthe scene. Visibility computations, exhibiting a quadratic growing rate, are the bottleneckfrom a theoretical point of view. Three approaches are discussed to speed up visibilitycomputations: (i) reducing the expected running time to O(N log N ) (ii) using approximation algorithms with O(N K) worst-case time, where K is the linear resolution of theimage, and (iii) applying parallel techniques leading to logarithmic time in the worst-case.Though the growing rate of the time requirement of pre-selection is significantly slowerthan that of visibility, it is demonstrated that pre-selection has to deal with a significantlyhigher amount of data than visibility computations, as the average clipping volume is 1/27of the volume of the model. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Signal and Image Processing in Java </title>
<author> Jonathan Campbell and Fionn Murtagh </author>
<affiliation> University of Ulster, Magee College, </affiliation>
 <address> Derry, BT48 7JL </address>
<email> email: jg.campbell@ulst.ac.uk. </email>
<note> Revisions available from </note>
<web> http://www.infm.ulst.ac.uk/research/preprints.html </web>
<note> Original paper presented at IMVIP '97University of Ulster, Magee College, Derry10-13 September 1997. </note>
<date> 9 September 1997 </date>
<note> Revised 20 September 1997Revised 6 November 1997 </note>
<abstract> AbstractWe describe the implementation of a multi-purpose data analysis laboratory, DataLab-J, inthe programming language Java. We briefly trace the stages of the evolution of DataLab from aFORTRAN-IV system in 1973 to the current Java development. Description of this evolution allowsus to discuss some key design and functionality decisions and issues that arose throughout the years;many of these issues remain topical, so, in addition to an evaluation of Java, we identify and discusswhat are for us the major issues in the design of such software. Moreover, we address questionsraised by the need to convert legacy systems, e.g. those programmed in C and various versions ofFORTRAN. The experience of redesign and implementation in Java is described, together with abrief evaluation of the suitability of Java for 'number-crunching'. Overall conclusions are drawn,regarding design of such software, lessons learned, traps to avoid, and on Java itself. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Rule-Based CQL for 2-Dimensional Tables </title>
<author> Mohand-Sad Hacid, Patrick Marcel, and Christophe Rigotti </author>
<affiliation> Laboratoire d'Ingenierie des Systemes d'InformationINSA Lyon, </affiliation>
 <address> B^atiment 501, F-69621 Villeurbanne Cedex </address>
<phone> Tel : 72 43 85 88 Fax: 72 43 87 13 </phone><email> fmohand,patrick,crigg@lisi.insa-lyon.fr </email>
<abstract> Abstract. We describe the core of a rule-based CQL, devoted to themanipulation of 2-dimensional tabular databases. The rules provide asimple and declarative way to restructure and query tables, and the constraints allow to define cell contents by formulas over concrete domains.We define a model-theoretic semantics and develop an equivalent fixpointtheory that leads to a naive evaluation procedure. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> SEE ME, HEAR ME: INTEGRATING AUTOMATIC SPEECH RECOGNITION ANDLIP-READING </title>
<author> Paul Duchnowski 1 Uwe Meier 1 Alex Waibel 1;2 </author>
<affiliation> 1 University of Karlsruhe, </affiliation>
 <address> Karlsruhe, Germany </address>
 <affiliation> 2 Carnegie Mellon University, </affiliation>
 <address> Pittsburgh PA, USA </address>
<abstract> ABSTRACTWe present recent work on integration of visual information (automatic lip-reading) with acoustic speech for better overall speech recognition. A Multi-State Time DelayNeural Network performs the recognition of spelled lettersequences taking advantage of lip images from a standardcamera. The problems addressed include efficient but effective representation of the visual information and optimummanner of combining the two modalities when rendering adecision. We show results for several alternatives to directgray level image as the visual evidence. These are: PrincipalComponents, Linear Discriminants, and DFT coefficients.Dimensionality of the input is decreased by a factor of 12while maintaining recognition rates. Combination of thevisual and acoustic information is performed at three different levels of abstraction. Results suggest that integrationof higher order input features works best. On a continuousspelling task, visual-alone recognition of 45-55%, when combined with acoustic data, lowers audio-alone error rates by30-40%. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Stochastic Case Frame Approach for Natural Language Understanding </title>
<author> Wolfgang Minker, Samir Bennacef, Jean-Luc Gauvain </author>
<affiliation> Spoken Language Processing GroupLIMSI-CNRS </affiliation>
<address> 91403 Orsay cedex, FRANCE </address>
<email> email: fminker,bennacef,gauvaing@limsi.fr </email>
<abstract> ABSTRACTA stochastically based approach for the semantic analysis component of a natural spoken language system for the ATIS task has beendeveloped. The semantic analyzer of the spoken language systemalready in use at LIMSI makes use of a rule-based case grammar. Inthis work, the system of rules for the semantic analysis is replacedwith a relatively simple, first order Hidden Markov Model. Theperformance of the two approaches can be compared because theyuse identical semantic representations despite their rather differentmethods for meaning extraction. We use an evaluation methodologythat assesses performance at different semantic levels, including thedatabase response comparison used in the ARPA ATIS paradigm. </abstract>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Tracking Drifting ConceptsBy Minimizing Disagreements </title>
<author> David P. Helmbold and Philip M. Long  </author>
<affiliation> CIS BoardUC Santa Cruz </affiliation>
<address> Santa Cruz, CA 95064 </address>
<date> March 24, 1994 </date>
<abstract> AbstractIn this paper we consider the problem of tracking a subset of a domain (called the target) whichchanges gradually over time. A single (unknown) probability distribution over the domain is usedto generate random examples for the learning algorithm and measure the speed at which the targetchanges.Clearly, the more rapidly the target moves, the harder it is for the algorithm to maintain a goodapproximation of the target. Therefore we evaluate algorithms based on how much movement ofthe target can be tolerated between examples while predicting with accuracy *. Furthermore, thecomplexity of the class H of possible targets, as measured by d, its VC-dimension, also effects thedifficulty of tracking the target concept.We show that if the problem of minimizing the number of disagreements with a sample fromamong concepts in a class H can be approximated to within a factor k, then there is a simple trackingalgorithm for H which can achieve a probability * of making a mistake if the target movement rateis at most a constant times * 2 =(k(d + k) ln 1* ), where d is the Vapnik-Chervonenkis dimension ofH. Also, we show that if H is properly PAC-learnable, then there is an efficient (randomized)algorithm that with high probability approximately minimizes disagreements to within a factor of7d + 1, yielding an efficient tracking algorithm for H which tolerates drift rates up to a constanttimes * 2 =(d 2 ln 1In addition, we prove complementary results for the classes of halfspaces and axis-aligned hyperrectangles showing that the maximum rate of drift that any algorithm (even with unlimitedcomputational power) can tolerate is a constant times * 2 =d. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Monotonic Measure for OptimalFeature Selection </title>
<author> Huan Liu 1 and Hiroshi Motoda 2 and Manoranjan Dash 3 </author>
<affiliation> 1 Dept of Info Sys &amp; Comp Sci, National University of Singapore, </affiliation>
 <address> Singapore 119260. </address>
<affiliation> 2 Division of Intelligent Sys Sci, Osaka University, </affiliation>
 <address> Ibaraki, Osaka 567, Japan. </address>
<affiliation> 3 BioInformatics Centre, National University of Singapore, </affiliation>
 <address> Singapore 119074. </address>
<email> fliuh, manoranjg@iscs.nus.edu.sg motoda@sanken.osaka-u.ac.jp </email>
<abstract> Abstract. Feature selection is a problem of choosing a subset of relevantfeatures. In general, only exhaustive search can bring about the optimalsubset. With a monotonic measure, exhaustive search can be avoidedwithout sacrificing optimality. Unfortunately, most error- or distance-based measures are not monotonic. A new measure is employed in thiswork that is monotonic and fast to compute. The search for relevantfeatures according to this measure is guaranteed to be complete but notexhaustive. Experiments are conducted for verification. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Understanding Neural Networks via Rule Extraction </title>
<author> Rudy Setiono and Huan Liu  </author>
<affiliation> Department of Information Systems and Computer ScienceNational University of Singapore </affiliation>
<address> Kent Ridge, Singapore 0511 </address>
<email> frudys,liuhg@iscs.nus.sg </email>
<abstract> AbstractAlthough backpropagation neural networksgenerally predict better than decision trees dofor pattern classification problems, they are often regarded as black boxes, i.e., their predictions are not as interpretable as those of decision trees. This paper argues that this is because there has been no proper technique thatenables us to do so. With an algorithm thatcan extract rules 1 , by drawing parallels withthose of decision trees, we show that the predictions of a network can be explained via rules extracted from it, thereby, the network can be understood. Experiments demonstrate that rulesextracted from neural networks are comparable with those of decision trees in terms of predictive accuracy, number of rules and averagenumber of conditions for a rule; they preservehigh predictive accuracy of original networks. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in Expert Systems with Applications: An International Journal, Vol.10(1996) </note>
<title> Efficient Rule Induction from Noise Data </title>
<author> Huan Liu </author>
<affiliation> Department of Information Systems and Computer ScienceNational University of Singapore </affiliation>
<address> Kent Ridge, Singapore 0511 </address>
<email> liuh@iscs.nus.sg </email>
<phone> Tel: (+65)-772-6563; Fax: (+65) 779-4580 </phone>
<note> AcknowledgmentsMany thanks to Rudy Setiono and Tiow Seng Tan for providing valuable comments and help. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in the journal Presence </note>
<date> 06/02/97 4:57 PM 1 </date>
<title> Integrating Pedagogical Agents into Virtual Environments </title>
<author> W. Lewis JohnsonJeff RickelRandy StilesAllen Munro 1 </author>
<abstract> AbstractIn order for a virtual environment to be effective as a training tool, it is not enough toconcentrate on the fidelity of the renderings and the accuracy of the simulated behaviors.The environment should help trainees develop an understanding of the task being trained,and should provide guidance and assistance as needed. This paper describes a system fordeveloping virtual environments in which pedagogical capabilities are incorporated intoautonomous agents that interact with trainees. These pedagogical agents can monitortrainees progress and provide guidance and assistance. The agents interact withsimulations of objects in the environment, and with trainees. The paper describes thearchitectural features of the environment and of the agents that permit the agents to meetinstructional objectives within the virtual environment. It also discusses how agent-basedinstruction is combined with other methods of delivering instruction. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Generating Word Lattices from Abstract Meaning Representation </title>
<author> Irene Langkilde and Kevin Knight </author>
<affiliation> Information Sciences InstituteUniversity of Southern California </affiliation>
<address> Marina del Rey, CA 90292 </address>
<email> ilangkil@isi.edu and knight@isi.edu </email>
<abstract> AbstractLarge-scale generation of natural language requires anabstract meaning representation and a mechanism forintegrating immense amounts of lexical, morphological, grammatical, and conceptual knowledge. Theavailability of corpus-based statistical knowledge motivates the invention of a new style of generation inwhich word lattices compactly encode many possiblesentence renderings and a statistical extractor choosesthe best ones. The focus of generation thus shiftsto how word lattices can be generated from abstractmeaning representation. This paper presents a flexiblemeaning representation scheme and generation mechanism. It includes an efficient generation algorithm andgrammar formalism that maps from a meaning representation to a lattice. This mapping is flexible enoughto allow meaning representation along a continuum ofsemantic depth. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Multicast Congestion Control Mechanism Using Representatives </title>
<author> Dante DeLucia Katia Obraczka </author>
<affiliation> Hughes Research Laboratories USC Information Sciences Institute </affiliation>
<address> 3011 Malibu Canyon Road 4676 Admiralty Way Suite 1001Malibu CA 90265 Marina Del Rey, CA 90292 </address>
<email> email: dante@usc.edu email: katia@isi.edu </email>
<abstract> AbstractIn this paper, we propose a congestion controlmechanism for reliable multicast applications thatuses a small set of group members, or representatives,to provide timely and accurate feedback on behalf ofcongested subtrees of a multicast distribution tree.Our algorithm does not need to compute round-triptime (RTT) from all receivers to the source, nor doesit require knowledge of group membership or networktopology. Through simulations, we evaluate our algorithm with and without TCP cross traffic. This initial evaluation study shows that our algorithm takesadvantage of network bandwidth when available, yetdoes not starve competing flows. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Tool for Massively Replicating Internet Archives:Design, Implementation, and Experience </title>
<author> Katia Obraczka </author>
<affiliation> University of Southern CaliforniaInformation Science Institute </affiliation>
<address> 4676 Admiralty WayMarina del Rey, CA 90292, USA </address>
<email> katia@isi.edu </email>
<author> Peter Danzig, Dante DeLucia, Erh-Yuan Tsai </author>
<affiliation> University of Southern CaliforniaComputer Science Department </affiliation>
<address> Los Angeles, CA 90089-0781 </address>
<email> fdanzig, dante, erhyuantg@usc.edu </email>
<abstract> AbstractThis paper reports the design, implementation, and performance of a scalable and efficient tool to replicate Internet information services. Our tool targets replicationdegrees of tens of thousands of weakly-consistent replicas scattered throughout the Internet's thousands of autonomously administered domains. The main goal of ourreplication tool is to make existing replication algorithmsscale in today's exponentially-growing, autonomously-managed internetworks. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Information Gathering Plans With Sensing Actions </title>
<author> Naveen Ashish and Craig A. Knoblock Alon Levy </author>
<affiliation> Information Sciences Institute and AT&amp;T Bell LaboratoriesDepartment of Computer Science AI Principles Research Dept. </affiliation>
<affiliation> University of Southern California </affiliation>
 <address> 600 Mountain Ave., Room 2A-4404676 Admiralty Way Murray Hill, NJ 07974Marina del Rey, CA 90292 </address>
 <email> levy@research.att.comfashish,knoblockg@isi.edu </email>
<abstract> AbstractInformation gathering agents can automate the task of retrieving and integrating datafrom a large number of diverse information sources. The key issue in their performance isefficient query planning that minimizes the number of information sources used to answera query. Previous work on query planning has considered generating information gatheringplans solely based on compile-time analysis of the query and the models of the informationsources. We argue that at compile-time it may not be possible to generate an efficientplan for retrieving the requested information because of the large number of possiblyrelevant sources. We describe an approach that naturally extends query planning to userun-time information to optimize queries that involve many sources. First, we describe analgorithm for generating a discrimination matrix, which is a data structure that identifiesthe information that can be sensed at run-time to optimize a query plan. Next, we describehow the discrimination matrix is used to decide which of the possible run-time sensingactions to perform. Finally, we demonstrate that this approach yields significant savings(over 90% for some queries) in a real-world task. </abstract>
<note> The first and second authors is supported in part by Rome Laboratory of the Air Force Systems Commandand the Advanced Research Projects Agency under contract no. F30602-94-C-0210, and in part by the NationalScience Foundation under grant number IRI-9313993. The views and conclusions contained in this paper are theauthor's and should not be interpreted as representing the official opinion or policy of ARPA, RL, NSF, AT&amp;TLabs, or any person or agency connected with them. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Rule Induction for Semantic Query Optimization </title>
<author> Chun-Nan Hsu and Craig A. Knoblock </author>
<affiliation> Information Sciences Institute and Department of Computer ScienceUniversity of Southern California </affiliation>
<address> 4676 Admiralty Way, Marina del Rey, CA 90292 </address>
<email> fchunnan,knoblockg@isi.edu </email>
<abstract> AbstractSemantic query optimization can dramatically speed up database query answering byknowledge intensive reformulation. But theproblem of how to learn required semanticrules has not previously been solved. Thispaper describes an approach using an inductive learning algorithm to solve the problem. In our approach, learning is triggeredby user queries and then the system induces semantic rules from the information indatabases. The inductive learning algorithmused in this approach can select an appropriate set of relevant attributes from a potentially huge number of attributes in real-worlddatabases. Experimental results demonstratethat this approach can learn sufficient background knowledge to reformulate queries andprovide a 57 percent average performance improvement. </abstract>
<intro> 1 INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Synergy of Agent Components:Social Comparison for Failure Detection </title>
<author> Gal A. Kaminka Milind Tambe </author>
<affiliation> Information Sciences Institute and Computer Science DepartmentUniversity of Southern California </affiliation>
<address> 4676 Admiralty Way, Marina del Rey, CA 90292 </address>
<email> galk, tambe-@isi.edu </email>
<intro> 1 Overview </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Learning Finite Automata Using Local Distinguishing Experiments +L </title>
<author> Wei-Min Shen </author>
<affiliation> Microelectronics and Computer Technology Corporation </affiliation>
<address> 3500 West Balcones Center DriveAustin, TX 78759, U.S.A. </address>
<abstract> AbstractOne of the open problems listed in [ Rivest andSchapire, 1989 ] is whether and how that thecopies of L in their algorithm can be combined into one for better performance. Thispaper describes an algorithm called D thatdoes that combination. The idea is to representthe states of the learned model using observablesymbols as well as hidden symbols that are constructed during learning. These hidden symbols are created to reflect the distinct behaviorsof the model states. The distinct behaviors arerepresented as local distinguishing experiments(LDEs) (not to be confused with global distinguishing sequences), and these LDEs are created when the learner's prediction mismatchesthe actual observation from the unknown machine. To synchronize the model with the environment, these LDEs can also be concatenated to form a homing sequence. It canbe shown that D can learn, with probability1 ~, a model that is an *-approximation ofthe unknown machine, in a number of actionspolynomial in the size of the environment and </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Adaptive Agent Tracking in Real-worldMulti-Agent Domains: A Preliminary Report </title>
<author> Milind Tambe, Lewis Johnson and Wei-Min Shen </author>
<affiliation> Information Sciences Institute and Computer Science DepartmentUniversity of Southern California </affiliation>
<address> 4676 Admiralty Way, Marina del Rey, CA 90292 </address>
<email> ftambe,johnson,sheng@isi.edu </email>
<date> October 30, 1996 </date>
<abstract> AbstractIntelligent interaction in multi-agent domains frequently requires an agent to track otheragents' mental states: their current goals, beliefs, and intentions. Accuracy in this agenttracking task is critically dependent on the accuracy of the tracker's (tracking agent's) modelof the trackee (tracked agent). Unfortunately, in real-world situations, model imperfectionsarise due to the tracker's resource and information constraints, as well as due to trackees'dynamic behavior modification. While such model imperfections are unavoidable, a trackermust nonetheless attempt to be adaptive in its agent tracking. This article identifies key issuesin adaptive agent tracking and presents an approach called DEFT. At its core, DEFT is basedon discrimination-based learning. The main idea is to identify the deficiency of a model basedon tracking failures, and revise the model by using features that are critical in discriminatingsuccessful and failed tracking episodes. Because in real-world situations the set of candidatediscriminating features is very large, DEFT relies on knowledge-based focusing to limit thediscrimination to those features that it determines were relevant in successful tracking episodeswith an autonomous explanation capability as a major source of this knowledge. This articlereports on experiments with an implementation of key aspects of DEFT in a complex syntheticair-to-air combat domain. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in the Proceedings of the Fifteenth National Conference on Artificial Intelligence (AAAI-98) </note>
<title> Learning to Predict User Operations for Adaptive Scheduling </title>
<author> Melinda T. Gervasio and Wayne Iba and Pat Langley </author>
<affiliation> Institute for the Study of Learning and Expertise </affiliation>
<address> 2164 Staunton Court, Palo Alto, California 94306 </address>
<email> fgervasio,iba,langleyg@isle.org </email>
<abstract> AbstractMixed-initiative systems present the challenge of finding an effective level of interaction between humansand computers. Machine learning presents a promising approach to this problem in the form of systemsthat automatically adapt their behavior to accommodate different users. In this paper, we present an empirical study of learning user models in an adaptiveassistant for crisis scheduling. We describe the problem domain and the scheduling assistant, then presentan initial formulation of the adaptive assistant's learning task and the results of a baseline study. After this,we report the results of three subsequent experimentsthat investigate the effects of problem reformulationand representation augmentation. The results suggestthat problem reformulation leads to significantly better accuracy without sacrificing the usefulness of thelearned behavior. The studies also raise several interesting issues in adaptive assistance for scheduling. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> To appear in Proceedings of the Second International Conference on AI Planning Systems (1994). Chicago: AAAI Press. </note>
<title> Reactive and Automatic Behavior in Plan Execution </title>
<author> Pat Langley Wayne Iba Jeff Shrager </author>
<affiliation> Robotics Laboratory Recom Technologies Palo Alto Research CenterComputer Science Dept. </affiliation>
 <address> Mail Stop 269-2 </address>
 <affiliation> Xerox CorporationStanford University NASA Ames Research Center </affiliation>
 <address> 3333 Coyote Hill RoadStanford, CA 94305 Moffett Field, CA 94035 Palo Alto, CA 94304 </address>
<email> langley@cs.stanford.edu iba@wind.arc.nasa.gov shrager@xerox.com </email>
<abstract> AbstractMuch of the work on execution assumes that the agentconstantly senses the environment, which lets it respondimmediately to errors or unexpected events. In this paper, we argue that this purely reactive strategy is onlyoptimal if sensing is inexpensive, and we formulate a simple model of execution that incorporates the cost of sensing. We present an average-case analysis of this model,which shows that in domains with high sensing cost orlow probability of error, a more `automatic' strategy -one with long intervals between sensing can lead toless expensive execution. The analysis also shows thatthe distance to the goal has no effect on the optimal sensing interval. These results run counter to the prevailingwisdom in the planning community, but they promise amore balanced approach to the interleaving of executionand sensing. </abstract>
<intro> Reactive and Automatic Execution </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Where Do SE-trees Perform? (Part I) </title>
<author> Ron Rymon  </author>
<affiliation> Intelligent Systems Program </affiliation>
<address> 901 Cathedral of Learning </address>
<affiliation> University of Pittsburgh </affiliation>
<address> Pittsburgh, PA 15260 </address>
<email> E-mail: Rymon@ISP.Pitt.edu </email>
<date> March 5, 1995 </date>
<abstract> AbstractAs a classifier, a Set Enumeration (SE) tree can be viewed as a generalization ofdecision trees. We empirically characterize domains in which SE-trees are particularlyadvantageous relative to decision trees. Specifically, we show that:1. SE-trees excel in domains in which relatively few examples are available; and </abstract>
</NEW_HEADER>
<NEW_HEADER>
<title> Advanced Transaction Processing in Multilevel Secure FileStores </title>
<author> Elisa Bertino Sushil Jajodia Luigi Mancini Indrajit Ray x </author>
<abstract> AbstractThe concurrency control requirements for transaction processing in a multilevel secure file system are different from those in conventional transaction processing systems.In particular, there is the need to coordinate transactions at different security levelsavoiding both potential timing covert channels and the starvation of transactions athigher security levels. Suppose a transaction at a lower security level attempts to writea data item that is being read by a transaction at a higher security level. On the onehand, a timing covert channel arises if the transaction at the lower security level is eitherdelayed or aborted by the scheduler. On the other hand, the transaction at the highsecurity level may be subjected to an indefinite delay if it is forced to abort repeatedly.This paper extends the classical two-phase locking mechanism to multilevel securefile systems. The scheme presented here prevents potential timing covert channels andavoids the abort of higher level transactions nonetheless guaranteeing serializability.The programmer is provided with a powerful set of linguistic constructs that supportsexception handling, partial rollback and forward recovery. The proper use of theseconstructs can prevent the indefinite delay in completion of a higher level transaction,and allows the programmer to trade off starvation with transaction isolation. </abstract>
<keyword> Index Terms|Data management system, File system management, Transaction processing, Concurrency control, Two-phase locking, Exception handling, Security kernel,Mandatory access control, Covert channels. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Image Indexing and Retrieval Based onHuman Perceptual Color Clustering  </title>
<author> Yihong Gong, Guido Proietti , and Christos Faloutsos  </author>
<affiliation> Robotics Institute, Carnegie Mellon University </affiliation>
<address> 5000 Forbes Avenue, Pittsburgh, PA 15213 </address>
<email> fygong, proietti, christosg@cs.cmu.edu </email>
<abstract> AbstractWe propose a new image retrieval method basedon human perceptual clustering of color images. Thiscolor clustering produces for each image a small set ofrepresentative colors which captures the color properties of the image, and a small set of sizable contiguousregions which captures the spatial/geometrical properties of the image. The proposed method outperformsthe traditional histogram and its improved methods notonly with its richer image retrieval capabilities whichcover a wider spectrum of user requirements, but alsowith its powerful indexing scheme which is essential tocater for large scale image databases. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, 1995. </note>
<title> Using Introspective Reasoning to Refine Indexing </title>
<author> Susan Fox and David B. Leake </author>
<affiliation> Computer Science Department </affiliation>
<address> Lindley Hall 215 </address>
<affiliation> Indiana University </affiliation>
<address> Bloomington, IN 47405 USA </address>
<email> E-mail: fsfox,leakeg@cs.indiana.edu </email>
<abstract> AbstractIntrospective reasoning about a system's ownreasoning processes can form the basis forlearning to refine those reasoning processes.The ROBBIE 1 system uses introspective reasoning to monitor the retrieval process of acase-based planner to detect retrieval of inappropriate cases. When retrieval problemsare detected, the source of the problems is explained and the explanations are used to determine new indices to use during future caseretrieval. The goal of ROBBIE's learning is toincrease its ability to focus retrieval on relevantcases, with the aim of simultaneously decreasing the number of candidates to consider andincreasing the likelihood that the system will beable to successfully adapt the retrieved cases tofit the current situation. We evaluate the benefits of the approach in light of empirical resultsexamining the effects of index learning in theROBBIE system. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> ACCESSIBILITY UNDER SAMPLING </title>
<author> * Eduardo D. Sontag ** Hector J. Sussmann </author>
<affiliation> Department of MathematicsRutgers University </affiliation>
<address> New Brunswick, NJ 08903 </address>
<abstract> ABSTRACTThis note addresses the following problem: Find conditions under which a continuous-time (nonlinear)system gives rise, under constant rate sampling, to a discrete-time system which satisfies the accessibilityproperty. </abstract>
<note> * Research supported in part by US Air Force Grant AFOSR 80-0196** Research supported in part under an NSF Grant </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> NEURAL NETWORKS FOR CONTROL </title>
<author> Eduardo D. Sontag </author>
<affiliation> Department of Mathematics, Rutgers University </affiliation>
<address> New Brunswick, NJ 08903, USA </address>
<abstract> AbstractThis paper starts by placing neural net techniques in a general nonlinearcontrol framework. After that, several basic theoretical results on networksare surveyed. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Global Stabilization of Linear Discrete-Time Systemswith Bounded Feedback </title>
<author> Yudi Yang </author>
<affiliation> IBM, </affiliation>
<address>  MD3401311 Mamaroneck AveWhite Plains, NY 10605 </address>
<email> yudiy@vnet.ibm.com </email>
<author> Eduardo D. Sontag  </author>
<affiliation> Department of MathematicsRutgers University </affiliation>
<address> New Brunswick, NJ 08903 </address>
<email> sontag@hilbert.rutgers.edu </email>
<author> Hector J. Sussmann  </author>
<affiliation> Department of MathematicsRutgers University </affiliation>
<address> New Brunswick, NJ 08903 </address>
<email> sussmann@hilbert.rutgers.edu </email>
<abstract> AbstractThis paper deals with the problem of global stabilization of linear discrete time systems by means ofbounded feedback laws. The main result proved is an analog of one proved for the continuous time caseby the authors, and shows that such stabilization is possible if and only if the system is stabilizablewith arbitrary controls and the transition matrix has spectral radius less or equal to one. The proofprovides in principle an algorithm for the construction of such feedback laws, which can be implementedeither as cascades or as parallel connections ("single hidden layer neural networks") of simple saturationfunctions. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Construction of a CipherFrom a Single Pseudorandom Permutation </title>
<author> Shimon Even 1 and Yishay Mansour 2 </author>
<abstract> AbstractWe suggest a scheme for a block cipher which uses only one randomly chosen permutation, F . The key, consisting of two blocks, K 1and K 2 is used in the following way: The message block is XORedwith K 1 before applying F , and the outcome is XORed with K 2 , toproduce the cryptogram block. We show that the resulting cipheris secure (when the permutation is random or pseudorandom). Thisremoves the need to store, or generate a multitude of permutations. </abstract>
<affiliation> 1 Comp. Sci. Dept., Technion, Israel Institute of Technology, </affiliation>
 <address> Haifa, Israel 32000. </address>
</NEW_HEADER>
<NEW_HEADER>
<title> ON COMPUTABLE BELIEFS OF RATIONAL MACHINES </title>
<author> Nimrod Megiddo  </author>
<abstract> Abstract. Traditional decision theory has assumed that agents have complete, consistent and readily available beliefs and preferences. Obviously, even ifan expert system has complete and consistent beliefs, it cannot have them readilyavailable. Moreover, some beliefs about beliefs are not even approximately computable. It is shown that if all players have complete and consistent beliefs, theycan compute approximate beliefs about beliefs of any order by considering eventsarbitrarily close in some well-defined sense to the ones in question. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Constructing Small Sample Spaces Satisfying GivenConstraints </title>
<author> Daphne Koller  </author>
<email> e-mail: daphne@cs.stanford.edu </email>
<author> Nimrod Megiddo  </author>
<email> e-mail: megiddo@almaden.ibm.com </email>
<abstract> AbstractAbstract. The subject of this paper is finding small sample spaces for joint distributions ofn discrete random variables. Such distributionsare often only required to obey a certain limited set of constraints of the form P r(E) = .We show that the problem of deciding whetherthere exists any distribution satisfying a givenset of constraints is NP-hard. However, if theconstraints are consistent, then there exists a distribution satisfying them which is supported bya "small" sample space (one whose cardinality isequal to the number of constraints). For the important case of independence constraints, wherethe constraints have a certain form and are consistent with a joint distribution of n independentrandom variables, a small sample space can beconstructed in polynomial time. This last resultis also useful for de-randomizing algorithms. Wedemonstrate this technique by an application tothe problem of finding large independent sets insparse hypergraphs. </abstract>
<affiliation> Department of Computer Science, Stanford University, </affiliation>
 <address> Stanford, CA 94305; </address>
 <affiliation> and IBM Almaden ResearchCenter, </affiliation>
 <address> 650 Harry Road, San Jose, CA 95120. </address>
<affiliation> IBM Almaden Research Center, </affiliation>
 <address> 650 Harry Road, SanJose, CA 95120; </address>
 <affiliation> and School of Mathematical Sciences, TelAviv University, </affiliation>
 <address> Tel Aviv, Israel. </address>
<note> Research supported in part by ONR Contract N00014-91-C-0026 and by the Air Force Office of ScientificResearch (AFSC), under Contract F49620-91-C-0080.(Paste copyright notice here.) </note>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Published in SPIE Proceeding #1667 Practical Holography VI (SPIE, Bellingham, WA, February 1992) paper #04 (in press). </note>
<title> Optimization of Hologram Computation for Real-Time Display </title>
<author> Mark Lucente </author>
<affiliation> MIT Media LaboratorySpatial Imaging Group </affiliation>
<address> 20 Ames St.Cambridge, MA 02139USA </address>
<abstract> ABSTRACTSeveral methods of increasing the speed and simplicity of the computation of off-axis transmission holograms arepresented, with applications to the real-time display of holographic images. A bipolar intensity approach enables alinear summation of interference fringes, a factor of two speed increase, and the elimination of image noise caused byobject self-interference. An order of magnitude speed increase is obtained through the use of precomputed look-uptables containing a large array of elemental interference patterns corresponding to point source contributions fromeach of the possible locations in image space. Results achieved using a data-parallel supercomputer to computehorizontal-parallax-only holographic patterns containing 6 megasamples indicate that an image comprised of 10,000points with arbitrary brightness (grayscale) can be computed in under one second. </abstract>
<intro> INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Authoring and Transcription Toolsfor Speech-Based Hypermedia Systems </title>
<author> Barry Arons </author>
<affiliation> MIT Media Laboratory </affiliation>
<address> 20 Ames Street, E15-353Cambridge MA, 02139 </address>
<phone> Phone: +1 617-253-2245 </phone><email> E-mail: barons@media-lab.mit.edu </email>
<abstract> AbstractAuthoring is usually one of the most difficult parts in the design and implementation of hypertext andhypermedia systems. This problem is exacerbated if the data to be presented by the system is speech,rather than text or graphics, because of the slow and serial nature of speech. This paper provides anoverview of speech-only hypermedia, discusses the difficulties associated with authoring databases forsuch a system, and explores a variety of techniques to assist in the authoring process. </abstract>
<intro> Speech-Only Hypermedia </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Evolution of Memory and Mental ModelsUsing Genetic Programming </title>
<author> Scott Brave </author>
<affiliation> Computer Science Dept.Stanford University </affiliation>
<address> Stanford, California 94305 </address>
<email> brave@cs.stanford.edu </email>
<abstract> ABSTRACTThis paper applies genetic programmingto the evolution of intelligent agents thatgradually build internal representations oftheir surroundings for later use inplanning. The method used allows for thecreation of dynamically determinedrepresentations that are not pre-designedby the human creator of the system. In anillustrative path-planning problem, evolvedprograms learn a model of their world anduse this internal representation to plantheir successive actions. The results showthat the proposed method is successful inevolving programs that solve the planningproblem and is thus a worthy basis forfurther investigation. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> DESIGNING AN ECOLOGY OF DISTRIBUTED AGENTS </title>
<author> byNelson Minar </author>
<degree> B.A. Mathematics (1994)Reed College </degree><email> &amp;lt;nelson@media.mit.edu&amp;gt; </email>
<web> http://www.media.mit.edu/nelson/ </web><degree> Submitted to the Program in Media Arts and Sciences, School of Architecture andPlanning, in partial fulfillment of the requirements for the degree of Master of Science inMedia Arts and Sciences at the Massachusetts Institute of Technology </degree><date> September 1998 </date>
<note> c fl1998 Massachusetts Institute of Technology. All rights reserved. </note>
<note> AuthorNelson MinarDepartment of Media Arts and SciencesAugust 7, 1998 </note>
<degree> Certified byPattie MaesAssociate Professor of Media Arts and SciencesMIT Media LabAccepted byStephen A. BentonProfessor of Media Arts and SciencesChair, Departmental Committee on Graduate StudentsProgram in Media Arts and Sciences </degree><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> State Reconstruction for Determining Predictabilityin Driven Nonlinear Acoustical Systems </title>
<degree> Diploma Thesis </degree><affiliation> MEDIA LABORATORYMassachusetts Institute of Technology </affiliation>
<degree> Professor Neil GershenfeldInstitut fur Elektrische NachrichtentechnikRheinisch-Westphalische Technische Hochschule AachenUniv. Professor Dr.-Ing. H.D. Luke </degree><author> byBernd Schoner </author>
<date> May 1996 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Stability of the replica symmetric solution for the informationconveyed by a neural network </title>
<author> Simon Schultzy and Alessandro Trevesz </author>
<affiliation> Department of Experimental Psychology, </affiliation>
 <address> South Parks Rd., </address>
 <affiliation> University of Oxford, </affiliation>
<address>  Oxford OX13UD, U.K. </address>
<affiliation> Programme in Neuroscience, International School for Advanced Studies, </affiliation>
 <address> via Beirut 2-4, 34013Trieste, Italy </address>
<date> (November 7, 1997) </date>
<abstract> AbstractThe information that a pattern of firing in the output layer of a feedforwardnetwork of threshold-linear neurons conveys about the network's inputs isconsidered. A replica-symmetric solution is found to be stable for all butsmall amounts of noise. The region of instability depends on the contributionof the threshold and the sparseness: for distributed pattern distributions,the unstable region extends to higher noise variances than for very sparsedistributions, for which it is almost nonexistant. </abstract>
<note> 84.35.+i,89.70.+c,87.10.+eTypeset using REVT E X </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> An Optimal Weighting Criterion of Case Indexing for Both Numericand Symbolic Attributes </title>
<author> Takao Mohri and Hidehiko Tanaka </author>
<affiliation> Information Engineering Course, Faculty of EngineeringThe University of Tokyo </affiliation>
<address> 7-3-1 Hongo Bunkyo-ku, Tokyo 113, Japan </address>
<email> fmohri,tanakag@MTL.T.u-tokyo.ac.jp </email>
<abstract> AbstractIndexing of cases is an important topic for Memory-Based Reasoning(MBR). One key problem is how toassign weights to attributes of cases. Although severalweighting methods have been proposed, some methods cannot handle numeric attributes directly, so itis necessary to discretize numeric values by classification. Furthermore, existing methods have no theoretical background, so little can be said about optimality.We propose a new weighting method based on a statistical technique called Quantification Method II. It canhandle both numeric and symbolic attributes in thesame framework. Generated attribute weights are optimal in the sense that they maximize the ratio of variance between classes to variance of all cases. Experiments on several benchmark tests show that in manycases, our method obtains higher accuracies than someother weighting methods. The results also indicatethat it can distinguish relevant attributes from irrelevant ones, and can tolerate noisy data. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Comparative Study of Reliable Error Estimatorsfor Pruning Regression Trees </title>
<author> Lus Torgo </author>
<affiliation> LIACC/FEP University of Porto </affiliation>
<address> R. Campo Alegre, 823, 2 - 4150 PORTO - PORTUGAL </address>
<phone> Phone : (+351) 2 607 8830 Fax : (+351) 2 600 3654 </phone><email> email : ltorgo@ncc.up.pt </email>
 <web> WWW : http://www.ncc.up.pt/~ltorgo </web><abstract> Abstract. This paper presents a comparative study of several methods for estimatingthe true error of treestructured regression models. We evaluate these methods in thecontext of regression tree pruning. Pruning is considered a key issue for obtainingreliable treestructured models in a real world scenario. The major step of a pruningprocess consists of obtaining accurate estimates of the error of alternative treemodels. We evaluate experimentally four methods for obtaining these estimates intwelve domains. The goal of this evaluation was to characterise the performance ofthe methods in the task of selecting the best possible tree among the set of treesconsidered during pruning. The results of the comparison show that certainestimators lead to poor decisions in some domains. The Cross Validation variant thatwe have proposed achieved the best results on the setups we have considered. </abstract>
<keyword> Keywords : Machine Learning, Regression Trees, Pruning methods. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Rule CombinationinInductive Learning </title>
<author> Luis Torgo </author>
<affiliation> LIACC </affiliation>
<address> R.Campo Alegre, 823 - 2.4100 PORTOPORTUGAL </address>
<phone> Telf. : (+351) 2 600 16 72 - Ext. 115Fax : (+351) 2 600 3654 </phone><email> email : ltorgo@ciup1.ncc.up.pt </email>
<abstract> Abstract. This paper describes the work on methods for combining rulesobtained by machine learning systems. Three methods for obtaining theclassification of examples with those rules are compared. The advantages anddisadvantages of each method are discussed and the results obtained on threereal world domains are commented. The methods compared are: selection ofthe best rule; PROSPECTOR-like probabilistic approximation for rulecombination; and MYCIN-like approximation. Results show significantdifferences between methods indicating that the problemsolving strategy isimportant for accuracy of learning systems. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Rule Revision with Recurrent Neural Networks </title>
<author> Christian W. Omlin a;b and C.L. Giles a;c </author>
<affiliation> a NEC Research Institute, </affiliation>
 <address> 4 Independence Way, Princeton, New Jersey </address>
<affiliation> b Computer Science Department, Rensselaer Polytechnic Institute, </affiliation>
 <address> Troy, New York </address>
<affiliation> c Institute for Advanced Computer Studies, University of Maryland, </affiliation>
 <address> College Park, Maryland </address>
<abstract> AbstractRecurrent neural networks readily process, recognize and generate temporal sequences. By encodinggrammatical strings as temporal sequences, recurrent neural networks can be trained to behave like deterministic sequential finite-state automata. Algorithms have been developed for extracting grammaticalrules from trained networks. Using a simple method for inserting prior knowledge (or rules) into recurrentneural networks, we show that recurrent neural networks are able to perform rule revision. Rule revisionis performed by comparing the inserted rules with the rules in the finite-state automata extracted fromtrained networks. The results from training a recurrent neural network to recognize a known non-trivial,randomly generated regular grammar show that not only do the networks preserve correct rules but thatthey are able to correct through training inserted rules which were initially incorrect. (By incorrect, wemean that the rules were not the ones in the randomly generated grammar.) </abstract>
<keyword> Index Terms: Deterministic Finite-State Automata, Genuine and Incorrect Rules, Knowledge Insertionand Extraction, Recurrent Neural Networks, Regular Languages, Rule Revision. </keyword>
<note> Published in IEEE Trans. on Knowledge and Data Engineering, vol. 8, no. 1, p. 183, 1996. Copyright IEEE. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Delay Damage Model Selection Algorithm for NARXNeural Networks  </title>
<author> Tsungnan Lin 1;2y ,C. Lee Giles 1;3 , Bill G. Horne 1 , S.Y. Kung 2 </author>
<affiliation> 1 NEC Research Institute, </affiliation>
 <address> 4 Independence Way, Princeton, NJ 08540 </address>
<affiliation> 2 Department of Electrical Engineering, Princeton University, </affiliation>
 <address> Princeton, NJ 08540 </address>
<affiliation> 3 UMIACS, University of Maryland, </affiliation>
 <address> College Park, MD 20742 </address>
<abstract> AbstractRecurrent neural networks have become popular models for system identification and timeseries prediction. NARX (Nonlinear AutoRegressive models with eXogenous inputs) neuralnetwork models are a popular subclass of recurrent networks and have been used in manyapplications. Though embedded memory can be found in all recurrent network models, it isparticularly prominent in NARX models.We show that using intelligent memory order selection through pruning and good initialheuristics significantly improves the generalization and predictive performance of these nonlinearsystems on problems as diverse as grammatical inference and time series prediction. </abstract>
<keyword> Keywords: Recurrent neural networks, tapped-delay lines, long-term dependencies,time series, automata, memory, temporal sequences, gradient descent training, latching,NARX networks, auto-regressive, pruning, embedding theory. </keyword>
<note> Published in IEEE Transactions on Signal Processing, "Special Issue on Neural Networks," vol. 45, no. 11, p.2719-2730, 1997. Copyright IEEE.Current address: </note>
 <affiliation> Epson Palo Alto Laboratory,  </affiliation>
 <address> 3145 Porter Drive, Suite 104, Palo Alto, CA 94304 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> What Size Neural Network Gives Optimal Generalization?Convergence Properties of Backpropagation </title>
<author> Steve Lawrence 1;2 , C. Lee Giles 1 , Ah Chung Tsoi 2 </author>
<email> flawrence,actg@elec.uq.edu.au, giles@research.nj.nec.com </email>
<affiliation> 1 NEC Research Institute, </affiliation>
 <address> 4 Independence Way, Princeton, NJ 08540 </address>
<affiliation> 2 Department of Electrical and Computer EngineeringUniversity of Queensland, </affiliation>
 <address> St. Lucia 4072, Australia </address>
<pubnum> Technical ReportUMIACS-TR-96-22 and CS-TR-3617 </pubnum>
<affiliation> Institute for Advanced Computer StudiesUniversity of Maryland </affiliation>
<address> College Park, MD 20742 </address>
<date> June 1996 </date>
 <note> (Revised August 1996) </note>
<abstract> AbstractOne of the most important aspects of any machine learning paradigm is how it scales accordingto problem size and complexity. Using a task with known optimal training error, and a pre-specifiedmaximum number of training updates, we investigate the convergence of the backpropagation algorithmwith respect to a) the complexity of the required function approximation, b) the size of the network inrelation to the size required for an optimal solution, and c) the degree of noise in the training data. Ingeneral, for a) the solution found is worse when the function to be approximated is more complex, forb) oversized networks can result in lower training and generalization error in certain cases, and for c)the use of committee or ensemble techniques can be more beneficial as the level of noise in the trainingdata is increased. For the experiments we performed, we do not obtain the optimal solution in any case.We further support the observation that larger networks can produce better training and generalizationerror using a face recognition example where a network with many more parameters than training pointsgeneralizes better than smaller networks. </abstract>
<keyword> Keywords: Local Minima, Generalization, Committees, Ensembles, Convergence, Backpropagation, Smoothness,Network Size, Problem Complexity, Function Approximation, Curse of Dimensionality. </keyword>
<web> http://www.neci.nj.nec.com/homepages/lawrence </web><note> Also with the </note>
 <affiliation> Institute for Advanced Computer Studies, University of Maryland, </affiliation>
 <address> College Park, MD 20742. </address>
<web> http://www.neci.nj.nec.com/homepages/giles.html </web><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> Appears in the Seventh International World Wide Web Conference, Brisbane, Australia, Elsevier Science, pp.95-105, 1998. </note>
<title> Inquirus, the NECI meta search engine </title>
<author> Steve Lawrence and C. Lee Giles </author>
<affiliation> NEC Research Institute, </affiliation>
<address> 4 Independence Way, Princeton, NJ 08540, U.S.A. </address>
<email> lawrence@research.nj.nec.com and giles@research.nj.nec.com </email>
<abstract> Abstract World Wide Web (WWW) search engines (e.g. AltaVista, Infoseek, HotBot, etc.) have a number ofdeficiencies including: periods of downtime, low coverage of the WWW, inconsistent and inefficient userinterfaces, out of date databases, poor relevancy ranking and precision, and difficulties with spammingtechniques. Meta search engines have been introduced which address some of these and other difficulties insearching the WWW. However, current meta search engines retain some of these difficulties and may alsointroduce their own problems (e.g. reduced relevance because one or more of the search engines returns resultswith poor relevance). We present Inquirus, the NECI meta search engine, which addresses many of thedeficiencies in current techniques. Rather than working with the list of documents and summaries returned bysearch engines, as current meta search engines typically do, the Inquirus meta search engine works bydownloading and analyzing the individual documents. The Inquirus meta search engine makes improvementsover existing search engines in a number of areas, e.g.: more useful document summaries incorporating queryterm context, identification of both pages which no longer exist and pages which no longer contain the queryterms, advanced detection of duplicate pages, improved document ranking using proximity information,dramatically improved precision for certain queries by using specific expressive forms, and quick jump linksand highlighting when viewing the full documents.  </abstract>
<keyword> Keywords Information retrieval; Search engine; Meta search; Context-based search  </keyword>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On the uniqueness of the convolution theorem forthe fourier transform </title>
<author> Harold S. StoneLance R. Williams </author>
<affiliation> NEC Research Institute </affiliation>
<address> 4 Independence WayPrinceton, NJ 08540 </address>
<note> Revision 1, </note>
 <date> 13 February 1995 </date>
<abstract> AbstractThis paper shows that members of the fourier transform family are the only lineartransforms that have a convolution theorem, that is, that can replace O(N 2 ) operationsof a convolution in a time domain by O(N) operations in a transform domain. Generally,there is an additional cost to compute the transform itself. Our observation is motivated byrecent activity in wavelet and subband decompositions and related spectral analyses, whichare attractive alternatives for signal compression applications. A natural question whenusing such techniques is to determine if convolutions of N -point signals can be calculatedwith fewer operations in a compressed transform domain than in an uncompressed timedomain. The answer is negative for a broad set of assumptions. This paper indicates whatassumptions must be relaxed in seeking a linear transform that has a convolution theoremcomparable to the convolution theorem for fourier transforms. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Chapter 1 </note>
<title> Scheduling To Minimize Average Completion Time:Off-line and On-line Algorithms </title>
<author> Leslie A. Hall David B. Shmoys Joel Wein  </author>
<abstract> AbstractTime-indexed linear programming formulations have recently received a great deal of attention for their practicaleffectiveness in solving a number of single-machine scheduling problems. We show that these formulations are also animportant tool in the design of approximation algorithmswith good worst-case performance guarantees. We give simple new rounding techniques to convert an optimal fractionalsolution into a feasible schedule for which we can prove aconstant-factor performance guarantee, thereby giving thefirst theoretical evidence of the strength of these relaxations.Specifically, we consider the problem of minimizing thetotal weighted job completion time on a single machinesubject to precedence constraints, and give a polynomial-time (4 + *)-approximation algorithm, for any * &amp;gt; 0;the best previously known guarantee for this problem wassuperlogarithmic. With somewhat larger constants, we alsoshow how to extend this result to the case with release dateconstraints, and still more generally, to the case with midentical parallel machines. We give two other techniques forproblems in which there are release dates, but no precedenceconstraints: the first is based on other new LP roundingalgorithms, whereas the second is a general framework fordesigning on-line algorithms to minimize the total weightedcompletion time. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The Anisotropy in the Cosmic Microwave BackgroundAt Degree Angular Scales. </title>
<author> C. B. Netterfield, N. Jarosik, L. Page, D. Wilkinson, &amp; E. Wollack 1 </author>
<affiliation> Princeton University, Department of Physics, </affiliation>
 <address> Jadwin Hall, P.O. Box 708, Princeton, NJ08544 </address>
<note> Received ; acceptedSubmitted Ap. J. Letters </note>
<affiliation> 1 NRAO, </affiliation>
 <address> 2015 Ivy Rd., Charlottesville, VA, 22903 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> BUTP-98/ </note>
<title> Relation between the simple, guessed,and the complicated, derived,super-Hamiltonians for shell dynamics </title>
<author> P. Hajcek </author>
<affiliation> Institute for Theoretical PhysicsUniversity of Bern </affiliation>
<address> Sidlerstrasse 5, CH-3012 Bern, Switzerland </address>
<date> March 1998 </date>
<abstract> AbstractThe Hamiltonian dynamics of spherically symmetric massive thin shellsin the general relativity is considered. Two different constraint dynamicalsystems representing this dynamics have been described recently; the relationof these two systems is investigated. The symmetry groups of both systemsare found. The systems are reduced to the presymplectic manifolds 1 and 2 ,lest non-physical aspects like gauge fixings or embeddings in extended phasespaces hinder the argument. The following facts are shown. 1 is three- and 2is five-dimensional; the description of the shell dynamics by 1 is incompleteso that some measurable properties of the shell cannot be predicted. 1 islocally equivalent to a subsystem of 2 and the corresponding local morphismsare not unique, due to the large symmetry group of 2 . The local equivalenceexplains why the same radial equation results from both systems; what is,however, the physical importance of just local, but not global equivalence ofconstraint dynamical systems remains unclear. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Laser Remote Sensing Techniques for Vertical Profiling of Cloud andAerosol Extinction and Back-scatter in the Lower Atmosphere.A Brief Review </title>
<author> $flfl Papayannis*, E. Fokitis </author>
<affiliation> National Technical University of Athens, Physics Department </affiliation>
<address> Zografou Campus, 15780 Zografou, GREECE </address>
<email> Email: apdlidar@central.ntua.gr </email>
<abstract> AbstractIn this brief contribution we present the three principal laser remotesensing ( lidar) techniques developed to retrieve the vertical profiling ofclouds and of the suspended aerosols (extinction and backscatter) in thelower atmosphere, namely in the 0-7 km altitude region. The three lidartechniques include the elastic ( Klett inversion, Doppler broadening) andthe nonelastic backscattering techniques ( Raman scattering). We reporton the potential of these techniques, as well as on the typical accuraciesof these techniques in the retrieval of the cloud and aerosol extinctionand backscatter vertical profiles in the troposphere (0-7 km ASL). </abstract>
<intro> flfl Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Designing Distributed Applicationswith Mobile Code Paradigms </title>
<author> Antonio Carzaniga </author>
<affiliation> Politecnico di Milano </affiliation>
<address> Piazza Leonardo da Vinci, 3220133 Milano, Italy </address>
<phone> +39-2-2399-3638 </phone><email> carzaniga@elet.polimi.it </email>
<author> Gian Pietro Picco </author>
<affiliation> Politecnico di Torino </affiliation>
<address> Corso Duca degli Abruzzi, 2410129 Torino, Italy </address>
<phone> +39-11-564-7008 </phone><email> picco@athena.polito.it </email>
<author> Giovanni Vigna </author>
<affiliation> Politecnico di Milano </affiliation>
<address> Piazza Leonardo da Vinci, 3220133 Milano, Italy </address>
<phone> +39-2-2399-3666 </phone><email> vigna@elet.polimi.it </email>
<abstract> ABSTRACTLarge scale distributed systems are becoming ofparamount importance, due to the evolution of technology and to the interest of market. Their development,however, is not yet supported by a sound technological and methodological background, as the results developed for small size distributed systems often do notscale up. Recently, mobile code languages (MCLs) havebeen proposed as a technological answer to the problem.In this work, we abstract away from the details of theselanguages by deriving design paradigms exploiting codemobility that are independent of any particular technology. We present such design paradigms, togetherwith a discussion of their features, their application domain, and some hints about the selection of the correctparadigm for a given distributed application. </abstract>
<keyword> KeywordsMobile code, design paradigms, distributed applications. </keyword>
<intro> INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<note> Proceedings of the 19th Annual Conference of the CognitiveScience Society, Mahwah, NJ:Erlbaum p. 253-258 (1997).253 </note>
<title> The Dynamics of Prefrontal Cortico-Thalamo-Basal Ganglionic Loops andShort-Term Memory Interference Phenomena </title>
<author> Jack Gelfand 1 , Vijay Gullapalli 1 , Marcia Johnson 1 , Carol Raye 1 andJeffrey Henderson 2 </author>
<affiliation> Department of Psychology 1 and Department of Computer Science 2Princeton University </affiliation>
<address> Princeton, NJ 08544 </address>
<email> jjg@princeton.edu </email>
<abstract> AbstractWe present computer simulations of a model of the brainmechanisms operating in short-term memory tasks that areconsistent with the anatomy and physiology of prefrontalcortex and associated subcortical structures. Thesesimulations include dynamical processes in thalamo-cortical loops which are used to generate short-termpersistent responses in prefrontal cortex. We discuss thismodel in terms of the representation of input stimuli incortical association areas and prefrontal short-termmemory areas. We report on interference phenomena thatresult from the interaction of these dynamical processesand lateral projections within cortical columns. Theseinterference phenomena can be used to elucidate therepresentational organization of short-term memory. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Uniform Actions in Asynchronous DistributedSystems </title>
<author> Dalia Malki Ken Birman Aleta Ricciardi Andre Schiper x </author>
<pubnum> TR 94-1447 </pubnum>
<affiliation> Department of Computer Science, Cornell University </affiliation>
<abstract> AbstractWe develop necessary conditions for the development of asynchronous distributedsoftware that will perform uniform actions (events that if performed by any process,must be performed at all processes). The paper focuses on dynamic uniformity, whichdiffers from the classical problems in that processes continually leave and join theongoing computation. Here, we first treat a static version of the problem (lacking joins),and then extend the results so obtained to also include joins. Our results demonstratethat in contrast to Consensus, which cannot be solved in asynchronous systems witheven a single faulty process, dynamic uniformity can be solved using a failure detectionmechanism that makes bounded numbers of mistakes. Because dynamic uniformityarises in systems that maintain safety within a "primary partition" of a network, ourpaper provides a rigorous characterization of the framework upon which several existingdistributed programming environments are based. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On the Boosting Ability of Top-DownDecision Tree Learning Algorithms  </title>
<author> Michael Kearns </author>
<affiliation> AT&amp;T Research </affiliation>
<author> Yishay Mansour </author>
<affiliation> Tel-Aviv University </affiliation>
<date> May 1996 </date>
<abstract> AbstractWe analyze the performance of top-down algorithms for decision tree learning, such as those employedby the widely used C4.5 and CART software packages. Our main result is a proof that such algorithmsare boosting algorithms. By this we mean that if the functions that label the internal nodes of thedecision tree can weakly approximate the unknown target function, then the top-down algorithms westudy will amplify this weak advantage to build a tree achieving any desired level of accuracy. The boundswe obtain for this amplification show an interesting dependence on the splitting criterion used by thetop-down algorithm. More precisely, if the functions used to label the internal nodes have error 1=2 as approximations to the target function, then for the splitting criteria used by CART and C4.5, treesof size (1=*) O(1= 2 * 2 ) and (1=*) O(log(1=*)= 2 ) (respectively) suffice to drive the error below *. Thus (forexample), a small constant advantage over random guessing is amplified to any larger constant advantagewith trees of constant size. For a new splitting criterion suggested by our analysis, the much strongerbound of (1=*) O(1= 2 ) (which is polynomial in 1=*) is obtained, which is provably optimal for decisiontree algorithms. The differing bounds have a natural explanation in terms of concavity properties of thesplitting criterion.The primary contribution of this work is in proving that some popular and empirically successfulheuristics that are based on first principles meet the criteria of an independently motivated theoreticalmodel. </abstract>
<note> A preliminary version of this paper appears in Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory ofComputing, pages 459-468, ACM Press, 1996. Authors' addresses: </note>
 <author> M. Kearns, </author>
 <affiliation> AT&amp;T Research, </affiliation>
 <address> 600 Mountain Avenue, Room2A-423, Murray Hill, New Jersey 07974; </address>
 <email> electronic mail mkearns@research.att.com. </email>
 <author> Y. Mansour, </author>
 <affiliation> Department of ComputerScience, Tel Aviv University, </affiliation>
 <address> Tel Aviv, Israel; </address>
 <email> electronic mail mansour@math.tau.ac.il. </email>
 <note> Y. Mansour was supported in part bythe Israel Science Foundation, administered by the Israel Academy of Science and Humanities, and by a grant of the IsraeliMinistry of Science and Technology. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Update rules for parameter estimation in Bayesian networks </title>
<author> Eric Bauer </author>
<affiliation> Stanford University </affiliation>
<email> ebauer@cs.stanford.edu </email>
<author> Daphne Koller </author>
<affiliation> Stanford University </affiliation>
<email> koller@cs.stanford.edu </email>
<author> Yoram Singer </author>
<affiliation> AT&amp;T Labs </affiliation>
<email> singer@research.att.com </email>
<abstract> AbstractThis paper re-examines the problem of parameter estimation in Bayesian networks with missing values andhidden variables from the perspective of recent work inon-line learning [12]. We provide a unified frameworkfor parameter estimation that encompasses both on-linelearning, where the model is continuously adapted to newdata cases as they arrive, and the more traditional batchlearning, where a pre-accumulated set of samples is usedin a one-time model selection process. In the batch case,our framework encompasses both the gradient projectionalgorithm [2, 3] and the EM algorithm [14] for Bayesiannetworks. The framework also leads to new on-line andbatch parameter update schemes, including a parameterized version of EM. We provide both empirical and theoretical results indicating that parameterized EM allowsfaster convergence to the maximum likelihood parameters than does standard EM. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Systematic Approach toHost Interface Design for High-Speed Networks </title>
<author> Peter Steenkiste </author>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> 5000 Forbes AvenuePittsburgh, Pennsylvania 15213-3891 </address>
<abstract> AbstractIn recent years, networks with media rates of 100 Mbit/second or more have become widely available (FDDI, ATM,HIPPI, ..). However, many computer systems cannot make use of the available bandwidth because of the highoverhead associated with network communication. In this paper we review the operations involved in communication over high-speed networks, and we describe optimizations of the network interface that improve networkthroughput. We also discuss how the payoff of the optimizations is influenced by features of the host software andarchitecture. This paper is based on our experience with the interfaces for the Nectar and Gigabit Nectar networks. </abstract>
<keyword> Keywords: network interfaces, high-speed networks, buffer management, memory hierarchy </keyword>
<note> This research was sponsored by the Defense Advanced Research Projects Agency (DOD) under contract number MDA972-90-C-0035, in part by the National Science Foundation and the Defense AdvancedResearch Projects Agency under Cooperative Agreement NCR-8919038 with the Corporation for National Research Initiatives. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Automatically Selecting and Using Primary Effectsin Planning: Theory and Experiments </title>
<author> Eugene Fink  </author>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213, USA </address>
<email> eugene@cs.cmu.edu </email>
<web> http://www.cs.cmu.edu/~eugene </web><author> Qiang Yang  </author>
<affiliation> School of Computing ScienceSimon Fraser University </affiliation>
<address> Burnaby, BC V5A1S6, Canada </address>
<email> qyang@cs.sfu.ca </email>
<web> http://fas.sfu.ca/cs/people/Faculty/Yang </web><abstract> AbstractThe use of primary effects of operators is an effective approach to improving theefficiency of planning. The characterization of "good" primary effects, however, hasremained at an informal level and there have been no algorithms for selecting primaryeffects of operators.We formalize the use of primary effects in planning and present a criterion forselecting useful primary effects, which guarantees efficiency and completeness. Weanalyze the efficiency of planning with primary effects and the quality of the resultingplans.We then describe a learning algorithm that automatically selects primary effectsand demonstrate, both analytically and empirically, that the use of this algorithmsignificantly reduces planning time and does not compromise completeness. </abstract>
<note> Eugene Fink is supported by Wright Laboratory, Aeronautical Systems Center, Air Force MaterielCommand, USAF, and the Advanced Research Projects Agency (ARPA) under grant number F33615-93-1-1330. Qiang Yang is supported by Natural Sciences and Engineering Research Council of Canada (NSERC)under grant number OGP0184883. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> DYNAMIC COUPLING OFUNDERACTUATED MANIPULATORS </title>
<author> Marcel Bergerman Christopher Lee Yangsheng Xu </author>
<affiliation> The Robotics InstituteCarnegie Mellon University </affiliation>
<address> Pittsburgh PA 15213 </address>
<email> -mbergerm|chrislee|xu+-@cs.cmu.edu </email>
<note> Proceedings of the 4th IEEE Conference on Control Applications, Albany, USA, Sep. 1995, pp. 500-505. </note>
<abstract> AbstractIn recent years, researchers have been dedicated to thestudy of underactuated manipulators which have morejoints than control actuators. In previous works,assumptions were made as to the existence of enoughdynamic coupling between the active and the passivejoints of the manipulator for it to be possible to controlthe position of the passive joints via the dynamiccoupling. In this work, the authors aim to develop anindex to measure the dynamic coupling, so as to addresswhen control of the underactuated system is possible,and how the motion and robot configuration can bedesigned. We discuss extensively the nature of thedynamic coupling and of the proposed coupling index,and their applications in the analysis and design ofunderactuated systems, and in control and planning ofrobot motion configuration. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Unification and Polymorphism in Region Inference </title>
<author> Mads Tofte, </author>
 <affiliation> Department of Computer Science, University of Copenhagen </affiliation>
<author> Lars Birkedal, </author>
 <affiliation> School of Computer Science, Carnegie Mellon University </affiliation>
<note> Dedicated to Robin Milner on the occasion of his 60th birthday. </note>
<abstract> AbstractRegion Inference is a technique for inferring lifetimes of values in strict, higher-order programming languages such as Standard ML. The purpose of this paper is to show how ideasfrom Milner's polymorphic type discipline can serve as a basis for region inference, even in thepresence of a limited form of polymorphic recursion. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Linear Spine Calculus </title>
<author> Iliano Cervesato and Frank Pfenning 1 </author>
<date> April 10, 1997 </date>
<pubnum> CMU-CS-97-125 </pubnum>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<abstract> AbstractWe present the spine calculus S !ffi&amp;&amp;gt; as an efficient representation for the linear -calculus !ffi&amp;&amp;gt;which includes intuitionistic functions (!), linear functions (ffi), additive pairing (&amp;), and additive unit(&amp;gt;). S !ffi&amp;&amp;gt; enhances the representation of Church's simply typed -calculus as abstract Bohm treesby enforcing extensionality and by incorporating linear constructs. This approach permits proceduressuch as unification to retain the efficient head access that characterizes first-order term languages withoutthe overhead of performing -conversions at run time. Potential applications lie in proof search, logicprogramming, and logical frameworks based on linear type theories. We define the spine calculus, givetranslations of !ffi&amp;&amp;gt; into S !ffi&amp;&amp;gt; and vice-versa, prove their soundness and completeness with respectto typing and reductions, and show that the spine calculus is strongly normalizing and admits uniquecanonical forms. </abstract>
<note> 1 The authors can be reached at iliano@cs.cmu.edu and fp@cs.cmu.edu. </note>
</NEW_HEADER>
<NEW_HEADER>
<title> Sensor-based Registration and Stackingof Electronic Substrate Layers </title>
<author> Andrew E. Brennemann, 1 Robert Hammer, 2William V. Jecusco II, 3and Ralph L. Hollis 4 </author>
<affiliation> IBM Research DivisionThomas J. Watson Research Center </affiliation>
<address> Yorktown Heights, New York, USA </address>
<abstract> AbstractSubstrates for most of today's electronic products contain many wiring layerswhich are individually fabricated, mechanically registered with one another,and laminated together. Alignment tolerances of 0.05 mm to 0.1 mm aresufficient to register the vertical connection pads or vias on each layer. Moreaggressive designs of the future will, however, require manufacturing accuracies of at least an order of magnitude better to accommodate much finerwire widths and pin spacings. Conventional equipment relying on mechanical"pin-in-slot" methods will likely be inadequate, and a new approach will beneeded.We describe here a sensor-based approach for registration and stackingof electronic substrate sublaminates that replaces pin-in-slot methods, yetdoes not require accurate automation equipment. A pilot work cell for thisapproach is presented, which has an IBM 7576 coarse-positioning robot, aspecially-developed fine-positioning robot, optical sensors, and several routinelow accuracy fixtures. A novel robot bracing method was used to minimizeenvironmental vibration during sublaminate stacking.Pairs of test sublaminates, each containing an identical pattern of 100m holes, were aligned, stacked and bonded. The accuracy of registration </abstract>
<note> 1 Retired, </note>
 <address> 4 Morningside Court, Ossining, NY, 10562. </address>
</NEW_HEADER>
<NEW_HEADER>
<title> Tactile Gestures for Human/Robot Interaction </title>
<author> Richard M. Voyles, Jr. Pradeep K. Khosla  </author>
<affiliation> Robotics Ph.D. ProgramDept. of Electrical and Computer EngineeringCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<note> 7 </note>
<abstract> AbstractGesture-Based Programming is a new paradigm to easethe burden of programming robots. By tapping in to theusers wealth of experience with contact transitions,compliance, uncertainty and operations sequencing, wehope to provide a more intuitive programming environmentfor complex, real-world tasks based on the expressivenessof non-verbal communication. A requirement for this to beaccomplished is the ability to interpret gestures to infer theintentions behind them. As a first step toward this goal, thispaper presents an application of distributed perception forinferring a users intentions by observing tactile gestures.These gestures consist of sparse, inexact, physicalnudges applied to the robots end effector for thepurpose of modifying its trajectory in free space. A set ofindependent agents - each with its own local, fuzzified,heuristic model of a particular trajectory parameter -observes data from a wrist force/torque sensor to evaluatethe gestures. The agents then independently determine theconfidence of their respective findings and distributedarbitration resolves the interpretation through voting. </abstract>
<intro> 1 Gesture-based programming </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Fundamentals of Texture Mapping and Image Warping </title>
<degree> Master's Thesisunder the direction of Carlo Sequin </degree><author> Paul S. Heckbert </author>
<affiliation> Dept. of Electrical Engineering and Computer ScienceUniversity of California, </affiliation>
 <address> Berkeley, CA 94720 </address>
<note> c fl1989 Paul S. Heckbert </note>
<date> June 17, 1989 </date>
<note> This Postscript version is missing about 40 paste-up figures. To get a complete version,order report no. UCB/CSD 89/516 from the Computer Science Division at the addressabove. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Using a DEM to Determine Geospatial Object Trajectories </title>
<author> Robert T. Collins, Yanghai Tsin, J. Ryan Miller and Alan J. Lipton </author>
<affiliation> The Robotics Institute, Carnegie Mellon University, </affiliation>
 <address> Pittsburgh, PA. 15213 </address>
<email> Email: frcollins,ytsin,jmce,ajlgcs.cmu.edu </email>
<abstract> AbstractThis paper addresses the estimation of moving object trajectories within a geospatial coordinate system,using a network of video sensors. A high-resolution(0.5m grid spacing) digital elevation map (DEM) hasbeen constructed using a helicopter-based laser range-finder. Object locations are estimated by intersecting viewing rays from a calibrated sensor platformwith the DEM. Continuous object trajectories can thenbe assembled from sequences of single-frame locationestimates using spatio-temporal filtering and domainknowledge. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Optimizing ML with Run-Time Code Generation </title>
<author> Mark Leone Peter Lee </author>
<date> December 1995 </date>
<pubnum> CMU-CS-95-205 </pubnum>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<abstract> AbstractWe describe the design and implementation of a compiler that automatically translates ordinaryprograms written in a subset of ML into code that generates native code at run time. Run-timecode generation can make use of values and invariants that cannot be exploited at compile time,yielding code that is superior to statically optimal code. But the cost of optimizing and generatingcode at run time can be prohibitive. We demonstrate how compile-time specialization can reducethe cost of run-time code generation by an order of magnitude without greatly affecting codequality. Several benchmark programs are examined, which exhibit an average cost of six cycles perinstruction generated at run time. </abstract>
<note> The authors' electronic mail addresses are </note>
 <email> Mark.Leone@cs.cmu.edu and Peter.Lee@cs.cmu.edu.  </email>
<note> This research was sponsored in part by the Advanced Research Projects Agency CSTO under the title "The FoxProject: Advanced Langauges for Systems Software," ARPA Order No. C533, issued by ESC/ENS under ContractNo. F19628-95-C-0050. The views and conclusions contained in this document are those of the authors and shouldnot be interpreted as representing the official policies, either expressed or implied, of the Advanced Research ProjectsAgency or the U.S. Government. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> Formal Aspects of Computing (1998) 3: 1-000c 1998 BCS </note>
<title> Protective Interface Specifications </title>
<author> Gary T. Leavens 2 and Jeannette M. Wing 3 </author>
<affiliation> 1 Department of Computer Science, Iowa State University, </affiliation>
 <address> Ames, IA 50011 USA </address>
<affiliation> 2 Computer Science Department, Carnegie Mellon University, </affiliation>
<address>  Pittsburgh, PA 15213 USA </address>
<abstract> Abstract. The interface specification of a procedure describes the procedure'sbehavior using pre- and postconditions. These pre- and postconditions are written using various functions. If some of these functions are partial, or underspec-ified, then the procedure specification may not be well-defined.We show how to write pre- and postcondition specifications that avoid suchproblems, by having the precondition "protect" the postcondition from the effectsof partiality and underspecification. We formalize the notion of protection frompartiality in the context of specification languages like VDM-SL and COLD-K.We also formalize the notion of protection from underspecification for the Larchfamily of specification languages, and for Larch show how one can prove that aprocedure specification is protected from the effects of underspecification. </abstract>
<intro> 1. The Problem </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> A Field Guide to Boxology:Preliminary Classification of Architectural Styles for Software Systems </title>
<author> Mary Shaw and Paul Clements </author>
<affiliation> Computer Science Department and Software Engineering InstituteCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<date> April 1996 </date>
<abstract> Abstract:Software architects use a number of commonly-recognized stylesto guide their design of system structures. Each of these is appropriate forsome classes of problems, but none is suitable for all problems. How, then,does a software designer choose an architecture suitable for the problem athand? Two kinds of information are required: (1) careful discriminationamongthe candidate architectures and (2) design guidanceon how to makeappropriate choices. Here we support careful discriminationwith apreliminary classification of styles. We use a two-dimensional classificationstrategy with control and data issues as the dominant organizing axes. Weposition the major styles within this space and use finer-graineddiscriminations to elaborate variations on the styles. This provides aframework for organizing design guidance, which we partially flesh out withrules of thumb. </abstract>
<keyword> Keywords: software architecture, architectural styles, style classification/taxonomy </keyword>
<note> This document was created with FrameMaker 4.0.4 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Geometric Sensing of Known Planar Shapes </title>
<author> Yan-Bin Jia Michael Erdmann </author>
<affiliation> The Robotics Institute and School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, Pennsylvania 15213-3891 </address>
<date> March 12, 1995 </date>
<note> International Journal of Robotics Research, 15(4):365-392, 1996. </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Exploiting Redundancy to Reduce Impact Force </title>
<author> Jin-Oh Kim 2 , Matthew Wayne Gertz 3 , and Pradeep K. Khosla 4 </author>
<affiliation> Advanced Manipulators LaboratoryThe Robotics InstituteCarnegie Mellon University </affiliation>
<address> Pittsburgh, Pennsylvania 15213 </address>
<abstract> AbstractThis paper presents two strategies for reducing the impact force resulting from the collision of akinematically redundant manipulator with its environment, where it is assumed that the impactevent has some finite duration. The first, an impact control strategy, involves adding torques to thejoints of the redundant manipulator to impede motion into the environment with which it is colliding. The second, an impact planning strategy, involves choosing the configuration best suited forminimizing the impact force from an impact event, the approximate location of which is knownahead of time. Simulated results from both strategies are presented and discussed, and it is shownthat both are successful in minimizing the impact force resulting from planned and unplanned collisions. </abstract>
<note> 1. This research was funded in part by NASA (grant number NAG-1-1075), the Dept. of Elec. and Comp. Engineering, </note>
</NEW_HEADER>
<NEW_HEADER>
<title> Remote Access to Interactive Media </title>
<author> Roger B. Dannenberg </author>
<affiliation> Carnegie Mellon University, School of Computer Science </affiliation>
<address> Pittsburgh, PA 15213 USA </address>
<email> Email: dannenberg@cs.cmu.edu </email>
<abstract> ABSTRACTDigital interactive media augments interactive computing with video, audio, computer graphics and text,allowing multimedia presentations to be individually and dynamically tailored to the user. Multimedia, andparticularly continuous media pose interesting problems for system designers, including those of latencyand synchronization. These problems are especially evident when multimedia data is remote and must beaccessed via networks. Latency and synchronization issues are discussed, and an integrated system,Tactus, is described. Tactus facilitates the implementation of interactive multimedia computer programs bymanaging latency and synchronization in the framework of an object-oriented graphical user interfacetoolkit. </abstract>
<intro> 1. Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Improving Programming-by-Demonstration With Better Semantic Expression </title>
<degree> Thesis Proposal </degree><author> Richard McDaniel </author>
<date> November 14, 1995 </date>
<abstract> AbstractThe domain of applications that can be created with programming-by-demonstration(PBD) can be extended by improving the developers ability to communicate with the system. Thetechniques provided in this thesis will allow nonprogrammers to create a new variety of complete,interactive applications including many board games and educational software using PBD.A PBD software tool uses inferencing to induce programs by watching the developer demonstrate examples that show how the application should behave. Current systems reduce their scopeor resort to having the developer program because they do not provide sufficient ways to expressbehaviors and the factors that affect them. Therefore, the goal of this thesis is to develop understandable forms of annotated expression and manipulation that help a system infer a broader rangeof behavior. To test these ideas, this proposal introduces a new system called Gamut that willpresent the techniques in a unified software tool.The first technique replaces the macro recorder method for demonstrating behavior usedin other PBD systems with a technique called nudges. The developer demonstrates by correctingthe system at important points during program execution and also using two nudge commands tocommunicate important situations. First, the Do Something! nudge causes the system to reconsiderpast learned behavior and try to generalize its knowledge to fit the current situation. Using theStop That! nudge will point out improper behavior and generate negative examples.Second, Gamut will use a new deck-of-playing-cards metaphor to express concepts suchas randomness, sequencing, and data storage. By constructing an appropriate deck, shufing, sorting, and playing cards at key moments, developers can incorporate many effects not available without programming in other systems.Third, Gamut will improve communication about behaviors by making them more manipulable than in previous systems. Behaviors will be represented as small icons near the objects theyaffect. Using the familiar cut, copy, and paste commands, the developer can transfer behaviorbetween objects. Determining how to make a behavior operate in the new context will be inferredautomatically. An objects state from the recent past will be represented as temporal ghosts inwhich objects become dimmed, translucent images. Many sorts of behavior refer to prior statessuch as a previous position or an old property value. The ghost objects will allow the developer tomake explicit connections.Finally, to reduce the number of options the system must explore, the developer will beable to give hints by highlighting important objects and properties. A new inferencing algorithmwill be created that will take advantage of the hints.By combining these techniques, Gamut will provide a rich medium for expressing developer intentions, fostering greater communication between the PBD system and the developer andenabling the developer to create highly interactive software with minimal programming expertise. </abstract>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> A Whole SentenceMaximum Entropy Language Model </title>
<author> R. Rosenfeld </author>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<abstract> Abstract We introduce a new kind of language model, which models whole sentences or utterances directly using the Maximum Entropyparadigm. The new model is conceptually simpler, and more naturallysuited to modeling whole-sentence phenomena, than the conditional MEmodels proposed to date. By avoiding the chain rule, the model treatseach sentence or utterance as a "bag of features", where features arearbitrary computable properties of the sentence. The model is unnor-malizable, but this does not interfere with training (done via sampling)or with use. Using the model is computationally straightforward. Themain computational cost of training the model is in generating samplesentences from a Gibbs distribution. Interestingly, this cost has different dependencies, and is potentially lower, than in the comparableconditional ME model. </abstract>
<intro> 1 Motivation </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> TOLERATING LATENCY THROUGHSOFTWARE-CONTROLLED DATA PREFETCHING </title>
<degree> a dissertationsubmitted to the </degree> <affiliation> department of electrical engineering +L </affiliation>
<degree> and the committee on graduate studiesof </degree> <affiliation> stanford university </affiliation>
<degree> in partial fulfillment of the requirementsfor the degree ofdoctor of philosophy </degree><author> ByTodd C. Mowry </author>
<date> March 1994 </date>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Tolerating Latency Through Software-Controlled Prefetchingin Shared-Memory Multiprocessors </title>
<author> Todd Mowry and Anoop Gupta </author>
<affiliation> Computer Systems LaboratoryStanford University, CA 94305 </affiliation>
<note> To appear in the Journal of Parallel and Distributed Computing, June 1991. </note>
<abstract> AbstractThe large latency of memory accesses is a major obstacle in obtaining high processor utilization in largescale shared-memory multiprocessors. Although the provision of coherent caches in many recent machineshas alleviated the problem somewhat, cache misses still occur frequently enough that they significantly lowerperformance. In this paper we evaluate the effectiveness of non-binding software-controlled prefetching, asproposed in the Stanford DASH Multiprocessor, to address this problem. The prefetches are non-binding inthe sense that the prefetched data is brought to a cache close to the processor, but is still available to the cachecoherence protocol to keep it consistent. Prefetching is software-controlled since the program must explicitlyissue prefetch instructions.The paper presents results from detailed simulation studies done in the context of the Stanford DASHmultiprocessor. Our results show that for applications with regular data access patterns|we evaluate a particle-based simulator used in aeronautics and an LU-decomposition application|prefetching can be very effective.It was easy to augment the applications to do prefetching and it increased their performance by 100-150% whenwe prefetched directly into the processor's cache. However, for applications with complex data usage patterns,prefetching was less successful. After much effort, the performance of a distributed-time logic simulationapplication that made extensive use of pointers and linked lists could be increased only by 30%. The paperalso evaluates the effects of various hardware optimizations such as separate prefetch issue buffers, prefetchingwith exclusive ownership, lockup-free caches, and weaker memory consistency models on the performance ofprefetching. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Predicting Data Cache Misses in Non-Numeric ApplicationsThrough Correlation Profiling </title>
<author> Todd C. Mowry Chi-Keung Luk </author>
<affiliation> Department of Computer Science Department of Computer ScienceCarnegie Mellon University University of Toronto </affiliation>
<address> Pittsburgh, PA 15213 Toronto, Canada M5S 3G4 </address>
<email> tcm@cs.cmu.edu luk@eecg.toronto.edu </email>
<abstract> AbstractTo maximize the benefit and minimize the overhead of software-based latency tolerance techniques,we would like to apply them precisely to the set ofdynamic references that suffer cache misses. Unfortunately, the information provided by the state-of-the-art cache miss profiling technique (summary profiling)is inadequate for references with intermediate missratios|it results in either failing to hide latency, orelse inserting unnecessary overhead. To overcome thisproblem, we propose and evaluate a new technique|correlation profiling|which improves predictability bycorrelating the caching behavior with the associated dynamic context. Our experimental results demonstratethat roughly half of the 22 non-numeric applicationswe study can potentially enjoy significant reductionsin memory stall time by exploiting at least one of thethree forms of correlation profiling we consider. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Learning Maps for Indoor Mobile Robot Navigation </title>
<author> Sebastian Thrun </author>
<affiliation> Computer Science Department and Robotics InstituteCarnegie Mellon University, Pittsburgh </affiliation>
<note> Accepted for Publication in Artificial Intelligence </note>
<abstract> AbstractAutonomous robots must be able to learn and maintain models of their environments.Research on mobile robot navigation has produced two major paradigms for mapping indoorenvironments: grid-based and topological. While grid-based methods produce accuratemetric maps, their complexity often prohibits efficient planning and problem solving inlarge-scale indoor environments. Topological maps, on the other hand, can be used muchmore efficiently, yet accurate and consistent topological maps are often difficult to learnand maintain in large-scale environments, particularly if momentary sensor data is highlyambiguous. This paper describes an approach that integrates both paradigms: grid-basedand topological. Grid-based maps are learned using artificial neural networks and naiveBayesian integration. Topological maps are generated on top of the grid-based maps, bypartitioning the latter into coherent regions. By combining both paradigms, the approachpresented here gains advantages from both worlds: accuracy/consistency and efficiency.The paper gives results for autonomous exploration, mapping and operation of a mobilerobot in populated multi-room environments. </abstract>
<note> ? This research was sponsored in part by the National Science Foundation under award IRI-9313367, and by the Wright Laboratory, Aeronautical Systems Center, Air Force MaterielCommand, USAF, and the Darpa Advanced Research Projects Agency (DARPA) undergrant number F33615-93-1-1330. We also acknowledge financial support by Daimler BenzCorp.Preprint submitted to Elsevier Science 15 September 1997 </note>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> WWW Electronic Commerce and Java Trojan Horses </title>
<author> J. D. Tygar Alma Whitten </author>
<email> tygar@cs.cmu.edu alma@cs.cmu.edu </email>
<affiliation> Carnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213 </address>
<abstract> AbstractWorld Wide Web electronic commerce applicationsoften require consumers to enter private information (such as credit card numbers) into forms in thebrowser window. If third parties can insert trojanhorse applications onto a consumer's machine, theycan monitor keyboard strokes and steal private information.This paper outlines a simple way to accomplishthis using Java or similar remote execution facilities.We implemented a simple version of this attack. Wegive a general method, window personalization, thatcan thwart or prevent this attack. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Bayesian Analysis of Variance Component Models via RejectionSampling </title>
<author> Russell D. Wolfinger </author>
<affiliation> SAS Institute Inc., </affiliation>
 <address> SAS Campus Drive,Cary, NC 27513, U.S.A. </address>
<author> and Robert E. Kass </author>
<affiliation> Department of Statistics, Carnegie Mellon University </affiliation>
<address> Pittsburgh, PA 15213, U.S.A. </address>
<date> January, 1996 </date>
<abstract> AbstractWe consider the usual Normal linear mixed model for "components of variance" from a Bayesianviewpoint. Instead of using Gibbs sampling or other Markov Chain schemes that rely on fullconditional distributions, we propose and investigate a method for simulating from posterior distributions based on rejection sampling. The method applies with arbitrary prior distributions butwe also employ as a default reference prior a version of Jeffreys's prior based on the integrated("restricted") likelihood. We demonstrate the ease of application and flexibility of this approachin several familiar settings, even in the presence of unbalanced data. A program implementing thealgorithm discussed here will be available in the SAS MIXED procedure. </abstract>
<keyword> Some key words: Jeffreys's prior, Mixed model, Posterior simulation, Reference prior, REML. </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Backfitting in Smoothing Spline ANOVA </title>
<author> By Zhen Luo 1 </author>
<affiliation> Pennsylvania State University </affiliation>
<abstract> AbstractA scheme to compute smoothing spline ANOVA estimates for large data sets with a (near)tensor-product structure is proposed. Such data sets are common in spatial-temporal analysis andimage analysis. This scheme combines backfitting algorithm with iterative imputation algorithm inorder to save both computational space and time. The convergence of this algorithm and variousways to further speed it up, such as collapsing component functions and successive over-relaxation,are discussed. Issues related to its application in spatial-temporal analysis are discussed too. Anapplication to a global analysis of historical surface temperature data is described. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> Working Paper IS-98-01 (Information Systems) </pubnum>
<affiliation> Leonard N. Stern School of Business, New York University. </affiliation>
<note> In: Proceedings of the IEEE/IAFE/INFORMS Conference on Computational Intelligence for Financial Engineering(CIFEr'98, New York, March 1998) </note>
<web> http://www.stern.nyu.edu/~aweigend/Research/Papers/TradeStyles </web><title> Uncovering Hidden Structure in Bond Futures Trading </title>
<author> Fei CHEN , Stephen FIGLEWSKI ,Jeffrey HEISLER zz , Andreas S. WEIGEND  </author>
<abstract> Abstract. This study uncovers trading styles in the transaction records of US Treasury bond futures.It uses transaction-by-transaction data from the Commodity Futures Trading Commissions' (CFTC)Computerized Trade Reconstruction (CTR) records. The data set consists of 30 million transaction|the complete US T-bond futures market for 3 years. Each transaction record consists of time (by theminute), price, volume, buy/sell, and an identifier of the specific account.We use statistical clustering techniques to group together trades that are similar. Two sets ofassumptions have to be made: (1) What is a trade? We define a trade to begin when an account opensa position, and to end when its position size returns to zero. We describe each trade by several trade-specific variables (e.g., length of trade, maximum position size, opening move, long or short) and severalexogenous, market-specific variables (e.g., price, volatility, trading volume). (2) What process generatedthe data? We assume a mixture of Gaussians. An observed trade is interpreted as a noisy realization ofone of the mixture components. This paper assumes identity covariance matrices. Furthermore, eachtrade is fully assigned to a single cluster. We compare this approach to diagonal and to full covariancestructure with probabilistic assignments.Trade profit was held back in the clustering process. It turns out that the clusters differ significantly in their profit and risk characteristics. Using conditional distributions, we summarize featuresof profitable trading styles and contrast them with losing strategies. We find that profitable styles tendto hold trades longer, trade at higher volatility, and trade earlier in the contracts. We also show howsome clusters uncover "technical" traders. Using the information about the individual accounts, theassignments of accounts to clusters are described by entropy, and the transitions of a given accountthrough clusters is modeled by a first order Markov model. </abstract>
<intro> 1 Motivation and Overview </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Problem Solving for Redesign </title>
<author> Anita Pos 1 and Hans Akkermans 1 and Remco Straatman 2 </author>
<affiliation> 1 University of Twente (UT)Department of Computer Science </affiliation>
<address> P.O. Box 217NL-7500 AE EnschedeThe Netherlands </address>
<email> E-mail: fpos,akkermang@cs.utwente.nl </email>
<affiliation> 2 University of Amsterdam (UvA)Department of Social Science Informatics (SWI) </affiliation>
<address> Roetersstraat 151081 WB AmsterdamThe Netherlands </address>
<email> E-mail: remco@swi.psy.uva.nl </email>
<abstract> Abstract. A knowledge-level analysis of complex tasks like diagnosis and design can give us a better understanding of these tasks in terms of the goals theyaim to achieve and the different ways to achieve these goals. In this paper wepresent a knowledge-level analysis of redesign. Redesign is viewed as a family ofmethods based on some common principles, and a number of dimensions alongwhich redesign problem solving methods can vary are distinguished. By examining the problem-solving behavior of a number of existing redesign systems and approaches, we came up with a collection of problem-solving methods for redesignand developed a task-method structure for redesign.In constructing a system for redesign a large number of knowledge-related choicesand decisions are made. In order to describe all relevant choices in redesign problem solving, we have to extend the current notion of possible relations betweentasks and methods in a PSM architecture. The realization of a task by a problem-solving method, and the decomposition of a problem-solving method into subtasks are the most common relations in a PSM architecture. However, we suggestto extend these relations with the notions of task refinement and method refinement. These notions represent intermediate decisions in a task-method structure,in which the competence of a task or method is refined without immediately paying attention to its operationalization in terms of subtasks. Explicit representationof this kind of intermediate decisions helps to make and represent decisions in amore piecemeal fashion. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> An Extensible Protocol Architecture forApplication-Specific Networking </title>
<author> Marc E. FiuczynskiBrian N. Bershad </author>
<email> fmef,bershadg@cs.washington.edu </email>
<affiliation> Department of Computer Science and EngineeringUniversity of Washington </affiliation>
<address> Seattle, WA 98195 </address>
<abstract> AbstractPlexus is a networking architecture that allows applications to achieve high performance with customizedprotocols. Application-specific protocols are written ina typesafe language and installed dynamically into theoperating system kernel. Because these protocols execute within the kernel, they can access the networkinterface and other operating system services with lowoverhead. Protocols implemented with Plexus outperform equivalent protocols implemented on conventional monolithic systems. Plexus runs in the contextof the SPIN extensible operating system. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> The OPENET Architecture </title>
<author> Israel CidonTony HsiaoAsad KhamisyAbhay ParekhRaphael RomMoshe Sidi </author>
<pubnum> SMLI TR-95-37 </pubnum>
<date> December 1995 </date>
<abstract> Abstract:ATM networks will soon be moving from the experimental stage of test-beds to a commercial statewhere production networks are deployed and operated. The progress of ATM networks appears to beat risk due to the lack of a universal, open, and efficient ATM network control platform. The emergingPrivate Network to Network Interface (PNNI) standard introduces a control platform that can be usedas an internetwork and possibly as an intra-network solution. However, the current PNNI still falls shortin providing an acceptable universal solution, due to lack of performance optimizations for intra-network operation, limited functionality, and the lack of open interfaces for future functional extensionsand services.OPENET is a common portable, open, and high-performance network control platform based on performance and functional enhancements to the PNNI standard. It is vendor-independent, scalable (interms of network size and volume of calls), high-performance (in terms of call processing latency andthroughput), and extensible (in terms of integrating customer-specific and value-added services).OPENET is designed as an extension to current PNNI so it can serve as a next generation PNNI. It iscompatible with PNNI in the internetworking environment allowing large networks to be partitionedaccording to natural topological or organizational boundaries rather than the artificial use of internet-work interfaces at vendor boundaries.This report describes the OPENET architecture. The major novelties of the OPENET architecture compared to the current PNNI are: the use of native ATM switching for the dissemination of utilizationupdates; lightweight call setup; take down and modification signaling; a new signaling paradigm thatbetter supports fast reservation and multicast services; and a rich signaling infrastructure that enablesthe development of augmented services (such as mobility, directory, etc.), leveraging the existing functions of the network control platform. </abstract>
<email> email address:raphael.rom@eng.sun.com </email>
<address> M/S 29-012550 Garcia AvenueMountain View, CA 94043 </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Two Computer Systems Paradoxes: Serialize-to-Parallelize,and Queuing Concurrent-Writes </title>
<author> Rimon Orni and Uzi Vishkin  </author>
<date> September 17, 1995 </date>
<abstract> AbstractWe present and examine the following Serialize-to-Parallelize Paradox: suppose aprogrammer has a parallel algorithm in mind; the programmer must serialize the algorithm, and is actually trained to suppress its parallelism, while writing code; later,however, compilation and runtime techniques are used to reverse the results of this serialization effort and extract as much parallelism as possible. This work actually providesexamples where parallel or parallel-style code enables extracting more parallelism thanstandard serial code.The "arbitrary concurrent-write" convention is useful in parallel algorithms and programs and appears to be not too difficult to implement in hardware for serial machines.Still, typically concurrent-writes to the same memory location in a program are implemented by queuing the write operations, thus requiring time linear in the number ofwrites. We call this the Queuing Concurrent-Writes Paradox.Assuming that providing useful, easy-to-program programming paradigms to improve the overall effectiveness of computer systems is of interest, this work is a modestexample for applying such software-driven considerations to computer architecture issues. This work may be the first to relate parallel algorithms and parallel programmingwith the technology of instruction level parallelism. </abstract>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Mobile Robot Localization using Landmarks </title>
<author> Margrit Betke  </author>
<affiliation> Massachusetts Institute of TechnologyLaboratory for Computer Science </affiliation>
<address> Cambridge, MA 02139 </address>
<author> Leonid Gurvits  </author>
<affiliation> NEC Research Institute </affiliation>
<address> 4 Independence WayPrinceton, NJ 08540 </address>
<date> April 27, 1995 </date>
<abstract> AbstractWe describe an efficient method for localizing a mobile robot in an environment with landmarks. We assume that the robot can identify these landmarksand measure their bearings relative to each other. Given such noisy input, thealgorithm estimates the robot's position and orientation with respect to themap of the environment. The algorithm makes efficient use of our representation of the landmarks by complex numbers. The algorithm runs in time linearin the number of landmarks. We present results of simulations and proposehow to use our method for robot navigation. </abstract>
<keyword> Keywords: Robotics, mobile robot localization, landmark navigation, mapalgorithms, triangulation. </keyword>
<note> Part of this research was done while the author was visiting Siemens Corporate Research. Theauthor is also supported by NSF grant ASC-9217041. Author's net address: </note>
<email>  margrit@lcs.mit.edu </email>
<note> Author's net address: </note>
 <email> gurvits@research.nj.nec.com </email>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Learning and Vision Algorithms forRobot Navigation </title>
<author> byMargrit Betke </author>
<degree> S.M., Massachusetts Institute of Technology (1992)Submitted to the </degree> <affiliation> Department of Electrical Engineering and ComputerScience </affiliation>
 <degree> in partial fulfillment of the requirements for the degree ofDoctor of Philosophy in Electrical Engineering and Computer Scienceat the </degree><affiliation> MASSACHUSETTS INSTITUTE OF TECHNOLOGY </affiliation>
<date> June 1995 </date>
<note> c Massachusetts Institute of Technology 1995. All rights reserved. </note>
<degree> Author : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : </degree><affiliation> Department of Electrical Engineering and Computer Science </affiliation>
<date> May 18, 1995 </date>
<degree> Certified by : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :Ronald L. RivestProfessorThesis SupervisorAccepted by : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :F. R. MorgenthalerChairman, Department Committee on Graduate Students </degree><page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<pubnum> CAR-TR-858N00014-95-1-0521 </pubnum>
<date> June 1997 </date>
<title> Information-Conserving Object Recognition </title>
<author> Margrit Betke and Nicholas C. Makris : </author>
<affiliation> Computer Vision LaboratoryCenter for Automation ResearchUniversity of Maryland </affiliation>
<address> College Park, MD 20742-3275 </address>
<abstract> AbstractThe problem of recognizing objects imaged in complex real-world scenes is examined froma parametric perspective using the theory of statistical estimation. A scalar measure of anobject's complexity, which is invariant under affine transformation and changes in image noiselevel, is extracted from the object's Fisher information. The volume of Fisher information isshown to provide an overall statistical measure of the object's recognizability in a particularimage, while the complexity provides an intrinsically physical measure that characterizes theobject in any image. An information-conserving method is then developed for recognizingan object imaged in a complex scene. Here the term "information-conserving" means thatthe method uses all the measured data pertinent to the object's recognizability, attains thetheoretical lower bound on estimation error for any unbiased estimate of the parameter vectordescribing the object, and therefore is statistically optimal. This method is then successfullyapplied to finding objects imaged in thousands of complex real-world scenes. </abstract>
<note> The support of the Office of Naval Research under Contract N00014-95-1-0521 is gratefully acknowledged. Author's new address (starting September 1997): </note>
 <affiliation> Department of Computer Science, Boston College, </affiliation>
<address> Fulton Hall, Chestnut Hill, MA 02167. </address>
 <email> Email: betke@cs.bc.edu </email>
<note> N. C. Makris was with the Naval Research Laboratory, Washington, DC 20375. His new address is </note>
 <affiliation> Department of Ocean Engineering, Massachusetts Institute of Technology, </affiliation>
 <address> Cambridge, MA 02138. </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Augmenting Collective Adaptationwith Simple Process Agents </title>
<author> Thomas Haynes </author>
<affiliation> Department of Mathematical &amp; Computer Sciences </affiliation>
<address> 600 South College Ave. </address>
<affiliation> The University of Tulsa </affiliation>
<address> Tulsa, OK 74104-3189 </address>
<email> e-mail: haynes@euler.mcs.utulsa.edu </email>
<abstract> AbstractWe have integrated the distributed search of geneticprogramming based systems with collective memoryto form a collective adaptation search method. Such asystem significantly improves search as problem complexity is increased. However, there is still considerable scope for improvement. In collective adaptation, search agents gather knowledge of their environment and deposit it in a central information repository. Process agents are then able to manipulate thatfocused knowledge, exploiting the exploration of thesearch agents. We examine the utility of increasingthe capabilities of the centralized process agents. </abstract>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Parallel Algorithms </title>
<author> Guy E. Blelloch and Bruce M. Maggs </author>
<affiliation> School of Computer ScienceCarnegie Mellon University </affiliation>
<address> 5000 Forbes AvenuePittsburgh, PA 15213 </address>
<email> guyb@cs.cmu.edu, bmm@cs.cmu.edu </email>
<intro> Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> Trainable Cataloging for Digital Image Libraries with Applicationsto Volcano Detection </title>
<author> M.C. Burl yz , U.M. Fayyad , P. Perona , P. Smyth  </author>
<affiliation> California Institute of Technology Jet Propulsion Laboratory </affiliation>
<address> MS 116-81 | Pasadena, CA 91125 MS 525-3660 | Pasadena, CA 91109 </address>
<email> fburl,peronag@systems.caltech.edu ffayyad,pjsg@aig.jpl.nasa.gov </email>
<pubnum> Computation and Neural Systems Technical ReportCNS-TR-96-01 | </pubnum>
<date> October 2, 1996 </date>
<abstract> AbstractUsers of digital image libraries are often not interested in image data per se but in derivedproducts such as catalogs of objects of interest. Converting an image database into a usablecatalog is typically carried out manually at present. For many larger image databases thepurely manual approach is completely impractical. In this paper we describe the developmentof a trainable cataloging system: the user indicates the location of the objects of interest fora number of training images and the system learns to detect and catalog these objects in therest of the database. In particular we describe the application of this system to the catalogingof small volcanoes in radar images of Venus. The volcano problem is of interest because of thescale (30,000 images, order of 1 million detectable volcanoes), technical difficulty (the variabilityof the volcanoes in appearance) and the scientific importance of the problem. The problem ofuncertain or subjective ground truth is of fundamental importance in cataloging problems of thisnature and is discussed in some detail. Experimental results are presented which quantify andcompare the detection performance of the system relative to human detection performance. Thepaper concludes by discussing the limitations of the proposed system and the lessons learned ofgeneral relevance to the development of digital image libraries. </abstract>
<keyword> Keywords: digital image libraries, pattern recognition, science data analysis, volcanoes, Venus,SAR, detection, classification, learning, remote sensing </keyword>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<title> Perfect Simulation of some Point Processesfor the Impatient User </title>
<author> Elke Thonnes </author>
<affiliation> Department of Statistics, University of Warwick  </affiliation>
<date> February 9, 1998 </date>
<abstract> AbstractRecently Propp and Wilson [14] have proposed an algorithm, calledCoupling from the Past (CFTP), which allows not only an approximate but perfect (i.e. exact) simulation of the stationary distributionof certain finite state space Markov chains. Perfect Sampling usingCFTP has been successfully extended to the context of point processes, amongst other authors, by Haggstrom et al. [5]. In [5] Gibbssampling is applied to a bivariate point process, the penetrable spheresmixture model [19]. However, in general the running time of CFTPin terms of number of transitions is not independent of the state sampled. Thus an impatient user who aborts long runs may introduce asubtle bias, the user impatience bias. Fill [3] introduced an exact sampling algorithm for finite state space Markov chains which, in contrastto CFTP, is unbiased for user impatience. Fill's algorithm is a formof rejection sampling and similar to CFTP requires sufficient mono-tonicity properties of the transition kernel used. We show how Fill'sversion of rejection sampling can be extended to an infinite state spacecontext to produce an exact sample of the penetrable spheres mixtureprocess and related models. Following [5] we use Gibbs sampling andmake use of the partial order of the mixture model state space. Thus </abstract>
<note> Research supported by EPSRC earmarked studentship and University of Warwickgraduate award. Postal address: </note>
 <affiliation> Dept. of Statistics, University of Warwick, </affiliation>
 <address> Coventry,CV4 7AL, UK </address>
<page> +PAGE+ </page>
</NEW_HEADER>
<NEW_HEADER>
<note> 127 </note>
<title> Progress for Local Variables in UNITY </title>
<author> Rob Udink and Ted Herman and Joost Kok </author>
<affiliation> Department of Computer Science, Utrecht University, </affiliation>
<address> P.O. Box 80089, 3508 TB Utrecht, The Netherlands </address>
<email> e-mail: frob,ted,joostg@cs.ruu.nl </email>
<abstract> A new notion of refinement for UNITY programs with local variables is defined. Thisnotion is compositional in the following sense: programs can be refined in arbitrary contexts such that all unless and leadsto properties (i.e. temporal properties for both safetyand progress) of the composition are preserved. The refinement notion is based on preservation of a new kind of UNITY-like property that takes into account the locality ofvariables. We do a small case study about registers. </abstract>
<note> Keyword Codes: F.3.1 </note>
<keyword> Keywords: Specifying and Verifying and Reasoning about Programs </keyword>
<intro> 1. INTRODUCTION </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> On the Relation Between Unity Propertiesand Sequences of States </title>
<author> R.T. Udink  </author>
<affiliation> Utrecht University, Department of Computer Science, </affiliation>
<address> P.O. Box 80.089, 3508 TB Utrecht, the Netherlands </address>
<author> J.N. Kok </author>
<affiliation> Utrecht University, Department of Computer Science, </affiliation>
<address> P.O. Box 80.089, 3508 TB Utrecht, the Netherlands </address>
<abstract> ABSTRACT Stepwise refinement of programs has proven to be a suitablemethod for developing parallel and distributed programs. We examine and compare anumber of different notions of program refinement for Unity. Two of these notions arebased on execution sequences. Refinement corresponds to the reduction of the set of execution sequences, i.e. reducing the amount of nondeterminism. The other refinementnotions are based on Unity properties as introduced by Chandy and Misra. The Unity approach is to refine specifications. Although it has proven a suitable formalism for derivingalgorithms, it seems less suitable for handling implementation details. Following Sandersand Singh, we formalize program refinement in the Unity framework as the preservationof Unity properties. We show that Unity properties are not powerful enough to characterize execution sequences. As a consequence, the notion of property-preserving refinementdiffers from the notion of reducing the set of execution sequences. </abstract>
<keyword> Keywords Semantic models, Unity, program refinement. </keyword>
<note> CONTENTS0 Introduction </note>
</NEW_HEADER>
<NEW_HEADER>
<title> Adaptive Information Filtering using Evolutionary Computation </title>
<author> D.R. Tauritz &amp; J.N. Kok &amp; I.G. Sprinkhuizen-Kuyper </author>
<affiliation> Department of Computer Science, Leiden University </affiliation>
<address> P.O. Box 9512, 2300 RA Leiden, The Netherlands </address>
<intro> 1 Introduction </intro>
</NEW_HEADER>
<NEW_HEADER>
<title> SuperWeb: Towards a Global Web-Based Parallel Computing Infrastructure </title>
<author> Albert D. Alexandrov, Maximilian Ibel, Klaus E. Schauser, and Chris J. Scheiman </author>
<affiliation> Department of Computer ScienceUniversity of California, Santa Barbara </affiliation>
<address> Santa Barbara, CA 93106 </address>
<email> fberto,ibel,schauser,chrissg@cs.ucsb.edu </email>
<abstract> AbstractThe Internet, best known by most users as the WorldWide-Web, continues to expand at an amazing pace. Wepropose a new infrastructure to harness the combined resources, such as CPU cycles or disk storage, and make themavailable to everyone interested. This infrastructure has thepotential for solving parallel supercomputing applicationsinvolving thousands of cooperating components. Our approach is based on recent advances in Internet connectivityand the implementation of safe distributed computing embodied in languages such as Java.We developed a prototype of a global computing infrastructure, called SuperWeb, that consists of hosts, brokersand clients. Hosts register a fraction of their computing resources (CPU time, memory, bandwidth, disk space) withresource brokers. Client computations are then mapped bythe broker onto the registered resources. We examine an economic model for trading computing resources, and discussseveral technical challenges associated with such a globalcomputing environment. </abstract>
<keyword> Keywords: Global computing, Internet, Java, WorldWide-Web, massively parallel computing, secure computing,microeconomic model. </keyword>
<intro> 1 Introduction </intro>
</NEW_HEADER>
</HEADER>